{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CosmoTransitions (modernized)","text":"<p>A modern, test-driven update of CosmoTransitions for studying first-order phase transitions (FOPTs) and their gravitational-wave signatures \u2014 now in Python 3.13, with clearer APIs, numerical utilities, examples, and documentation.</p> <p>Original project by Carroll L. Wainwright (MIT). Modernization by Igor Almeida da Silva Gouv\u00eaa Stellet (advisor: Felipe Tovar Falciano).</p>"},{"location":"#quick-links","title":"Quick links","text":"<ul> <li>\ud83e\udded Roadmap &amp; Schedule \u2192 roadmap.md </li> <li>\ud83e\udde9 Architecture &amp; Module Flow \u2192 architecture.md</li> </ul>"},{"location":"#examples-core-modules-only","title":"Examples (Core modules only)","text":"<p>If you are only interested in learning how to use the main modules and obtain the results/graphs for the phase transition, here is the place. Below are links to explanations of only the most important aspects needed to use each main function and get the respective results/plots.</p> <p>The main explanation of the codes used and all images can be found in the example folder.</p>"},{"location":"#tunneling-1d","title":"Tunneling 1D","text":"<ul> <li>Single Field Instaton \u2192 example_single_field.md</li> </ul>"},{"location":"#index-of-all-functions","title":"Index of all functions","text":""},{"location":"#helper-functions","title":"Helper Functions","text":"<ul> <li>Miscellaneous Functions \u2192 miscellaneous_functions.md</li> <li>Numerical integration Functions \u2192 Numerical_integration.md</li> <li>Numerical Derivatives Functions \u2192 Numerical_derivatives.md</li> <li>Interpolation Functions \u2192 intepolation_functions.md</li> </ul>"},{"location":"#finite-t-functions","title":"Finite T Functions","text":"<ul> <li>Exact Thermal Integrals \u2192 Exact_Thermal_Integrals.md</li> <li>Spline Thermal Integrals \u2192  Spline_Thermal_Integrals.md</li> <li>Approx Thermal Integrals \u2192  Approx_Thermal_Integrals.md</li> <li>Short Hand for all Thermal Integrals \u2192 Short_Hand_Jb&amp;Jf.md</li> </ul>"},{"location":"#tunneling1d-functions","title":"Tunneling1D Functions","text":"<ul> <li>Single Field functions: modules/tunneling1D/single_field</li> <li>Tests of SF functions: modules/tunneling1D/tests_single_field</li> </ul>"},{"location":"#install-dev-quick-start","title":"Install (dev) &amp; Quick Start","text":"<p>Requires Python 3.11+ (targeting 3.13). We recommend a fresh virtualenv.</p> <pre><code>python -m pip install -U pip\npip install -e .[dev]   # editable install with dev deps (pytest, ruff, black)\n</code></pre>"},{"location":"architecture/","title":"Architecture &amp; Module Flow","text":"<p>This page summarizes how modules relate and call each other during typical workflows.</p> <p>See also: per-module pages under Docs \u2192 Modules.</p>"},{"location":"architecture/#flowchart-of-the-modules","title":"Flowchart of the modules","text":"<pre><code>graph TD\n    %% ========== MAIN MODULES ==========\n    subgraph \"MAIN MODULES\"\n        T1D[Tunneling1D&lt;br/&gt;Bounce solution in 1 field]\n        PD[pathDeformation&lt;br/&gt;Bounce solution in multiple fields]\n        TF[transitionFinder&lt;br/&gt;Locate Tn and phase structure]\n        GP[generic_potential&lt;br/&gt;Model definition and potential plotting]\n\n        T1D --&gt; PD\n        T1D --&gt; TF\n        T1D --&gt; GP\n        PD --&gt; TF\n        PD --&gt; GP\n        TF --&gt; GP\n    end\n\n    %% ========== AUXILIARY MODULES ==========\n    subgraph \"AUXILIARY MODULES\"\n        HF[helper_functions&lt;br/&gt;Utility functions]\n        FT[finiteT&lt;br/&gt;Finite-temperature corrections]\n        MFP[multi_field_plotting&lt;br/&gt;Visualization for 3+ fields]\n    end\n\n    %% ========== DEPENDENCIES ==========\n    AUX --&gt; MAIN\n\n    %% ========== STYLES ==========\n    style T1D fill:#357a38,color:white\n    style PD fill:#d32f2f,color:white\n    style TF fill:#357a38,color:white\n    style GP fill:#357a38,color:white\n    style HF fill:#1565c0,color:white\n    style FT fill:#1565c0,color:white\n    style MFP fill:#d32f2f,color:white\n\n    linkStyle 0 stroke:#1b5e20,stroke-width:2px\n    linkStyle 1 stroke:#1b5e20,stroke-width:2px\n    linkStyle 2 stroke:#1b5e20,stroke-width:2px\n    linkStyle 3 stroke:#1b5e20,stroke-width:2px\n    linkStyle 4 stroke:#1b5e20,stroke-width:2px\n    linkStyle 5 stroke:#1b5e20,stroke-width:2px\n    linkStyle 6 stroke:#0d47a1,stroke-width:3px</code></pre>"},{"location":"architecture/#main-modules","title":"\ud83d\udce6 Main Modules","text":"Module Description Methods &amp; Functionality Links Tunneling1D Computes bounce (instanton) solution for a single scalar field. Uses the overshoot/undershoot method to solve the Euclidean equation of motion and find the tunneling profile Module page pathDeformation Computes instantons for multiple scalar fields. First finds a 1D solution constrained to an initial path in field space. Then iteratively deforms this path until transverse forces vanish, yielding the correct multi-dimensional solution. None transitionFinder Computes the phase structure of the potential at finite temperature. Locates potential minima as a function of temperature, determines critical temperatures (degenerate vacua), and computes the nucleation temperature for phase transitions Module page generic_potential Abstract class that defines the physical model of interest. The user provides a subclass implementing the specific effective potential \\(V(\\phi, T)\\). Also provides methods to plot the potential and visualize its phase structure. Module page"},{"location":"architecture/#auxiliary-modules","title":"\ud83d\udd27 Auxiliary Modules","text":"Module Description Purpose Links helper_functions Numerical utilities (e.g., numerical integration, interpolation, numerical differentiation). Called by all core modules. Module page finiteT Finite-temperature effective-potential corrections (boson/fermion thermal pieces). Feeds generic_potential and transition_finder. Module page multi_field_plotting Visualization helpers for 3+ field landscapes and paths. Used mainly with pathDeformation and generic_potential. None"},{"location":"roadmap/","title":"\ud83d\udcc5 Roadmap &amp; Schedule","text":"<p>Approach: The project\u2019s timeline and flowchart are presented below. The main idea is to split this long task into four primary phases, each lasting up to ~2 weeks, while running consistency tests throughout development and after finishing each phase. Each phase follows the cycle: Modification \u2192 Testing \u2192 Fixes \u2192 Validation.</p> <ul> <li>See also: Architecture &amp; Module Flow</li> </ul>"},{"location":"roadmap/#phases-overview","title":"Phases (overview)","text":"<p>The first phase aims to update CosmoTransition's auxiliary modules, which are called by the main modules. The second phase and third phase, the codes that find the bounce solution and the thermodynamic parameters (two main modules). Finally, the fourth and final phase aims to modify the functions that create the generic potential and the plots generated given the initial parameters. Everything will be done for the 1D part for now; the 2D part will remain as before.</p> <p>Depending on the progress of the project, a fifth phase will be carried out to add new plots and graphs to the code, as well as update the part that calculates multiple fields.</p>"},{"location":"roadmap/#documentation-recommended-reading-pre-modifications","title":"\ud83d\udcd6 Documentation &amp; Recommended Reading (pre-modifications)","text":"<p>Before modifying any module, consult the official documentation and/or the original paper to understand the algorithms:</p> <ul> <li>Official Documentation:https://clwainwright.net/CosmoTransitions/index.html</li> <li>Original Paper (arXiv): arXiv:1109.4189</li> <li>Computer Physics Communications: 10.1016/j.cpc.2012.04.004</li> </ul>"},{"location":"roadmap/#project-timeline","title":"Project Timeline","text":"<pre><code>gantt\n    %%%%%%%%\n    title Development Timeline - CosmoTransitions\n    dateFormat  YYYY-MM-DD\n    axisFormat  %d/%m\n\n    section Phase 0: Planning\n    Flowchart and Timeline          :done, 2025-08-27, 7d\n    Methodology Definition          :done, 2025-09-05, 10d\n\n    section Phase 1: Auxiliar Functions Update\n    Modify helper_function.py       :done, 2025-09-08, 12d\n    Modify finiteT.py               :done, 2025-09-20, 12d\n\n    section Phase 1.5: Testing the Modifications of Auxiliar Functions\n    Testing all modifications       :done,2025-10-02, 4d\n    Fixes and Adjustments           :done,2025-10-02, 4d\n\n    section Phase 2: Tunneling 1D Module\n    Modify/tests Tunneling1D.py     :done,2025-10-07, 12d\n    Examples Tunneling1D.py         :active,2025-10-20, 3d\n\n    section Phase 3: Transtions Finder Module\n    Modify/tests transitionFinder.py :2025-10-24, 12d      \n    Examples transitionFinder        :2025-11-06, 3d\n\n    section Phase 4: Generic Potential Module\n    Modify/tests generic_potential.py  :2025-11-10, 12d\n    Examples generic_potential.py      :2025-11-25, 5d\n\n    section Phase 5: Extras (Optional)\n    Additional Plots                :2025-12-01, 10d\n    Multi-field Solution            :2025-12-10, 10d\n    Final Optimizations             :2025-12-10, 10d</code></pre>"},{"location":"roadmap/#milestones-checklist","title":"Milestones &amp; Checklist","text":"<ul> <li> Phase 0: Planning and first meeting </li> <li> Create dependency flowchart </li> <li> <p> Create refactoring schedule </p> </li> <li> <p> Phase 1: Auxiliary functions </p> </li> <li> Refactor <code>helper_functions.py</code></li> <li> <p> Refactor <code>finiteT.py</code></p> </li> <li> <p> Phase 1.5: Modification tests </p> </li> <li> Validate isolated functions with simple analytic examples  </li> <li> <p> exercise error paths and validations</p> </li> <li> <p> Phase 2: Tunneling 1D Core Module </p> </li> <li> Refactor <code>tunneling1D.py</code> </li> <li> <p>Examples modernized <code>tunneling1D.py</code> </p> </li> <li> <p> Phase 3: Transtions Finder Core Module </p> </li> <li>Refactor <code>transtionFinder.py</code> </li> <li> <p>Test modernized <code>transtionFinder.py</code></p> </li> <li> <p> Phase 4: Generic Potential Core Module  </p> </li> <li>Refactor <code>generic_potential.py</code> </li> <li>Test modernized <code>generic_potential.py</code></li> <li> <p>Run all old examples and validate cosistency between versions</p> </li> <li> <p> Phase 5 (optional): Extensions</p> </li> <li>Update plotting, add energy density and other figures useful for paper/thesis and other parameters</li> <li>New plot types (e.g., direct GW spectrum, GW energy density vs T, etc.) </li> <li>Modernize multi-field plotting codes <code>mult_field_plotting.py</code> and <code>path_deformation.py</code></li> </ul> <pre><code>graph TD\n    Start[Project Start] --&gt; Phase1[Phase 1: Auxiliar Functions]\n    Start --&gt; Phase2[Phase 2: Tunneling 1d]\n    Start --&gt; Phase3[Phase 3: Transition Finder]    \n    Start --&gt; Phase4[Phase 4: Generic Potential]\n\n    Phase1 --&gt; Test1[Consistency Tests]\n    Phase2 --&gt; Test2[Consistency Tests]\n    Phase3 --&gt; Test3[Consistency Tests]\n    Phase4 --&gt; Test4[Consistency Tests]\n\n    Test1 --&gt; Adjust1[Adjustments, Documentation &amp; Fixes]\n    Test2 --&gt; Adjust2[Adjustments, Documentation &amp; Fixes]\n    Test3 --&gt; Adjust3[Adjustments, Documentation &amp; Fixes]\n    Test4 --&gt; Adjust4[Adjustments, Documentation &amp; Fixes]\n\n    Adjust1 --&gt; FinalValidation[Final Validation]\n    Adjust2 --&gt; FinalValidation\n    Adjust3 --&gt; FinalValidation\n    Adjust4 --&gt; FinalValidation\n\n    FinalValidation --&gt; Decision{Satisfactory progress?}\n\n    Decision -- Yes --&gt; Phase5[Phase 5: New Plots and Figures, 3D+ &amp; More parameters]\n    Decision -- No --&gt; Review[Review and Optimizations]\n\n    Phase5 --&gt; ProjectEnd[Project Completed]\n    Review --&gt; ProjectEnd\n\n    style Start fill:#e1f5fe\n    style Phase1 fill:#e8f5e8\n    style Phase2 fill:#fff3e0\n    style Phase3 fill:#f3e5f5\n    style Phase4 fill:#ffebee\n    style Phase5 fill:#ffebee\n    style ProjectEnd fill:#c8e6c9</code></pre>"},{"location":"examples/example_tunneling1D/","title":"Tunneling 1D full example","text":"<p>from src.CosmoTransitions import SingleFieldInstanton</p>"},{"location":"examples/example_tunneling1D/#tunneling-1d-all-that-you-need-to-know","title":"Tunneling 1D - All that you need to know","text":"<p>This page aims to teach you only what's necessary for someone to use and call the functions that find the bounce solution in the single-field (1D) case.</p> <p>If you're not interested in seeing how each function works separately, with clear examples fore every sub-fuctions, this is the place. However, if you have questions about a specifc functions or want to inspect one in detail, I recommend checking the folder modules/tunneling1D.</p>"},{"location":"examples/example_tunneling1D/#single-field-instaton","title":"Single Field Instaton","text":""},{"location":"examples/example_tunneling1D/#introduction-and-minimal-params","title":"Introduction and minimal params","text":"<p>In this module we solve the differential equation </p> \\[\\frac{d^2 \\phi}{dr^2}+\\frac{\\alpha}{r}\\frac{d\\phi}{dr} = \\frac{dV}{d\\phi} \\] <p>This comes from writing the Laplacian in spherical coordinates and assuming spherical symmetry.  More importantly, we are already in Euclidean signature: after the Wick rotation in the time  coordinate  \\(t\\rightarrow -i\\tau\\), the field equation becomes:</p> \\[\\nabla^2 \\phi = V'(\\phi) \\quad (\\text{with }\\nabla \\text{ in 4D}); \\qquad \\rho\\equiv \\sqrt{\\tau^2+x^2+y^2+z^2}\\] <p>Semiclassical picture. This is a semiclassical approximation valid for tunneling. It governs the part where the field transition through classically forbidden paths. After tunneling, we switch back to real time and evolve classically. At (t=0) what we \"see\" in space is the radial bounce profile \\(\\phi_b(\\rho)\\) we just solved for, and them the Minkowski evolution follows:</p> \\[\\ddot{\\phi} -\\nabla^2 \\phi \\equiv\\Box \\phi = -V'(\\phi) \\qquad \\dot{\\phi}=0; \\quad \\phi(x,t=0)=\\phi_{bounce}(r)  \\] <p>This point is quite crucial; we can imagine a timeline from \\(\\tau \\rightarrow \\infty\\) until \\(\\tau=0\\)  that has the semiclassical description made here. </p> <p>Remembering that \\(\\tau \\gg\\) 1 are high temperatures (we are closer to the beginning of the universe)  and \\(\\tau\\) = 0 would be more towards the \"future\". At \\(\\tau=0\\) we return to real time and return to the classical description with the equation above</p> <p>About \\(\\alpha\\). The \u201cfriction\u201d coefficient is \\(\\alpha=d-1\\), where (d)  Thermal effects compactify Euclidean time with period \\(\\beta=1/T\\). At high temperature the time circle is small,  the solution is effectively 3D, and \\(\\alpha=2\\) O(3). In the zero-temperature limit the solution is O(4) and \\(\\alpha=3\\).  In practice, transitions are often high-(T), so we default to \\(\\alpha=2\\).</p> <p>With that minimal intro, here\u2019s what you must provide for the solver (three parameters):</p> <ul> <li>\\(\\phi_{\\text{true}}\\): field value at the true (stable) minimum</li> <li>\\(\\phi_{\\text{meta}}\\): field value at the false/metastable minimum</li> <li>\\(V(\\phi)\\): the scalar potential</li> </ul> <p>If you also have analytic \\(V'(\\phi)\\) or \\(V''(\\phi)\\), you can pass them too. Likewise, set \\(\\alpha\\) if you want something different from the default.</p> <pre><code>from CosmoTransitions.tunneling1D import SingleFieldInstanton\n\nphi_abs = 1.0\nphi_meta = 0.0\nalpha = 2 # O(3) \ndef V ... # Define your potential here\n\ninst = SingleFieldInstanton(\n        phi_absMin= phi_abs,\n        phi_metaMin=phi_meta,\n        V=V,\n        alpha=alpha,\n        phi_eps=1e-3)\n</code></pre> <p>How to run this example</p> <pre><code>python -m docs.examples.example_tunneling1D\n</code></pre> <p>In all examples the potentials chosen was:</p> \\[\\text{THIN}: \\frac{1}{4}\\phi ^4 - 0.49\\phi ^3 + 0.235 \\phi ^2 \\] \\[\\text{THICK}:  \\frac{1}{4}\\phi ^4 - \\frac{2}{5}\\phi^3 + \\frac{1}{10}\\phi^2 \\]"},{"location":"examples/example_tunneling1D/#about-the-boundary-conditions","title":"About the boundary conditions","text":"<p>What we want from a bounce is simple to state: the solution starts at rest at the center and, as \\(r\\to\\infty\\),  it asymptotically approaches the false vacuum and stops on it.</p> <p>Keep in mind the inverted-potential picture. After the Wick rotation \\(t\\to -i\\tau\\), the Euclidan equation reads \\(\\phi''+frac{\\alpha}{r}\\phi'=V'(\\phi)\\). </p> <p>This is equivalent to a particle moving in the inverted potential (-V) with a time dependent friction \\(\\alpha/r\\): the particle is realeased near the \"top\" corresponding to the true vacuum (a maximum of -V) and must roll, losing energy to friction, to the other \"top\" at the false vacuum, arriving there with zero velocity.  There is a unique \"just-right\" starting point \\(\\phi_0\\) for which this happens.</p> <p>Therefore, the boundary contions are:</p> <ul> <li>\\(\\phi'(0)=0\\)</li> <li>\\(\\lim_{r \\to \\infty} \\phi'(r) = 0\\)</li> <li>\\(\\lim_{r \\to \\infty} \\phi(r) = \\phi_{meta}\\)</li> </ul> <p>Notice none of these impose something on \\(\\phi_0\\) (\\(\\equiv \\phi(0)\\)).  The initial field value in Euclidean \"time\" can be anywhere between the true and false vacua, as long as  it is the one that makes the particle land and stop at \\(\\phi_{meta}\\) as \\(r\\to \\infty\\).</p> <p>And how do we ever reach the true vacuum? After tunneling, we go back to real time. At (t=0) the initial data are \\(\\dot\\phi(x,0)=0,\\quad \\phi(x,0)=\\phi_{\\text{bounce}}(r).\\) The bubble expands and the field relaxes toward \\(\\phi_{true}\\) (that's the phenomelogy we usually expects). It's always good to keep in mind that the classical model governs the dynamics after the transition,  and it will determine what will happen to the field after the transition.</p> <p>Why \\(\\phi'(0)=0\\) * Radial symmetry and Regularity at the origin forces \\(\\phi' _0=0\\) and more precisely, a smooth Taylor expansion \\(\\phi(r) = \\phi_0 +\\mathcal{O}(r^2)\\). * The friction term \\(\\alpha/r \\phi'\\) would be singular at r=0 unless \\(\\phi'\\) vanishes there * It is important to note that radial symmetry alone guarantees that the derivative will be 0 at r=0</p> <p>Real time echo of this: At t=0 we set \\(\\dot{\\phi} = 0\\). After that, \\(\\dot{\\phi}\\) generally becomes nonzero as the bubble grows. The configuration remains spherically symmetric (no angular dependence), but spatial gradients (\\partial_r \\phi) are zero only at the center (r=0), not everywhere. </p> <p>That's the whole boundary condition story resume. With this in place, we can move on to the key diagnostics the code computes</p>"},{"location":"examples/example_tunneling1D/#other-imporants-params-in-vphi-lot-2-of-the-code","title":"Other imporants params in \\(V(\\phi)\\) | Lot 2 of the code","text":"<p>There are two especially useful landmarks \\(V(\\phi)\\). </p> <p>1) The \"bar\" point \\(\\phi_{bar}\\)</p> <p>In the inverted potential (-V) picture, we can think that, for \\(\\phi_0\\) reach the false vacuum level, energy must be at least equal to \\(V(\\phi_{meta})\\). </p> <p>Therefore, the field value \\(\\phi_{bar}\\) is defined on the true-vaccum side of the barrier by:</p> \\[V(\\phi_{bar})= V(\\phi_{meta}) \\quad (\\text{with} \\phi_{bar} \\text{located beyond the barrier peak})\\] <p>This gives a clean search window for the correct initial value \\(\\phi_0\\):</p> \\[V(\\phi_{bar}) \\geq V(\\phi_0) \\geq V(\\phi_{True}) \\] <p>Intuitively: \\(\\phi_{bar}\\) marks the lowest energy starting point (on the true side) that still has the same Euclidean \"energy\" as the false vacuum; anything bellow it cannot reach \\(\\phi_{meta}\\) once friction is included.</p> <p>Small clarification on commom mental image: sometimes people describe \\(\\phi_{bar}\\) as a \"turning point\" if realeased from \\(\\phi_{meta}\\)  in the inverted potential. Strictly speaking, if you start exactly at \\(\\phi_{meta}\\) with  zero velocity you just sit there and just go for the other side by thermal fluctuations or quantum tunneling.</p> <p>2) The barrier top \\(\\phi_{top}\\) and the curvature scale \\(\\phi_{top}\\) is simply the maximum of \\(V(\\phi)\\) (the peak of the barrier). Near this point we  can approximate: </p> \\[ V(\\phi) \\approx V_{top}-\\frac{1}{2} k^2 (\\phi-\\phi_{top})^2\\] <p>This motivates a curvature length scale</p> \\[r_{scale} \\equiv \\frac{1}{\\sqrt{|V''(\\phi_{top})|}} \\] <p>It is a very handy measure of how \"step\" the barrier is and shows up in several numerical limits and diagnostics. In thin-wall situations the barrier is steep \\(\\Rightarrow |V''|\\) large \\(\\Rightarrow\\) \\(r_{scale}\\) small. In thick-wall cases the top is shallow \\(\\Rightarrow |V''|\\) small \\(\\Rightarrow\\) \\(r_{scale}\\) large; which matches each name.</p> <p>Practical note (used in the code): When the curvature at ther top is extremly small, dectyly using \\(V''(\\phi_{top})\\) can be noisy. In that case we fall back to more robust proxies, a cubic fit across the wall region.</p>"},{"location":"examples/example_tunneling1D/#visualizing-potential-and-its-inversion","title":"Visualizing potential and its inversion","text":"<p>Here is a plot for thin wall and thick wall with all the interesting points.</p> <p>Thin-wall \u2014 Potential with marks </p> <p>Thick-wall \u2014 Potential with marks </p> <p>And now the inverted plots (-V) with the founded \\(\\phi_0\\) solution:</p> <p>Thin-wall \u2014 \\(-V(\\phi)\\) </p> <p>Thick-wall \u2014 \\(-V(\\phi)\\) </p>"},{"location":"examples/example_tunneling1D/#near-solutions-and-initial-conditions-lot-3","title":"Near solutions and initial conditions| Lot 3","text":"<p>For any field value \\(\\phi(r)\\) taken near some arbitraty \\(\\phi_0\\), we can rewrite the ODE in a locally linearized form and solve it exactly. Around \\(\\phi_0\\)</p> \\[V'(\\phi)\\approx V'(\\phi_0)+V''(\\phi_0)(\\phi-\\phi_0)\\] <p>The solution reads  </p> \\[\\phi(r)-\\phi_0 = \\frac{V'(\\phi_0)}{V''(\\phi_0)}\\Bigg[\\Gamma(\\nu+1)\\Big(\\tfrac{t}{2}\\Big)^{-\\nu} I_\\nu(t)-1\\Bigg]\\] <p>where \\(I_\\nu\\) is the modified Bessel functions.</p> <p>The key point: This expressing is valid whenever the field is sitting near a point with \\(\\phi' \\approx 0\\). It doesn't matter if \\(r\\) is tiny or moderately large - if the derivative stays small, the approximation keeps tracking. In practice we use it around the chosen \\(\\phi_0\\); if you need it elsewhere, re-exapand around a new \\(\\phi_0\\).</p> <p>Because the equation has a formal singularaty at \\(r=0\\), we start the numerical integration a little away from the origin, at \\(r=r_{min}&gt;0\\). To do that cleanly we introduce a lower bound \\(\\Delta\\phi_{cutoff}\\) and choose \\(r_{min}\\) such that:</p> \\[|\\phi(r_{min})-\\phi_{true}| \\gtrsim \\Delta \\phi_{cutoff} \\] <p>evaluating \\(phi(r_{min})\\) with the exact small-r formula above.</p> <p>We also need an inatial guess for \\(\\phi_0\\). Internally this is handled, but it's worth sating explicitly:</p> \\[\\phi_0 = \\phi_{true} + \\Delta \\phi, qquad \\text{with} \\phi_0 \\in [\\phi_{true}, \\phi_{bar}\\] <p>The algorthm procceds as follows (conceptually):</p> <ol> <li>Pick a trial \\(\\phi_0\\) in [\\(\\phi_{true}, \\phi_{bar}\\)]</li> <li>Use the exact small-r solution to evaluate \\(\\phi(r)\\) at an initial \\(r_{min}\\)</li> <li>If \\(|\\phi(r_{min})-\\phi_{true}| &lt; \\Delta \\phi_{cutoff}\\) increase \\(r_{min}\\) (keeping the same \\(\\phi_0\\)) and check again.    Otherwise, start the full integration from that \\(r_{min}\\).</li> <li>If the boundary condition at infinity is not met (overshoot/undershoot), update \\(\\phi_0\\) and repeat</li> </ol> <p>Heuristic that i follow: choose \\(\\Delta \\phi_{cutoff}\\) as small as makes the code stable, so we don't sart too far from \\(\\phi_{true}\\). This matters even more in the thin-wall regime, where the correct \\(phi_0\\) typically sits very close to \\(\\phi_{true}\\)</p> <p>Note that if we choose a very high cutoff we may find a wrong solution that would still converge!</p> <p>Bellow are one example of a bad use of the \\(\\Delta \\phi_{cutoff}\\) in a thin wall case:</p> <p>Error case Thin-wall \u2014 \\(\\Delta \\phi_{cutoff} =0.15\\) </p> <p>So how do I know I've found the right one cutoff? I had the same question, but the key is to realize that if  your cutoff was too high, then your \\(\\phi\\) is below what it should be, and its derivative pulls it towards the correct value  (i.e., \\(\\phi'_0 \\neq 0\\)). A good practice is to check your graph, as in the one above,  to see if \\(\\phi_0\\) (pink dot) is increasing towards some value going towards r=0; this shouldn't happen, as we expect \\(\\phi'_0=0\\).</p> <p>In the case above: $\\phi'_0 = -1.05e-01 $</p> <p>The correct thing is that going to r=0 there is a plateau at \\phi_0 (not so much grow)</p> <p>In the end  are the correct solutions with \\(\\Delta \\phi_{cutoff}=0.01\\).</p> <p>Bellow are the plots for \\(\\phi\\) and \\(\\phi'\\) near \\(r=0\\)</p> <p>Thin-wall - \\(\\phi\\) near r=0 </p> <p>Thick-wall \u2014 \\(\\phi\\) near r=0 </p> <p>We can clearly see that both prevent the singularity of the friction term at the origin.</p> <p>Thin wall with \\(\\phi'\\) = 0 and thick with \\(\\phi' \\propto r\\), as we expected.</p>"},{"location":"examples/example_tunneling1D/#odeintegrate-saveprofile","title":"ODE/Integrate &amp; Saveprofile","text":"<p>Inside the ODE the state is package as \\((\\phi,y)\\) with</p> \\[\\phi'=y;\\quad  \\phi''=V'(\\phi)- \\alpha/r \\dot{\\phi}\\] <p>(Here primes mean derivatives with respect to the radial coordinate r. I stick to primes to avoid confusion with time-dots used later in real time evolution).</p> <p>Given the initial conditions and this ODE, we integrate with RKCK and look for a solution that satisfies</p> \\[|\\phi(\\infty)-\\phi_{metamin}|&lt; \\epsilon_{\\phi}; \\qquad |\\phi'(\\infty)| &lt; \\epsilon_{d\\phi} \\] <p>What <code>integrate</code> actually does is evolve from the chosen initial condition until one of the following stopping criteria triggers:</p> <ol> <li>Converged-- Both tolerances above are met. We return the arrays \\(r, \\phi(r)\\), and \\(\\phi'(r)\\)</li> <li>Undershoot-- The field strts turning back before reaching the false vacuum. In practice this show up as \\(\\phi'(r)\\) changing sign to positive whle \\(\\phi(r)&gt;\\phi_{meta}\\).  Physically: friction wins, not enough energy to climb all the way. We stop at the first turning point where \\(\\phi'(r)=0\\) and return \\(r,\\phi,\\phi'\\) there.</li> <li>Overshoot-- The trajectory crosses the false vacuum, i.e., \\(\\phi(r)-\\phi_{meta}&lt;0\\) within a step. Too much energy: it blows past the target. We stop at (or bracket to) the point where \\(\\phi=\\phi_{meta}\\)</li> </ol> <p>On undershoot/overshoot, the code adjusts the initial field value \\(\\phi_0\\) and repeats (classic shooting), until the exact solution is found.</p> <p>Once the correct initial condition is locked in, we run integrate-and-save to build the full bounce profile: we evaluate and store \\(\\phi(r)\\) on a user-controlled radius grid R. If the adaptive RKCK steps are coarser than the requested spacing, we fill in the missing samples by cubic interpolation between the integrator outputs (and, when available, we use the stored \\(\\phi'(r)\\) to do Hermit-quality interpolation). This produces a clean (\\(R\\), \\(\\phi(R),\\phi'(R)\\)) profile ready for diagnostics and plots.</p>"},{"location":"examples/example_tunneling1D/#find-profile","title":"Find profile","text":"<p>This is the most important part of the module\u2014the place where a few internally chosen parameters are worth knowing  (and sometimes tweaking).</p> <p>Minimum radius. The seach starts near the true vacuum at</p> \\[r_{\\min}=10^{-4} r_{\\text{scale}}\\] <p>Tolerances. <code>phi_tol</code> defaults to \\(10^{-4}\\).  From it  build the relative end point tolerances \\(\\varepsilon_\\phi\\) and \\(\\varepsilon_{\\phi'}\\) that the solution must satisfy at large r, as \\(\\phi\\) reachs the false vacuum.</p> <p>Cutoff. Used</p> \\[\\texttt{cutoff}=10^{-2}|\\phi_{\\text{meta}}-\\phi_{\\text{true}}|\\] <p>as the lower bound for the initial displacement needed to leave the immediate vicinity of  \\((\\phi_{\\text{true}})\\).</p> <p>How the initial condition is guessed</p> <p>Because \\(\\phi_0 \\equiv \\phi(0)\\) is not known a priori, the code parametrizes it  with a single shooting variable (x):</p> \\[\\phi_0(x)=\\phi_{\\text{true}}+e^{-x}\\bigl(\\phi_{\\text{meta}}-\\phi_{\\text{true}}\\bigr)\\] <ul> <li>Large (x)  \\(\\Rightarrow \\phi_0\\) close to the true vacuum.</li> <li>Small (x)  \\(\\Rightarrow \\phi_0\\) close to the false (meta) vacuum.</li> </ul> <p>The code starts from the conservative side: pick (x) such that  \\(\\phi_0=\\phi_{\\text{bar}}\\) (remember \\(\\phi_0\\ge \\phi_{\\text{bar}}\\)). Then:</p> <ol> <li>Try to find an admissible starting radius for this \\((\\phi_0)\\). Otherwise, if can\u2019t find any  , increase (x) (move \\(\\phi_0\\) a bit toward \\(\\phi_{\\text{true}}\\)) and try again.</li> <li>Integrate until we either converge or detect undershoot/overshoot (see below).</li> </ol> <p>What undershoot / overshoot mean here (and how x gets update)</p> <ul> <li> <p>Undershoot: friction wins and the field turns around before reaching \\(\\phi_{\\text{meta}}\\)   (\\(\\phi'(r)\\) flips to positive while \\(\\phi&gt;\\phi_{\\text{meta}}\\)).   \u2192 We started too close to \\(\\phi_{\\text{bar}}\\) (not enough energy).   \u2192 Set \\(x_{\\min}=x\\) and increase (x): \\(x\\leftarrow \\tfrac{1}{2}(x_{\\min}+x_{\\max})\\).</p> </li> <li> <p>Overshoot: the trajectory crosses \\(\\phi_{\\text{meta}}\\).   \u2192 We started too close to \\(\\phi_{\\text{true}}\\) (too much energy).   \u2192 Set \\(x_{\\max}=x\\) and decrease (x): \\(x\\leftarrow \\tfrac{1}{2}(x_{\\min}+x_{\\max})\\).</p> </li> </ul> <p>This bisection on (x) repeats until both end-point tolerances are satisfied.</p> <p>After the correct \\((\\phi_0)\\) is found</p> <p>Builds a radius grid</p> \\[R={r_0,\\dots,r_f}\\quad\\text{with}\\quad \\text{n_points}\\] <p>starting at the found \\(r_0\\) from the initial-condition logic and going out to \\(r_f\\).  Note that \\(r_0\\) can be well above zero (especially in thin wall): the field may  sit almost flat before it \u201cdecides\u201d to roll.</p> <p>For the interior \\(r\\) &lt; \\(r_0\\), The code fills the bubble by the exact small-(r) expansion  around \\(\\phi_0\\) (we effectively have \\(\\phi'\\approx 0\\) there), which gives a smooth and  physically correct core.</p> <p>Good practice. Always sanity-check that \\(\\phi'_0\\approx 0\\); if it\u2019s not,  you\u2019re likely starting a bit too far out or with an inconsistent \\(\\phi_0\\).</p> <p>Bellow are all the plots for thin and thick wall with the correct solution for this simple case.</p> <pre><code># To get the profile\ninst = SingleFieldInstanton(\n        phi_absMin= phi_abs,\n        phi_metaMin=phi_meta,\n        V=V,\n        alpha=alpha,\n        phi_eps=1e-3)\n\nprofile = inst.findProfile(\n        xguess=None, phitol=phitol,\n        thinCutoff=thinCutoff, npoints=npoints,\n        max_interior_pts=max_interior_pts,\n        _MAX_ITERS= _MAX_ITERS\n    )\nR= profile.R\nphi = profile.Phi\ndphi = profile.dPhi\n</code></pre> <p>Thin-wall - Path of \\(\\phi(r)\\) on \\(V(\\phi)\\) </p> <p>Thin-wall - Path of \\(\\phi(r)\\) on \\(V(\\phi)\\) </p> <p>Thin-wall - Bounce Solution (\\(\\phi_b(r)\\)) \\(\\phi(r)\\)x r </p> <p>Thick-wall - Bounce Solution (\\(\\phi_b(r)\\)) \\(\\phi(r)\\)x r </p> <p>Some plots to represent what we would see in 3D space,  at the moment after the bubble nucleation (t=0)</p> <p>Thin-wall - Cartesian slice </p> <p>Thick-wall - Cartesian slice </p> <p>Thin-wall - Surface 3D </p> <p>Thick-wall - Surface 3D </p>"},{"location":"examples/example_tunneling1D/#action-beta-and-terms-contributions","title":"Action, \\(\\beta\\) and terms contributions","text":"<p>Inside the class SingleFieldInstaton there is also a function to evaluate the action of the founded solution. </p> <p>The action (with the false-vacuum constant removed) is</p> \\[S = \\int_{r_0}^{\\infty}\\Big[\\tfrac12(\\partial_r\\phi)^2+\\big(V(\\phi)-V(\\phi_{\\rm meta})\\big)\\Big]  r^\\alpha dr\\Omega_\\alpha +\\] \\[+\\underbrace{ \\int_{0}^{r_0} \\big(V(\\phi(r_0)) - V(\\phi_{\\rm meta})\\big),d^dr }_{\\text{\u201cinterior bulk\u201d}}\\] <p>because thin-wall integrations start at \\((r=r_0&gt;0)\\). Regularity implies$ (\\phi'(r)\\sim\\mathcal{O}(r))$, so the gradient contribution from \\(([0,r_0])\\) is negligible, but the potential offset must be accounted for via the (d)-ball volume:</p> \\[{\\rm Vol}_d(r_0)=\\frac{\\pi^{d/2}}{\\Gamma(d/2+1)}r_0^d\\] <p>The function <code>inst.actionBreakdown(profile)</code> returns</p> <p>A named tuple with:</p> <ul> <li><code>S_total</code>: valued with <code>findAction(profile)</code>.</li> <li><code>S_kin</code>, <code>S_pot</code>: line integrals of the kinetic and potential pieces separately.</li> <li><code>S_interior</code>: the interior bulk correction.</li> <li>Copies of <code>r</code>, <code>phi</code>, <code>dphi</code>.</li> <li> <p><code>density</code>: a dict with arrays</p> </li> <li> <p><code>density[\"kin\"]</code> = \\(\\frac{1}{2}\\Phi'^2 r^\\alpha \\Omega_\\alpha\\),</p> </li> <li><code>density[\"pot\"]</code> = \\((V(\\Phi)-V_{\\rm meta}) r^\\alpha \\Omega_\\alpha\\)</li> <li><code>density[\"tot\"] = density[\"kin\"] + density[\"pot\"]</code>.</li> </ul> <p>From this we can see how the action density varies with r.</p> <p>The code also includes a function to calculate an approximate inverse  time scale \\((\\beta)\\). This function uses 1/rscale or thickness.</p> <p>To understand this further or see everything the code can do,  see the complete code in docs/examples/tunneling1D  or the full .md explanation of each function in docs/modules/tunneling1D/single_field</p> <p>Bellow are the plots made and the full diagnostics;</p> <p>Thin-wall -  ODE Terms contributions </p> <p>Thick-wall -  ODE Terms contributions </p> <p>Thin-wall -  Action </p> <p>Thick-wall - Action </p> <pre><code>Wall diagnostics:\n\n{\n  \"label\": \"thin-wall\",\n  \"phi_metaMin\": 0.0,\n  \"phi_absMin\": 1.0,\n  \"phi_bar\": 0.8371714313771578,\n  \"phi_top\": 0.4699999983395586,\n  \"V(phi_meta)\": 0.0,\n  \"V(phi_true)\": -0.0050000000000000044,\n  \"V(phi_top)\": 0.013237432499999993,\n  \"DeltaV_true_minus_meta\": -0.0050000000000000044,\n  \"r0\": 40.55284169790182,\n  \"phi0\": 0.9900000000000001,\n  \"dphi0\": -0.007033518046022252,\n  \"rscale_cubic\": 1.6677093050224265,\n  \"rscale_curv\": 2.003609750059915,\n  \"wall_r_hi\": 50.18104547208761,\n  \"wall_thickness\": 6.229542940963725,\n  \"S_total\": 1093.4288131878518,\n  \"S_kin\": 1638.3947831914747,\n  \"S_pot\": -544.9659700036232,\n  \"S_interior\": 0.0,\n  \"beta_rscale\": 0.5996248848575876,\n  \"beta_curvature\": 0.49909918859817576,\n  \"beta_wall\": 0.16052542048057503\n}\n\n{\n  \"label\": \"thick-wall\",\n  \"phi_metaMin\": 0.0,\n  \"phi_absMin\": 1.0,\n  \"phi_bar\": 0.31010205014581543,\n  \"phi_top\": 0.20000000196657425,\n  \"V(phi_meta)\": 0.0,\n  \"V(phi_true)\": -0.05000000000000002,\n  \"V(phi_top)\": 0.0011999999999999992,\n  \"DeltaV_true_minus_meta\": -0.05000000000000002,\n  \"r0\": 0.0002357022627131459,\n  \"phi0\": 0.7421401843117063,\n  \"dphi0\": -8.151238531343361e-06,\n  \"rscale_cubic\": 2.357022627131459,\n  \"rscale_curv\": 2.499999981574293,\n  \"wall_r_hi\": 7.990901987734343,\n  \"wall_thickness\": 7.990901987734343,\n  \"S_total\": 6.6298736618724545,\n  \"S_kin\": 9.943318384815374,\n  \"S_pot\": -3.3134447229429216,\n  \"S_interior\": 0.0,\n  \"beta_rscale\": 0.42426406454019444,\n  \"beta_curvature\": 0.4000000002104124,\n  \"beta_wall\": 0.1251423182933482\n}\n</code></pre>"},{"location":"examples/example_tunneling1D/#notes","title":"Notes","text":"<p>It's important to emphasize that within this example, you can apply your own potential and test it to obtain all these graphs.  Note that so far, there are no temperature corrections or anything like that; we're doing everything very simply.  The rest will be covered in the next modules.</p> <p>Go to: docs/examples/example_tunneling1D.py</p> <ol> <li>At the beginning of the code, define your potential.</li> </ol> <p><pre><code>def V_mine(phi: float) -&gt;float:\n    return 0.25 * phi ** 4 - 0.49 * phi ** 3 + 0.235 * phi ** 2\n</code></pre> 2. Go to the end of the code and uncomment the line with</p> <pre><code>run_all(case=\"mine\", xguess=None, phitol=1e-5,thinCutoff=0.01,\n             phi_abs= 1.0, phi_meta =0.0, save_dir=None)\n</code></pre> <p>Note that you need to know a priori what \\(\\phi_{true}\\) and  \\(\\phi_{meta}\\) are, and you may need to adjust some parameters depending  on the error encountered raised throughout the code.</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/","title":"Approx Thermal Integrals (Jb, Jf)","text":""},{"location":"modules/finiteT/Approx_Thermal_Integrals/#low-x-high-t-approximate-thermal-integrals","title":"Low-x (High-T) Approximate Thermal Integrals","text":"<p>This page documents the small (x) (high temperature) asymptotic expansions for the 1 loop thermal integrals:</p> \\[J_b(x)=\\int_0^\\infty dy y^2\\ln\\bigl(1-e^{-\\sqrt{y^2+x^2}}\\bigr)\\qquad J_f(x)=\\int_0^\\infty dy -y^2\\ln\\bigl(1+e^{-\\sqrt{y^2+x^2}}\\bigr)\\] <p>with (x = m/T). The functions below implement the low (x) series used ubiquitously in finite temperature QFT.</p> <p>Purpose (for both): provide fast, vectorized approximations valid for (\\(|x|\\ll 1\\)). They return types (scalar-in \u2192 scalar-out; array-in \u2192 array-out), using modern numerics and clear error handling.</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#signatures","title":"Signatures","text":"<pre><code>Jb_low(x: float | array_like, n: int = 20) -&gt; float | np.ndarray\nJf_low(x: float | array_like, n: int = 20) -&gt; float | np.ndarray\n</code></pre>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#formulas","title":"Formulas","text":"<p>For small (|x|), the bosonic and fermionic integrals admit the asymptotic series</p> \\[\\boxed{ \\begin{aligned} J_b(x) &amp;= -\\frac{\\pi^4}{45} +\\frac{\\pi^2}{12} x^2 -\\frac{\\pi}{6} x^3 -\\frac{1}{32} x^4\\Big(\\ln x^2 - C_b\\Big) +\\sum_{i=1}^{n} g^{(b)}*i x^{2i+4} \\\\ J_f(x) &amp;= -\\frac{7\\pi^4}{360} +\\frac{\\pi^2}{24}x^2 +\\frac{1}{32}x^4\\Big(\\ln x^2 - C_f\\Big) +\\sum_{i=1}^{n} g^{(f)}_i x^{2i+4} \\end{aligned}}\\] <p>where</p> \\[C_b = \\tfrac{3}{2}-2\\gamma_E + 2\\ln(4\\pi)\\qquad C_f = \\tfrac{3}{2}-2\\gamma_E + 2\\ln(\\pi) \\] <p>and (\\(\\gamma_E\\)) is the Euler Mascheroni constant. The tail coefficients (\\(g^{(b)}_i, g^{(f)}_i\\)) are precomputed from combinations of the Riemann zeta and Gamma functions (as in the literature), and we truncate the tail at order (n) (default (n=20), capped at 50).</p> <p>Implementation notes</p> <ul> <li>The (\\(x^4\\ln x^2\\)) piece has a removable singularity at (x=0). We evaluate it as exactly zero at (\\(x=0\\)) to avoid \\((0\\times(-\\infty))\\) numerics.</li> <li>The tail (\\(\\sum_{i=1}^{n}g_i x^{2i+4}\\)) is accumulated as (\\(x^4 \\sum_i g_i (x^2)^i\\)) for stability and performance.</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#parameters-returns-errors","title":"Parameters, Returns &amp; Errors","text":"<p>Parameters (both)</p> <ul> <li><code>x</code> (<code>float | array_like</code>): argument (x=m/T). Intended for the small (x) regime.</li> <li><code>n</code> (<code>int</code>, default <code>20</code>): number of tail terms to add. Clipped to the available (50) precomputed terms.</li> </ul> <p>Returns (both)</p> <ul> <li><code>float | np.ndarray</code>: \\((J_{b,f}(x))\\) with the chosen truncation; preserves scalar/array shape.</li> </ul> <p>Raises (both)</p> <ul> <li><code>ValueError</code> if <code>n &lt; 0</code>.</li> <li><code>TypeError</code> if <code>x</code> is complex. (Low (x) expansions are defined for real (x). For complex/imaginary mass, use the exact or spline implementations.)</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#when-to-use","title":"When to use","text":"<ul> <li>Use <code>Jb_low</code> / <code>Jf_low</code> for fast high-T evaluations with (\\(|x|\\ll 1\\)) when you don\u2019t need the full integral and want smooth dependence near the origin.</li> <li>Prefer the exact or spline versions outside the small (x) window or when high accuracy is required globally.</li> </ul> <p>Caveats (asymptotic series):</p> <ul> <li>Adding more terms (<code>n</code>) usually improves accuracy for sufficiently small (x), but for fixed (x) the series is asymptotic\u2014there is an optimal truncation beyond which errors grow.</li> <li>Not suitable for complex (x) (no physical meaning for mixed real+imag parts here; use exact/spline branches instead).</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#usage-hints","title":"Usage hints","text":"<pre><code># Small-x grid (e.g., up to x ~ 0.5)\nx = np.linspace(0.0, 0.5, 200)\n\n# Fast approximations\nJb_approx = Jb_low(x, n=20)\nJf_approx = Jf_low(x, n=20)\n\n# Cross-check near the origin (optional)\nJb0 = Jb_low(0.0)   # \u2248 -\u03c0^4/45\nJf0 = Jf_low(0.0)   # \u2248 -7\u03c0^4/360\n</code></pre> <p>For full validation plots and quantitative error checks against the exact integrals, see the test suite for this sub-module.</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#test-low-x-high-t","title":"Test - Low-x (High-T)","text":"<p>Comparison: exact vs. low-x series</p> <p>Setup: (\\(x \\in [0,,1.5]\\)). We intentionally go beyond the strictly small-(x) window to show where the series starts to degrade. Truncation length (n=20) (can be tuned).</p> <p>Note: If you change the grid one can see that for \\(x \\geq 3\\), \\(J_f\\) diverges quickly. The same thing happens for \\(x \\geq 5.5\\) in \\(J_b\\). </p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#plots","title":"Plots","text":"<ul> <li> <p>Boson: exact vs. low-x approximation   </p> </li> <li> <p>Fermion: exact vs. low-x approximation   </p> </li> <li> <p>Relative error (both species on one panel; log scale)   </p> </li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#expected-behavior","title":"Expected behavior","text":"<ul> <li>Near (\\(x\\approx 0\\)), the low (x) series is excellent for both (\\(J_b\\)) and (\\(J_f\\)).</li> <li>Accuracy gradually decreases as (x) grows; with \\((n\\approx 20)\\), the series is typically more reliable up to (\\(x\\sim 1.5{-}2\\)).</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#console-output","title":"Console output","text":"<pre><code>=== Test 1: LOW-x (high-T) comparison: exact vs low-x series ===\nBoson  (low-x)  n=20: max abs err=9.492e-10, max rel err=7.029e-10\nFermion(low-x)  n=20: max abs err=9.492e-10, max rel err=7.411e-10\n  threshold 1e-03: max x with rel err &lt; thr \u2192  J_b: 1.500,  J_f: 1.500\n  threshold 1e-04: max x with rel err &lt; thr \u2192  J_b: 1.500,  J_f: 1.500\nExpectation: The low-x series is excellent near x\u22480 and degrades gradually;\n             truncation at n\u224820 is typically sufficient up to x~1.5\u20132.\n</code></pre> <ul> <li>see tests/finiteT/Approx_Thermal_Integrals for more</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#high-x-low-t-approximate-thermal-integrals","title":"High-x (Low-T) Approximate Thermal Integrals","text":"<p>This page documents the large (x) (low temperature) asymptotic expansions of the 1 loop thermal integrals,</p> \\[J_b(x)=\\int_0^\\infty dy y^2\\ln \\bigl(1-e^{-\\sqrt{y^2+x^2}}\\bigr)\\qquad J_f(x)=\\int_0^\\infty dy -y^2\\ln \\bigl(1+e^{-\\sqrt{y^2+x^2}}\\bigr)\\] <p>with (x=m/T). For (\\(x\\gg 1\\)), both integrals admit rapidly convergent series in terms of the modified Bessel functions (\\(K_\\nu\\)).</p> <p>Purpose (for all functions in this block): provide fast, vectorized, and numerically stable high (x) approximations (and up to 3 derivatives) using sums of (\\(K_\\nu\\)).</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#signatures_1","title":"Signatures","text":"<pre><code># Term (single-k) building blocks\nx2K2(k: int, x: float | array_like)  -&gt; float | np.ndarray\ndx2K2(k: int, x: float | array_like) -&gt; float | np.ndarray\nd2x2K2(k: int, x: float | array_like)-&gt; float | np.ndarray\nd3x2K2(k: int, x: float | array_like)-&gt; float | np.ndarray\n\n# High-x sums (public)\nJb_high(x: float | array_like, deriv: int = 0, n: int = 8) -&gt; float | np.ndarray\nJf_high(x: float | array_like, deriv: int = 0, n: int = 8) -&gt; float | np.ndarray\n</code></pre>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#formulation","title":"Formulation","text":"<p>The expansions are built from the \u201csingle (k)\u201d terms</p> \\[T_k(x)\\equiv -\\frac{x^2}{k^2}K_2\\big(k|x|\\big)\\] <p>whose derivatives w.r.t. (x) (accounting for the even/odd symmetry through (|x|)) are:</p> <ul> <li>0th: \\((T_k(x)= -\\dfrac{x^2}{k^2}K_2\\big(k|x|\\big))\\).</li> <li>1st: \\((\\dfrac{dT_k}{dx} = \\dfrac{x|x|}{k}K_1\\big(k|x|\\big))\\) (odd, vanishes at (x=0)).</li> <li>2nd: \\((\\dfrac{d^2T_k}{dx^2} = |x|\\left(\\dfrac{K_1(k|x|)}{k}-|x|K_0(k|x|)\\right))\\) (even).</li> <li>3rd: \\((\\dfrac{d^3T_k}{dx^3} = x\\left(|x|k K_1(k|x|)-3K_0(k|x|)\\right))\\) (odd).</li> </ul> <p>Then:</p> \\[\\boxed{J_b^{\\text{high}}(x) \\approx \\sum_{k=1}^{n} \\frac{d^{\\text{deriv}}}{dx^{\\text{deriv}}}T_k(x)}\\] \\[\\boxed{J_f^{\\text{high}}(x) \\approx \\sum_{k=1}^{n} (-1)^{k-1}\\frac{d^{\\text{deriv}}}{dx^{\\text{deriv}}}T_k(x)} \\] <p>The alternating sign for (\\(J_f\\)) reflects Fermi\u2013Dirac statistics. Each term decays (\\(\\sim e^{-k|x|}\\)), so only a few terms are needed for (\\(x\\gtrsim\\mathcal{O}(1)\\)).</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#small-x-limits-for-single-k-terms","title":"Small-(x) limits for single-(k) terms","text":"<p>Used to avoid numerical issues and ensure smoothness at (x=0):</p> \\[\\lim_{x\\to 0} T_k(x) = -\\frac{2}{k^4}\\qquad \\lim_{x\\to 0} \\frac{dT_k}{dx} = 0\\qquad \\lim_{x\\to 0} \\frac{d^2T_k}{dx^2} = \\frac{1}{k^2}\\qquad \\lim_{x\\to 0} \\frac{d^3T_k}{dx^3} = 0\\]"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#parameters-returns-errors_1","title":"Parameters, Returns &amp; Errors","text":"<p>Parameters (all):</p> <ul> <li><code>x</code> (<code>float | array_like</code>, real): argument (x=m/T). These high-(x) series target real (x).</li> <li><code>deriv</code> (<code>int</code>, default <code>0</code> for <code>J*_high</code>): order of derivative to return (<code>0</code>, <code>1</code>, <code>2</code>, <code>3</code>).</li> <li><code>n</code> (<code>int</code>, default <code>8</code> for <code>J*_high</code>): number of exponential terms in the truncated sum; must be \u2265 1.</li> </ul> <p>Returns (all):</p> <ul> <li><code>float | np.ndarray</code>: the requested approximation, preserving scalar/array shape.</li> </ul> <p>Raises (all):</p> <ul> <li><code>TypeError</code> if <code>x</code> is complex (no physical meaning for mixed real+imag here; use exact/spline branches for complex analyses).</li> <li><code>ValueError</code> if <code>deriv \u2209 {0,1,2,3}</code> or if <code>n &lt; 1</code>.</li> <li><code>ValueError</code> if a term helper is called with <code>k \u2264 0</code> (internal guard).</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#when-to-use_1","title":"When to use","text":"<ul> <li>Use <code>Jb_high</code> / <code>Jf_high</code> (and derivatives) when (x) is moderately to very large (e.g. (\\(x \\gtrsim 2\\))), where the series converges exponentially fast.</li> <li> <p>For small or intermediate (x), prefer:</p> </li> <li> <p><code>Jb_low</code> / <code>Jf_low</code> (low (x) series, high T),</p> </li> <li><code>Jb_exact</code> / <code>Jf_exact</code> (direct quadrature),</li> <li>or <code>Jb_spline</code> / <code>Jf_spline</code> (global interpolation).</li> <li>Complex (x) has no direct physical interpretation here and is not supported by the high (x) series.</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#usage-hints_1","title":"Usage hints","text":"<pre><code># Example: values (no derivatives), n=8 terms\nx = np.linspace(2.0, 8.0, 60)\nJb = Jb_high(x, deriv=0, n=8)\nJf = Jf_high(x, deriv=0, n=8)\n\n# First derivatives\ndJb = Jb_high(x, deriv=1, n=8)\ndJf = Jf_high(x, deriv=1, n=8)\n\n# Scalar input \u2192 scalar output\nval_b = Jb_high(5.0)        # float\nval_f = Jf_high(5.0, 2, 10) # d\u00b2/dx\u00b2 with 10 terms\n</code></pre> <p>Convergence tip: increase <code>n</code> until your observable stops changing at the precision you need. Because terms scale as (\\(e^{-k|x|}\\)), a modest <code>n</code> (6\u201312) is usually enough for (\\(x \\gtrsim 2\\)).</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#numericalimplementation-notes","title":"Numerical/Implementation Notes","text":"<ul> <li>We evaluate Bessel functions with SciPy (<code>scipy.special.kv</code>), always using (k|x|) in the argument to maintain the correct even/odd symmetry of derivatives.</li> <li>At <code>x == 0</code>, we insert the analytic limits listed above to avoid underflow/overflow and ensure smoothness.</li> <li>Functions are fully vectorized (array-in \u2192 array-out) while preserving scalar behavior (scalar-in \u2192 scalar-out), consistent with the legacy API.</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#high-x-low-t-test","title":"High-x (Low-T) - Test","text":"<p>comparison: exact vs. high x series</p> <p>Setup: (\\(x \\in [2,,10]\\)). We compare the exact integrals against the high (x) sums with (\\(n\\in{4,8,12}\\)) terms to illustrate exponential convergence.</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#plots_1","title":"Plots","text":"<ul> <li> <p>Boson: (\\(|J_b|\\)) semilog \u2014 exact vs. high-(x) (n=4,8,12)   </p> </li> <li> <p>Fermion: (\\(|J_f|\\)) semilog \u2014 exact vs. high-(x) (n=4,8,12)   </p> </li> <li> <p>Boson: relative error vs. (x) (n=4,8,12)   </p> </li> <li> <p>Fermion: relative error vs. (x) (n=4,8,12)   </p> </li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#expected-behavior_1","title":"Expected behavior","text":"<ul> <li>Both (\\(|J_b|\\)) and (\\(|J_f|\\)) decay roughly (\\(\\sim e^{-x}\\)); the high-(x) sums track the exact curves closely on semilog axes.</li> <li>Relative error drops rapidly with increasing (n) and (x); \\((n\\approx 8{-}12)\\) is usually very accurate for (\\(x\\gtrsim 2\\)).</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#console-output_1","title":"Console output","text":"<pre><code>=== Test 2: HIGH-x (low-T) comparison: exact vs high-x series ===\n\nHigh-x error summary (boson):\n  n= 4: max rel err=1.619e-04, median rel err=3.945e-12\n  n= 8: max rel err=6.351e-07, median rel err=3.778e-16\n  n=12: max rel err=4.527e-09, median rel err=2.949e-16\n\nHigh-x error summary (fermion):\n  n= 4: max rel err=1.113e-04, median rel err=3.929e-12\n  n= 8: max rel err=3.878e-07, median rel err=3.485e-16\n  n=12: max rel err=2.618e-09, median rel err=2.686e-16\n\nExpectation: High-x sums converge exponentially fast with n and x;\n             even n\u22488\u201312 is typically very accurate for x\u22732.\n\n---------- END OF TESTS: Approx Thermal Integrals ----------\n</code></pre> <ul> <li>see tests/finiteT/Approx_Thermal_Integrals for more</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/","title":"Exact Thermal Integrals (Jb, Jf)","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_asarray","title":"<code>_asarray</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature","title":"Signature","text":"<pre><code>_asarray(x: ArrayLike) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose","title":"Purpose","text":"<p>Convert input to a NumPy array without copying when possible (thin wrapper around <code>np.asarray</code>). Normalizes heterogeneous inputs (lists, tuples, scalars) into an <code>ndarray</code> for downstream vectorized code.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>x</code> (<code>array_like</code>): Any object that can be interpreted as an array (e.g., list, tuple, scalar, or <code>ndarray</code>).</li> </ul> <p>Returns</p> <ul> <li><code>np.ndarray</code>: A NumPy view of <code>x</code> if <code>x</code> is already an <code>ndarray</code>; otherwise a newly allocated array.</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Propagates exceptions from <code>np.asarray</code> if <code>x</code> cannot be interpreted as an array.</li> </ul> <p>Notes</p> <ul> <li>Internal helper only, used by other functions</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_is_scalar","title":"<code>_is_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_1","title":"Signature","text":"<pre><code>_is_scalar(x: ArrayLike) -&gt; bool\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_1","title":"Purpose","text":"<p>Check whether <code>x</code> is a scalar (Python/NumPy numeric scalar or a 0-D <code>ndarray</code>). Useful to preserve the contract \u201cscalar-in \u2192 scalar-out\u201d from legacy.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_1","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>x</code> (<code>array_like</code>): Object to inspect.</li> </ul> <p>Returns</p> <ul> <li><code>bool</code>: <code>True</code> if <code>x</code> is scalar (including 0-D arrays), otherwise <code>False</code>.</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Never raises by design; if <code>np.ndim(x)</code> errors for exotic objects, the function safely returns <code>False</code>.</li> </ul> <p>Notes</p> <ul> <li>Internal helper only, used by other functions</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_apply_elementwise","title":"<code>_apply_elementwise</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_2","title":"Signature","text":"<pre><code>_apply_elementwise(f: Callable[[Number], Number],x: ArrayLike,*,dtype: np.dtype = np.float64,) -&gt; Union[Number, np.ndarray]\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_2","title":"Purpose","text":"<p>Apply a scalar function <code>f</code> to <code>x</code> (scalar or array) element wise, preserving scalar-in \u2192 scalar-out like legacy version. Mirrors the legacy behavior: any element that causes an exception during evaluation is mapped to <code>NaN</code> (instead of raising). Supports real or complex outputs via <code>dtype</code>.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_2","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>f</code> (<code>callable</code>): Function of a single numeric argument returning a numeric value.</li> <li><code>x</code> (<code>array_like</code>): Input value(s); scalar or array-like of any shape.</li> <li><code>dtype</code> (<code>np.dtype</code>, optional): Output dtype when <code>x</code> is array-like (use <code>np.complex128</code> for complex results). Default <code>np.float64</code>.</li> </ul> <p>Returns</p> <ul> <li> <p><code>number | np.ndarray</code>:</p> </li> <li> <p>If <code>x</code> is scalar: the scalar result <code>f(x)</code> (or <code>NaN</code>/<code>NaN+0j</code> on failure).</p> </li> <li>If <code>x</code> is array-like: an array with the same shape as <code>x</code>, containing element-wise results (or <code>NaN</code> where evaluation fails).</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Designed not to raise for per-element failures (they become <code>NaN</code>).</li> <li>May propagate errors only if <code>dtype</code> is invalid or memory allocation fails.</li> </ul> <p>Notes</p> <ul> <li>Preserves shape for array inputs and scalar semantics for scalar inputs.</li> <li>For complex outputs, pass <code>dtype=np.complex128</code> to avoid down-casting.</li> <li>Internal helper; used by other functions</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_jf_exact_scalar","title":"<code>_Jf_exact_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_3","title":"Signature","text":"<pre><code>_Jf_exact_scalar(x: Number) -&gt; Number\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_3","title":"Purpose","text":"<p>Evaluate the exact one-loop fermionic thermal integral (\\(J_f(x)\\)) for a scalar input (x) (real or complex),</p> \\[J_f(x) = \\int_{0}^{\\infty}  dy \\big(-y^2\\big)\\ln\\Big(1 + e^{-\\sqrt{y^2+x^2}}\\Big)\\] <p>where (\\(x \\equiv m/T\\)) and (\\(E=\\sqrt{y^2+x^2}\\)) is the dimensionless energy. This scalar kernel is used internally by the vectorized public wrapper <code>Jf_exact</code>.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#where-the-formula-comes-from-qft-background","title":"Where the formula comes from (QFT background)","text":"<p>At one loop in finite-temperature field theory, the thermal correction for fermionic modes is proportional to \\((\\int d^3 p \\ln \\big (1+e^{-E_p/T}\\big))\\). After factoring constants and using spherical coordinates (\\(p/T \\to y\\)), the angular integration yields (\\(4\\pi\\)), and the radial part becomes exactly the integral above with the weight (\\(y^2\\)).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#real-argument-path-direct-integral","title":"Real-argument path (direct integral)","text":"<p>For real (x), the integrand is real and we integrate directly:</p> \\[J_f(x)=\\int_0^\\infty -y^2\\ln\\big(1+e^{-E}\\big)dy \\qquad E=\\sqrt{y^2+x^2}\\] <p>We use the numerically stable identity \\((ln(1+e^{-E})=\\mathrm{log1p} (e^{-E}))\\).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#pore-complex-argument-path-domain-split","title":"Pore Complex-argument path (domain split)","text":"<p>If (x) carries an imaginary part only, then for (\\(0\\le y \\le |x|\\)) the principal branch energy becomes purely imaginary:</p> <p>(E= iz) with \\((z=\\sqrt{|x|^2-y^2})\\). In this regime,</p> \\[1+e^{-E} = 1+e^{-i z} = 2e^{-i z/2}\\cos(z/2)\\quad\\Rightarrow\\quad \\big|1+e^{-E}\\big| = 2|\\cos(z/2)|.\\] <p>Therefore, we split the integral at (\\(a_x=|x|\\)) and evaluate</p> \\[\\boxed{ \\begin{aligned} J_f(x)=\\int_0^{a_x}-y^2\\ln\\Big(2\\big|\\cos\\big(\\tfrac{\\sqrt{a_x^2-y^2}}{2}\\big)\\big|\\Big)dy \\quad +\\int_{a_x}^{\\infty}-y^2,\\ln\\Big(1+e^{-\\sqrt{y^2+x^2}}\\Big)dy \\end{aligned}}\\] <p>so that both pieces are real valued integrands, suitable for high accuracy quadrature.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_3","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>x</code> (<code>Number</code>): Scalar input, real or complex.</li> </ul> <p>Returns</p> <ul> <li><code>Number</code>: The value of \\((J_f(x))\\). For real <code>x</code>, the result is real. For complex <code>x</code>, the value is computed via real integrands on both pieces and is real as well (principal-branch prescription).</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Assumes the principal square root branch. Numerical quadrature tolerances are set to <code>epsabs=1e-10</code>, <code>epsrel=1e-8</code>, <code>limit=200</code>.</li> </ul> <p>Notes</p> <ul> <li>This is an internal scalar kernel. Use the public <code>Jf_exact</code> for array inputs (vectorized and with dtype control).</li> <li>The use of <code>log1p</code> improves robustness near (\\(E\\approx 0\\)).</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_jb_exact_scalar","title":"<code>_Jb_exact_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_4","title":"Signature","text":"<pre><code>_Jb_exact_scalar(x: Number) -&gt; Number\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_4","title":"Purpose","text":"<p>Evaluate the exact one-loop bosonic thermal integral \\((J_b(x))\\) for a scalar input (x) (real or complex),</p> \\[J_b(x) = \\int_{0}^{\\infty} dy y^2\\ln\\Big(1 - e^{-\\sqrt{y^2+x^2}}\\Big)\\] <p>where (\\(x=m/T\\)) and (\\(E=\\sqrt{y^2+x^2}\\)).</p> <p>This scalar kernel is used internally by the vectorized public wrapper <code>Jb_exact</code>.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#where-the-formula-comes-from-qft-background_1","title":"Where the formula comes from (QFT background)","text":"<p>For bosonic modes, the finite (T) one-loop contribution is proportional to \\((\\int d^3p \\ln(1-e^{-E_p/T}))\\). After the angular integral and rescaling (\\(p/T\\to y\\)), we obtain the radial integral above with weight (\\(y^2\\)).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#real-argument-path-direct-integral_1","title":"Real-argument path (direct integral)","text":"<p>For real (x),</p> \\[J_b(x)=\\int_0^\\infty y^2\\ln\\big(1-e^{-E}\\big)dy\\qquad E=\\sqrt{y^2+x^2}\\] <p>We employ the stable identity \\((\\ln(1-e^{-E})=\\mathrm{log1p}(-e^{-E}))\\).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#pure-complex-argument-path-domain-split","title":"Pure Complex-argument path (domain split)","text":"<p>If (x) has an imaginary component, then for (\\(0\\le y \\le |x|\\)), (E=iz) with (\\(z=\\sqrt{|x|^2-y^2}\\)) and</p> \\[1-e^{-E} = 1-e^{-i z} = 2e^{-i z/2}i\\sin(z/2)\\quad\\Rightarrow\\quad  \\big|1-e^{-E}\\big| = 2|\\sin(z/2)|\\] <p>Thus, we split at (\\(a_x=|x|\\)) and evaluate</p> \\[\\boxed{ \\begin{aligned} J_b(x) &amp;=\\int_0^{a_x}y^2\\ln\\Big(2\\big|\\sin\\big(\\tfrac{\\sqrt{a_x^2-y^2}}{2}\\big)\\big|\\Big)dy\\ \\quad +\\int_{a_x}^{\\infty}y^2\\ln\\Big(1-e^{-\\sqrt{y^2+x^2}}\\Big)dy \\end{aligned}}\\] <p>which again yields real integrands in both intervals.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_4","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>x</code> (<code>Number</code>): Scalar (real or complex).</li> </ul> <p>Returns</p> <ul> <li><code>Number</code>: The value of ($J_b(x) $). For real <code>x</code> the result is real; with complex <code>x</code>, the split formulas ensure a real valued integral (principal branch choice).</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Principal square-root branch. Quadrature settings: <code>epsabs=1e-10</code>, <code>epsrel=1e-8</code>, <code>limit=200</code>.</li> </ul> <p>Notes</p> <ul> <li>Internal scalar kernel; the vectorized public API is <code>Jb_exact</code>.</li> <li><code>log1p(-exp(-E))</code> mitigates loss of significance near (\\(E\\approx 0\\)) for bosons.</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_jf_exact2_scalar","title":"<code>_Jf_exact2_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_5","title":"Signature","text":"<pre><code>_Jf_exact2_scalar(theta: Number) -&gt; float\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_5","title":"Purpose","text":"<p>Evaluate the exact one-loop fermionic thermal integral (J_f) as a function of the real scalar (\\(\\theta \\equiv x^2 = (m/T)^2\\)) equivalent to the functions above:</p> \\[J_f(\\theta) = \\int_{0}^{\\infty} dy \\big(-y^2\\big)\\ln\\Big(1 + e^{-\\sqrt{y^2+\\theta}}\\Big) \\] <p>This is the scalar kernel used internally by the vectorized public wrapper <code>Jf_exact2(theta)</code>.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#why-a-based-api-and-why-keep-it-alongside-the-x-based-one","title":"Why a \u03b8-based API (and why keep it alongside the x based one)?","text":"<ul> <li>Physics-first variable. In finite-T QFT the natural scalar entering the thermal integrals is (\\(\\theta=m^2/T^2\\)) (a real quantity that may be negative in symmetry-broken/tachyonic regions).</li> <li>Numerical stability. With (\\(\\theta\\in\\mathbb{R}\\)) the integrand is always chosen real-valued, even for (\\(\\theta&lt;0\\)) (see splitting below). Quadrature is typically faster and more robust.</li> <li>Interpolation/caching. Tabulating in (\\(\\theta\\)) is convenient for splines (next block) and reuse across scans.</li> <li>Compatibility. Remains legacy code that supplies (\\(x=m/T\\)) directly. Both compute the same physics when (x) is real or purely imaginary ((\\(\\theta=x^2\\)) real).</li> </ul> <p>Implementation detail: this function takes the real part of <code>theta</code> internally (<code>th = float(np.real(theta))</code>) to enforce (\\(\\theta\\in\\mathbb{R}\\)) as used in physics.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#positive-branch-thetage-0","title":"Positive-\u03b8 branch \\((\\theta\\ge 0)\\)","text":"\\[J_f(\\theta)=\\int_0^\\infty -y^2\\ln\\big(1+e^{-\\sqrt{y^2+\\theta}}\\big)dy\\] <p>computed directly with the numerically stable identity \\((\\ln(1+e^{-E})=\\mathrm{log1p}(e^{-E}))\\).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#negative-branch-theta0-domain-split-with-real-integrands","title":"Negative-\u03b8 branch \\((\\theta&lt;0)\\) \u2014 domain split with real integrands","text":"<p>Write \\((\\theta=-\\mu^2) ((\\mu&gt;0))\\). Then</p> \\[E=\\sqrt{y^2+\\theta}=\\sqrt{y^2-\\mu^2}= \\begin{cases} i\\sqrt{\\mu^2-y^2}\\equiv i z &amp; 0\\le y&lt;\\mu  \\sqrt{y^2-\\mu^2}\\in\\mathbb{R}*+  &amp; y\\ge \\mu. \\end{cases}\\] <p>For (E=iz), (\\(1+e^{-E}=2e^{-iz/2}\\cos(z/2)\\)) and (\\(\\big|1+e^{-E}\\big|=2|\\cos(z/2)|\\)). Thus we split:</p> \\[\\boxed{ \\begin{aligned} J_f(\\theta) &amp;=\\int_{0}^{\\mu}-y^2\\ln\\Big(2\\big|\\cos!\\big(\\tfrac{\\sqrt{\\mu^2-y^2}}{2}\\big)\\big|\\Big)dy\\ \\quad+\\int_{\\mu}^{\\infty}-y^2\\ln\\Big(1+e^{-\\sqrt{y^2-\\mu^2}}\\Big)dy \\end{aligned}}\\] <p>Both pieces are real, ensuring stable high-accuracy quadrature.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_5","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>theta</code> (<code>Number</code>): Scalar; only its real part is used internally.</li> </ul> <p>Returns</p> <ul> <li><code>float</code>: \\((J_f(\\theta))\\) as a real number.</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Principal square-root branch. Quadrature tolerances are <code>epsabs=1e-10</code>, <code>epsrel=1e-8</code>, <code>limit=200</code>.</li> </ul> <p>Notes</p> <ul> <li>Prefer the \u03b8 API in new code (it is what the spline based approximations will use).</li> <li>For (x) real or (\\(x=i\\mu\\)) (pure imaginary), <code>_Jf_exact_scalar(x)</code> and <code>_Jf_exact2_scalar(\\theta=x^2)</code> coincide.</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_jb_exact2_scalar","title":"<code>_Jb_exact2_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_6","title":"Signature","text":"<pre><code>_Jb_exact2_scalar(theta: Number) -&gt; float\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_6","title":"Purpose","text":"<p>Evaluate the exact one-loop bosonic thermal integral (\\(J_b\\)) as a function of the real scalar (\\(\\theta \\equiv x^2 = (m/T)^2\\)):</p> \\[J_b(\\theta) = \\int_{0}^{\\infty} dy y^2\\ln\\Big(1 - e^{-\\sqrt{y^2+\\theta}}\\Big)\\] <p>This is the scalar kernel used internally by the vectorized public wrapper <code>Jb_exact2(theta)</code>.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#why-a-based-api-and-why-keep-it-alongside-the-x-based-one_1","title":"Why a \u03b8 based API (and why keep it alongside the x-based one)?","text":"<p>Same rationale as fermions:</p> <ul> <li>(\\(\\theta=m^2/T^2\\)) is the natural real control variable (possibly negative).</li> <li>Splitting at (\\(\\theta&lt;0\\)) yields real integrands everywhere \u21d2 more stable and faster quadrature.</li> <li>Ideal for spline tables and caching; x API kept for compatibility with legacy callers providing (x).</li> </ul> <p>Implementation detail: only the real part of <code>theta</code> is used internally.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#positive-branch-thetage-0_1","title":"Positive-\u03b8 branch \\((\\theta\\ge 0)\\)","text":"\\[J_b(\\theta)=\\int_0^\\infty y^2\\ln\\big(1-e^{-\\sqrt{y^2+\\theta}}\\big)dy\\] <p>computed via the stable \\((\\ln(1-e^{-E})=\\mathrm{log1p}(-e^{-E}))\\).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#negative-branch-theta0-domain-split-with-real-integrands_1","title":"Negative-\u03b8 branch \\((\\theta&lt;0)\\) \u2014 domain split with real integrands","text":"<p>Let (\\(\\theta=-\\mu^2\\)) \\((\\mu&gt;0)\\). For (\\(y&lt;\\mu\\)), (E=i z) with (\\(z=\\sqrt{\\mu^2-y^2}\\)) and</p> \\[1-e^{-E}=2e^{-iz/2}i\\sin(z/2)\\quad\\Rightarrow\\quad \\big|1-e^{-E}\\big|=2|\\sin(z/2)|.\\] <p>Therefore,</p> \\[\\boxed{ \\begin{aligned} J_b(\\theta) &amp;=\\int_{0}^{\\mu}y^2\\ln\\Big(2\\big|\\sin\\big(\\tfrac{\\sqrt{\\mu^2-y^2}}{2}\\big)\\big|\\Big)dy\\ \\quad+\\int_{\\mu}^{\\infty}y^2\\ln\\Big(1-e^{-\\sqrt{y^2-\\mu^2}}\\Big)dy \\end{aligned}}\\] <p>Again, both integrands are real.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_6","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>theta</code> (<code>Number</code>): Scalar; only its real part is used internally.</li> </ul> <p>Returns</p> <ul> <li><code>float</code>: \\((J_b(\\theta))\\) as a real number.</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Principal square-root branch. Quadrature settings as above.</li> </ul> <p>Notes</p> <ul> <li>Prefer the \u03b8-API for new code and for spline approximation.</li> <li>For (x) real or (\\(x=i\\mu\\)), <code>_Jb_exact_scalar(x)</code> and <code>_Jb_exact2_scalar(\\theta=x^2)</code> agree.</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#relationship-between-the-x-and-based-functions","title":"Relationship between the x- and \u03b8 based functions","text":"<ul> <li>If (x) is real or purely imaginary \\(((x=i\\mu\\Rightarrow \\theta=-\\mu^2))\\), both APIs are equivalent and yield the same physics.</li> <li>The \u03b8-API enforces (\\(\\theta\\in\\mathbb{R}\\)) and constructs real integrands in all regimes, which improves numerical behavior and matches how downstream interpolation/approximations will operate.</li> <li>The x API remains for backward compatibility with callers that already supply (\\(x=m/T\\)).</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_djf_exact_scalar","title":"<code>_dJf_exact_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_7","title":"Signature","text":"<pre><code>_dJf_exact_scalar(x: Number) -&gt; float\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_7","title":"Purpose","text":"<p>Compute the exact derivative \\((\\dfrac{dJ_f}{dx})\\) for a scalar (x) with a numerically stable integrand. For fermions,</p> \\[J_f(x)=\\int_0^\\infty -y^2\\ln\\Big(1+e^{-\\sqrt{y^2+x^2}}\\Big)dy \\qquad E\\equiv\\sqrt{y^2+x^2}.\\]"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#differentiating-under-the-integral-sign","title":"Differentiating under the integral sign","text":"<p>Under standard regularity conditions (smooth, absolutely integrable integrand), we may exchange derivative and integral:</p> \\[\\frac{dJ_f}{dx} =\\int_0^\\infty \\frac{\\partial}{\\partial x}\\left[-y^2\\ln\\big(1+e^{-E}\\big)\\right]dy.\\] <p>Using</p> \\[\\frac{d}{dE}\\Big[-\\ln\\big(1+e^{-E}\\big)\\Big] =\\frac{e^{-E}}{1+e^{-E}} =\\frac{1}{e^{E}+1}\\equiv  n_F(E) \\qquad \\frac{dE}{dx}=\\frac{x}{E}\\] <p>we obtain the fermionic derivative kernel</p> \\[\\boxed{ \\frac{dJ_f}{dx}  =\\int_0^\\infty y^2 n_F(E) \\frac{x}{E} dy =\\int_0^\\infty y^2\\frac{x}{E}\\frac{1}{e^{E}+1}dy \\qquad E=\\sqrt{y^2+x^2}}\\]"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#numerical-stability-choices","title":"Numerical stability choices","text":"<ul> <li>We implement ( \\(n_F(E)=\\dfrac{1}{e^{E}+1}\\) ) as <code>special.expit(-E)</code> (the logistic function), which is stable for large (E).</li> <li>By parity, \\((J_f(x))\\) is even in (x) (i.e., \\((J_f(-x)=J_f(x))\\) ), hence ( $\\tfrac{dJ_f}{dx}\\big|_{x=0}=0 $). The function returns 0 exactly at (x=0).</li> <li>Internally we form (\\(E=\\sqrt{y^2+x_r^2}\\)) with (\\(x_r=|x|\\ge 0\\)) to guarantee (\\(E\\ge 0\\)). In physical use (\\(x=m/T\\ge 0\\)).   (For explicit sign handling: \\((\\tfrac{dJ_f}{dx}(-x)=-\\tfrac{dJ_f}{dx}(x))\\) ).</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_7","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>x</code> (<code>Number</code>): Scalar (real or complex). In physical applications (\\(x\\in\\mathbb{R}_{\\ge 0}\\)).</li> </ul> <p>Returns</p> <ul> <li><code>float</code>: The real value of \\((\\dfrac{dJ_f}{dx})\\).</li> </ul> <p>Notes</p> <ul> <li>Quadrature settings: <code>epsabs=1e-10</code>, <code>epsrel=1e-8</code>, <code>limit=200</code>.</li> <li>Integration domain \\((y\\in[0,\\infty))\\) with stable integrand \\((y^2,\\dfrac{x}{E},n_F(E))\\).</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_djb_exact_scalar","title":"<code>_dJb_exact_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_8","title":"Signature","text":"<pre><code>_dJb_exact_scalar(x: Number) -&gt; float\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_8","title":"Purpose","text":"<p>Compute the exact derivative \\((\\dfrac{dJ_b}{dx})\\) for a scalar (x). For bosons,</p> \\[ J_b(x)=\\int_0^\\infty y^2\\ln\\Big(1-e^{-\\sqrt{y^2+x^2}}\\Big)dy \\qquad E\\equiv\\sqrt{y^2+x^2}.\\]"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#differentiating-under-the-integral-sign_1","title":"Differentiating under the integral sign","text":"\\[\\frac{dJ_b}{dx} =\\int_0^\\infty \\frac{\\partial}{\\partial x}\\left[y^2\\ln\\big(1-e^{-E}\\big)\\right]dy\\] <p>Using</p> \\[\\frac{d}{dE}\\ln\\big(1-e^{-E}\\big) =\\frac{e^{-E}}{1-e^{-E}}  =\\frac{1}{e^{E}-1}\\equiv n_B(E)\\qquad \\frac{dE}{dx}=\\frac{x}{E} \\] <p>we obtain the bosonic derivative kernel</p> \\[\\boxed{ \\frac{dJ_b}{dx} =\\int_0^\\infty y^2 n_B(E)\\frac{x}{E}dy =\\int_0^\\infty y^2\\frac{x}{E}\\frac{1}{e^{E}-1}dy \\qquad E=\\sqrt{y^2+x^2} }\\]"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#numerical-stability-choices_1","title":"Numerical stability choices","text":"<ul> <li>We implement ( \\(n_B(E)=\\dfrac{1}{e^{E}-1}\\) ) as <code>1/np.expm1(E)</code>, which is stable as (\\(E\\to 0^+\\)).</li> <li>By parity, \\((J_b(x))\\) is even in (x) (i.e., \\((J_b(-x)=J_b(x))\\) ), hence \\((\\tfrac{dJ_b}{dx}\\big|_{x=0}=0)\\). The function returns 0 at (x=0).</li> <li>Internally (\\(E=\\sqrt{y^2+x_r^2}\\)) with (\\(x_r=|x|\\ge 0\\)), consistent with the physical case (\\(x=m/T\\ge 0\\)).   (For sign handling: ( $\\tfrac{dJ_b}{dx}(-x)=-\\tfrac{dJ_b}{dx}(x) $).)</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_8","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>x</code> (<code>Number</code>): Scalar (real or complex). In physical applications (\\(x\\in\\mathbb{R}_{\\ge 0}\\)).</li> </ul> <p>Returns</p> <ul> <li><code>float</code>: The real value of \\((\\dfrac{dJ_b}{dx})\\).</li> </ul> <p>Notes</p> <ul> <li>Quadrature settings: <code>epsabs=1e-10</code>, <code>epsrel=1e-8</code>, <code>limit=200</code>.</li> <li>Integration domain \\((y\\in[0,\\infty))\\) with stable integrand \\((y^2,\\dfrac{x}{E}n_B(E))\\).</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#jf_exact-jf_exact2-jb_exact-jb_exact2-djf_exact-djb_exact","title":"Jf_exact; Jf_exact2; Jb_exact; Jb_exact2; dJf_exact; dJb_exact","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_9","title":"Purpose","text":"<p>These functions are vectorized, user-facing wrappers around the exact scalar kernels for the one-loop thermal integrals (\\(J_b\\)), (\\(J_f\\)) and their derivatives. They:</p> <ul> <li>preserve the legacy cosmoTransitions API (same names/behavior),</li> <li>accept scalars or arrays and apply the scalar kernels element-wise (scalar-in \u2192 scalar-out),</li> <li>offer both x-based ((\\(x=m/T\\))) and \u03b8 based \\((\\theta=x^2=m^2/T^2\\in\\mathbb{R})\\) entry points.</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signatures","title":"Signatures","text":"<pre><code>Jf_exact(x: ArrayLike) -&gt; Union[Number, np.ndarray]\nJf_exact2(theta: ArrayLike) -&gt; Union[float, np.ndarray]\n\nJb_exact(x: ArrayLike) -&gt; Union[float, np.ndarray]\nJb_exact2(theta: ArrayLike) -&gt; Union[float, np.ndarray]\n\ndJf_exact(x: ArrayLike) -&gt; Union[float, np.ndarray]\ndJb_exact(x: ArrayLike) -&gt; Union[float, np.ndarray]\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters","title":"Parameters","text":"<ul> <li> <p>For x based functions (<code>Jf_exact</code>, <code>Jb_exact</code>, <code>dJf_exact</code>, <code>dJb_exact</code>):</p> </li> <li> <p><code>x</code> (<code>float | complex | array-like</code>): argument(s) (\\(x=m/T\\)).     \u2022 Real inputs are treated as <code>abs(x)</code> (legacy).     \u2022 Complex inputs are accepted for backward compatibility only; see Notes.</p> </li> <li> <p>For \u03b8 based functions (<code>Jf_exact2</code>, <code>Jb_exact2</code>):</p> </li> <li> <p><code>theta</code> (<code>float | array-like</code>): (\\(\\theta=x^2=m^2/T^2\\)) (its real part is used).     May be negative; the implementation splits the domain to keep the integrand real.</p> </li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#returns","title":"Returns","text":"<ul> <li>Scalar if the input is scalar; <code>ndarray</code> with the same shape as the input otherwise.</li> <li>On array inputs, any element that fails to evaluate returns NaN (legacy behavior preserved).</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#notes-apply-to-all","title":"Notes (apply to all)","text":"<ul> <li>Vectorization &amp; semantics. All functions act element-wise on arrays and preserve shapes.</li> <li> <p>Numerical stability. Internally use stable forms:</p> </li> <li> <p><code>log1p</code> / <code>log1p(-exp(-E))</code> for the logs,</p> </li> <li><code>special.expit(-E)</code> for the Fermi factor \\((1/(e^E+1))\\),</li> <li><code>1/np.expm1(E)</code> for the Bose factor \\((1/(e^E-1))\\).</li> <li> <p>Branching / complex inputs.</p> </li> <li> <p>For \u03b8-API (<code>*_exact2</code>): (\\(\\theta\\in\\mathbb{R}\\)). If (\\(\\theta&lt;0\\)) the integral is split at (\\(y=\\sqrt{|\\theta|}\\)) and expressed with (\\(\\cos\\)) / (\\(\\sin\\)), yielding real integrands throughout.</p> </li> <li>For x-API (<code>*_exact</code>): complex (x) triggers the legacy branch splitting (over (\\([0,|x|]\\))) to keep the integrals numerically real/stable.     Physical note: a general complex (x) has no standard physical meaning here; it is supported only for backward compatibility. In physics workflows, (\\(x=m/T\\)) is real (or equivalently (\\(\\theta\\)) is real).</li> <li>Recommended usage. Prefer the \u03b8 based functions (<code>Jf_exact2</code>, <code>Jb_exact2</code>) in new code (better for interpolation/splines and uniformly real integrands). Use x based names for seamless drop in replacement in legacy pipelines.</li> <li>Derivatives. <code>dJf_exact</code>, <code>dJb_exact</code> implement the differentiated kernels:</li> </ul> <p>\\(\\(\\frac{dJ_f}{dx}=\\int_0^\\infty y^2\\frac{x}{E}\\frac{1}{e^E+1}dy\\qquad  \\frac{dJ_b}{dx}=\\int_0^\\infty y^2\\frac{x}{E}\\frac{1}{e^E-1}dy \\quad E=\\sqrt{y^2+x^2}\\)\\)   and return 0 exactly at <code>x==0</code> (removable singularity; evenness in (x)).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#exact-thermal-integrals-examples","title":"Exact Thermal Integrals \u2014 Examples","text":"<p>This page documents progressive sanity/consistency checks for the exact one-loop thermal integrals and their derivatives:</p> <p>\\(\\(J_b(x)=\\int_0^\\infty y^2\\ln\\bigl(1-e^{-\\sqrt{y^2+x^2}}\\bigr)dy\\quad J_f(x)=\\int_0^\\infty -y^2\\ln\\bigl(1+e^{-\\sqrt{y^2+x^2}}\\bigr)dy\\)\\) We test the public API: <code>Jb_exact</code>, <code>Jf_exact</code>, <code>Jb_exact2</code>, <code>Jf_exact2</code>, <code>dJb_exact</code>, <code>dJf_exact</code>.</p> <p>All figures below are produced by the script <code>tests/finiteT/Exact_Thermal_Integrals.py</code>. see tests/finiteT/Exact_Thermal_Integrals for more</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-1-small-x-physics-sanity-constants-at-x0-and-near-zero-behavior","title":"Test 1 \u2014 Small-x physics sanity: constants at (x=0) and near-zero behavior","text":"<p>What it checks</p> <ul> <li>The known limits:</li> <li> <p>\\(\\(J_b(0)=-\\frac{\\pi^4}{45},\\qquad   J_f(0)=-\\frac{7\\pi^4}{360}.\\)\\)</p> </li> <li> <p>For small positive (x), both (J_b) and (J_f) increase toward 0, as mass/temperature (\\(x=m/T\\)) grows.</p> </li> </ul> <p>Figure</p> <ul> <li>Small-x behavior: </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 1: Small-x sanity (x \u2192 0) ===\nJ_b(0): num=-2.164646467421e+00, expected=-2.164646467422e+00, |\u0394|=1.60e-12\nJ_f(0): num=-1.894065658994e+00, expected=-1.894065658994e+00, |\u0394|=6.66e-16\nExpectation: For both bosons and fermions, J(x) starts negative and increases toward 0 as x grows. \nAs we can see in the image above, this expectation is met.\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-2-consistency-jx-vs-jthetax2-for-xge-0","title":"Test 2 \u2014 Consistency: (J(x)) vs (J(\\(\\theta=x^2\\))) for (\\(x\\ge 0\\))","text":"<p>What it checks</p> <ul> <li>Numerical agreement between the x-API (<code>J*_exact</code>) and the \u03b8-API (<code>J*_exact2</code>) when (\\(\\theta=x^2\\)) with (\\(x\\ge 0\\)).</li> <li>Differences should be at quadrature noise level.</li> </ul> <p>Figure</p> <ul> <li>Direct consistency, (J(x)-J(\\(\\theta\\))): </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 2: Consistency J(x) vs J(theta=x^2) (x \u2265 0) ===\nMax |J_b(x) - J_b(theta)| over grid: 0.000e+00\nMax |J_f(x) - J_f(theta)| over grid: 0.000e+00\nExpectation: differences ~ 0 within quadrature noise. \nThis expectation its valid as we can see in the image above\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-2b-negative-theta-branch-and-imaginary-x-cross-check","title":"Test 2b \u2014 Negative-(\\(\\theta\\)) branch and imaginary (x) cross-check","text":"<p>What it checks</p> <ul> <li>For (\\(\\theta&lt;0\\)), compare the \u03b8-API values (J(\\(\\theta=-\\mu^2\\))) with the x-API evaluated at (\\(x=i\\mu\\)) (dashed).   This confirms that our real, piecewise integrands for negative (\\(\\theta\\)) match the legacy branch split for purely imaginary (x).</li> </ul> <p>Figure</p> <ul> <li>(\\(\\theta&lt;0\\)) (solid) vs (\\(x=i\\mu\\)) (dashed): </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 2b: Negative-\u03b8 branch and imaginary-x consistency ===\nMax |J_b(\u03b8&lt;0) - J_b(x=i\u03bc)| over grid: 5.551e-13\nMax |J_f(\u03b8&lt;0) - J_f(x=i\u03bc)| over grid: 5.596e-12\nExpectation: solid and dashed curves overlap within quadrature accuracy.\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-3-derivatives-shape-and-sign-djdx-ge-0-for-xge-0","title":"Test 3 \u2014 Derivatives: shape and sign (\\((dJ/dx \\ge 0)\\) for (\\(x\\ge 0\\)))","text":"<p>What it checks</p> <ul> <li>From the derivative formulas,</li> </ul> <p>\\(\\(\\frac{dJ_f}{dx}=\\int_0^\\infty y^2\\frac{x}{E}\\frac{1}{e^E+1}dy\\qquad   \\frac{dJ_b}{dx}=\\int_0^\\infty y^2\\frac{x}{E}\\frac{1}{e^E-1}dy\\quad E=\\sqrt{y^2+x^2}\\)\\)</p> <p>we expect non negative derivatives for (\\(x\\ge 0\\)). * Plots should show both (\\(dJ_b/dx\\)) and (\\(dJ_f/dx\\)) positive and decreasing toward 0 as (x) increases.</p> <p>Figure</p> <ul> <li>Derivatives vs (x): </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 3: Derivative sign/shape (dJ/dx \u2265 0 for x \u2265 0) ===\nMin dJ_b/dx on grid: 0.000e+00  (expected \u2265 0)\nMin dJ_f/dx on grid: 0.000e+00  (expected \u2265 0)\nExpectation: derivatives are positive (curves move up toward 0). As we can see this is satisfied\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-4-cross-check-djdx-via-finite-difference-gradientfunction-order4","title":"Test 4 \u2014 Cross-check (dJ/dx) via finite-difference <code>gradientFunction</code> (order=4)","text":"<p>What it checks</p> <ul> <li>Independent numerical differentiation (order-4 central differences) reproduces <code>dJ*_exact</code> closely.</li> </ul> <p>Figures</p> <ul> <li> <p>Boson derivative cross-check: </p> </li> <li> <p>Fermion derivative cross-check: </p> </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 4: Cross-check dJ/dx using gradientFunction (order=4) ===\nMax |dJ_b (FD) - dJ_b (exact)|: 1.318e-10\nMax |dJ_f (FD) - dJ_f (exact)|: 1.705e-11\nExpectation: order-4 finite differences should track the exact derivative closely (small max absolute error).\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-5a-global-trend-x-from-0-to-large-approach-to-0","title":"Test 5A \u2014 Global trend: (x) from 0 to large (approach to 0)","text":"<p>What it checks</p> <ul> <li>Over a wide range (\\(x\\in[0,10]\\)), both (\\(J_b\\)) and (\\(J_f\\)) approach 0 as (x) grows (heavier mass over temperature).</li> <li>The plot includes a (y=0) reference line.</li> </ul> <p>Figure</p> <ul> <li>Global trend with (y=0) guide: </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 5A: Global trend (x from 0 to large) with y=0 reference ===\nExpectation: as x increases (heavier over T), both J_b and J_f approach 0 exponentially.\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-5b-large-x-tails-semilog-and-bessel-proxy-x2-k_2x","title":"Test 5B \u2014 Large-(x) tails (semilog) and Bessel proxy \\((x^2 K_2(x))\\)","text":"<p>What it checks</p> <ul> <li>On a semilog scale, (|J|) decays roughly like \\((\\exp(-x))\\).</li> <li>The empirical proxy \\((-x^2 K_2(x))\\) captures the qualitative tail behavior.</li> </ul> <p>Figures</p> <ul> <li> <p>Semilog magnitudes: </p> </li> <li> <p>Tail ratio vs proxy: </p> </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 5B: Large-x tail (semilog plots) ===\nTail check (medians):\n median[ J_b / ( -x^2 K2 ) ] = 1.000\n median[ J_f / ( -x^2 K2 ) ] = 1.000\nExpectation: both |J| decay ~exp(-x); the Bessel proxy captures the trend qualitatively.\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-6-physical-illustration-thermal-piece-v_tpropto-sum_i-n_ij_pmm_it","title":"Test 6 \u2014 Physical illustration: thermal piece \\((V_T\\propto \\sum_i n_i,J_{\\pm}(m_i/T))\\)","text":"<p>What it checks</p> <ul> <li>With illustrative degeneracies (n_b, n_f) and (T=1), thermal contributions built from (\\(J_b\\)) and (\\(J_f\\)) are largest near (x=0) and vanish for (\\(x\\gg 1\\)).</li> </ul> <p>Figure</p> <ul> <li>Illustrative thermal potential piece: </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n# For illustration only (not a strict unit test):\nT = 1.0  # set T=1 to focus on x=m/T\ndeg_b, deg_f = 2.0, 4.0  # example degeneracies\nx_phys = np.linspace(0.0, 10.0, 160)\nVb = (T**4 / (2*np.pi**2)) * deg_b * Jb_exact(x_phys)\nVf = (T**4 / (2*np.pi**2)) * deg_f * Jf_exact(x_phys).real\n\n=== Test 6: Thermal contribution V_T \u221d J(x) with x = m/T ===\nExpectation: contributions are largest near x\u22480 and vanish exponentially for x\u226b1.\n---------- END OF TESTS: Exact Thermal Integrals ----------\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#reproducibility-notes","title":"Reproducibility notes","text":"<ul> <li>Quadrature tolerances used internally: <code>epsabs=1e-10</code>, <code>epsrel=1e-8</code>, <code>limit=200</code>.</li> <li>Small differences across machines/BLAS/SciPy versions are expected at the \\((10^{-9})\\)-\\((10^{-7})\\) level in these tests.</li> </ul>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/","title":"Short Hand for All Thermal Integrals","text":"<p># Dispatcher Helpers \u2014 <code>Jb</code> and <code>Jf</code> Short Hands</p>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#purpose","title":"Purpose","text":"<p>Thin, user friendly wrappers that dispatch to the implementations of the Jb &amp; Jf modernized:</p> <ul> <li><code>exact</code> (numerical quadrature),</li> <li><code>low</code> (small-(x), high-T series),</li> <li><code>high</code> (large-(x), low-T Bessel-(K) sum),</li> <li><code>spline</code> (cubic spline in (\\(\\theta=x^2\\)), allowing (\\(\\theta&lt;0\\))).</li> </ul> <p>They preserve the legacy API and defaults, validate inputs consistently, and keep scalar-in \u2192 scalar-out behavior (vectorized over arrays).</p>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#signatures","title":"Signatures","text":"<pre><code>Jb(x, approx: str = \"high\", deriv: int = 0, n: int = 8) -&gt; float | np.ndarray\nJf(x, approx: str = \"high\", deriv: int = 0, n: int = 8)  -&gt; float | complex | np.ndarray\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#parameters-common","title":"Parameters (common)","text":"<ul> <li><code>x</code> (<code>float | array-like</code>):   For <code>approx in {\"exact\",\"low\",\"high\"}</code> this is the usual real (x=m/T).   For <code>approx==\"spline\"</code>, <code>x</code> is (\\(\\theta = (m/T)^2\\)) (can be negative; legacy behavior).</li> <li><code>approx</code> (<code>\"exact\"|\"high\"|\"low\"|\"spline\"</code>): Which evaluator to use (default <code>\"high\"</code>).</li> <li><code>deriv</code> (<code>int</code>): Derivative order \u2014 allowed per mode:   <code>exact</code>: 0 or 1 \u2022 <code>low</code>: 0 \u2022 <code>high</code>: 0..3 \u2022 <code>spline</code>: 0..3.</li> <li><code>n</code> (<code>int</code>): Truncation \u2014 used only in series/sum modes:   <code>low</code>: number of tail terms (\u2264 50) \u2022 <code>high</code>: number of Bessel-sum terms.</li> </ul>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#returns","title":"Returns","text":"<ul> <li><code>Jb</code>: <code>float | ndarray</code></li> <li><code>Jf</code>: <code>float | complex | ndarray</code> (in <code>exact</code> mode, legacy complex dtype is preserved; use <code>.real</code> if you only need the physical value for real (x)).</li> </ul>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#notes","title":"Notes","text":"<ul> <li>Spline mode uses (\\(\\theta\\)), not (x), by design. This allows (\\(\\theta&lt;0\\)) (tachyonic curvature) and matches the legacy spline tables.</li> <li>Complex (x) has no physical meaning here and is not supported by these wrappers; if you truly need complex analysis, call the exact scalar routines directly.</li> <li>Validation mirrors each backend\u2019s capability (<code>low</code> supports values only; <code>high</code> supports up to 3rd derivative; etc.).</li> </ul>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#see-also-all-details","title":"See also (all details)","text":"<ul> <li>Exact integrals and derivatives: Exact Thermal Integrals (J_b, J_f)</li> <li>Spline construction &amp; use: Spline Thermal Integrals (J_b, J_f)</li> <li>Low-(x) (high-T) series: Approx \u2014 Low-x Series</li> <li>High-(x) (low-T) series: Approx \u2014 High-x Series</li> </ul>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#tests-jb-jf-all-plots","title":"Tests (<code>Jb</code>, <code>Jf</code>) - All plots","text":""},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-a-exact-j_b-j_f-on-010","title":"Test A \u2014 Exact (\\(J_b\\), \\(J_f\\)) on (\\([0,10]\\))","text":"<p>What it checks: Baseline curves from numerical quadrature; values at (x=0) match \\((J_b(0)=-\\pi^4/45)\\) and \\((J_f(0)=-7\\pi^4/360)\\). Expectation: Both start negative and monotonically approach 0 as (x) grows.</p> <p>Figure </p> <p>Console output</p> <pre><code>=== Test A: exact J_b, J_f on [0,10] ===\nAt x=0: J_b=-2.164646467421e+00, J_f=-1.894065658994e+00.\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-b-spline-j_b-j_f-on-010-with-thetax2","title":"Test B \u2014 Spline (\\(J_b\\), \\(J_f\\)) on ([0,10]) with (\\(\\theta=x^2\\))","text":"<p>What it checks: Spline evaluation agrees with exact on the same (x)-grid (using (\\(\\theta=x^2\\))). Expectation: Small max relative differences, consistent with spline accuracy.</p> <p>Figure </p> <p>Console output</p> <pre><code>=== Test B: spline J_b, J_f on [0,10] (\u03b8 = x^2) ===\nMax relative diff spline vs exact on [0,10]:  J_b: 5.564e-04,  J_f: 2.479e-05\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-c-exact-first-derivatives-mathrm-djmathrm-dx-on-010","title":"Test C \u2014 Exact first derivatives \\((\\mathrm dJ/\\mathrm dx)\\) on ([0,10])","text":"<p>What it checks: Direct quadrature of (dJ/dx). Expectation: (dJ/dx) is (0) at (x=0) (removable singularity handled), positive for (x&gt;0), and decays with (x).</p> <p>Figure </p> <p>Console output</p> <pre><code>=== Test C: exact derivatives dJ/dx on [0,10] ===\ndJ_b/dx at x=0: 0.000e+00 (expected 0);  dJ_f/dx at x=0: 0.000e+00 (expected 0)\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-d-spline-first-derivative-mapped-to-x-via-chain-rule","title":"Test D \u2014 Spline first derivative mapped to (x) via chain rule","text":"<p>What it checks: Spline derivatives (computed in \\((\\theta))\\) correctly mapped to (x): \\((\\frac{dJ}{dx} = 2x,\\frac{dJ}{d\\theta})\\). Expectation: Close agreement with exact (dJ/dx).</p> <p>Figure </p> <p>Console output</p> <pre><code>=== Test D: spline first derivative (chain rule to dJ/dx) on [0,10] ===\nMax relative diff (spline\u2192x) vs exact dJ/dx:  J_b: 3.758e-02,  J_f: 2.851e-03\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-e-spline-second-derivative-mapped-to-x","title":"Test E \u2014 Spline second derivative mapped to (x)","text":"<p>What it checks: Chain rule for the second derivative:</p> \\[\\frac{d^2J}{dx^2} = 2,\\frac{dJ}{d\\theta} + 4x^2\\frac{d^2J}{d\\theta^2}\\] <p>Expectation: Smooth, sensible curvature; finite at (x=0).</p> <p>Figure </p>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-f-low-x-series-vs-exact-with-relative-error","title":"Test F \u2014 Low-(x) series vs exact (with relative error)","text":"<p>What it checks: High-T (small (x)) series accuracy windows.</p> <p>Ranges: (\\(J_b\\)) on ([0,7]), (J_f) on ([0,3.7]).</p> <p>Expectation: Low relative error in these windows; error grows as (x) leaves the intended regime.</p> <p>Figures</p> <ul> <li>Boson: series vs exact \u2014 </li> <li>Boson: relative error \u2014 </li> <li>Fermion: series vs exact \u2014 </li> <li>Fermion: relative error \u2014 </li> </ul> <p>Console output</p> <pre><code>=== Test F: low-x series vs exact (with relative error) ===\nBoson low-x: max rel err = 1.183e+02\nFermion low-x: max rel err = 1.422e+01\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-g-high-x-series-vs-exact-on-110-with-relative-error","title":"Test G \u2014 High-(x) series vs exact on ([1,10]) (with relative error)","text":"<p>What it checks: Low-T (large (x)) Bessel-sum accuracy. Expectation: Semilog plot shows exponential tails; series tracks exact well with modest (n) (here (n=8)).</p> <p>Figures</p> <ul> <li>Semilog magnitude \u2014 </li> <li>Relative error \u2014 </li> </ul> <p>Console output</p> <pre><code>=== Test G: high-x series vs exact (x in [1,10]) ===\nHigh-x: max rel err  J_b: 6.351e-07,  J_f: 3.878e-07\n\n---------- END OF TESTS: Dispatcher (Jb, Jf) ----------\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#notes_1","title":"Notes","text":"<ul> <li>Spline mode input: remember that the dispatcher expects (\\theta=x^2) as input in <code>\"spline\"</code> mode; chain rule conversions are used for derivatives in (x).</li> <li>Relative error definition: (\\(\\mathrm{rel}=\\frac{|A-B|}{\\max(|B|,10^{-12})}\\)).</li> <li>For quicker runs, reduce grid sizes or narrow (x)-ranges during development.</li> <li>see tests/finiteT/Short_Hand for more</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/","title":"Spline Thermal Integrals (Jb, Jf)","text":"<p>The advantage of these functions is that, after creating a spline from the exact function's placement points,  we can quickly obtain a value for any desired point x on the curve without having to go through the integration process directly required by the exact method. Furthermore, we can expect good compatibility between the values. This is one of the spline's main uses.</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#spline-thermal-integrals-j_f","title":"Spline Thermal Integrals (J_f)","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#purpose","title":"Purpose","text":"<p>Provide a fast, differentiable surrogate for the exact fermionic thermal integral</p> \\[J_f(\\theta)\\equiv J_f\\bigl(x^2\\bigr)\\quad \\theta=(m/T)^2\\in\\mathbb{R}\\] <p>by fitting a cubic B-spline to samples of the exact function \\((J_f(\\theta))\\) on a non-uniform grid. The spline preserves the legacy API/behavior:</p> <ul> <li>Input is (\\(\\theta=x^2\\)) (not (x)); (\\(\\theta\\)) can be negative (imaginary (x) branch).</li> <li>For (\\(\\theta &lt; \\theta_{\\min}\\)): returns the clamped value \\((J_f(\\theta_{\\min}))\\).</li> <li>For (\\(\\theta &gt; \\theta_{\\max}\\)): returns 0 (and its derivatives 0), matching the physical larg -mass suppression in the legacy code.</li> <li>Supports derivatives w.r.t. (\\(\\theta\\)) via <code>n</code> (uses <code>BSpline.derivative(n)</code>).</li> </ul> <p>Domain used: (\\(\\theta_{\\min} = -6.82200203,\\quad \\theta_{\\max} = 1.35\\times 10^3.\\))</p> <p>Notes: * The spline is built from <code>Jf_exact2(theta)</code> (exact quadrature) and cached to disk for reproducibility/speed. * Physically meaningful inputs here are real (\\(\\theta\\)). A complex and real (x) (thus complex (\\(\\theta\\))) has no direct meaning in this spline API\u2014use the exact routines if you need analytic continuation details.</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#jf_spline","title":"<code>Jf_spline</code>","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#signature","title":"Signature","text":"<pre><code>Jf_spline(X: float | np.ndarray, n: int = 0) -&gt; float | np.ndarray\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#parameters","title":"Parameters","text":"<ul> <li><code>X</code> (<code>float | array_like</code>): Input theta values (\\(\\theta=(m/T)^2\\)). Scalar-in \u2192 scalar-out.</li> <li><code>n</code> (<code>int</code>, default <code>0</code>): Derivative order w.r.t. (\\theta) (0 for the function value, 1 for first derivative, etc).</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#returns","title":"Returns","text":"<ul> <li> <p><code>out</code> (<code>float | ndarray</code>): \\((J_f(\\theta))\\) (or its (n)-th (\\(\\theta\\))-derivative) evaluated by the spline.   Behavior outside the fit domain:</p> </li> <li> <p>If (\\(\\theta &lt; \\theta_{\\min}\\)): returns the constant value at \\((\\theta_{\\min})\\).</p> </li> <li>If (\\(\\theta &gt; \\theta_{\\max}\\)): returns 0.0 (derivatives also 0.0), per legacy behavior.</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#notes","title":"Notes","text":"<ul> <li>Backend: <code>scipy.interpolate.BSpline</code> (created via <code>make_interp_spline(..., k=3)</code>).</li> <li>The grid is denser near (\\(\\theta\\le 0\\)) and small positive (\\(\\theta\\)), and sparser on the large-(\\(\\theta\\)) tail.</li> <li>Accuracy is typically at the few \u00d7 \\(10^{-6}\u201310^{-8}\\) level relative to the exact integral over the intended domain (depends on the internal grid sizes).</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#_ensure_jf_spline","title":"<code>_ensure_Jf_spline</code>","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#signature_1","title":"Signature","text":"<pre><code>_ensure_Jf_spline() -&gt; scipy.interpolate.BSpline\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#purpose_1","title":"Purpose","text":"<p>Construct (once) and return the global <code>BSpline</code> object for \\((J_f(\\theta))\\). First tries to load a cached spline; if not found, it builds the dataset with <code>Jf_exact2()</code>, fits a cubic spline, and saves the spline parameters to disk.</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#notes_1","title":"Notes","text":"<ul> <li>The cache file (by default) is <code>Jf_spline_v1.npz</code>, containing the knot vector <code>t</code>, coefficients <code>c</code>, and degree <code>k</code>.</li> <li>If the directory is read-only, the code silently skips saving (still works in-memory).</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#_build_jf_dataset","title":"<code>_build_Jf_dataset</code>","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#signature_2","title":"Signature","text":"<pre><code>_build_Jf_dataset(n_neg: int = 420, n_pos_lin: int = 380, n_pos_log: int = 300) -&gt; tuple[np.ndarray, np.ndarray]\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#purpose_2","title":"Purpose","text":"<p>Generate a non-uniform theta grid and its exact values \\((J_f(\\theta))\\) used to fit the spline.</p> <ul> <li>Negative branch: linear grid on (\\([\\theta_{\\min}, 0]\\)) (dense).</li> <li>Positive small: linear grid on (\\([0, 50]\\)).</li> <li>Positive tail: log grid on \\((50, \\theta_{\\max}])\\).</li> </ul> <p>Returns <code>(theta, y)</code> with <code>y = Jf_exact2(theta)</code>.</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#_load_jf_cache-_save_jf_cache","title":"<code>_load_Jf_cache</code> / <code>_save_Jf_cache</code>","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#signatures","title":"Signatures","text":"<pre><code>_load_Jf_cache() -&gt; None | tuple[np.ndarray, np.ndarray, int]\n_save_Jf_cache(theta: np.ndarray, coeffs: np.ndarray, t: np.ndarray, k: int) -&gt; None\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#purpose-brief","title":"Purpose (brief)","text":"<ul> <li><code>_load_Jf_cache</code>: try to load a previously saved spline <code>(t, c, k)</code>. Returns <code>None</code> if not available.</li> <li><code>_save_Jf_cache</code>: best-effort save of spline parameters to disk so subsequent runs are instantaneous.</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#reproducibility-performance","title":"Reproducibility &amp; Performance","text":"<ul> <li>The spline is deterministic given the internal grid sizes and the exact integrator tolerances (in <code>Jf_exact2</code>).</li> <li>First build takes ~seconds (quadrature over a few hundred points), thereafter ~milliseconds per call thanks to evaluation of a cubic B-spline (and its derivatives).</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#spline-thermal-integrals-j_b","title":"Spline Thermal Integrals (J_b)","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#purpose_3","title":"Purpose","text":"<p>Provide a fast, differentiable surrogate for the exact bosonic thermal integral \\((J_b(\\theta) \\equiv J_b(x^2))\\) with (\\(\\theta=(m/T)^2\\in\\mathbb{R}\\)), by fitting a cubic B-spline to samples of the exact function \\((J_b(\\theta))\\) on a non-uniform grid. The spline preserves the legacy API/behavior:</p> <ul> <li>Input is (\\(\\theta=x^2\\)) (not (x)); (\\(\\theta\\)) may be negative (imaginary-mass branch handled via the exact routine during fitting).</li> <li>For (\\(\\theta &lt; \\theta_{\\min}\\)): return the clamped value \\((J_b(\\theta_{\\min}))\\).</li> <li>For (\\(\\theta &gt; \\theta_{\\max}\\)): return 0.0 (and derivatives 0.0), matching the legacy tail suppression.</li> <li>Support derivatives w.r.t. \\((\\theta)\\) via parameter <code>n</code> (uses <code>BSpline.derivative(n)</code>).</li> </ul> <p>Domain used (legacy-compatible): (\\(\\displaystyle \\theta_{\\min} = -3.72402637,\\qquad \\theta_{\\max} = 1.41\\times 10^3.\\))</p> <p>Physically meaningful inputs here are real (\\(\\theta\\)). Complex (x) (thus complex (\\(\\theta\\))) is not used in this spline API; for analytic-continuation details use the exact routines.</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#jb_spline","title":"<code>Jb_spline</code>","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#signature_3","title":"Signature","text":"<pre><code>Jb_spline(X: float | np.ndarray, n: int = 0) -&gt; float | np.ndarray\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#parameters_1","title":"Parameters","text":"<ul> <li><code>X</code> (<code>float | array_like</code>): Input theta values (\\(\\theta=(m/T)^2\\)). Scalar-in \u2192 scalar-out.</li> <li><code>n</code> (<code>int</code>, default <code>0</code>): Derivative order w.r.t. \\((\\theta)\\) (0 for the function value, 1 for first derivative, etc.).</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#returns_1","title":"Returns","text":"<ul> <li> <p><code>out</code> (<code>float | ndarray</code>): \\((J_b(\\theta))\\) (or its (n)-th (\\(\\theta\\))-derivative) evaluated by the spline.   Outside the fitted domain:</p> </li> <li> <p>If (\\(\\theta &lt; \\theta_{\\min}\\)): returns the constant value at (\\(\\theta_{\\min}\\)).</p> </li> <li>If (\\(\\theta &gt; \\theta_{\\max}\\)): returns 0.0 (derivatives also 0.0), per legacy behavior.</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#notes_2","title":"Notes","text":"<ul> <li>Backend: <code>scipy.interpolate.BSpline</code> (created via <code>make_interp_spline(..., k=3)</code>).</li> <li>The grid used for fitting is denser near (\\(\\theta\\le 0\\)) and small positive (\\(\\theta\\)), and sparser on the large-(\\(\\theta\\)) tail.</li> <li>Choice of (\\(\\theta_{\\min}\\)) coincides with the minimum of (\\(J_b\\)), so the clamp at the left boundary plus the vanishing right tail makes the evaluated curve monotonic increasing and (\\(C^1\\))-continuous (matching the legacy intent).</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#spline-construction-caching-same-pattern-as-jf_spline","title":"Spline construction &amp; caching (same pattern as Jf_spline)","text":"<p>The internal helpers follow the same design as for <code>Jf_spline</code>:</p> <ul> <li>Dataset build: generate a non-uniform \\((\\theta)\\) grid   (linear on (\\([\\theta_{\\min},0]\\)), linear on (\\([0,50]\\)), logarithmic on \\(((50,\\theta_{\\max}]))\\) and compute ground-truth values via <code>Jb_exact2(theta)</code>.   (Function: <code>_build_Jb_dataset</code>.)</li> <li>Spline fit: build a cubic interpolating spline (<code>make_interp_spline</code>) with <code>extrapolate=False</code>.   (Created inside <code>_ensure_Jb_spline</code>.)</li> <li>Caching: first try to load a cached spline <code>(t, c, k)</code> from   <code>Jb_spline_v1.npz</code> under <code>spline_data_path</code>; if not present, fit and then save best-effort.   (Functions: <code>_load_Jb_cache</code>, <code>_save_Jb_cache</code>, called by <code>_ensure_Jb_spline</code>.)</li> </ul> <p>Performance: first build takes seconds (due to exact quadrature at a few hundred (\\theta) nodes); subsequent runs are milliseconds (BSpline evaluation).</p> <p>Reproducibility: the cache pins the fitted spline; if the directory is read-only, the code still works (keeps the spline in memory).</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#spline-thermal-integrals-j_b-j_f-tests","title":"Spline Thermal Integrals (\\(J_b, J_f\\)) \u2014 Tests","text":"<p>This page documents the verification suite for the Spline Thermal Integrals. We validate that the spline surrogates <code>Jb_spline(\u03b8)</code> and <code>Jf_spline(\u03b8)</code> (with \\((\\theta=x^2=(m/T)^2)\\) ) reproduce the exact one-loop integrals and their \u03b8-derivatives,  and that the spline implementation is consistent with the B-spline basis from <code>helper_functions.Nbspl</code>.</p> <p>Plot styling used below</p> <ul> <li>Solid: exact curve (as a function of (x), with (\\(\u03b8=x^2\\))).</li> <li>Dashed: spline curve.</li> <li>Dots: collocation nodes (subset with (\\(x\\le 10\\))) used to fit the spline.</li> <li>see tests/finiteT/Spline_Thermal_Integrals for more</li> </ul> <p>We also print simple error metrics for quick checks.</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#test-1-spline-vs-exact-for-xin010","title":"Test 1 \u2014 Spline vs exact for (\\(x\\in[0,10]\\))","text":"<p>Compare <code>Jb_spline(\u03b8=x^2)</code> and <code>Jf_spline(\u03b8=x^2)</code> against <code>Jb_exact(x)</code> and <code>Jf_exact(x)</code> on the same (x)-grid.</p> <p>Expectation: curves overlap within quadrature/spline noise; max absolute error across the grid should be small.</p> <p>Boson \\((J_b)\\): exact vs spline (with nodes)</p> <p></p> <p>Fermion \\((J_f)\\): exact vs spline (with nodes)</p> <p></p> <pre><code>\"\"\"\n=== Test 1: Spline vs Exact for x \u2208 [0, 10] ===\nMax |J_b (spline) - J_b (exact)| over x\u2208[0,10]: 1.180e-03\nMax |J_f (spline) - J_f (exact)| over x\u2208[0,10]: 4.638e-05\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#test-2-derivatives-partial-jpartial-spline-vs-exact-via-chain-rule","title":"Test 2 \u2014 Derivatives: ( $\\partial J/\\partial \u03b8 $) (spline) vs exact via chain rule","text":"<p>The spline returns derivatives with respect to (\u03b8). We compare against the exact derivative with respect to (x) using the chain rule:</p> \\[\\frac{\\partial J}{\\partial \u03b8} = \\frac{\\partial J}{\\partial x}\\frac{\\partial x}{\\partial \u03b8} =  \\frac{1}{2\\sqrt{\u03b8}},\\frac{\\partial J}{\\partial x} \\quad(\\text{with } x=\\sqrt{\u03b8} \u03b8&gt;0)\\] <p>We avoid (x=0) (singularity in (1/(2x))) and take (\\(x\\in(10^{-3},10]\\)).</p> <p>Expectation: close agreement; small deviations can appear near the very small-(x) end where the chain rule magnifies numerical noise.</p> <p>Boson (\\(dJ_b/d\u03b8\\)): exact vs spline (with nodes)</p> <p></p> <p>Fermion (\\(dJ_f\\)/d\u03b8): exact vs spline (with nodes)</p> <p></p> <pre><code>\"\"\"\n=== Test 2: Derivatives \u2014 spline dJ/dtheta vs exact (chain rule) ===\nMax |dJ_b/d\u03b8 (spline) - dJ_b/d\u03b8 (exact)| over x\u2208(1e-3,10]: 3.156e-02\nMax |dJ_f/d\u03b8 (spline) - dJ_f/d\u03b8 (exact)| over x\u2208(1e-3,10]: 1.240e-03\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#test-3-compatibility-with-helper_functionsnbspl","title":"Test 3 \u2014 Compatibility with <code>helper_functions.Nbspl</code>","text":"<p>We reconstruct the spline value using the B-spline basis:</p> \\[s(\u03b8) = \\sum_i c_i,N_{i,k}(\u03b8)\\] <p>where (t) (knots), (c) (coefficients) and (k) (degree) come from the fitted <code>BSpline</code>. We evaluate <code>Nbspl(t, \u03b8, k) @ c</code> and compare to the direct <code>J*_spline(\u03b8)</code> evaluation for (\\(\u03b8\\in[0,100]\\)).</p> <p>Expectation: the two evaluations should match to near machine precision.</p> <p>Boson (\\(J_b\\)): BSpline vs Nbspl reconstruction</p> <p></p> <p>Fermion (\\(J_f\\)): BSpline vs Nbspl reconstruction</p> <p></p> <pre><code>\"\"\"\n=== Test 3: Compatibility with helper_functions.Nbspl ===\nMax |J_f (spline) - J_f (Nbspl rebuild)| on \u03b8\u2208[0,100]: 4.441e-16\nMax |J_b (spline) - J_b (Nbspl rebuild)| on \u03b8\u2208[0,100]: 2.220e-16\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#notes-plotting-details","title":"Notes &amp; plotting details","text":"<ul> <li>Input to the splines is always (\\(\u03b8=x^2\\)). For Tests 1\u20132, we limit the x-axis to ([0,10]) and filter the node dots to (\\(x\\le 10\\)) to avoid automatic axis expansion by far-right collocation nodes (which can reach (\\(x\\sim\\sqrt{\u03b8_{\\max}}\\))).</li> <li>Left boundary handling is clamp at (\\(\u03b8_{\\min}\\)); right boundary is zero for (\\(\u03b8&gt;\u03b8_{\\max}\\)), matching the legacy API (this is visible only if you probe beyond the fitted domain).</li> <li><code>Jf_exact(x)</code> returns complex (legacy); in the plots we show its real part, which is the physically relevant branch for real (x).</li> </ul>"},{"location":"modules/helper_functions/Miscellaneous_functions/","title":"Miscellaneous functions","text":""},{"location":"modules/helper_functions/Miscellaneous_functions/#set_default_args","title":"<code>set_default_args</code>","text":""},{"location":"modules/helper_functions/Miscellaneous_functions/#signature","title":"Signature","text":"<pre><code>set_default_args(func: Callable, inplace: bool = True, **kwargs) -&gt; Callable\n</code></pre>"},{"location":"modules/helper_functions/Miscellaneous_functions/#purpose","title":"Purpose","text":"<p>Update the default values of a function\u2019s parameters without changing its external behavior for explicit arguments. This is handy when a top-level API calls deeply nested functions but you want to tweak defaults of those inner functions without touching every call site. When placing the desired function you can create a new one (wrapper) or keep the existing one with the new default parameters.</p> <p>\u26a0\ufe0f Unlike <code>functools.partial</code>, this does not bind/force arguments at call time; it only changes what the function uses when an argument is omitted by the caller.</p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#parameters-returns-and-raises","title":"Parameters, returns and Raises","text":"<p>Parameters - func: the function (or unbound method) whose defaults will be updated.</p> <ul> <li>inplace:</li> <li> <p>True \u2014 mutate func in place by editing defaults (positional/positional-or-keyword) and kwdefaults (keyword-only).</p> </li> <li> <p>False \u2014 return a wrapper that applies the new defaults but leaves the original func untouched; the wrapper\u2019s signature is updated to show the new defaults.</p> </li> <li> <p>**kwargs: mapping of parameter_name=new_default_value.</p> </li> </ul> <p>Returns - If inplace=True: the same (possibly bound) object you passed (so existing references still work).</p> <ul> <li>If inplace=False: a new callable wrapper with updated signature.</li> </ul>"},{"location":"modules/helper_functions/Miscellaneous_functions/#raises","title":"Raises","text":"<ul> <li> <p>TypeError if func is not callable.</p> </li> <li> <p>ValueError if a passed name does not exist in func\u2019s signature.</p> </li> <li> <p>ValueError if a passed name exists but does not have a default (you cannot create a default where none exists).</p> </li> <li> <p>ValueError if you try to target args or *kwargs (variadics have no defaults).</p> </li> </ul>"},{"location":"modules/helper_functions/Miscellaneous_functions/#when-to-use-and-examples","title":"When to use and Examples","text":"<p>Use when you control a pipeline with deep calls and want different defaults globally for a nested function. Or when you want to expose a variant of a function with new defaults while keeping the original intact (use inplace=False).</p> <p>see tests/helper_functions/Miscellaneouys for more Examples <pre><code># 1) Positional + keyword-only defaults (in-place)\ndef f(a, b=2, c=3, *, d=4):\n    return a, b, c, d\n\nprint(f(10))           # -&gt; (10, 2, 3, 4)\n\n# Mutate the original defaults\nset_default_args(f, b=20, d=40)\n\nprint(f(10))           # -&gt; (10, 20, 3, 40)\n\n#2) Non in-place: return a wrapper with update defaults\ndef g(a, b=2, c=3, *, d=4):\n    return a, b, c, d\n\ng2 = set_default_args(g, inplace=False, b=99, d=111)\n\nprint(g(1))            # -&gt; (1, 2, 3, 4)   (original unchanged)\nprint(g2(1))           # -&gt; (1, 99, 3, 111) (wrapper uses new defaults)\n\n#3) Exapected errors (bad names / no default present)\ndef h(a, b, c=3):\n    return a, b, c\n\ntry:\n    set_default_args(h, x=1)          # No parameter `x` in `h`\nexcept ValueError as e:\n    print(\"Error:\", e)\n\ntry:\n    set_default_args(h, b=10)         # `b` exists but has NO default in the signature\nexcept ValueError as e:\n    print(\"Error:\", e)\n####################################\n</code></pre></p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#monotonic_indices","title":"<code>monotonic_indices</code>","text":""},{"location":"modules/helper_functions/Miscellaneous_functions/#signature_1","title":"Signature","text":"<pre><code>monotonic_indices(x: array_like) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Miscellaneous_functions/#purpose_1","title":"Purpose","text":"<p>Return the indices of a strictly increasing subsequence of x, always including the first and last elements. This is useful to \"repair\" a nearly-monotonic grid(e.g., a few spurious downward spikes) without sorting or regridding\u2014a common need before calling routines that require  strictly increasing coordinates (e.g., numerical differentiation or interpolation).  This function removes non-increasing points between the start and end of the array</p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#parameters-returns-and-raises_1","title":"Parameters, returns and Raises","text":"<p>Parameters - <code>x</code>: (array_like): Input 1D sequence (Numpy array).</p> <p>Returns - <code>np.ndaary</code> of shape (m,): Indices I such that <code>x[I]</code> is strictly increasing and <code>I[0]==0</code>, <code>I[-1]==len(x)-1</code> if x is increasing and the opposite if x is decreasing</p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#raises-assumptions","title":"Raises / Assumptions","text":"<ul> <li>If the overall trend is decreasing (<code>x[0] &gt; x[-1]</code>), the function works by reversing internally and then mapping the indices back</li> <li>assumes <code>len(x)&gt;=1</code> and that x is a ndarray.</li> </ul>"},{"location":"modules/helper_functions/Miscellaneous_functions/#when-to-use-and-examples_1","title":"When to use and Examples","text":"<ul> <li>Before calling finite difference derivatives which require strictly monotonic coordinate arrays.</li> <li>Before interpolation on grids that should be increasing but contain small gliches</li> <li>To quickly visualize or compute on a clean, mnotone subset of a noise 1D grid withoud sorting or re-sampling</li> </ul> <p>see the full test script in tests/helper_functions/Miscellaneouys for more</p> <p>Examples <pre><code># 1) Clean a mostly-increasing sequence with one bad spike\nx = [1, 2, 3, -1, 20, 19, 50]  # overall increasing, but has local decreases\nidx = monotonic_indices(x)\nx_clean = [x[i] for i in idx]\nprint(idx)      # e.g., [0, 1, 2, 4, 6]\nprint(x_clean)  #     -&gt; [1, 2, 3, 20, 50]  (strictly increasing, kept endpoints)\n\n# 3) Pre-conditioning before derivatives (deriv14, deriv23, deriv1n)\n# Suppose x is supposed to be increasing, but isn\u2019t strictly so due to noise.\nx = np.array([0.0, 0.1, 0.21, 0.20, 0.4, 0.5])  # small non-monotonic blip at 0.21 -&gt; 0.20\ny = np.sin(x)\n\nidx = monotonic_indices(x)\nx_mono = x[idx]\ny_mono = y[idx]\n# Now x_mono is strictly increasing and safe for derivative/interpolation routines.\n####################################\n</code></pre></p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#clamp_val","title":"<code>clamp_val</code>","text":""},{"location":"modules/helper_functions/Miscellaneous_functions/#signature_2","title":"Signature","text":"<pre><code>clamp_val(x: np.array, a: int, b: int) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Miscellaneous_functions/#purpose_2","title":"Purpose","text":"<p>Force (or \"clip\") all values of <code>x</code> to lie inside the closed interval <code>[min(a,b), max[a,b]]</code> This is useful to eliminate non-physical or unstable values (e.g., negative densities, probabilites outside <code>[0,1]</code>, or arguments to <code>log/sqrt</code> that must stay positive)</p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#parameters-returns-and-raises_2","title":"Parameters, returns and Raises","text":"<p>Parameters - <code>x</code> (array_like): Values to clamp. Any shape; will be returned as a NumPy array - <code>a,b</code>(int or array): Lower and upper bounds. Can be a scalar or a array. Bounds can be given in any order</p> <p>Returns - <code>np.ndaary</code>: Array with the same shape as <code>x</code>, where every entry is clipped to <code>[a,b]</code> interval. </p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#raises_1","title":"Raises","text":"<ul> <li>No custom exceptions.</li> </ul>"},{"location":"modules/helper_functions/Miscellaneous_functions/#when-to-use-and-examples_2","title":"When to use and Examples","text":"<ul> <li>When you want to enforce physical constraints, like negative densities, probabilites outside <code>[0,1]</code>, or arguments to <code>log/sqrt</code> that must stay positive</li> <li>To avoid numerical pathologies in interative algorithms</li> <li>Sanitizing imputs for pltting or interpolation routines</li> </ul> <p>see the full test script in tests/helper_functions/Miscellaneouys for more</p> <p>Examples <pre><code># 1) Simple clamping with scalar bounds\nx = [1, 2, 3, -1, 20, 19, 50]\ny = clamp_val(x, a=1, b=20)\nprint(y)  # -&gt; [ 1  2  3  1 20 19 20]\n\n# 3) Array bounds with broadcasting (per-column limits)\nX = np.array([[ -5.0, 0.2,  9.0],\n              [  0.5, 2.5, 11.0]])\nlow  = np.array([0.0, 0.0,  1.0])   # shape (3,)\nhigh = np.array([1.0, 2.0, 10.0])   # shape (3,)\nprint(clamp_val(X, low, high))\n# -&gt; [[0.  0.2 9. ]\n#     [0.5 2.  10.]]\n\n# 4) Prevent non-physical negatives before a sqrt\ndata = np.array([1e-6, -1e-8, 4.0])\nsafe = clamp_val(data, 0.0, np.inf)\nprint(np.sqrt(safe))  # well-defined\n</code></pre></p>"},{"location":"modules/helper_functions/Numerical_derivatives/","title":"Numerical Derivatives functions","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#fd_weights_1d","title":"<code>fd_weights_1d</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature","title":"Signature","text":"<pre><code>fd_weights_1d(x_nodes: np.ndarray, x0: float, der: int) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose","title":"Purpose","text":"<p>Computes the finite difference weithts that approximate the <code>der</code>-th derivatie of a function at point <code>x0</code> using an aribtraty stencil <code>x_nodes</code> (they do not need to be uniform or ordered). see fw_weights_jornal  if you want to know more.</p> <p>It is the \u201cengine\u201d that the derivative routines use to form linear combinations of the type</p> \\[f^{der}(x_0) \\approx \\sum_j w_j f(x_j) \\]"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises","title":"Parameters, returns and Raises","text":"<p>Parameters - <code>x_nodes</code> (<code>array like</code>, shape <code>(m,)</code>): Distinct stencil nodes; not required to be uniform or sorted - <code>x0</code> (<code>float</code>): Expansion point where the derivatie is approximated - <code>der</code> (<code>int</code>): Derivative order (0,1,2,...) Claim: In this project we typically use <code>der \u2208 {1,2}</code>, but the algorithm supports <code>0 &lt;= der &lt;= m-1</code></p> <p>Returns - <code>w</code> (<code>np,ndarray</code>, shape (<code>m,</code>)): Weights such that <code>f^(der)(x0) = \\sum_j w[j]*f(x_nodes[j])</code> </p>"},{"location":"modules/helper_functions/Numerical_derivatives/#raises","title":"Raises","text":"<ul> <li><code>ValueError</code> if <code>der&lt;0</code> or if <code>m-1&lt;der</code> (need at least <code>m=der+1</code> nodes)</li> <li><code>ZeroDivisionError</code> if two stencil nodes coincide (nodes must be distinct)</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#how-to-use-and-intuition","title":"How to use and Intuition","text":"<p>This function has no examples because it is called by others (e.g., deriv14, deriv1n, ...)</p> <p>intuition (Where the coefficients come from): Build the Lagrange interpolant \\(p(x)=\\sum_j f(x_j)L_j(x)\\) The weiths are precisely \\(w_j = L_j ^{der}(x_0)\\). Fornberg's algorithm computes these derivatives recuservely and stably filling a table <code>c[j,k]</code> (node j, derivative order k) and returning the column k=der chosen.</p> <p>Notes</p> <ul> <li>Typical accuracy (near-uniform stencils): \\((\\mathcal{O}(h^{m-der}))\\) for smooth functions, with h a characteristic spacing</li> <li>Polynomial exactness: Exact for all polynomials up do degree <code>m-1</code></li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#_stencil_indices","title":"<code>_stencil_indices</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_1","title":"Signature","text":"<pre><code>_stencil_indices(n: int, k: int, m: int) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_1","title":"Purpose","text":"<p>Returns a contiguos, length- <code>m</code> window of indices insied <code>[0,n-1]</code> that is as centered around <code>k</code> as possible. Near the boundaries is falls back to left or right aligned windowns. For even <code>m</code>, the window is biased one step to the left of perfect centering. Internal helper to choose the stencil for finite-difference weights/derivatives use it to obtain a centered window in the interior and one-sided windows near the boundaries.</p>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_1","title":"Parameters, returns and Raises","text":"<p>Parameters - <code>n (int)</code>: Total number of samples (valid indices are <code>0..n-1</code>) - <code>k (int)</code>: Target center index - <code>m (int)</code>: Stencil lenght (window size)</p> <p>Returns - <code>idx (np.ndarray[int])</code>, shape <code>(m,)</code>: Monotonically increasing, contiguous indices <code>start...start+m+1</code></p>"},{"location":"modules/helper_functions/Numerical_derivatives/#deriv14_const_dx","title":"<code>deriv14_const_dx</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_2","title":"Signature","text":"<pre><code>deriv14_const_dx(y: np.ndarray, dx: float = 1.0) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_2","title":"Purpose","text":"<p>Compute the first derivative along the last axis of <code>y</code> sampled on a uniform grid, using the 5-point, 4th-order finite-difference scheme. The routine is fully vectorized (no Python loops) and preserves the shape of <code>y</code>, making the function faster than <code>deriv14</code>.</p> <p>\u26a0\ufe0f Unlike <code>deriv14</code>, This function doesn't call <code>fd_weights_1d</code>, so it doesn't go through any loops and therefore calculates derivatives much faster.  The price to pay for this is providing a uniform grid</p> <ul> <li>Interior (k = 2..n\u22123): centered 5-point, 4th-order</li> </ul> \\[f'(x_k)\\ \\approx\\ \\frac{f_{k-2}-8f_{k-1}+8f_{k+1}-f_{k+2}}{12h}\\] <ul> <li>Boundaries: standard one-sided 5-point formulas (also 4th-order) for <code>k\u2208{0,1,n\u22122,n\u22121}</code>.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_2","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>y</code> (<code>array_like</code>, shape <code>(..., n)</code>): Samples on a uniform grid along the last axis.</li> <li><code>dx</code> (<code>float</code>, optional): Uniform spacing <code>h</code> between consecutive samples (default <code>1.0</code>).</li> </ul> <p>Returns</p> <ul> <li><code>dy</code> (<code>np.ndarray</code>, same shape as <code>y</code>): Numerical approximation to \u2202y/\u2202x along the last axis.</li> </ul> <p>Raises / Assumptions</p> <ul> <li><code>ValueError</code> if <code>y.shape[-1] &lt; 5</code> (needs at least five points).</li> <li>Assumes uniform spacing with finite <code>dx</code> and monotonic (increasing or decreasing).</li> <li>\u26a0\ufe0f Error is \\(\\mathcal{O}(h^4)\\) in the interior; at the ends it remains 4th-order but with typically larger constants.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples","title":"When to use and Examples","text":"<p>Use when your data are on a uniform grid and you want a high-accuracy first derivative with a small, explicit stencil and fast vectorized implementation.</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples</p> <ul> <li> <p>Derivative of (sin) using deriv14_const_dx </p> </li> <li> <p>Error of the derivative </p> </li> </ul> <pre><code>'''\n=== Test derivative: Uniform grid, first derivative (sin profile) ===\nGrid: N=201, dx=3.142e-02, function: sin(kx), k=1.0\nMax abs error (dy): 1.945e-07  (expected ~O(h^4) ~ 9.7e-07)\nNote: boundary stencils are one-sided; error is typically larger at the ends than in the interior.\n'''\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#deriv14","title":"<code>deriv14</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_3","title":"Signature","text":"<pre><code>deriv14(y: np.ndarray, x: np.ndarray) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_3","title":"Purpose","text":"<p>Compute the first derivative along the last axis of <code>y</code> sampled at non-uniform coordinates <code>x</code>, using 5-point finite-difference stencils. The routine builds Fornberg weights per local stencil, yielding 4th-order accuracy in the interior on smooth data (with one-sided high-order stencils at the boundaries). Works for strictly increasing or decreasing <code>x</code>!! .</p> <p>\u26a0\ufe0f Unlike <code>deriv14_const_dx</code>, This function call <code>fd_weights_1d</code>, so it goes through many loops and therefore calculates derivatives slower. What gains in return is the ability to compute on an arbitrary non-uniform grid</p>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_3","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>y</code> (<code>array_like</code>, shape <code>(..., n)</code>): Function values along the last axis.</li> <li><code>x</code> (<code>array_like</code>, shape <code>(n,)</code>): Sample locations, strictly monotonic (increasing or decreasing). Requires <code>n \u2265 5</code>.</li> </ul> <p>Returns</p> <ul> <li><code>dy</code> (<code>np.ndarray</code>, same shape as <code>y</code>): Numerical approximation to \u2202y/\u2202x along the last axis.</li> </ul> <p>Raises / Assumptions</p> <ul> <li><code>ValueError</code> if <code>x</code> is not 1D, if <code>n &lt; 5</code>, or if <code>x</code> is not strictly monotonic.</li> <li>Interior uses centered windows <code>[k-2..k+2]</code>; endpoints use one-sided 5-point stencils.</li> <li>Interior truncation error is typically \\(\\mathcal{0}(h^4)\\) on near-uniform meshes (with \\(h\\) a typical spacing), while boundary errors have larger constants.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#notes","title":"Notes","text":"<ul> <li>Uses <code>fd_weights_1d</code> to obtain exact polynomial reproductions up to degree 4 on each stencil.</li> <li>Vectorized accumulation via <code>np.tensordot</code> along the last axis.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples_1","title":"When to use and Examples","text":"<p>Use when your samples lie on a non-uniform 1D grid and you want high order interior accuracy without resampling to a uniform mesh.</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples (same structure as <code>deriv14_const_dx</code>; you can adapt the <code>x</code> grid to be non-uniform):</p> <p>Examples</p> <ul> <li>Derivative of (exp) using deriv14 </li> </ul> <pre><code>'''\n=== Test 3: Non-uniform grid, first derivatives (exp profile) ===\nNon-uniform grid size: N=161\nMax abs error (dy):  6.659e-09\n=== Test 6: Expected error cases ===\nToo few points (deriv14): deriv14 requires at least 5 samples.\nx not 1D (deriv14): x must be 1D\nNon-monotonic x (deriv14): x must be strictly monotonic (increasing or decreasing).\n'''\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#deriv23","title":"<code>deriv23</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_4","title":"Signature","text":"<pre><code>deriv23(y: np.ndarray, x: np.ndarray) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_4","title":"Purpose","text":"<p>Same algorithmic idea, assumptions, and stencil policy as <code>deriv14</code>, but for the second derivative on a non-uniform 1D grid. Uses 5-point stencils with Fornberg weights (<code>der=2</code>): centered in the interior, one-sided near boundaries. Accuracy in smooth problems is typically 3rd\u20134th order in the interior (exact for polynomials up to degree 4 on uniform stencils).</p>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_4","title":"Parameters, returns and Raises","text":"<ul> <li>Parameters, shape constraints, monotonicity checks, and error handling are the same pattern as <code>deriv14</code>, with <code>der=2</code>.</li> <li>Returns an array with the same shape as <code>y</code>, containing \\(\\partial y^2/ \\partial x^2\\) along the last axis.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples_2","title":"When to use and Examples","text":"<p>Use when you need second derivatives on non-uniform grids with high-order interior accuracy and robust boundary handling.</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples</p> <ul> <li>Second Derivative of (exp) using deriv23 </li> </ul> <pre><code>'''\n=== Test 3: Non-uniform grid, second derivatives (exp profile) ===\nNon-uniform grid size: N=161\nMax abs error (d2y): 2.625e-06\n\n=== Test 6: Expected error cases ===\nToo few points (deriv23): deriv23 requires at least 5 samples.\nx not 1D (deriv23): x must be 1D\nNon-monotonic x (deriv23): x must be strictly monotonic (increasing or decreasing).\n'''\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#deriv23_const_dx","title":"<code>deriv23_const_dx</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_5","title":"Signature","text":"<pre><code>deriv23_const_dx(y: np.ndarray, dx: float = 1.0) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_5","title":"Purpose","text":"<p>Same idea as <code>deriv14_const_dx</code>, but computing the second derivative on a uniform grid using the 5-point, 4th-order scheme. Interior uses the standard centered 5-point formula,</p> \\[ f''(x_k)\\approx\\frac{-f_{k-2}+16f_{k-1}-30f_k+16f_{k+1}-f_{k+2}}{12\\,h^2}, \\] <p>with one-sided 5-point stencils at the boundaries</p>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_5","title":"Parameters, returns and Raises","text":"<ul> <li>Parameters and return shape mirror <code>deriv14_const_dx</code> (but for \\(\\partial y^2/ \\partial x^2\\)). Requires at least 5 points along the last axis; raises <code>ValueError</code> otherwise.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples_3","title":"When to use and Examples","text":"<p>Use for uniform grids when you want a fast, vectorized second derivative with high accuracy and small stencil.</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples</p> <ul> <li> <p>Second Derivative of (sin) using deriv23_const_dx </p> </li> <li> <p>Error of the second derivative </p> </li> </ul> <pre><code>'''\n=== Test 2: Uniform grid, second derivative (sin profile) ===\nMax abs error (d2y): 2.580e-05  (expected ~O(h^3) at edges ~ 3.1e-05)\nNotes: The interior is still O(h^4) (see graph)\n'''\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#deriv1n","title":"<code>deriv1n</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_6","title":"Signature","text":"<pre><code>deriv1n(y: np.ndarray, x: np.ndarray, n: int) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_6","title":"Purpose","text":"<p>General first-derivative on a non-uniform 1D grid using an (n+1)-point stencil with Fornberg weights. Same overall idea/policies as <code>deriv14</code> (centered interior, one-sided near boundaries), but here the stencil size is configurable via <code>n</code> (so <code>m = n+1</code> points).  For smooth data on near-uniform meshes, interior truncation error scales \\((\\approx \\mathcal{O}(h^n))\\) (e.g., <code>n=4</code> \u2192 5-point, ~4th-order like <code>deriv14</code>).</p> <p>What\u2019s different vs. <code>deriv14</code> / <code>deriv14_const_dx</code>:</p> <ul> <li>You choose accuracy/stencil size with <code>n</code> (recommended 4 \u2264 n \u2264 8: good accuracy vs. stability).</li> <li>Larger stencils can be more sensitive to noise and wider spacing; extremely irregular nodes may degrade conditioning.</li> <li>Uses <code>_stencil_indices</code> to pick a centered window when possible, otherwise one-sided near edges.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises-briefly","title":"Parameters, returns and Raises (briefly)","text":"<ul> <li><code>y</code>: values along the last axis <code>(..., N)</code>.</li> <li><code>x</code>: strictly monotonic 1D array <code>(N,)</code>; requires <code>N \u2265 n+1</code>.</li> <li><code>n</code>: desired accuracy order; stencil size is <code>m = n+1</code>.</li> <li>Returns <code>dy</code> with the same shape as <code>y</code> (\u2202y/\u2202x along the last axis).</li> <li>Raises <code>ValueError</code> if <code>x</code> not 1D/monotonic, if <code>N &lt; n+1</code>, or if <code>n &lt; 2</code>.</li> <li>Internally: Fornberg weights with <code>der=1</code>, accumulated via <code>np.tensordot</code>.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples_4","title":"When to use and Examples","text":"<p>When you want to dial precision (and stencil width) for first derivatives on non-uniform grids without resampling.</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples</p> <pre><code>\"\"\"\n=== Test 4: Accuracy vs stencil size (deriv1n on sin) ===\nn=4 (stencil m=5): max abs error = 2.964e-07\nn=6 (stencil m=7): max abs error = 2.573e-10\nn=8 (stencil m=9): max abs error = 2.558e-13\nExpected: error generally decreases as stencil size increases (for smooth functions).\n\"\"\"\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#gradientfunction-callable-class","title":"<code>gradientFunction</code> (callable class)","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_7","title":"Signature","text":"<pre><code>ArrayLike = Union[np.ndarray, float]\n\nclass gradientFunction:\n    def __init__(self, f: Callable, eps: ArrayLike, Ndim: int, order: int = 4) -&gt; None: ...\n    def __call__(self, x: ArrayLike, *args, **kwargs) -&gt; np.ndarray: ...\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_7","title":"Purpose","text":"<p>Build a callable gradient operator for a scalar field \\(f:\\mathbb{R}^{N}\\to\\mathbb{R}\\) using finite differences of order 2 or 4, with per-axis steps <code>eps</code>. Once constructed, <code>gradientFunction(...)</code> behaves like a function: <code>df(x) \u2192 \u2207f(x)</code>.</p> <p>Intuition: along each coordinate \\(i\\), evaluate \\(f\\) at symmetrically shifted points \\(x \\pm \\alpha\\,\\varepsilon_i\\,\\hat e_i\\) (second or fourth-order central differences).  Combine the batched evaluations with the precomputed coefficients to get the \\(i\\)-th partial derivative. All axes are processed in one vectorized call.</p>"},{"location":"modules/helper_functions/Numerical_derivatives/#why-a-class-not-just-a-function","title":"Why a class (not just a function)?","text":"<ul> <li>Precomputation &amp; reuse: offsets and peraxis coefficients depend only on <code>(eps, Ndim, order)</code>. The class builds them once and reuses across many calls \u2192 less Python overhead in tight loops (optimization, sampling, PDE steps).</li> <li>Stateful configuration: keeps <code>f</code>, <code>Ndim</code>, <code>eps</code>, <code>order</code> together; the result is a callable object that plugs cleanly anywhere a function is expected.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_6","title":"Parameters, returns and Raises","text":"<p><code>__init__(f, eps, Ndim, order=4)</code></p> <ul> <li><code>f</code> (<code>callable</code>): scalar field; must accept arrays with last axis of length <code>Ndim</code> (any leading batch axes allowed) and return an array of the same leading shape (scalar per point).</li> <li><code>eps</code> (<code>float | array_like</code>): FD step(s). Scalar is broadcast to all axes; or pass a length-<code>Ndim</code> array for peraxis steps.</li> <li><code>Ndim</code> (<code>int</code>): dimensionality of the input points.</li> <li><code>order</code> (<code>{2,4}</code>): FD accuracy. <code>2</code> uses \\([-1,+1]\\) with coefficients \\([-1/2,+1/2]\\); <code>4</code> uses ([-2,-1,+1,+2]/12<code>with coefficients</code>[+1,-8,+8,-1]/12`.</li> </ul> <p><code>__call__(x, *args, **kwargs)</code></p> <ul> <li><code>x</code> (<code>array_like</code>, shape <code>(..., Ndim)</code>): evaluation points (1 or many).</li> <li>Returns <code>grad</code> (<code>np.ndarray</code>, shape <code>(..., Ndim)</code>): gradient \\(\\nabla f(x)\\).</li> <li>Any extra <code>*args/**kwargs</code> are forwarded to <code>f</code>.</li> </ul> <p>Raises / Assumptions</p> <ul> <li><code>ValueError</code> if <code>order \u2209 {2,4}</code>, if <code>eps</code> is not scalar or <code>(Ndim,)</code>, if <code>x</code>\u2019s last axis \u2260 <code>Ndim</code>, or if <code>Ndim</code> is inconsistent.</li> <li><code>f</code> must be vectorized enough to broadcast over the added stencil axes; the class constructs inputs of shape <code>(..., order, Ndim, Ndim)</code> and expects outputs <code>(..., order, Ndim)</code> (scalar per displaced point).</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#notes_1","title":"Notes","text":"<ul> <li>Accuracy vs. step size: truncation error decreases with smaller <code>eps</code>, but round off grows pick <code>eps</code> consistent with the scale of <code>x</code> and <code>f</code> (a common rule of thumb: start near \\(\\sqrt{\\varepsilon_\\text{mach}} \\times \\text{scale}\\) for order-2, and somewhat larger for order-4).</li> <li>Anisotropic steps: use an <code>eps</code> vector to reflect different physical scales per axis.</li> <li>Performance/memory: very large <code>Ndim</code> or huge batches may increase temporary array sizes; if needed, evaluate in tiles.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples_5","title":"When to use and Examples","text":"<p>Use when you need a drop-in gradient for a black-box scalar function (e.g., potentials \\(V(\\phi)\\) in multi-field models, without deriving/maintaining analytic gradients. It\u2019s especially handy inside optimizers, line searches, or field evolution steps).</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples</p> <ul> <li> <p>Gradient of \\(V(x,y)=\\sin(x)*\\cos(y) [order=4]\\) </p> </li> <li> <p>Gradient field for intuition </p> </li> </ul> <pre><code>\"\"\"\n=== Test 7: Gradient on V(x,y) = sin(x) * cos(y) (order=4) ===\nGrid: 101x101, eps=1e-4 (per axis), order=4\nMax |grad error| = 4.145e-12,  Mean |grad error| = 1.757e-12\nNotes: O(h^3) at edges\n\"\"\"\n</code></pre> <ul> <li>Convergence with eps (1D) </li> </ul> <p><pre><code># Convergence is faster with higher order, as expected\n</code></pre> - Physical example: Electrostatic Field </p> <ul> <li>Physical example: 2D anisotropic harmonic oscillator </li> </ul> <pre><code>\"\"\"\n=== Test 11: Electrostatic potential (softened) and field via gradientFunction ===\nRel. error stats away from charges: max=1.394e-09, mean=2.493e-11\n\n=== Test 12 (bonus): 2D anisotropic harmonic oscillator with rkqs and \u2207V ===\nEnergy stats: Emin=1.000000, Emax=1.000001, \u0394E=6.510e-07```\n\"\"\"\n</code></pre> <pre><code>\"\"\"\n=== Test 13: Expected error cases (gradient) ===\nInvalid order (gradientFunction): order must be 2 or 4\nWrong eps shape (gradientFunction): `eps` must be scalar or have shape (2,)\nx last axis mismatch (gradientFunction): Last axis of x must have length Ndim=2\nNon-scalar f (gradientFunction): ValueError('operands could not be broadcast together with shapes (4,4,2,2) (4,2) ')\n\"\"\"\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#hessianfunction-callable-class","title":"<code>hessianFunction</code> (callable class)","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_8","title":"Signature","text":"<pre><code>class hessianFunction:\n    def __init__(self, f: Callable, eps: ArrayLike, Ndim: int, order: int = 4) -&gt; None: ...\n    def __call__(self, x: ArrayLike, *args, **kwargs) -&gt; np.ndarray: ...\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_8","title":"Purpose","text":"<p>Build a callable Hessian operator for a scalar field \\(f:\\mathbb{R}^N\\!\\to\\!\\mathbb{R}\\) using finite differences of order 2 or 4 with per-axis steps <code>eps</code>. Once constructed, <code>hessianFunction(...)</code> acts like a function: <code>hf(x) \u2192 H(x)</code> with shape <code>(..., Ndim, Ndim)</code>.</p> <p>Intuition (how entries are formed): \u2022 Diagonal terms \\(H_{ii}\\) use 1D second-derivative stencils along axis \\(i\\) (order-2: 3-point; order-4: 5-point). \u2022 Off-diagonal terms \\(H_{ij}\\) with \\(i\\neq j\\) use the tensor product of two first-derivative stencils (one in \\(i\\), one in \\(j\\)), i.e.</p> \\[ \\frac{\\partial^2 f}{\\partial x_i\\,\\partial x_j}(x) \\;\\approx\\; \\sum_{a,b}\\frac{c^{(1)}_a}{\\varepsilon_i}\\,\\frac{c^{(1)}_b}{\\varepsilon_j}\\; f\\!\\big(x + a\\,\\varepsilon_i\\,\\hat e_i + b\\,\\varepsilon_j\\,\\hat e_j\\big), \\] <p>where \\(c^{(1)}\\) are the central-difference coefficients of order 2 or 4. The class precomputes all shifts and weights and then evaluates <code>f</code> in batched fashion.</p>"},{"location":"modules/helper_functions/Numerical_derivatives/#why-a-class-not-just-a-function_1","title":"Why a class (not just a function)?","text":"<ul> <li>Precomputation &amp; reuse: shifts/weights depend only on <code>(eps, Ndim, order)</code>. The class builds them once and reuses across many calls \u2192 less overhead in inner loops (optimizers, Newton steps, variational solvers).</li> <li>Stateful configuration: keeps <code>f</code>, <code>Ndim</code>, <code>eps</code>, <code>order</code> together; exposes a clean callable API.</li> <li>Vectorized batching: each diagonal/off-diagonal block is evaluated by feeding a whole bundle of shifted points to <code>f</code> at once, then combining with the stored weights.</li> <li>Symmetry by construction: it sets \\(H_{ij}\\!=\\!H_{ji}\\) after computing \\(i&gt;j\\).</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_7","title":"Parameters, returns and Raises","text":"<p><code>__init__(f, eps, Ndim, order=4)</code></p> <ul> <li><code>f</code> (<code>callable</code>): scalar field; must accept arrays with last axis size <code>Ndim</code> (any leading batch dims allowed) and return a scalar per point (same leading shape).</li> <li><code>eps</code> (<code>float | array_like</code>): FD step size(s). Scalar broadcasts to all axes; or pass a length-<code>Ndim</code> array for anisotropic steps.</li> <li><code>Ndim</code> (<code>int</code>): dimensionality of the input points.</li> <li><code>order</code> (<code>{2,4}</code>): finite-difference accuracy (order-2 or order-4 central stencils).</li> </ul> <p><code>__call__(x, *args, **kwargs)</code></p> <ul> <li><code>x</code> (<code>array_like</code>, shape <code>(..., Ndim)</code>): evaluation points.</li> <li>Returns <code>H</code> (<code>np.ndarray</code>, shape <code>(..., Ndim, Ndim)</code>): the Hessian at <code>x</code>.</li> <li>Any extra <code>*args/**kwargs</code> are forwarded to <code>f</code>.</li> </ul> <p>Raises / Assumptions</p> <ul> <li><code>ValueError</code> if <code>order \u2209 {2,4}</code>, if <code>eps</code> is not scalar or <code>(Ndim,)</code>, or if <code>x</code>\u2019s last axis \u2260 <code>Ndim</code>.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#notes_2","title":"Notes","text":"<ul> <li>Stencils used:   \u2022 Order-2: first-deriv offsets \\([-1,+1]\\) with coeffs \\([-1/2,+1/2]\\); second-deriv offsets \\([-1,0,+1]\\) with coeffs \\([1,-2,1]\\).   \u2022 Order-4: first-deriv offsets \\([-2,-1,+1,+2]\\) with coeffs \\([+1,-8,+8,-1]/12\\); second-deriv offsets \\([-2,-1,0,+1,+2]\\) with coeffs \\([-1,16,-30,16,-1]/12\\).</li> <li>Work per call (per point): roughly \\(\\sum_i m_2\\) (diagonals) + \\(\\sum_{i&gt;j} m_1^2\\) (off-diagonals) function evaluations, where \\(m_1\\) and \\(m_2\\) are the first/second-derivative stencil lengths (2 or 4 \u2192 \\(m_1=2,4\\); \\(m_2=3,5\\)). These are batched per block to reduce Python overhead.</li> <li>Accuracy vs step size: smaller <code>eps</code> reduces truncation error but increases round-off sensitivity; pick <code>eps</code> commensurate with scales of <code>x</code> and <code>f</code>.</li> <li>Anisotropic physics: per-axis <code>eps</code> is useful when coordinates have different natural scales.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples_6","title":"When to use and Examples","text":"<p>Use when you need a drop-in Hessian for a black-box scalar potential\u2014e.g., multi-field potentials \\(V(\\phi)\\) in phase-transition scans\u2014without deriving analytic second derivatives. Useful in Newton/Quasi-Newton methods, curvature analysis, and stability checks.</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples</p> <pre><code>\"\"\"\n=== Test 8: Hessian exactness on quadratic form (order=4) ===\nMax |H - A| = 1.426e-06,  Mean |H - A| = 7.628e-08\nExpected: near machine precision for smooth quadratics with small eps.\n=== Test 9: Hessian with mixed terms (order=4) ===\nGrid 60x60, eps=[1e-4,3e-4]: max |H_num - H_ex| = 7.461e-07\n=== Test 13: Expected error cases (hessian) ===\nInvalid order (hessianFunction): order must be 2 or 4\nNon-scalar f (hessianFunction): ValueError('operands could not be broadcast together with shapes (4,16,2) (16,) ')\n\"\"\"\n</code></pre>"},{"location":"modules/helper_functions/Numerical_integration/","title":"Numerical Integration functions","text":""},{"location":"modules/helper_functions/Numerical_integration/#_rkck","title":"<code>_rkck</code>","text":""},{"location":"modules/helper_functions/Numerical_integration/#signature","title":"Signature","text":"<pre><code>_rkck(y: np.ndarray, dydt: np.ndarray, t: float,f: Callable, dt: float, args: tuple = ()) -&gt; Tuple[np.ndarray, np.ndarray]\n</code></pre>"},{"location":"modules/helper_functions/Numerical_integration/#purpose","title":"Purpose","text":"<p>Perform one embedded Runge-Kutta Cash-Karp step (the classic 5th-order method with a 4th-order ebedded estimate)</p>"},{"location":"modules/helper_functions/Numerical_integration/#parameters-returns-and-raises","title":"Parameters, returns and Raises","text":"<p>Parameters - y  (array_like): Current state at time <code>t</code>. - dydt (array_like): Derivative <code>dy/dt</code> at (y, t), usually <code>f(y, t)</code>. - t (float): Current integration variable (independent variable). - f (callable): Derivative function with signature <code>f(y, t, *args)</code>. - dt (float): Step size. - args (tuple, optional) Extra positional arguments for f (usualy defaults)</p> <p>Returns - <code>dyout</code> (ndarray): The 5th-order increment \u0394y to update the state: y_next \u2248 y + dyout. - <code>yerr</code> (ndarray): An estimate of the local truncation error for the increment (the difference between 5th and 4th order formulas)</p>"},{"location":"modules/helper_functions/Numerical_integration/#raises","title":"Raises","text":"<ul> <li>No custom exceptions.</li> </ul>"},{"location":"modules/helper_functions/Numerical_integration/#when-to-use","title":"When to use","text":"<p>This function is used by the function below (<code>rkqs</code>) to solve the desired ODE and therefore is not called directly.  (That's why there are no examples of it)</p>"},{"location":"modules/helper_functions/Numerical_integration/#rkqs","title":"<code>rkqs</code>","text":""},{"location":"modules/helper_functions/Numerical_integration/#signature_1","title":"Signature","text":"<pre><code>rkqs(y: np.ndarray, dydt: np.ndarray, t: float, f: callable, dt_try: float, epsfrac: float, epsabs: float, args: tuple = ()) -&gt; _rkqs_rval\n</code></pre>"},{"location":"modules/helper_functions/Numerical_integration/#purpose_1","title":"Purpose","text":"<p>Perform one adpative step of the (RKCK) method with error control It's the acceptance/rejection + step control wrapper around the low-leve <code>_rkck</code> step. The function has larger steps when the error is very small and decreases the step when the error becomes large.  This ensures accuracy and speed in solving the integral.</p>"},{"location":"modules/helper_functions/Numerical_integration/#parameters-returns-and-raises_1","title":"Parameters, returns and Raises","text":"<p>Parameters - Same as _rkck (y, dydt, t, f, dt and args) plus: - dt_try  (float): Initial step-size guess  - epsfrac (float): Relative error tolerance (dimensionless) - epsabs (float): Absolute error tolerance (same units as <code>y</code>)</p> <p>Returns - named tuple <code>_rkqs_rval[Delta)y, Delta_t, dtxt]</code> - <code>Delta_y</code> (ndarray): 5th-order increment to advance the state: y_next \u2248 y + Delta_y.  - <code>Delta_t</code> (float): The actual step size used on the accepted step (may be smaller than dt_try). - <code>dtxt</code> (float): A suggested step size for the next call (based on the observed error)</p>"},{"location":"modules/helper_functions/Numerical_integration/#raises_1","title":"Raises","text":"<ul> <li><code>IntegrationError</code>: If the step size underflows numerically (i.e., <code>t+dt==t</code>) after repeated shrinking)</li> </ul>"},{"location":"modules/helper_functions/Numerical_integration/#how-to-use-and-examples","title":"How to use and Examples","text":"<ul> <li>The error is handled as follows:</li> <li>With the relative error <code>epsfrac</code> evaluate <code>denom = y * epsfrac</code></li> <li>With the absolute error <code>epsabs</code> evaluate <code>err_ratio = |yerr| / max(denom, epsabs)</code></li> <li>Then take errmax = max(err_ratio) and <code>if errmax &lt;1</code> accept pace. Otherwise compute a reduced dt until accepted</li> <li> <p>After acceptance, propose dtnxt (x5 if the step was extremely accurate and reduced if the error was not so accurate)</p> </li> <li> <p>Start with <code>epsfrac ~ 1e-6</code> (relative) and <code>epsfrac ~ 1e-9</code> (absolute) for typical float64 runs.</p> </li> <li>There is no predefined formula for errors, just trial and error with the desired ODE</li> </ul> <p>see the full test script in tests/helper_functions/Numerical_integration for more There are one more image and two more prints examples there. Examples <pre><code># Minimal usage pattern (pseudo-code)\ny = y0.copy()\nt = t0\ndt = dt_try\nwhile t &lt; t_end:\n    dydt = f(y, t, *args)\n    Delta_y, Delta_t, dtnxt = rkqs(y, dydt, t, f, dt, epsfrac, epsabs, args)\n    y += Delta_y\n    t += Delta_t\n    dt = dtnxt\n</code></pre> - Harmonic oscillator test images </p> <ul> <li>Adaptive step sizes </li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/","title":"Interpolation Functions","text":""},{"location":"modules/helper_functions/interpolation_functions/#makeinterpfuncs","title":"<code>makeInterpFuncs</code>","text":""},{"location":"modules/helper_functions/interpolation_functions/#signature","title":"Signature","text":"<pre><code>makeInterpFuncs(y0, dy0, d2y0, y1, dy1, d2y1) -&gt; Tuple[Callable, Callable]\n</code></pre>"},{"location":"modules/helper_functions/interpolation_functions/#purpose","title":"Purpose","text":"<p>Build a quintic (5th-degree) interpolant on the normalized domain x \u2208 [0,1] that matches value, first, and second derivatives at both endpoints:</p> \\[ f(0)=y_0,\\quad f'(0)=d y_0,\\quad f''(0)=d^2 y_0,\\qquad f(1)=y_1,\\quad f'(1)=d y_1,\\quad f''(1)=d^2 y_1. \\] <p>It returns two callables:</p> <ul> <li><code>f(x)</code>: the interpolating polynomial,</li> <li><code>df(x)</code>: its first derivative.</li> </ul> <p>Intuition: a quintic has 6 coefficients, exactly the number of endpoint constraints (value/slope/curvature at 0 and 1). We fix three coefficients from the left-end constraints and solve a small 3\u00d73 linear system for the remaining ones using the right-end constraints. This is the classic Hermite-type two-point interpolation with up to second derivatives.</p>"},{"location":"modules/helper_functions/interpolation_functions/#parameters-returns-and-raises","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>y0, dy0, d2y0</code>: value, 1st and 2nd derivative at <code>x=0</code>.</li> <li><code>y1, dy1, d2y1</code>: value, 1st and 2nd derivative at <code>x=1</code>.</li> </ul> <p>Returns</p> <ul> <li><code>f</code> (<code>callable</code>): evaluates the quintic at scalar/array <code>x</code> in <code>[0,1]</code>.</li> <li><code>df</code> (<code>callable</code>): evaluates the first derivative at the same <code>x</code>.</li> </ul> <p>(No custom exceptions; the internal 3\u00d73 system has a fixed, well-conditioned matrix.)</p>"},{"location":"modules/helper_functions/interpolation_functions/#notes","title":"Notes","text":"<ul> <li> <p>The polynomial is \\(p(x)=a_0+a_1 x+a_2 x^2+a_3 x^3+a_4 x^4+a_5 x^5\\).</p> </li> <li> <p>From the left endpoint:</p> \\[a_0=y_0,\\quad a_1= d y_0,\\quad a_2=\\tfrac{1}{2} d^2 y_0\\] </li> <li> <p>The remaining \\((a_3,a_4,a_5)\\) come from the right endpoint via     a fixed 3\u00d73 system (hard-coded matrix), solved against the residuals     after subtracting the known \\(a_0,a_1,a_2\\).</p> </li> <li>Both <code>f</code> and <code>df</code> use Horner\u2019s scheme for numeric stability and speed.</li> <li>To interpolate over an arbitrary interval \\([x_a,x_b]\\), map \\(x\\) to   \\(s=(x-x_a)/(x_b-x_a)\\in[0,1]\\). Endpoint derivatives must be scaled:</li> </ul> \\[\\frac{df}{dx}\\Big|_{x_a} = \\frac{1}{h}\\frac{df}{ds}\\Big|_{s=0}\\quad \\frac{d^2 f}{dx^2}\\Big|_{x_a} = \\frac{1}{h^2}\\frac{d^2 f}{ds^2}\\Big|_{s=0}\\] <p>with \\(h=x_b-x_a\\) (same at the right end).</p>"},{"location":"modules/helper_functions/interpolation_functions/#when-to-use-and-examples","title":"When to use and examples","text":"<p>Use when you need a smooth segment with continuous value, slope, and curvature at both ends (e.g., path stitching, potential profiles, or boundary-matched trajectories, without overshoot typical of low-order polynomials).</p> <p>see the full test script in tests/helper_functions/interpolation_functions for more</p> <p>Example</p> <pre><code># Endpoint constraints on x in [0,1]\ny0, dy0, d2y0 = 1.0, -0.5,  0.75\ny1, dy1, d2y1 = 2.0,  0.8, -0.25\nf, df = makeInterpFuncs(y0, dy0, d2y0, y1, dy1, d2y1)\n</code></pre> <ul> <li>Quintic Interpolation </li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#cubicinterpfunction","title":"<code>cubicInterpFunction</code>","text":""},{"location":"modules/helper_functions/interpolation_functions/#signature_1","title":"Signature","text":"<pre><code>class cubicInterpFunction:\n    def __init__(self, y0, dy0, y1, dy1) -&gt; None: ...\n    def __call__(self, t) -&gt; np.ndarray: ...\n</code></pre>"},{"location":"modules/helper_functions/interpolation_functions/#purpose_1","title":"Purpose","text":"<p>Cubic two-point interpolant on the normalized parameter t \u2208 [0,1] that matches value and first derivative at both ends. Implements the B\u00e9zier form that is algebraically equivalent to Hermite interpolation with endpoint slopes.</p> <p>Intuition: a cubic has 4 degrees of freedom\u2014exactly the endpoint value/tangent pair at t=0 and t=1. Writing it in B\u00e9zier form makes the geometry transparent: the middle control points are just the endpoints nudged in the tangent directions.</p>"},{"location":"modules/helper_functions/interpolation_functions/#parameters-returns-and-raises_1","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>y0, dy0</code>: value and slope at <code>t=0</code>.</li> <li><code>y1, dy1</code>: value and slope at <code>t=1</code>.   All can be scalar or array-like (vectors/fields); shapes must be broadcastable to a common shape.</li> </ul> <p>Returns</p> <ul> <li>Calling the instance: <code>y = cubic(t)</code> evaluates the interpolant at scalar/array <code>t</code>; the output shape follows <code>t</code> and the shapes of <code>y0/y1</code>.</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#notes_1","title":"Notes","text":"<ul> <li>B\u00e9zier control points (from Hermite data):</li> </ul> <p>$$P_0 = y_0,\\quad P_1 = y_0 + \\tfrac{1}{3}\\,d y_0,\\quad P_2 = y_1 - \\tfrac{1}{3}\\,d y_1,\\quad P_3 = y_1 $$</p> <p>and</p> <p>$$B(t)=(1-t)^3P_0+3(1-t)^2 t P_1+3(1-t)t^2 P_2+t^3 P_3 $$</p> <ul> <li>Endpoint slopes &amp; reparameterization: if you want slopes with respect to a physical coordinate \\(x\\in[x_a,x_b]\\) (not \\(t\\)), map \\(t=(x-x_a)/h\\) with \\(h=x_b-x_a\\) and set   <code>dy0 = (dy/dx at x_a) * h</code>, <code>dy1 = (dy/dx at x_b) * h</code>.</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#when-to-use-and-examples_1","title":"When to use and examples","text":"<p>Use when you need a compact, slope controlled segment between two states\u2014great for smooth paths, schedules, or boundary-matched profiles\u2014without the extra curvature constraints of the quintic.</p> <p>see the full test script in tests/helper_functions/interpolation_functions.py for more</p> <p>Example</p> <p><pre><code># 2) Cubic two-point interpolation (Bezier/Hermite): slope control\ny0, y1 = 0.0, 1.0\ndy0, dy1 = 2.0, -1.0\ncubic = cubicInterpFunction(y0, dy0, y1, dy1)\nts = np.linspace(0, 1, 400)\nys = cubic(ts)\n# Expected: curve starts rising fast (positive dy0) and ends with negative slope (dy1).\n</code></pre> - Cubic Interpolation </p>"},{"location":"modules/helper_functions/interpolation_functions/#_safe_div","title":"<code>_safe_div</code>","text":""},{"location":"modules/helper_functions/interpolation_functions/#signature_2","title":"Signature","text":"<pre><code>_safe_div(num, den) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/interpolation_functions/#purpose_2","title":"Purpose","text":"<p>Elementwise division with broadcasting that returns 0 where <code>den == 0</code>. Used inside the Cox\u2013de Boor recursion to safely handle repeated knots (zero denominators) without producing NaNs.</p> <p>Returns</p> <ul> <li>Array with the broadcasted shape of <code>num</code> and <code>den</code>, containing <code>num/den</code> where <code>den\u22600</code> and <code>0</code> where <code>den=0</code>.</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#nbspl","title":"<code>Nbspl</code>","text":""},{"location":"modules/helper_functions/interpolation_functions/#signature_3","title":"Signature","text":"<pre><code>Nbspl(t, x, k: int = 3) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/interpolation_functions/#purpose_3","title":"Purpose","text":"<p>Evaluate the B-spline basis functions of degree <code>k</code> for a given knot vector <code>t</code> at points <code>x</code>, using the Cox\u2013de Boor recursion. This returns the basis matrix \\(N\\) so you can build a spline curve or field as</p> \\[ S(x_j)\\;=\\;\\sum_{i=0}^{\\text{nb}-1} c_i\\,N_{i,k}(x_j), \\] <p>where \\(\\text{nb} = m - k - 1\\) is the number of degree-<code>k</code> basis functions (with m=len(t)) and \\(c_i\\) are your control coefficients.</p> <p>Intuition (how it works): \u2022 Degree 0 (piecewise constants): each \\(N_{i,0}\\) is 1 on the knot interval \\((t_i, t_{i+1}]\\) and 0 elsewhere (this code uses a right-closed convention to mirror the legacy behavior). \u2022 Elevate degree recursively: for \\(p=1..k\\),</p> \\[ N_{i,p}(x)\\;=\\;\\frac{x-t_i}{t_{i+p}-t_i}\\,N_{i,p-1}(x)\\;+\\;\\frac{t_{i+p+1}-x}{t_{i+p+1}-t_{i+1}}\\,N_{i+1,p-1}(x). \\] <p>The helper <code>_safe_div</code> makes each fraction zero if its denominator vanishes (e.g., repeated knots), which is the standard convention.</p>"},{"location":"modules/helper_functions/interpolation_functions/#parameters-returns-and-raises_2","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>t</code> (<code>array_like</code>, shape <code>(m,)</code>): Non-decreasing knot vector. Repeated knots are allowed (lower continuity).</li> <li><code>x</code> (<code>array_like</code>, shape <code>(n,)</code>): Points where you want the basis evaluated.</li> <li><code>k</code> (<code>int</code>, default <code>3</code>): Degree of the spline (cubic by default). Must satisfy <code>k &lt;= len(t) - 2</code>.</li> </ul> <p>Returns</p> <ul> <li><code>N</code> (<code>np.ndarray</code>, shape <code>(n, m-k-1)</code>):   Basis matrix with rows = evaluation points and columns = basis functions. Entry <code>N[j, i]</code> is \\(N_{i,k}(x_j)\\).</li> </ul> <p>Raises / Assumptions</p> <ul> <li><code>ValueError</code> if <code>k &gt; len(t) - 2</code>.</li> <li>Assumes <code>t</code> is non-decreasing. If many knots are identical, the corresponding denominators are zero and the code returns 0 for those fractions (as desired).</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#notes-properties-useful-facts","title":"Notes &amp; properties (useful facts)","text":"<ul> <li>Local support: \\(N_{i,k}(x)\\) is nonzero only on the interval \\([t_i,\\,t_{i+k+1}]\\). Hence each row of <code>N</code> has at most <code>k+1</code> nonzeros.</li> <li> <p>Partition of unity: for \\(x\\) strictly inside the knot span, \\(\\sum_i N_{i,k}(x)=1\\). At exact knot locations the right-closed convention assigns the mass to the right interval:</p> </li> <li> <p>At \\(x = t_0\\): all zeros (no interval to the left),</p> </li> <li>At \\(x = t_{m-1}\\): the last basis evaluates to 1.</li> <li>Continuity: with simple knots (no repetition), splines are \\(C^{k-1}\\). A knot of multiplicity <code>r</code> reduces continuity to \\(C^{k-r}\\).</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#when-to-use-and-examples_2","title":"When to use and examples","text":"<p>Use B-splines when you need smooth, local-control interpolation/approximation with tunable continuity via the knot vector\u2014ideal for smooth paths, potentials, or any 1D field where you want stability and partition-of-unity behavior.</p> <p>see the full test script in tests/helper_functions/Interpolation_functions for more</p> <p>Examples</p> <ul> <li>B-spline bases: partition of unity, non-negativity, local support</li> </ul> <pre><code>\"\"\"\"\n=== Test 3: B-spline bases (partition of unity &amp; local support) ===\nknots =  [0.  0.  0.  0.  0.2 0.4 0.6 0.8 1.  1.  1.  1. ]\nPartition of unity: max|sum_i N_i(x)-1| = 1.0\nNon-negativity: min(N) = 0.0  (should be &gt;= 0)\n\"\"\"\n</code></pre> <p></p> <p>What the figure shows:</p> <ul> <li>Partition of unity: at every <code>x</code>, the colored curves sum to 1 (visually, one \u201cstack\u201d fills the unit height).</li> <li>Non-negativity: each basis is \u2265 0.</li> <li> <p>Local support: at any <code>x</code> only <code>k+1=4</code> curves are nonzero (for cubic). This is why changing one coefficient <code>c_i</code> only affects a small neighborhood in the final spline.</p> </li> <li> <p>Exact interpolation via <code>N($x_i$) c = y</code> (Greville collocation)</p> </li> </ul> <pre><code>f  = lambda x: np.sin(2*np.pi*x) + 0.2*x\ny  = f(Xi)\n\n# Square collocation system (nb x nb)\nN_colloc = Nbspl(t, Xi, k=k)\nc = np.linalg.solve(N_colloc, y)             # exact at Xi\n\n# Evaluate on a fine grid\nxf = np.linspace(0, 1, 600)\nNf = Nbspl(t, xf, k=k)\nSf = Nf @ c\n\"\"\"\n=== Test 5: Exact interpolation via B-splines (solve for coefficients) ===\nMax residual at collocation points (should be ~1e-12): 2.220e-16\nMax abs error on fine grid (approx. quality, not necessarily tiny): 2.234e-03\n\"\"\"\n</code></pre> <p></p> <p>What the figure shows (caption/notes):</p> <ul> <li>The red dashed spline matches the black target exactly at the blue Greville points (interpolation).</li> <li> <p>Between collocation points the match is approximate (still very good here because we used 10 cubic bases on <code>[0,1]</code>).</p> </li> <li> <p>For exact interpolation, use Greville points to build a square, well-conditioned system and solve <code>N @ c = y</code>.</p> </li> <li>For fitting/denoising, solve <code>min_c ||N c \u2212 y||</code> (possibly with a smoothness regularizer).</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#nbspld1","title":"<code>Nbspld1</code>","text":""},{"location":"modules/helper_functions/interpolation_functions/#signature_4","title":"Signature","text":"<pre><code>Nbspld1(t: np.ndarray, x: np.ndarray, k: int = 3) -&gt; Tuple[np.ndarray, np.ndarray]\n</code></pre>"},{"location":"modules/helper_functions/interpolation_functions/#purpose_4","title":"Purpose","text":"<p>Same idea as <code>Nbspl</code>, but also returns the first derivatives of the degree-<code>k</code> B-spline basis with respect to <code>x</code>.  Internally it builds and caches all bases up to degree <code>k</code>, then uses the closed-form derivative:</p> \\[\\frac{d}{dx}N_{i,k}(x) = \\frac{k}{t_{i+k}-t_i}\\,N_{i,k-1}(x) - \\frac{k}{t_{i+k+1}-t_{i+1}}\\,N_{i+1,k-1}(x) \\] <p>with the convention that any term with zero denominator contributes 0 (repeated knots).</p>"},{"location":"modules/helper_functions/interpolation_functions/#parameters-returns-and-raises_3","title":"Parameters, returns and Raises","text":"<p>Parameters \u2014 same as <code>Nbspl(t, x, k)</code>.</p> <p>Returns</p> <ul> <li><code>N</code>  (<code>ndarray</code>, shape <code>(n, m-k-1)</code>): basis values \\(N_{i,k}(x_j)\\).</li> <li><code>dN</code> (<code>ndarray</code>, shape <code>(n, m-k-1)</code>): first derivatives \\(\\partial_x N_{i,k}(x_j)\\).</li> </ul> <p>Raises / Notes</p> <ul> <li><code>ValueError</code> if <code>k &gt; len(t) - 2</code>.</li> <li>Uses the same right-closed seed for the degree-0 basis as <code>Nbspl</code>.</li> <li>At clamped ends (<code>open</code> knots), derivatives near the extreme knots are well-defined but finite-difference checks must avoid crossing the boundary row (see fix below).</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#nbspld2","title":"<code>Nbspld2</code>","text":""},{"location":"modules/helper_functions/interpolation_functions/#signature_5","title":"Signature","text":"<pre><code>Nbspld2(t: np.ndarray, x: np.ndarray, k: int = 3) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]\n</code></pre>"},{"location":"modules/helper_functions/interpolation_functions/#purpose_5","title":"Purpose","text":"<p>As above, but also returns the second derivatives. It first computes all first-derivative tables for degrees <code>0..k</code>, then applies the same closed-form again on <code>dN_{*,k-1}</code>:</p> \\[\\frac{d^2}{dx^2}N_{i,k}(x)= \\frac{k}{t_{i+k}-t_i}\\,\\frac{d}{dx}N_{i,k-1}(x)- \\frac{k}{t_{i+k+1}-t_{i+1}}\\,\\frac{d}{dx}N_{i+1,k-1}(x), \\] <p>with the same zero-denominator convention.</p>"},{"location":"modules/helper_functions/interpolation_functions/#parameters-returns-and-raises_4","title":"Parameters, returns and Raises","text":"<p>Parameters \u2014 same as <code>Nbspl</code>.</p> <p>Returns</p> <ul> <li><code>N</code>   (<code>ndarray</code>, shape <code>(n, m-k-1)</code>): basis values.</li> <li><code>dN</code>  (<code>ndarray</code>, shape <code>(n, m-k-1)</code>): first derivatives.</li> <li><code>d2N</code> (<code>ndarray</code>, shape <code>(n, m-k-1)</code>): second derivatives.</li> </ul> <p>Raises / Notes</p> <ul> <li><code>ValueError</code> if <code>k &gt; len(t) - 2</code>.</li> <li>For <code>k=0</code> or <code>k=1</code>, the second derivative is identically 0 (as expected).</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#examples","title":"Examples","text":"<p>see the full test script in tests/helper_functions/Interpolation_functions for more</p> <ul> <li>Basis Functions derivatives (first and second)</li> </ul> <pre><code>\"\"\"\n=== Test 4: dN/dx and d\u00b2N/dx\u00b2 vs finite differences (sanity) ===\nMax |dN - FD|  = 1.374e-03\nMax |d2N - FD| = 3.208e-01\nExpected: small (method consistent); edges less accurate (central FD not applicable).\n\"\"\"\n</code></pre> <p></p> <ul> <li>Basis Functions with repeated knots (reduce smoothness)</li> </ul> <pre><code>\"\"\"\n=== Test 6: Repeated interior knot reduces smoothness (see jump in derivatives) ===\nInterior knot at x\u22480.5: left slope=-11.423134, right slope=-11.644709\nExpected: visible change in slope at the repeated knot (reduced continuity).\n\"\"\"\n</code></pre> <p></p> <pre><code>\"\"\"\n=== Test 7: Expected error cases ===\nk too large (Nbspl): Nbspl: require k &lt;= len(t)-2\nx not 1D (may raise/behave unexpectedly): ValueError('operands could not be broadcast together with shapes (2,1,3) (9,) ')\nknot length invalid (Nbspl): Nbspl: require k &lt;= len(t)-2\n\n(Equal for Nbspl, Nbspld1 and Nbspld2)\n\"\"\"\n</code></pre>"},{"location":"modules/tunneling1D/single_field/","title":"Single Field Instanton","text":"<p>This document describes the single-field instanton solver and the public API that underpins it. The implementation follows  the overshoot/undershoot shooting method and supports both thin-wall and thick-wall regimes with robust numerical defaults. see the example page of this class if you want to understand more of each function!.</p>"},{"location":"modules/tunneling1D/single_field/#module-overview","title":"Module overview","text":"<p><code>tunneling1D</code> provides tools to compute O(\u03b1+1)\u2013symmetric bounce (instanton) solutions in one field dimension. In the absence of gravity, the equation of motion for a radial profile <code>phi(r)</code> reads</p> \\[\\frac{d^2\\phi}{dr^2} + \\frac{\\alpha}{r}\\frac{d\\phi}{dr} = \\frac{dV}{d\\phi}\\] <p>with boundary conditions</p> \\[\\phi '(0)=0 \\qquad \\phi(\\infty)=\\phi_{\\rm metaMin}\\] <p>The primary entry point is the class <code>SingleFieldInstanton</code>, which:</p> <ul> <li>validates the potential and basic inputs,</li> <li>supplies numerically stable derivative approximations when the user does not provide them,</li> <li>detects a characteristic scale and the barrier location,</li> <li>and exposes high-level routines to find the profile and the action.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#behavioral-guarantees-compatibility","title":"Behavioral guarantees &amp; compatibility","text":"<ul> <li>Scalar/array semantics. All derivative helpers accept scalars or NumPy arrays and preserve shapes.</li> <li>Backward compatibility. Names and signatures are preserved. If you supply custom <code>dV</code>/<code>d2V</code>, the class uses them everywhere.</li> <li>Numerical robustness. Defaults favor stability in thin-wall and stiff potentials; the step size never collapses to zero even if the two minima coincide numerically.</li> <li>Clear errors. Missing metastability or barriers raise <code>PotentialError</code> with informative messages.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#quick-usage-example","title":"Quick usage example","text":"<pre><code>import numpy as np\nfrom CosmoTransitions.tunneling1D import SingleFieldInstanton\n\n# Quartic potential with two minima\ndef V(phi):  return 0.25*phi**4 - 0.49*phi**3 + 0.235*phi**2\n\n# Instantiate the solver (use builtin derivatives)\ninst = SingleFieldInstanton(\n    phi_absMin=1.0,\n    phi_metaMin=0.0,\n    V=V,\n    alpha=2,          # O(3) symmetry\n    phi_eps=1e-3,     # relative FD step (safe floor applied automatically)\n    fd_order=4,       # 4th-order differences\n    validate=True,\n)\n\n# prof = inst.findProfile()\n# S    = inst.findAction(prof)\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#reproducibility-notes","title":"Reproducibility notes","text":"<ul> <li>The FD step is <code>h = max(phi_eps * |\u0394phi|, fd_eps_min, auto_floor)</code>, where <code>auto_floor \u2248 sqrt(machine_eps) \u00d7 scale</code>.</li> <li>Built-in derivative formulas are central differences and do not cache potential evaluations across calls; users may optimize their <code>V</code> if desired.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#class-singlefieldinstanton","title":"Class: <code>SingleFieldInstanton</code>","text":"<p>Compute properties of a single-field instanton via the overshoot/undershoot method. Most users will only call <code>findProfile</code> and <code>findAction</code>,  but the constructor and derivative helpers are documented here because they define the potential interface and core validations.</p>"},{"location":"modules/tunneling1D/single_field/#signature","title":"Signature","text":"<pre><code>class SingleFieldInstanton:\n    def __init__(\n        self,\n        phi_absMin: float,\n        phi_metaMin: float,\n        V: Callable[[float | np.ndarray], float | np.ndarray],\n        dV: Callable | None = None,\n        d2V: Callable | None = None,\n        phi_eps: float = 1e-3,\n        alpha: int | float = 2,\n        phi_bar: float | None = None,\n        rscale: float | None = None,\n        *,\n        fd_order: int = 4,\n        fd_eps_min: float | None = None,\n        validate: bool = True,\n    )\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose","title":"Purpose","text":"<p>Create a solver instance for a single scalar field in a given potential <code>V(phi)</code>, with optional user-supplied derivatives.  The instance owns all numerical settings (finite-difference step/accuracy, friction <code>\u03b1</code>, barrier point, characteristic radius scale) required by later calls.</p>"},{"location":"modules/tunneling1D/single_field/#parameters","title":"Parameters","text":"<ul> <li> <p><code>phi_absMin</code> (float)   Field value of the stable (true) vacuum.</p> </li> <li> <p><code>phi_metaMin</code> (float)   Field value of the metastable (false) vacuum.</p> </li> <li> <p><code>V</code> (callable)   Potential <code>V(phi)</code>. It may accept scalars or NumPy arrays (vectorized); scalar support is sufficient.</p> </li> <li> <p><code>dV</code>, <code>d2V</code> (callable | None)   Optional first and second derivatives. If provided, they override the built-in finite-difference routines. Either or both may be supplied.</p> </li> <li> <p><code>phi_eps</code> (float, default <code>1e-3</code>) Relative finite-difference step used by the built-in <code>dV</code>/<code>d2V</code>. The absolute step is</p> </li> </ul> \\[h = \\texttt{phi_eps}\\times |\\phi_{metaMin}-\\phi_{absMin}| \\] <p>A safe lower floor is applied automatically (see Notes).</p> <ul> <li> <p><code>alpha</code> (int | float, default <code>2</code>)   Friction coefficient in the ODE. For O(\u03b1+1) symmetry, <code>alpha</code> equals the spatial dimension.</p> </li> <li> <p><code>phi_bar</code> (float | None)   Field value at the edge of the barrier, defined by <code>V(phi_bar) = V(phi_metaMin)</code>. If <code>None</code>, it is found by <code>findBarrierLocation()</code>.</p> </li> <li> <p><code>rscale</code> (float | None)   Characteristic radial scale. If <code>None</code>, it is found by <code>findRScale()</code>.</p> </li> <li> <p><code>fd_order</code> {2, 4}, keyword-only, default <code>4</code>   Order of the built-in central finite differences (ignored if the user passes <code>dV</code>/<code>d2V</code>).</p> </li> <li> <p><code>fd_eps_min</code> (float | None), keyword-only   Absolute lower bound on the FD step <code>h</code>. If <code>None</code>, a safe value of order <code>sqrt(machine_eps) \u00d7 scale</code> is used.</p> </li> <li> <p><code>validate</code> (bool, default <code>True</code>), keyword-only   Perform basic sanity checks and emit helpful errors/warnings.</p> </li> </ul>"},{"location":"modules/tunneling1D/single_field/#raises","title":"Raises","text":"<ul> <li> <p><code>PotentialError(\"V(phi_metaMin) &lt;= V(phi_absMin); tunneling cannot occur.\", \"stable, not metastable\")</code>   If the potential is not metastable.</p> </li> <li> <p><code>PotentialError(...)</code>   If barrier finding or scale detection fails (e.g., no barrier, negative curvature fit).</p> </li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes","title":"Notes","text":"<ul> <li> <p>Thin-wall acceleration. When minima are nearly degenerate, the solver starts integration near the wall using a local quadratic solution, making the search efficient even for extremely thin walls.</p> </li> <li> <p>FD step safety. The absolute step <code>h</code> is computed from the minima separation; if the separation is tiny (or zero due to user inputs), a machine-precision-aware floor is applied to prevent catastrophic cancellation.</p> </li> <li> <p>Overrides. If you pass custom <code>dV</code>/<code>d2V</code>, the solver will use those everywhere (including the high-accuracy helper <code>dV_from_absMin</code>).</p> </li> <li> <p>Caching. The constructor caches <code>V(phi_absMin)</code>, <code>V(phi_metaMin)</code> and basic deltas; downstream methods reuse them.</p> </li> </ul>"},{"location":"modules/tunneling1D/single_field/#lot-sf-1-potential-interface-validations","title":"Lot SF-1 \u2014 Potential interface &amp; validations","text":"<p>This lot modernizes the potential interface and core validations, and provides the built-in derivatives.  The public names are unchanged for backward compatibility.</p>"},{"location":"modules/tunneling1D/single_field/#__init__","title":"<code>__init__</code>","text":"<p>See the class section above for the full signature and behavior. Implementation highlights:</p> <ul> <li>Metastability check: require <code>V(phi_metaMin) &gt; V(phi_absMin)</code>.</li> <li>Robust FD step: <code>h = max(phi_eps * |\u0394phi|, fd_eps_min or auto_floor)</code>, where <code>\u0394phi = phi_metaMin - phi_absMin</code> and <code>auto_floor ~ sqrt(machine_eps) \u00d7 scale</code>.</li> <li>User overrides respected: any provided <code>dV</code>/<code>d2V</code> replace the built-ins transparently.</li> <li>Barrier/scale: compute <code>phi_bar</code> and <code>rscale</code> if not supplied; accept user input but warn if <code>V(phi_bar) \u2249 V(phi_metaMin)</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#dvphi","title":"<code>dV(phi)</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_1","title":"Signature","text":"<pre><code>dV(phi: float | np.ndarray) -&gt; float | np.ndarray\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_1","title":"Purpose","text":"<p>Built-in finite-difference approximation to ( V'(\\phi) ). Works with scalars or arrays (broadcasted).  If the user supplied a custom <code>dV</code> at construction, that override is used instead.</p>"},{"location":"modules/tunneling1D/single_field/#scheme","title":"Scheme","text":"<ul> <li> <p>Order 4 (default) \\(\\(V'(\\phi)\\approx\\frac{V(\\phi-2h)-8V(\\phi-h)+8V(\\phi+h)-V(\\phi+2h)}{12h}\\)\\)</p> </li> <li> <p>Order 2 (fallback) \\(\\(V'(\\phi)\\approx\\frac{V(\\phi+h)-V(\\phi-h)}{2h}\\)\\)</p> </li> </ul> <p>with h =  absolute FD step defined in <code>__init__</code>.</p>"},{"location":"modules/tunneling1D/single_field/#parameters-returns-and-raises","title":"Parameters, Returns and Raises","text":"<ul> <li>Parameters: <code>phi</code> (float | array-like) points where to evaluate.</li> <li>Returns: same shape as <code>phi</code>.</li> <li>Raises: only propagates exceptions from user <code>V</code> (non-finite, etc.).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes_1","title":"Notes","text":"<ul> <li>The routine is side-effect free and vectorization-friendly.</li> <li>The step <code>h</code> is absolute; see <code>__init__</code> for how it is chosen safely.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#dv_from_absmindelta_phi","title":"<code>dV_from_absMin(delta_phi)</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_2","title":"Signature","text":"<pre><code>dV_from_absMin(delta_phi: float) -&gt; float\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_2","title":"Purpose","text":"<p>High-accuracy derivative at \\((\\phi=\\phi_{\\rm absMin}+\\delta\\phi)\\). Near the minimum, direct finite differences can lose precision; we therefore blend a Taylor estimate using (V'') with the FD estimate. This happens because near the true minimum \\(V'(\\phi)\\) it's expected to be exactly zero, therefore it's relevant to evaluate with an alternative Method, i.e., <code>V'(\\phi) \\approx V''(\\phi_{\\rm absMin}) (\\phi-\\phi_{\\rm absMin})</code></p>"},{"location":"modules/tunneling1D/single_field/#method","title":"Method","text":"<ul> <li>Let \\((\\phi=\\phi_{\\rm absMin}+\\delta\\phi)\\)</li> <li>Compute <code>dV_fd = dV(phi)</code> (built-in or user override).</li> <li>Compute <code>dV_lin = d2V(phi) * delta_phi</code>.</li> <li>Blend with a smooth weight</li> </ul> <p>\\(\\(w = \\exp\\Big[-\\big(\\delta\\phi/h\\big)^2\\Big],\\qquad h=\\text{FD step}\\)\\)   Return \\((w\\cdot dV_{\\rm lin} + (1-w)dV_{\\rm fd})\\).</p>"},{"location":"modules/tunneling1D/single_field/#parameters-returns-and-raises_1","title":"Parameters, Returns and Raises","text":"<ul> <li>Parameters: <code>delta_phi</code> (float) offset from the absolute minimum.</li> <li>Returns: (float) blended derivative at <code>phi_absMin + delta_phi</code>.</li> <li>Raises: Propagates only if user-supplied <code>dV</code>/<code>d2V</code> fail.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes_2","title":"Notes","text":"<ul> <li>Guarantees <code>dV_from_absMin(0.0) = 0.0</code> to within round-off (through the blend).</li> <li>Uses the same <code>h</code> configured in <code>__init__</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#d2vphi","title":"<code>d2V(phi)</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_3","title":"Signature","text":"<pre><code>d2V(phi: float | np.ndarray) -&gt; float | np.ndarray\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_3","title":"Purpose","text":"<p>Built-in finite-difference approximation to \\((V''(\\phi))\\). Works with scalars or arrays (broadcasted).  If the user supplied a custom <code>d2V</code>, that takes precedence.</p>"},{"location":"modules/tunneling1D/single_field/#scheme_1","title":"Scheme","text":"<ul> <li> <p>Order 4 (default) \\(\\(V''(\\phi)\\approx\\frac{-V(\\phi-2h)+16V(\\phi-h)-30V(\\phi)+16V(\\phi+h)-V(\\phi+2h)}{12h^2}\\)\\)</p> </li> <li> <p>Order 2 (fallback) \\(\\(V''(\\phi)\\approx\\frac{V(\\phi+h)-2V(\\phi)+V(\\phi-h)}{h^2}\\)\\)</p> </li> </ul>"},{"location":"modules/tunneling1D/single_field/#parameters-returns-and-raises_2","title":"Parameters, Returns and Raises","text":"<ul> <li>Parameters: <code>phi</code> (float | array-like).</li> <li>Returns: same shape as <code>phi</code>.</li> <li>Raises: only propagates exceptions from <code>V</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes_3","title":"Notes","text":"<ul> <li>Uses the same safe absolute step <code>h</code> as <code>dV</code>.</li> <li>Vectorized; preserves input shape (scalar-in \u2192 scalar-out).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#lot-sf-2-barrier-scales","title":"Lot SF-2 \u2014 Barrier &amp; scales","text":"<p>This lot modernizes how we locate the barrier that separates the metastable (false) vacuum from the absolute (true) vacuum and  how we estimate a characteristic radial scale for the instanton solution.  Both functions keep their legacy names and public behavior, but the numerics and diagnostics are stronger and more transparent.</p>"},{"location":"modules/tunneling1D/single_field/#findbarrierlocation","title":"<code>findBarrierLocation</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_4","title":"Signature","text":"<pre><code>findBarrierLocation(self) -&gt; float\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_4","title":"Purpose","text":"<p>Return the edge of the barrier (<code>phi_bar</code>) defined implicitly by</p> \\[V(\\phi_{\\mathrm{bar}}) = V(\\phi_{\\mathrm{metaMin}})\\] <p>on the downhill side of the barrier when moving from the metastable minimum toward the absolute minimum. This is the crossing point at which the field \u201cleaves\u201d the false-vacuum plateau as it rolls toward the true vacuum.</p>"},{"location":"modules/tunneling1D/single_field/#behavior-algorithm-whats-new","title":"Behavior &amp; algorithm (what\u2019s new)","text":"<ul> <li>We first locate the barrier top (<code>phi_top</code>) \u2014 the maximizer of (V) \u2014 in the open interval between the two minima via a bounded 1D search (robust even if the potential has gentle wiggles).</li> <li>We then solve for the downhill crossing of \\((G(\\phi)=V(\\phi)-V(\\phi_{\\rm metaMin}))\\) between <code>phi_top</code> and the absolute minimum using a bracketed Brent root.</li> <li> <p>On success, we return <code>phi_bar</code>. We also cache diagnostics in <code>self._barrier_info</code>:</p> </li> <li> <p><code>phi_bar</code>, <code>phi_top</code>,</p> </li> <li><code>V_top_minus_Vmeta = V(phi_top) - V(phi_metaMin)</code>,</li> <li><code>V_meta</code>, <code>V_abs</code>,</li> <li><code>interval = (min(phi_metaMin, phi_absMin), max(...))</code>.</li> </ul> <p>This approach eliminates fragile reliance on strict monotonicity and makes error messages precise.</p>"},{"location":"modules/tunneling1D/single_field/#parameters-returns-and-raises_3","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <p>None (uses the instance state).</p> <p>Returns</p> <ul> <li><code>float</code>: <code>phi_bar</code> such that \\((V(\\phi_{\\rm bar})=V(\\phi_{\\rm metaMin}))\\).</li> </ul> <p>Raises</p> <ul> <li><code>PotentialError(\"\u2026\", \"no barrier\")</code>: if the barrier top cannot be located inside the interval, or the barrier height is non-positive (no barrier).</li> <li><code>PotentialError(\"\u2026\", \"stable, not metastable\")</code>: defensively raised if \\((V(\\phi_{\\rm metaMin}) \\le V(\\phi_{\\rm absMin}))\\).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes_4","title":"Notes","text":"<ul> <li>The method is purely 1D and makes no smoothness assumptions beyond what the line search and root solver require (continuous (V)).</li> <li>The cached <code>self._barrier_info</code> lets you reuse <code>phi_top</code> and heights in later analysis/plots without recomputation.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#findrscale","title":"<code>findRScale</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_5","title":"Signature","text":"<pre><code>findRScale(self) -&gt; float\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_5","title":"Purpose","text":"<p>Estimate a characteristic radial scale \\((r_{\\rm scale})\\) for the instanton solution.  This sets physical step sizes for ODE integration and helps select plotting ranges.</p>"},{"location":"modules/tunneling1D/single_field/#physical-meaning-of-the-scale","title":"Physical meaning of the scale","text":"<p>Near the barrier top the Euclidean EoM linearizes to</p> \\[\\phi'' + \\frac{\\alpha}{r}\\phi' \\simeq V''(\\phi_{\\rm top}) \\bigl(\\phi - \\phi_{\\rm top}\\bigr)\\] <p>If the top were strictly quadratic with curvature \\((V''(\\phi_{\\rm top})&lt;0)\\), a naive local scale is \\((r_{\\rm curv}\\sim 1/\\sqrt{\\lvert V''(\\phi_{\\rm top})\\rvert})\\). However, many relevant potentials in cosmology/phase transitions have flat-topped barriers \\(((V''(\\phi_{\\rm top})\\approx 0))\\), making \\((r_{\\rm curv})\\) blow up  even when tunneling is well-defined.</p> <p>To remain stable and legacy-compatible, we adopt a cubic surrogate for the barrier shape that matches:</p> <ul> <li>a maximum at the top \\(((\\phi_{\\rm top}))\\),</li> <li>a minimum at the metastable vacuum \\(((\\phi_{\\rm metaMin}))\\),</li> </ul> <p>which yields the robust scale</p> \\[\\boxed{ r_{\\rm scale} = r_{\\rm cubic} = \\frac{\\bigl|\\phi_{\\rm top}-\\phi_{\\rm metaMin}\\bigr|} {\\sqrt{6[V(\\phi_{\\rm top})-V(\\phi_{\\rm metaMin})]}} }\\] <p>This remains finite on flat tops and empirically tracks the small-oscillation period scale up to an \\((\\mathcal{O}(1))\\) factor \u2014 ideal for setting numerics.</p>"},{"location":"modules/tunneling1D/single_field/#behavior-algorithm-whats-new_1","title":"Behavior &amp; algorithm (what\u2019s new)","text":"<ul> <li>Reuses <code>findBarrierLocation</code> to validate the barrier and obtain <code>phi_top</code> and its height above the false vacuum.</li> <li>Computes and returns the legacy cubic scale \\((r_{\\rm cubic})\\) (unchanged public behavior).</li> <li>Also computes an optional curvature diagnostic \\((r_{\\rm curv} = 1/\\sqrt{-V''(\\phi_{\\rm top})})\\) when  \\((V''(\\phi_{\\rm top})&lt;0)\\) (otherwise (+\\infty)).</li> <li> <p>Caches diagnostics in <code>self._scale_info</code>:</p> </li> <li> <p><code>phi_top</code>, <code>V_top_minus_Vmeta</code>, <code>xtop = phi_top - phi_metaMin</code>,</p> </li> <li><code>rscale_cubic</code>, <code>rscale_curv</code>, <code>d2V_top</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#parameters-returns-and-raises_4","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <p>None (uses the instance state).</p> <p>Returns</p> <ul> <li><code>float</code>: \\((r_{\\rm scale} = r_{\\rm cubic})\\), used elsewhere for step sizes and domain lengths.</li> </ul> <p>Raises</p> <ul> <li><code>PotentialError(\"\u2026\", \"no barrier\")</code>: if the barrier fails validation (no interior top or non-positive height).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes_5","title":"Notes","text":"<ul> <li>Returning the cubic scale preserves the legacy interface and numerical behavior.</li> <li>The diagnostics are helpful for thin-wall detection, performance tuning, and sanity plots.</li> </ul> <p>Here\u2019s the continuation of <code>single_field.md</code> for the next block.</p>"},{"location":"modules/tunneling1D/single_field/#lot-sf-3-quadratic-local-solution-initial-conditions","title":"Lot SF-3 \u2014 Quadratic local solution &amp; initial conditions","text":"<p>This block implements the local (near-center) analytic control we use to (i) evaluate the field in a small neighborhood of the bubble center and (ii) generate safe initial conditions away from the (r=0) singular point of the radial equation. The two public members covered here are:</p> <ul> <li><code>exactSolution(r, phi0, dV, d2V)</code></li> <li><code>initialConditions(delta_phi0, rmin, delta_phi_cutoff)</code></li> </ul> <p>Both are methods of <code>SingleFieldInstanton</code>.</p>"},{"location":"modules/tunneling1D/single_field/#physical-background-why-bessel-functions-appear","title":"Physical background (why Bessel functions appear)","text":"<p>The Euclidean bounce equation for a spherically symmetric profile in \\(((\\alpha+1))\\) spatial dimensions is</p> \\[\\phi''(r) + \\frac{\\alpha}{r}\\phi'(r) = V'(\\phi)\\qquad r\\ge 0\\] <p>Near a chosen point \\((\\phi_0)\\) (typically very close to the true minimum \\((\\phi_{\\rm absMin})\\) when constructing thin-wall bounces),  Taylor-expand the potential to quadratic order:</p> \\[V'(\\phi) \\approx dV + d2V(\\phi-\\phi_0); \\quad dV = V'(\\phi_0);\\quad d2V = V''(\\phi_0)\\] <p>Let \\((\\delta\\phi(r)=\\phi(r)-\\phi_0)\\). Then</p> \\[\\delta\\phi'' + \\frac{\\alpha}{r}\\delta\\phi' - d2V\\delta\\phi = dV\\] <p>Shift out the constant drive with \\((\\delta\\phi=\\psi + dV/d2V)\\) (when \\((d2V\\neq 0)\\)), to obtain the homogeneous equation</p> \\[\\psi'' + \\frac{\\alpha}{r}\\psi' - d2V\\psi = 0\\] <p>whose regular solution at the origin is expressed in terms of Bessel functions. Defining</p> \\[\\nu \\equiv \\frac{\\alpha-1}{2}\\qquad ,\\beta \\equiv \\sqrt{|d2V|},\\qquad t \\equiv \\beta r\\] <p>the regular solution is</p> <ul> <li>Stable curvature ((d2V&gt;0), harmonic well):</li> </ul> \\[\\phi(r)-\\phi_0 = \\frac{dV}{d2V}\\Bigg[\\Gamma(\\nu+1)\\Big(\\tfrac{t}{2}\\Big)^{-\\nu} I_\\nu(t)-1\\Bigg]\\] <ul> <li>Unstable curvature ((d2V&lt;0), inverted well, e.g. near the barrier top): replace \\((I_\\nu \\to J_\\nu)\\).</li> </ul> <p>Regularity at the origin enforces \\((\\phi'(0)=0)\\) for any \\((\\alpha\\ge 0)\\).</p> <p>If (d2V=0) (flat curvature), the ODE reduces to a constant drive and the exact regular solution is the polynomial</p> \\[\\phi(r)=\\phi_0 + \\frac{dV}{2(\\alpha+1)}r^2\\qquad \\phi'(r)=\\frac{dV}{\\alpha+1}r\\] <p>These closed forms are what the code evaluates, with numerically stable branches for small/large arguments.</p>"},{"location":"modules/tunneling1D/single_field/#exactsolution","title":"<code>exactSolution</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_6","title":"Signature","text":"<pre><code>exactSolution(r: float, phi0: float, dV: float, d2V: float) -&gt; exactSolution_rval\n# exactSolution_rval = namedtuple(\"exactSolution_rval\", \"phi dphi\")\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_6","title":"Purpose","text":"<p>Compute the regular local solution \\(((\\phi(r),\\phi'(r)))\\) at radius (r) assuming a quadratic expansion of the potential around \\((\\phi_0)\\). This is used to:</p> <ul> <li>accurately probe the profile near the origin,</li> <li>build safe, physically consistent initial conditions for the global ODE solver.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#key-definitions-appearing-in-formulas-and-code","title":"Key definitions (appearing in formulas and code)","text":"<ul> <li>\\((\\alpha)\\): friction power in the radial term, i.e. spacetime dimension minus 1.</li> <li>\\((\\nu=(\\alpha-1)/2)\\): effective Bessel index fixed by the radial Laplacian.</li> <li>\\((\\beta=\\sqrt{|d2V|})\\) and \\((t=\\beta r)\\): scale &amp; argument controlling oscillatory/exponential behavior.</li> <li>Regularity: \\((\\phi'(0)=0)\\) (enforced exactly by the implementation).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#parameters_1","title":"Parameters","text":"<ul> <li><code>r</code> (<code>float</code>): radius (\u2265 0). At <code>r==0</code> the method returns <code>(phi0, 0.0)</code> exactly.</li> <li><code>phi0</code> (<code>float</code>): expansion point for the quadratic model.</li> <li><code>dV</code> (<code>float</code>): \\((V'(\\phi_0))\\).</li> <li><code>d2V</code> (<code>float</code>): \\((V''(\\phi_0))\\).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#returns","title":"Returns","text":"<ul> <li><code>exactSolution_rval(phi, dphi)</code>: field and radial derivative at radius <code>r</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#implementation-notes","title":"Implementation notes","text":"<ul> <li>Flat curvature (<code>d2V==0</code>): uses the exact polynomial solution above (no Bessel calls).</li> <li>Small argument (<code>t = beta*r \u2264 1e-5</code>): uses a short even-power series up to (t^6), which is well-conditioned and avoids any division by <code>r</code>.</li> <li>General case: uses the Bessel/modified-Bessel forms, with overflow/underflow warnings suppressed locally; the combined expressions are finite.</li> <li>Input validation ensures all inputs are finite and <code>r\u22650</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#physical-interpretation","title":"Physical interpretation","text":"<ul> <li>(d2V&gt;0): local restoring force; near a true minimum the solution is \u201cmassive\u201d and grows as \\((I_\\nu(t))\\) but regularized to match \\((\\phi'(0)=0)\\).</li> <li>(d2V&lt;0): local tachyonic/inverted curvature, relevant near the barrier top; the solution is oscillatory via \\((J_\\nu)\\).</li> <li>(d2V=0): locally flat\u2014driven purely by the constant slope (dV); the profile starts quadratically from the center.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#initialconditions","title":"<code>initialConditions</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_7","title":"Signature","text":"<pre><code>initialConditions(delta_phi0: float, rmin: float, delta_phi_cutoff: float) -&gt; initialConditions_rval\n# initialConditions_rval = namedtuple(\"initialConditions_rval\", \"r0 phi dphi\")\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_7","title":"Purpose","text":"<p>Choose where to start integrating the full ODE (away from the (r=0) singularity) and with which values \\(((\\phi,\\phi'))\\), using the local quadratic solution as a high-accuracy guide.  The goal is to start just outside the bubble center yet already sufficiently displaced from the true minimum to keep the  overshoot/undershoot search efficient and stable.</p>"},{"location":"modules/tunneling1D/single_field/#inputs-meaning","title":"Inputs &amp; meaning","text":"<ul> <li><code>delta_phi0</code>: desired central offset \\(( \\phi(0)-\\phi_{\\rm absMin} )\\). In thin-wall cases this can be very small.</li> <li><code>rmin</code>: the smallest radius allowed for starting the global integration (relative to <code>rscale</code> in higher-level code).</li> <li><code>delta_phi_cutoff</code>: the target magnitude of the field offset at the starting radius \\((r_0)\\):   \\((|\\phi(r_0)-\\phi_{\\rm absMin}| &gt; |\\delta\\phi_{\\rm cutoff}|)\\).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#strategy-what-the-code-does","title":"Strategy (what the code does)","text":"<ol> <li>Construct \\((\\phi_0 = \\phi_{\\rm absMin} + \\delta\\phi_0)\\) and compute \\((dV=V'(\\phi_0))\\), \\((d2V=V''(\\phi_0))\\).</li> <li> <p>Use <code>exactSolution</code> at <code>rmin</code>.</p> </li> <li> <p>If \\((|\\phi(r_{\\min})-\\phi_{\\rm absMin}| &gt; |\\delta\\phi_{\\rm cutoff}|)\\), start there.</p> </li> <li>If the field is moving the wrong way (sign of \\((\\phi'(r_{\\min}))\\) opposite to \\((\\delta\\phi_0))\\), start there as well; increasing (r) won\u2019t fix the direction.</li> <li>Otherwise, geometrically increase (r) (\u00d710 each step) and re-evaluate with <code>exactSolution</code> until the cutoff is exceeded (this brackets the crossing).</li> <li>Solve for the exact \\((r_0)\\) by a 1D root find on    \\((f(r)=|\\phi(r)-\\phi_{\\rm absMin}|-|\\delta\\phi_{\\rm cutoff}|)\\).</li> <li>Return \\(((r_0,\\phi(r_0),\\phi'(r_0)))\\) as a named tuple.</li> </ol> <p>If the geometric search fails to bracket the crossing (pathological potential/settings), a clear <code>IntegrationError</code> is raised.</p>"},{"location":"modules/tunneling1D/single_field/#returns_1","title":"Returns","text":"<ul> <li><code>initialConditions_rval(r0, phi, dphi)</code>: starting radius and values to feed the global integrator.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes-guidance","title":"Notes &amp; guidance","text":"<ul> <li>This method is agnostic to the global wall shape; it only relies on the local quadratic model, which is accurate near the true minimum where \\((r_0)\\) lives in thin-wall cases.</li> <li>Choosing a too large <code>delta_phi_cutoff</code> may degrade accuracy (starting too far from the regime where the quadratic model is excellent). Too small can slow down the shoot or underflow numerics. The default policy used upstream balances these effects.</li> <li>The named-tuple interface is intentional\u2014downstream code can unpack by name or position.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#common-assumptions-for-both-functions","title":"Common assumptions (for both functions)","text":"<ul> <li>Spherical symmetry and regularity at the origin \\(((\\phi'(0)=0))\\).</li> <li>The principal branches for \\((\\sqrt{\\cdot})\\) and Bessel functions are used.</li> <li>\\((\\alpha\\ge 0)\\) (physical cases); nonetheless, the formulas are coded generically.</li> <li>All inputs are finite; non-finite inputs raise a value error upfront.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#numerical-stability-accuracy","title":"Numerical stability &amp; accuracy","text":"<ul> <li>Small-argument regime: the (t)-series keeps terms through \\((t^6)\\), which is more than enough for \\((t\\lesssim 10^{-2})\\) in double precision.</li> <li>Flat curvature: handled by an exact polynomial; no Bessel calls or divisions-by-(r).</li> <li>Overflow/underflow: benign warnings inside SciPy\u2019s Bessel routines are silenced locally, and the combinations used are finite by construction.</li> <li>Deterministic regularity: at <code>r==0</code>, <code>exactSolution</code> returns <code>(phi0, 0.0)</code> exactly.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#quick-reference-symbols","title":"Quick reference (symbols)","text":"<ul> <li>\\((\\alpha)\\): friction power in the radial Laplacian; equals spacetime dimension minus 1.</li> <li>\\((\\nu=(\\alpha-1)/2)\\): Bessel index.</li> <li>\\((dV=V'(\\phi_0))\\), \\((d2V=V''(\\phi_0))\\): local slope &amp; curvature of the potential.</li> <li>\\((\\beta=\\sqrt{|d2V|})\\), \\((t=\\beta r)\\): scale and argument for Bessel functions.</li> <li>\\((\\phi_{\\rm absMin})\\), \\((\\phi_{\\rm metaMin})\\): true and false vacuum field values (set in the class constructor).</li> <li><code>delta_phi0</code>, <code>delta_phi_cutoff</code>: user-level displacements used to place the start of the integration.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#lot-sf-4-ode-core-equation-adaptive-driver-sampler","title":"Lot SF-4 \u2014 ODE core (equation, adaptive driver, sampler)","text":"<p>This lot contains the numerical engine that integrates the bounce equation once the potential interface and scales are known. It provides:</p> <ul> <li>the equation of motion in first-order form;</li> <li>an adaptive step driver that marches the solution and classifies the outcome as overshoot, undershoot, or converged;</li> <li>a sampler that fills a user-chosen radial grid with a smooth profile using cubic Hermite interpolation between accepted RK steps;</li> <li>a small tolerance normalizer to make error controls explicit and robust.</li> </ul> <p>Throughout, we solve the radial Euclidean EOM for a single field,</p> \\[\\frac{d^2\\phi}{dr^2}+\\frac{\\alpha}{r}\\frac{d\\phi}{dr}= \\frac{dV}{d\\phi}(\\phi)\\] <p>where \\((\\alpha)\\) is the \u201cfriction\u201d coefficient (commonly \\((\\alpha=2)\\) for (O(3)) finite-temperature bounces and \\((\\alpha=3)\\) for \\((O(4))\\) zero-temperature bounces).  The \\((\\alpha/r)\\) term comes from the radial Laplacian in \\(((\\alpha+1))\\) dimensions.</p>"},{"location":"modules/tunneling1D/single_field/#_normalize_tolerances-internal-helper","title":"<code>_normalize_tolerances</code> (internal helper)","text":"<p>Signature</p> <pre><code>@staticmethod\n_normalize_tolerances(epsfrac, epsabs) -&gt; tuple[float, float, float, float]\n</code></pre> <p>Purpose</p> <p>Accepts either scalars or 2-component arrays for the relative/absolute tolerances and returns:</p> <ol> <li><code>ef_scalar</code> \u2013 a single relative tolerance passed to the RK stepper (strictest across components);</li> <li><code>ea_scalar</code> \u2013 a single absolute tolerance for the RK stepper (strictest across components);</li> <li><code>eps_phi</code>   \u2013 absolute threshold (3\u00d7 <code>epsabs</code> for \\((\\phi)\\)) used by our event/convergence tests;</li> <li><code>eps_dphi</code>  \u2013 absolute threshold (3\u00d7 <code>epsabs</code> for \\((d\\phi)\\)) used likewise.</li> </ol> <p>This keeps the step controller simple (scalar tolerances) while still giving per-component, physically meaningful stopping criteria.</p> <p>Notes</p> <ul> <li>If <code>epsabs</code> is scalar, both \\((\\phi)\\) and \\((d\\phi)\\) use the same \\((3\\times)\\) threshold; with a 2-vector, they may differ.</li> <li>The factor 3 in <code>eps_phi</code>, <code>eps_dphi</code> mirrors the legacy \u201cwithin ~3\u00d7 absolute tol \u21d2 good enough\u201d convention used elsewhere in this module.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#equationofmotion","title":"<code>equationOfMotion</code>","text":"<p>Signature</p> <pre><code>equationOfMotion(y: np.ndarray, r: float) -&gt; np.ndarray\n</code></pre> <p>Purpose</p> <p>Right-hand side of the first-order system for \\((y=[\\phi, \\dot\\phi])\\) \\((dot \u2261 (d/dr))\\):</p> \\[\\dot{\\phi} = y_1\\qquad \\dot{y}_1 = \\frac{dV}{d\\phi}(\\phi) - \\frac{\\alpha}{r} y_1\\] <p>Implementation details</p> <ul> <li>To guard against accidental calls at (r=0) (which should not happen in production\u2014integrations always start at (r&gt;0)), we replace (r) by a tiny positive <code>r_eff</code> if needed so the friction term stays finite.</li> <li>Uses the user-provided/derived <code>self.dV(phi)</code>.</li> </ul> <p>Physics notes</p> <p>The \\(( \\alpha/r )\\) \u201cfriction\u201d originates from the radial Laplacian in \\(((\\alpha+1))\\) Euclidean dimensions. Regular bounce solutions satisfy \\(( d\\phi/dr = \\mathcal{O}(r) )\\) as \\(( r\\to 0 )\\), so the product \\(( (\\alpha/r)d\\phi )\\) remains finite.</p>"},{"location":"modules/tunneling1D/single_field/#integrateprofile","title":"<code>integrateProfile</code>","text":"<p>Signature</p> <pre><code>integrateProfile(\n    r0: float,\n    y0: array_like,      # [phi(r0), dphi(r0)]\n    dr0: float,\n    epsfrac, epsabs,     # scalar or 2-vector tolerances\n    drmin: float,\n    rmax: float,\n    *eqn_args\n) -&gt; namedtuple(\"integrateProfile_rval\", \"r y convergence_type\")\n</code></pre> <p>What it does</p> <p>Advances the ODE solution from \\(((r_0,y_0))\\) using an adaptive Cash\u2013Karp RK5(4) stepper (<code>rkqs</code>) until one of three conditions is met:</p> <ol> <li>converged \u2013 both \\((|\\phi-\\phi_{\\rm metaMin}|&lt;\\epsilon_{\\phi})\\) and \\((|d\\phi|&lt;\\epsilon_{d\\phi})\\);</li> <li>overshoot \u2013 within a step the field crosses \\((\\phi_{\\rm metaMin})\\);</li> <li>undershoot \u2013 within a step the field \u201cturns back\u201d (sign of \\((d\\phi)\\) indicates motion away from the target).</li> </ol> <p>In (2) and (3), we locate the event inside the last accepted step by cubic Hermite interpolation (our <code>cubicInterpFunction</code>), and refine with a bracketing root find (<code>scipy.optimize.brentq</code>). If bracketing fails (rare, degenerate slope), we fall back to the point minimizing the relevant magnitude (either \\((|\\phi-\\phi_{\\rm metaMin}|)\\) or \\((|d\\phi|))\\) on a small uniform subgrid of the step.</p> <p>Inputs &amp; error control</p> <ul> <li> <p><code>epsfrac</code>, <code>epsabs</code> can be scalars or 2-vectors. They are normalized via <code>_normalize_tolerances</code>:</p> </li> <li> <p><code>ef_scalar</code>, <code>ea_scalar</code> go to <code>rkqs</code>;</p> </li> <li><code>eps_phi</code>, <code>eps_dphi</code> define the event/convergence thresholds.</li> <li><code>drmin</code> prevents step underflow; if an accepted step requests <code>dr&lt;drmin</code>, we abort with a clear <code>IntegrationError</code>.</li> <li><code>rmax</code> limits the total travelled distance; we abort if \\((r &gt; r_0 + r_{\\max})\\).</li> </ul> <p>Direction logic (overshoot vs. undershoot)</p> <p>We define a sign <code>ysign</code> that encodes \u201cwhere the target is\u201d relative to the current motion:</p> <ul> <li>If we start noticeably away from the target, <code>ysign = sign(phi - phi_metaMin)</code>.</li> <li>If we start essentially on target, we use <code>ysign = -sign(dphi)</code> so that moving away is treated as an undershoot and a crossing back is an overshoot.</li> </ul> <p>Given <code>ysign</code>, we classify a step by looking at:</p> <ul> <li>undershoot if <code>dphi * ysign &gt; +eps_dphi</code> (slope keeps pushing further from target);</li> <li>overshoot if <code>(phi - phi_metaMin) * ysign &lt; -eps_phi</code> (crossing the target).</li> </ul> <p>Return value</p> <p>A named tuple with:</p> <ul> <li><code>r</code> \u2013 the final radius (event location or the last time where convergence was satisfied),</li> <li><code>y</code> \u2013 the final state \\(([\\phi, d\\phi])\\) at that radius,</li> <li><code>convergence_type</code> \u2013 one of <code>\"converged\"</code>, <code>\"overshoot\"</code>, <code>\"undershoot\"</code>.</li> </ul> <p>Why cubic Hermite interpolation?</p> <p>We know \\((y_0, dy/dr\\cdot {r_0})\\) and \\((y_1, dy/dr\\cdot {r_1})\\) for both ends of a step.  The cubic Hermite (a.k.a. piecewise cubic with end slopes) reconstructs a smooth in-step curve that respects both values and slopes,  giving accurate, monotone-friendly event localization without taking extra ODE mini-steps.</p> <p>Typical usage</p> <p><code>findProfile</code> uses this method in a bisection-like loop over the shooting parameter, reading only the outcome (\u201cover/under/converged\u201d) and the precise event radius.  After the best initial condition is found, it calls <code>integrateAndSaveProfile</code> to produce a full, nicely sampled wall profile.</p>"},{"location":"modules/tunneling1D/single_field/#integrateandsaveprofile","title":"<code>integrateAndSaveProfile</code>","text":"<p>Signature</p> <pre><code>integrateAndSaveProfile(\n    R: array_like,       # monotonically increasing radii\n    y0: array_like,      # [phi(R[0]), dphi(R[0])]\n    dr: float,\n    epsfrac, epsabs,     # scalar or 2-vector tolerances\n    drmin: float,\n    *eqn_args\n) -&gt; namedtuple(\"Profile1D\", \"R Phi dPhi Rerr\")\n</code></pre> <p>Purpose</p> <p>Integrate the ODE once more and fill a user-specified radial grid (R) with \\((\\phi(R_i))\\) and \\((d\\phi/dR(R_i))\\).  This is the second (\u201csampling\u201d) pass typically used after the shooting has determined the correct initial condition and outer radius.</p> <p>How it works</p> <ul> <li>Uses the same adaptive RK driver as <code>integrateProfile</code>.</li> <li>Between accepted RK step endpoints \\(((r_0,y_0))\\) and \\(((r_1,y_1))\\), it evaluates the same cubic Hermite interpolant and writes samples for all <code>R[i] \u2208 (r0, r1]</code>.</li> <li>If a proposed accepted step would have <code>dr &lt; drmin</code>, it clamps to <code>drmin</code>, records <code>Rerr</code> on first occurrence (the radius where step clamping first became necessary), and continues so the output arrays are always fully populated.</li> </ul> <p>Outputs</p> <ul> <li><code>R</code> \u2013 the input grid, echoed back;</li> <li><code>Phi</code> \u2013 values \\((\\phi(R_i))\\);</li> <li><code>dPhi</code> \u2013 values \\((d\\phi/dR(R_i))\\);</li> <li><code>Rerr</code> \u2013 <code>None</code> if every accepted step satisfied <code>dr \u2265 drmin</code>; otherwise the first radius where clamping was applied.</li> </ul> <p>Notes</p> <ul> <li>This routine does not attempt to classify events (over/under/converged). That logic belongs in <code>integrateProfile</code>. Here the goal is to sample a known good solution.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#practical-guidance","title":"Practical guidance","text":"<ul> <li> <p>Tolerances. A good starting point mirrors the legacy defaults used in the higher-level driver:</p> </li> <li> <p><code>epsfrac = [phitol, phitol]</code>,</p> </li> <li><code>epsabs = [|\u0394\u03c6|\u00b7phitol, |\u0394\u03c6|/rscale \u00b7 phitol]</code>,     with <code>phitol ~ 1e-4</code> and <code>\u0394\u03c6 = \u03c6_metaMin \u2212 \u03c6_absMin</code>. You can also pass scalars.</li> <li>Initial step. Set <code>dr0 ~ rmin</code> (the same \u201csmall\u201d radius where we start, coming from Lot SF-2\u2019s <code>rscale</code>).</li> <li>Limits. Choose <code>rmax</code> comfortably above the expected wall thickness (often <code>~O(10)\u00b7rscale)</code>); choose <code>drmin</code> at least a few orders of magnitude below the smallest features you want to resolve.</li> <li>Performance. The cubic Hermite interpolation avoids tiny corrective micro-steps for event localization, which keeps the driver fast while maintaining smooth, physically sensible crossings.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#failure-modes-and-messages","title":"Failure modes and messages","text":"<ul> <li><code>IntegrationError(\"... exceeded rmax ...\")</code> \u2013 the profile did not settle/cross within the allowed domain; revisit <code>rmax</code> or the shooting parameter.</li> <li><code>IntegrationError(\"... step underflow ...\")</code> \u2013 the stepper kept asking for <code>dr &lt; drmin</code> to meet tolerances; loosen tolerances or increase <code>drmin</code> cautiously.</li> <li>Value errors guard obvious API misuse (non-finite <code>y0</code>, wrong shapes, non-monotonic <code>R</code>, etc.).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#summary","title":"Summary","text":"<p>Lot SF-4 equips the <code>SingleFieldInstanton</code> class with a clean, robust integrator:</p> <ul> <li>a physically faithful ODE (with friction and a safe \\((r\\to 0)\\) guard),</li> <li>an adaptive, tolerance-driven stepper with explicit convergence semantics (over/under/converged),</li> <li>and a high-quality sampler that turns accepted steps into smooth profiles on any grid.</li> </ul> <p>These pieces are deliberately modular: subclasses (e.g., constant friction walls) reuse the same machinery by passing extra arguments to <code>equationOfMotion</code> via <code>*eqn_args</code>, while keeping the numerics identical.</p>"},{"location":"modules/tunneling1D/single_field/#lot-sf-5-profile-search-overshootundershoot","title":"Lot SF-5 \u2014 Profile search (overshoot/undershoot)","text":"<p>Goal. Find the full bounce profile \\(( \\phi(r) )\\) by shooting on the unknown center value \\(( \\phi(0) )\\).  We adjust a scalar parameter (x) so that the outward integration converges onto the false (metastable) vacuum as \\(( r\\to\\infty )\\).  The search uses classic overshoot/undershoot bracketing and a final dense sampling pass.</p>"},{"location":"modules/tunneling1D/single_field/#singlefieldinstantonfindprofile","title":"<code>SingleFieldInstanton.findProfile(...)</code>","text":"<p>Signature (unchanged).</p> <pre><code>findProfile(\n    xguess=None, xtol=1e-4, phitol=1e-4,\n    thinCutoff=0.01, npoints=500, rmin=1e-4, rmax=1e4,\n    max_interior_pts=None\n) -&gt; Profile1D  # (R, Phi, dPhi, Rerr)\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#what-problem-this-solves","title":"What problem this solves","text":"<p>We need the solution of</p> \\[\\phi''(r) + \\frac{\\alpha}{r}\\phi'(r) = V'(\\phi)\\] <p>that starts at the true minimum \\(((\\phi\\approx\\phi_{\\rm absMin}))\\) near (r=0) and asymptotes to the false minimum \\(((\\phi\\to\\phi_{\\rm metaMin}))\\) for large (r).  The correct central value \\((\\phi(0))\\) is not known a priori; we determine it by shoot-and-correct.</p>"},{"location":"modules/tunneling1D/single_field/#the-shooting-parameter-x","title":"The shooting parameter (x)","text":"<p>Instead of varying \\((\\phi(0))\\) directly, we vary</p> <p>\\(\\(\\boxed{\\phi(0) \\equiv \\phi_{\\rm absMin}+ e^{-x}\\big(\\phi_{\\rm metaMin}-\\phi_{\\rm absMin}\\big)}\\)\\)   so that:</p> <ul> <li>Small (x) \u2192 \\((\\phi(0))\\) close to the false minimum (high potential energy) \u2192 dynamics tend to overshoot across \\((\\phi_{\\rm metaMin})\\).</li> <li>Large (x) \u2192 \\((\\phi(0))\\) close to the true minimum (low energy) \u2192 dynamics turn around before reaching \\((\\phi_{\\rm metaMin})\\) (undershoot).</li> </ul> <p>If <code>xguess</code> is not provided, we choose a sensible default by placing \\((\\phi(0))\\) near the barrier \u201cedge\u201d \\((\\phi_{\\rm bar})\\), i.e.</p> \\[x_{\\rm init} \\approx -\\ln\\left( \\frac{\\phi_{\\rm bar}-\\phi_{\\rm absMin}}{\\phi_{\\rm metaMin}-\\phi_{\\rm absMin}} \\right).\\]"},{"location":"modules/tunneling1D/single_field/#radii-and-tolerances-numerics","title":"Radii and tolerances (numerics)","text":"<ul> <li> <p>We scale all radii with the characteristic <code>rscale</code> (Lot SF-2).</p> </li> <li> <p><code>rmin * rscale</code>: the starting radius guess and initial stepsize.</p> </li> <li><code>drmin = 0.01 * rmin * rscale</code>: minimum allowed stepsize for the RK driver.</li> <li><code>rmax * rscale</code>: maximum travel distance from the start.</li> <li> <p>Error controls for the adaptive RK driver (Lot SF-4):</p> </li> <li> <p><code>phitol</code> sets both relative (<code>epsfrac=[phitol, phitol]</code>) and absolute tolerances</p> </li> </ul> <p>\\(\\(epsabs = \\big[\\texttt{phitol}\\cdot |\\Delta\\phi|, \\texttt{phitol}\\cdot |\\Delta\\phi|/\\texttt{rscale}\\big]\\)\\)     for \\(([\\phi,\\phi'])\\).   * The driver uses a strict scalar for per-step control and per-component thresholds for event detection and convergence.</p>"},{"location":"modules/tunneling1D/single_field/#step-by-step-algorithm","title":"Step-by-step algorithm","text":"<ol> <li> <p>Map \\((x\\to\\Delta\\phi_0)\\). \\((\\Delta\\phi_0 = e^{-x}(\\phi_{\\rm metaMin}-\\phi_{\\rm absMin}))\\).</p> </li> <li> <p>Practical initial surface at \\((r_0&gt;0)\\).    Call <code>initialConditions(\u0394\u03c60, rmin*rscale, thinCutoff*|\u0394\u03c6|)</code>.    This uses the local quadratic solution (Lot SF-3) to pick \\((r_0)\\) such that    \\((|\\phi(r_0)-\\phi_{\\rm absMin}| \\approx \\texttt{thinCutoff}\\cdot|\\Delta\\phi|)\\)    and returns$ ((r_0,\\phi(r_0),\\phi'(r_0)))$.    Intuition: for thin walls, start integration near the wall (not at the exact center), which stabilizes shooting.</p> </li> <li> <p>Trial integration and event classification.    Run <code>integrateProfile(r0, y0, ...)</code> (Lot SF-4). Three outcomes:</p> </li> <li> <p><code>\"converged\"</code>: \\(( |\\phi-\\phi_{\\rm metaMin}| )\\) and \\(( |\\phi'| )\\) are within tolerance.</p> </li> <li><code>\"overshoot\"</code>: within the last step, \\((\\phi)\\) crossed \\((\\phi_{\\rm metaMin})\\);      we locate the crossing by cubic Hermite interpolation (with consistent slopes).</li> <li> <p><code>\"undershoot\"</code>: the field turns around before reaching \\((\\phi_{\\rm metaMin})\\)      (detected via \\((\\phi'=0 )\\)), again located by cubic interpolation.</p> </li> <li> <p>Bracket in (x) and bisect.    Maintain \\(([x_{\\min}, x_{\\max}])\\) such that:</p> </li> <li> <p>undershoot \u21d2 \\((x_{\\min} \\leftarrow x)\\) (we were too close to the true minimum);</p> </li> <li> <p>overshoot \u21d2 (\\(x_{\\max} \\leftarrow x)\\) (we were too close to the false minimum).      If no upper bound yet, expand geometrically (<code>xincrease \u2248 5</code>).      Once bracketing exists, bisect until \\((x_{\\max}-x_{\\min}&lt;\\texttt{xtol})\\) or we get <code>\"converged\"</code>.</p> </li> <li> <p>Final dense pass (returned profile).    With the last valid \\(((r_0,y_0))\\) and end radius \\((r_f)\\), build a uniform array    <code>R = linspace(r0, rf, npoints)</code> and call    <code>integrateAndSaveProfile(R, y0, ...)</code>.    This integrates adaptively and fills every <code>R[i]</code> by cubic Hermite interpolation between accepted RK steps. The return object is:</p> </li> <li> <p><code>R</code>: radii,</p> </li> <li><code>Phi</code>: (\\phi(R)),</li> <li><code>dPhi</code>: (\\phi'(R)),</li> <li> <p><code>Rerr</code>: first radius where the step would have fallen below <code>drmin</code> (if it happened), else <code>None</code>.</p> </li> <li> <p>(Optional) Interior points \\((0 \\le r &lt; r_0)\\).    If <code>max_interior_pts</code> is not zero, we synthesize points in the bubble interior using the analytic local solution (<code>exactSolution</code>) derived in Lot SF-3. We place up to <code>max_interior_pts</code> points on a non-uniform grid that lands exactly on (r=0) and \\((r=r_0)\\), then concatenate interior and integrated segments.</p> </li> <li> <p>If <code>max_interior_pts=None</code>, we default to <code>npoints//2</code>.</p> </li> <li>Set it to <code>0</code> to skip interior fill.</li> </ol>"},{"location":"modules/tunneling1D/single_field/#convergence-failure-modes-and-what-to-tweak","title":"Convergence / failure modes (and what to tweak)","text":"<ul> <li>Iteration cap reached while bracketing in (x): increase <code>rmax</code>, relax <code>phitol</code>, or widen <code>thinCutoff</code> so the initial surface is farther from the center (easier shooting).</li> <li>Step underflow (<code>dr &lt; drmin</code>) in the driver: increase <code>rmin</code> (hence <code>drmin</code>) or relax <code>phitol</code>.</li> <li>Both trials on the same side (can't bracket): try a smaller/larger <code>xguess</code>, or increase <code>xincrease</code> (implicitly done inside); extreme thin-wall cases often benefit from a larger <code>thinCutoff</code> (e.g. <code>0.05\u20130.2</code>).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#physical-interpretation_1","title":"Physical interpretation","text":"<ul> <li>In the thin-wall limit (almost degenerate minima), the correct (x) is large: \\((\\phi(0))\\) sits very close to the true vacuum and the wall is narrow. Small changes in (x) produce large changes in outcome\u2014hence the careful bracketing.</li> <li>In the thick-wall regime, the search is gentler: the field starts farther from the true minimum, and both overshoot/undershoot are easier to bracket.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#output-guarantees","title":"Output guarantees","text":"<ul> <li>The returned profile always corresponds to the last successful integration over \\(([r_0,r_f])\\), sampled at <code>npoints</code>. If an interior segment is synthesized, the profile begins at (r=0); otherwise it begins at \\((r=r_0&gt;0)\\) (typical for thin walls).</li> <li><code>Rerr</code> is purely diagnostic: if not <code>None</code>, it marks the first place where the integrator had to clamp a too-small step to <code>drmin</code>; the profile remains valid.</li> </ul> <p>In short: <code>findProfile</code> wraps three building blocks developed in the previous lots\u2014(i) a stable local start (<code>initialConditions</code>),  (ii) an event-aware, tolerance-controlled driver (<code>integrateProfile</code>), and (iii) a dense sampler (<code>integrateAndSaveProfile</code>)\u2014into a robust overshoot/undershoot search in the single scalar parameter (x).</p>"},{"location":"modules/tunneling1D/single_field/#lot-sf-6-action-post-processing","title":"Lot SF-6 \u2014 Action &amp; post-processing","text":"<p>Goal.  Given a converged bounce profile \\(((R,\\Phi(R),\\Phi'(R)))\\), compute the Euclidean action and provide diagnostics  and geometric scales that are useful for interpretation and downstream phenomenology. This lot modernizes the legacy <code>findAction</code> and adds practical post-processing helpers.</p> <p>Context &amp; notation</p> <ul> <li>We work in \\((d=\\alpha+1)\\) radial dimensions (i.e., \\((\\alpha=d-1)\\) in the ODE).</li> <li>The unit \\((\\alpha)\\)-sphere area is</li> </ul> \\[\\Omega_\\alpha \\equiv \\frac{2\\pi^{(\\alpha+1)/2}}{\\Gamma!\\big((\\alpha+1)/2\\big)}\\] <ul> <li>A profile is the named tuple returned by <code>findProfile</code>: <code>profile.R</code>, <code>profile.Phi</code>, <code>profile.dPhi</code> (and <code>profile.Rerr</code>).</li> <li>We subtract the false-vacuum energy \\((V(\\phi_{\\rm meta}))\\) so the action density is anchored at the metastable vacuum.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#whats-new-vs-the-legacy","title":"What\u2019s new vs. the legacy","text":"<ul> <li>New: <code>actionBreakdown(profile)</code> \u2014 splits (S) into kinetic/potential/\u201cinterior bulk\u201d pieces and returns per-radius densities for plotting and checks.</li> <li>New: <code>wallDiagnostics(profile, frac=(0.1,0.9))</code> \u2014 estimates wall position and thickness directly from the profile (levels in \\((\\phi)\\) and peak \\((|\\Phi'|)\\)).</li> <li>New: <code>betaEff(profile, method=...)</code> \u2014 proxies for an inverse length/time scale \\((\\beta_{\\rm eff})\\) (<code>\"rscale\"</code>, <code>\"curvature\"</code>, <code>\"wall\"</code>).</li> <li>Improved: <code>evenlySpacedPhi(...)</code> \u2014 robust \\((\\phi)\\)-space resampling with monotonicity enforcement and endpoint padding (zero slopes at vacua).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#physics-background-why-these-formulas","title":"Physics background (why these formulas)","text":"<p>The action (with the false-vacuum constant removed) is</p> \\[S = \\int_{r_0}^{\\infty}\\Big[\\tfrac12(\\partial_r\\phi)^2+\\big(V(\\phi)-V(\\phi_{\\rm meta})\\big)\\Big]  r^\\alpha dr\\Omega_\\alpha +\\] \\[+\\underbrace{ \\int_{0}^{r_0} \\big(V(\\phi(r_0)) - V(\\phi_{\\rm meta})\\big),d^dr }_{\\text{\u201cinterior bulk\u201d}}\\] <p>because thin-wall integrations start at \\((r=r_0&gt;0)\\). Regularity implies$ (\\phi'(r)\\sim\\mathcal{O}(r))$, so the gradient contribution from \\(([0,r_0])\\) is negligible, but the potential offset must be accounted for via the (d)-ball volume:</p> \\[{\\rm Vol}_d(r_0)=\\frac{\\pi^{d/2}}{\\Gamma(d/2+1)}r_0^d\\] <p>This matches the original legacy semantics while making the computation explicit and numerically stable.</p>"},{"location":"modules/tunneling1D/single_field/#findactionprofile","title":"<code>findAction(profile)</code>","text":"<p>What it computes. The scalar Euclidean action (S) using</p> \\[S_{\\rm line}=\\int_{r_0}^{\\infty}\\left[\\tfrac12\\Phi'(r)^2 + V(\\Phi(r))-V(\\phi_{\\rm meta})\\right] r^\\alpha dr\\Omega_\\alpha\\] \\[\\Delta S_{\\rm interior}={\\rm Vol}*d(r_0)\\big[V(\\Phi(r_0))-V(\\phi*{\\rm meta})\\big]\\] <p>and returns \\((S=S_{\\rm line}+\\Delta S_{\\rm interior})\\).</p> <p>Inputs. <code>profile</code> (from <code>findProfile</code>): arrays <code>R</code>, <code>Phi</code>, <code>dPhi</code> must be 1D, same length \\((\\ge 2)\\).</p> <p>Output. A single <code>float</code> \u2014 the Euclidean action.</p> <p>Why it matters. (S) controls the (zero-temperature) tunneling rate prefactor \\(( \\Gamma \\propto e^{-S} )\\) (up to determinants). In thermal problems \\((S_3/T)\\) plays the analogous role;  our formulation and helpers are designed to interface cleanly with those workflows later.</p> <p>Numerical notes.</p> <ul> <li>Uses Simpson integration on the line contribution with the correct geometric weight \\((r^\\alpha\\Omega_\\alpha)\\).</li> <li>Adds the interior potential-only bulk term if \\((r_0&gt;0)\\).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#evenlyspacedphiphi-dphi-npoints100-k1-fixabstrue","title":"<code>evenlySpacedPhi(phi, dphi, npoints=100, k=1, fixAbs=True)</code>","text":"<p>What it does. Resamples \\(((\\phi(r), \\phi'(r)))\\) onto a uniform grid in \\((\\phi)\\), returning arrays \\(((\\phi_i, \\phi'_i))\\) with \\((\\phi_i)\\) equally spaced.</p> <p>Why it\u2019s useful.</p> <ul> <li>Many diagnostics/plots are more readable vs field value than vs radius (e.g., comparing kinetic vs potential terms along the wall).</li> <li>Makes it easy to overlay different profiles in the same \\((\\phi)\\)-space.</li> </ul> <p>Key options.</p> <ul> <li><code>fixAbs=True</code> pads endpoints to exactly \\(((\\phi_{\\rm abs},\\phi_{\\rm meta}))\\) with zero slopes \u2014 physically correct for regular instantons.</li> <li>Enforces monotonic \\((\\phi)\\) (drops tiny backtracks before spline fitting) to avoid oscillatory spline artifacts.</li> <li><code>k=1</code> (linear) is very robust; <code>k=3</code> gives smooth derivatives when the data are clean.</li> </ul> <p>Output. <code>phi2</code>, <code>dphi2</code> (both 1D arrays with length <code>npoints</code>).</p>"},{"location":"modules/tunneling1D/single_field/#actionbreakdownprofile-new","title":"<code>actionBreakdown(profile)</code>  \u2014 New","text":"<p>What it returns. A named tuple with:</p> <ul> <li><code>S_total</code>: same value as <code>findAction(profile)</code>.</li> <li><code>S_kin</code>, <code>S_pot</code>: line integrals of the kinetic and potential pieces separately.</li> <li><code>S_interior</code>: the interior bulk correction.</li> <li>Copies of <code>r</code>, <code>phi</code>, <code>dphi</code>.</li> <li> <p><code>density</code>: a dict with arrays</p> </li> <li> <p><code>density[\"kin\"]</code> = \\(tfrac12\\Phi'^2 r^\\alpha \\Omega_\\alpha\\),</p> </li> <li><code>density[\"pot\"]</code> = \\((V(\\Phi)-V_{\\rm meta}) r^\\alpha \\Omega_\\alpha\\)</li> <li><code>density[\"tot\"] = density[\"kin\"] + density[\"pot\"]</code>.</li> </ul> <p>Why it\u2019s helpful.</p> <ul> <li>Lets you plot where the action is accumulated (e.g., most weight sits in the wall).</li> <li>Makes sanity checks straightforward (e.g., verify positivity of densities, small contribution far from the wall, etc.).</li> </ul> <p>Caveat. <code>density[\"tot\"]</code> covers only the line part; the interior bulk is a single additive scalar, not a distributed density.</p>"},{"location":"modules/tunneling1D/single_field/#walldiagnosticsprofile-frac01-09-new","title":"<code>wallDiagnostics(profile, frac=(0.1, 0.9))</code>  \u2014 New","text":"<p>Idea. Characterize the wall geometry directly from the profile.</p> <p>Definitions.</p> <ul> <li>Let \\((\\Delta\\phi \\equiv \\phi_{\\rm meta}-\\phi_{\\rm abs})\\).</li> <li>Define field levels</li> </ul> \\[\\phi_{\\rm lo}=\\phi_{\\rm abs}+f_{\\rm lo}\\Delta\\phi\\] \\[\\phi_{\\rm hi}= \\phi_{\\rm abs}+f_{\\rm hi}\\Delta\\phi  \\] \\[(\\phi_{\\rm mid}=\\tfrac12(\\phi_{\\rm abs}+\\phi_{\\rm meta})) \\] <ul> <li>Invert the (monotonic) profile to get radii \\((r(\\phi))\\);</li> </ul> <p>What it returns.</p> <ul> <li><code>r_peak</code>: radius where \\((|\\Phi'|)\\) is maximal (often used as \u201cwall center\u201d).</li> <li><code>r_mid</code>: radius where \\((\\phi=\\phi_{\\rm mid})\\).</li> <li><code>r_lo</code>, <code>r_hi</code>: radii at the chosen fractional field levels.</li> <li><code>thickness</code> = \\(|r_{\\rm hi} - r_{\\rm lo}|\\).</li> <li>The field levels <code>phi_lo</code>, <code>phi_hi</code>.</li> </ul> <p>Why it\u2019s useful.</p> <ul> <li>Provides a coordinate-free estimate of wall thickness and location.</li> <li>Enables simple comparisons between thin- and thick-wall regimes.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#betaeffprofile-methodrscale-new","title":"<code>betaEff(profile, method=\"rscale\")</code>  \u2014 New","text":"<p>Purpose. Return a proxy for the inverse timescale/length \\((\\beta_{\\rm eff})\\) often used for order-of-magnitude reasoning.  This is not the cosmological \\((\\beta \\equiv -d(S_3/T)/dt)\\); computing that requires a (T)-dependent potential and \\((S_3(T)/T)\\).</p> <p>Methods.</p> <ul> <li><code>\"rscale\"</code>: \\((\\beta_{\\rm eff} = 1/\\texttt{rscale})\\).   Always defined; <code>rscale</code> was obtained in Lot SF-2 from barrier geometry.</li> <li><code>\"curvature\"</code>: \\((\\beta_{\\rm eff} = \\sqrt{|V''(\\phi_{\\rm top})|})\\).   Uses the second derivative at the barrier top; agrees with \\((1/\\texttt{rscale})\\) up to \\((\\mathcal{O}(1))\\) in many models.</li> <li><code>\"wall\"</code>: \\((\\beta_{\\rm eff}=1/\\texttt{thickness})\\).   Thickness from <code>wallDiagnostics</code>; simple geometric proxy tied to the wall width.</li> </ul> <p>When to use which.</p> <ul> <li>If you just need one number: <code>\"rscale\"</code>.</li> <li>If the barrier curvature is physically meaningful in your model: <code>\"curvature\"</code>.</li> <li>If your analysis hinges on wall width (e.g., friction effects): <code>\"wall\"</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#practical-guidance-pitfalls","title":"Practical guidance &amp; pitfalls","text":"<ul> <li>Profiles starting at \\((r_0&gt;0)\\) (thin walls):   Expect a nonzero interior bulk potential term. The kinetic part from \\(([0,r_0])\\) is suppressed by regularity.</li> <li>Units &amp; scaling:   (S) is dimensionless if (r) and (V) are in consistent units (as in the usual bounce conventions). All geometric addends preserve dimensional consistency.</li> <li>Monotonicity in (\\phi):   Small numerical back-and-forth in (\\phi(r)) can spoil interpolation in (\\phi)-space. The resampler removes those via a monotonic-indices filter before spline fitting.</li> <li>Interpreting densities:   Most of the action density typically localizes in the wall; plotting <code>density[\"kin\"]</code> and <code>density[\"pot\"]</code> helps verify this and diagnose integration issues.</li> </ul>"},{"location":"modules/tunneling1D/tests_single_field/","title":"Tests \u2014 Single Field Instanton","text":"<p>This page collects hands-on examples for the Single Field Instanton module, organized by lot.  Each example states the physical meaning, the expected outcome, a slot for the console output/code and (when applicable) an image slot.</p> <p>These examples correspond to the class SingleFieldInstaton only.</p>"},{"location":"modules/tunneling1D/tests_single_field/#lot-sf-1-potential-interface-validations","title":"Lot SF-1 \u2014 Potential Interface &amp; Validations","text":"<p>See the full, executable script for this lot here: <code>tests/single_field/Lot_SF_1.py</code>. for all example the potential chosen was:</p> \\[\\text{THIN}: \\frac{1}{4}\\phi ^4 - 0.49\\phi ^3 + 0.235 \\phi ^2 \\] \\[\\text{THICK}:  \\frac{1}{4}\\phi ^4 - \\frac{2}{5}\\phi^3 + \\frac{1}{10}\\phi^2 \\] <p>How to run just this case</p> <pre><code>python -m tests.tunneling1D.single_field.Lot_SF1 \n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#example-1-metastability-validation-exception-path","title":"Example 1 \u2014 Metastability validation (exception path)","text":"<p>What it shows (physics): A tunneling solution exists only if the false (metastable) vacuum is higher in energy than the true (absolute) vacuum: \\((V(\\phi_{\\text{meta}}) &gt; V(\\phi_{\\text{abs}}))\\).  Swapping them violates metastability and must raise a clear error.</p> <p>Expected result: Constructing <code>SingleFieldInstanton</code> with <code>V(phi_metaMin) \u2264 V(phi_absMin)</code> raises a <code>PotentialError</code> explaining that the configuration is \u201cstable, not metastable.\u201d</p> <p>Console output:</p> <pre><code>=== Test 1: Metastability validation ===\nOK: PotentialError raised as expected -&gt; ('V(phi_metaMin) &lt;= V(phi_absMin); tunneling cannot occur.', 'stable, not metastable')\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#example-2-accuracy-of-derivative-helpers-o4-vs-o2-near-minimum-blend-tests-3-4","title":"Example 2 \u2014 Accuracy of derivative helpers (o4 vs o2) &amp; near-minimum blend (Tests 3 + 4)","text":"<p>What it shows (physics):</p> <ul> <li>For smooth potentials, 4th-order FD (our default) is more accurate than 2nd-order for both (V') and (V'').</li> <li>Very close to the absolute minimum, the helper <code>dV_from_absMin</code> smoothly blends to the local linear behavior \\((V'(\\phi)\\approx V''(\\phi),\\Delta\\phi)\\) , improving numerical stability where finite differences can be noisy.</li> </ul> <p>Expected result:</p> <ul> <li>Reported max errors for o(4) are lower than for o(2) when compared to analytic (V') and (V'') (both thin and thick quartic examples).</li> <li>The lines <code>delta=... -&gt; dV_from_absMin=..., ref\u2248d2V*delta=..., rel.err=...</code> show tiny relative errors (\u226a 1% for the tiny offsets used).</li> </ul> <p>Console output:</p> <pre><code>=== Test 3: Built-in FD vs analytic derivatives ===\n[THIN] max|dV_fd4 - dV_true|  = 1.253e-13\n[THIN] max|d2V_fd4 - d2V_true|= 3.888e-10\n[THIN] max|dV_fd2 - dV_true|  = 7.100e-07\n[THIN] max|d2V_fd2 - d2V_true|= 5.002e-07\n[THIN] barrier check: V(phi_bar) - V(phi_metaMin) = +2.602e-12\n\n[THICK] max|dV_fd4 - dV_true|  = 1.127e-13\n[THICK] max|d2V_fd4 - d2V_true|= 3.779e-10\n[THICK] max|dV_fd2 - dV_true|  = 8.000e-07\n[THICK] max|d2V_fd2 - d2V_true|= 5.002e-07\n[THICK] barrier check: V(phi_bar) - V(phi_metaMin) = +3.056e-11\n\n=== Test 4: dV_from_absMin near \u03c6_absMin ===\ndelta=1.0e-06 -&gt; dV_from_absMin=5.300e-07, ref\u2248d2V*delta=5.300e-07, rel.err=4.538e-10\ndelta=5.0e-06 -&gt; dV_from_absMin=2.650e-06, ref\u2248d2V*delta=2.650e-06, rel.err=5.739e-11\ndelta=1.0e-05 -&gt; dV_from_absMin=5.300e-06, ref\u2248d2V*delta=5.300e-06, rel.err=3.055e-09\ndelta=5.0e-05 -&gt; dV_from_absMin=2.651e-05, ref\u2248d2V*delta=2.651e-05, rel.err=3.604e-07\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#example-3-visual-check-vphi-vphi-vphi-test-5","title":"Example 3 \u2014 Visual check: \\((V(\\phi)), (V'(\\phi)), (V''(\\phi))\\) (Test 5)","text":"<p>What it shows (physics):</p> <ul> <li>Potential shapes for thin vs thick cases.</li> <li>Agreement between analytic and built-in derivative operators for (V') and (V'').</li> <li>This is a pre-instanton sanity check that the potential interface + derivative helpers behave as expected.</li> </ul> <p>Expected result:</p> <ul> <li>Curves for analytic vs built-in (V') and (V'') visually overlap.</li> <li>Residuals printed by the script are small (implementation- and BLAS-dependent, typically in the (10^{-8})\u2013(10^{-6}) range on these quartics).</li> </ul> <p>Image slots:</p> <p>Thin-wall \u2014 Potential </p> <p>Thin-wall \u2014 First derivative </p> <p>Thin-wall \u2014 Second derivative </p> <p>Thick-wall \u2014 Potential </p> <p>Thick-wall \u2014 First derivative </p> <p>Thick-wall \u2014 Second derivative </p> <p>Console output:</p> <pre><code>=== Test 5: Plots (potential and derivatives) ===\n[THIN] residuals: max|V'_fd - V'_ref|=1.253e-13, max|V''_fd - V''_ref|=3.888e-10\n[THICK] residuals: max|V'_fd - V'_ref|=1.127e-13, max|V''_fd - V''_ref|=3.779e-10\n\n---------- END OF TESTS: Lot SF-1 ----------\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#lot-sf-2-barrier-scales","title":"Lot SF-2 \u2014 Barrier &amp; scales","text":"<p>Goal. Visualize the potential barrier geometry and report the characteristic length scale(s) used by the solver:</p> <ul> <li> <p>Vertical markers for:</p> </li> <li> <p>\\(( \\phi_{\\rm top} )\\): location of the barrier maximum between \\(( \\phi_{\\rm meta} )\\) and \\(( \\phi_{\\rm bar} )\\);</p> </li> <li>\\(( \\phi_{\\rm bar} )\\): \u201cedge\u201d on the downhill side where \\(( V(\\phi_{\\rm bar}) = V(\\phi_{\\rm meta}) )\\).</li> <li>Horizontal line at \\(( V(\\phi_{\\rm meta}) )\\).</li> <li> <p>Printed diagnostics:</p> </li> <li> <p><code>phi_top</code>, <code>phi_bar</code>, \\(( \\Delta V_{\\rm top} \\equiv V(\\phi_{\\rm top}) - V(\\phi_{\\rm meta}) )\\);</p> </li> <li><code>rscale_cubic</code> (robust/legacy) and, when defined, <code>rscale_curv</code> from \\((V''(\\phi_{\\rm top}))\\).</li> </ul> <p>Physics intuition:</p> <ul> <li>Thin wall (nearly degenerate minima) \u2192 sharper barrier (more negative (V'') at the top) \u2192 smaller length scale (wall is thinner).</li> <li>Thick wall (more separated minima) \u2192 broader barrier \u2192 larger length scale.</li> </ul> <p>See the full, executable script for this lot here: <code>tests/single_field/Lot_SF2.py</code>. for all example the potential chosen was:</p> \\[\\text{THIN}: \\frac{1}{4}\\phi ^4 - 0.49\\phi ^3 + 0.235 \\phi ^2 \\] \\[\\text{THICK}:  \\frac{1}{4}\\phi ^4 - \\frac{2}{5}\\phi^3 + \\frac{1}{10}\\phi^2 \\] <p>Script: <code>tests/tunneling1D/single_field/Lot_SF2.py</code></p> <p>How to run just this case (Run both examples at once)</p> <pre><code>python -m tests.tunneling1D.single_field.Lot_SF2  # it includes thin- and thick-wall cases\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#test-a-thin-wall-barrier-markers-scales","title":"Test A \u2014 Thin-wall: barrier markers &amp; scales","text":"<p>What this shows</p> <ul> <li>\\((V(\\phi))\\) with the barrier top and edge identified.</li> <li>Console readout with the barrier height and the two characteristic scales.</li> </ul> <p>Expected outcome (physics)</p> <ul> <li>\\((\\phi_{\\rm top})\\) sits between \\((\\phi_{\\rm meta}=0)\\) and \\((\\phi_{\\rm abs}=1)\\).</li> <li>\\((V(\\phi_{\\rm top}) &gt; V(\\phi_{\\rm meta}))\\) so \\(( \\Delta V_{\\rm top} &gt; 0 )\\).</li> <li><code>rscale_cubic</code> is finite and typically smaller than in the thick-wall case (thinner wall).</li> <li><code>rscale_curv</code> is reported finite if \\((V''(\\phi_{\\rm top})&lt;0)\\); otherwise shown as \u221e (flat top).</li> </ul> <p>Example console output</p> <pre><code>========================================================================\nCASE: Thin-wall demo\n========================================================================\nBarrier diagnostics:\n  phi_metaMin = 0,  V(phi_metaMin) = 0\n  phi_top     = 0.46999999834,  \u0394V_top \u2261 V(top)-V(meta) = 0.0132374325\n  phi_bar     = 0.837171431377  (V equals V(phi_metaMin) on downhill side)\nScale diagnostics:\n  rscale_cubic (legacy/robust) = 1.66770930502\n  rscale_curv  (from V'' at top)= 2.00360975005  with  V''(top) = -0.249099999801\n</code></pre> <p>Figure \u201cThin-wall demo: Potential with barrier markers.\u201d </p>"},{"location":"modules/tunneling1D/tests_single_field/#test-b-thick-wall-barrier-markers-scales","title":"Test B \u2014 Thick-wall: barrier markers &amp; scales","text":"<p>What this shows</p> <ul> <li>Same plot/diagnostics as Test A, now for a broader barrier.</li> </ul> <p>Expected outcome (physics)</p> <ul> <li>\\((\\phi_{\\rm top})\\) again lies between \\((\\phi_{\\rm meta})\\) and \\((\\phi_{\\rm abs})\\).</li> <li>Barrier height and curvature differ from the thin-wall case; you should observe a larger <code>rscale_cubic</code> (thicker wall).</li> <li><code>rscale_curv</code> is finite if the barrier top is genuinely curved; otherwise \u221e for a flat-ish top.</li> </ul> <p>Example console output (you will paste your run here)</p> <pre><code>========================================================================\nCASE: Thick-wall demo\n========================================================================\nBarrier diagnostics:\n  phi_metaMin = 0,  V(phi_metaMin) = 0\n  phi_top     = 0.200000001967,  \u0394V_top \u2261 V(top)-V(meta) = 0.0012\n  phi_bar     = 0.310102050146  (V equals V(phi_metaMin) on downhill side)\nScale diagnostics:\n  rscale_cubic (legacy/robust) = 2.35702262713\n  rscale_curv  (from V'' at top)= 2.49999998156  with  V''(top) = -0.16000000236\n</code></pre> <p>Figure \u201cThick-wall demo: Potential with barrier markers.\u201d </p>"},{"location":"modules/tunneling1D/tests_single_field/#lot-3-quadratic-local-solution-initial-conditions","title":"Lot 3 \u2014 Quadratic local solution &amp; initial conditions","text":"<p>See the full, executable script for this lot here: <code>tests/single_field/Lot_SF3.py</code>. for all example the potential chosen was:</p> \\[\\text{THIN}: \\frac{1}{4}\\phi ^4 - 0.49\\phi ^3 + 0.235 \\phi ^2 \\] \\[\\text{THICK}:  \\frac{1}{4}\\phi ^4 - \\frac{2}{5}\\phi^3 + \\frac{1}{10}\\phi^2 \\] <p>This lot illustrates the local (small-radius) analytic solution used by <code>SingleFieldInstanton.exactSolution</code> and how we choose practical starting points via <code>SingleFieldInstanton.initialConditions</code>. We work with the same thin- and thick-wall toy potentials from previous lots.</p> <p>How to run just this case (Run both examples at once)</p> <pre><code>python -m tests.tunneling1D.single_field.Lot_SF3  # it includes all tests (more than the ones here)\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#test-1-local-quadratic-solution-near-the-true-minimum-stable-curvature","title":"Test 1 \u2014 Local quadratic solution near the true minimum (stable curvature)","text":"<p>What it shows</p> <ul> <li>Around the stable minimum, \\((V''(\\phi_0)&gt;0)\\), the non-singular solution behaves smoothly with \\((\\phi'(0)=0)\\) and a quadratic rise at small (r).</li> <li>The plot overlays \\((\\phi(r)-\\phi_0)\\) and \\((\\phi'(r))\\) computed by <code>exactSolution</code>.</li> </ul> <p>Expected result</p> <ul> <li>\\((\\phi'(0)=0)\\) numerically.</li> <li>\\((\\phi(r)-\\phi_0)\\) grows \\((\\propto r^2)\\) for very small (r); \\((\\phi'(r)\\propto r)\\).</li> </ul> <p>Console excerpts (typical)</p> <pre><code>=== Test 1: Local quadratic solution near abs minimum (d2V &gt; 0) ===\n Thin: dV(phi0)=5.315e-04, d2V(phi0)=5.331e-01, rscale\u22481.668e+00\n  Expectation: phi'(0)=0, smooth quadratic rise; numerical curve should be regular.\n\n Thick: dV(phi0)=8.018e-04, d2V(phi0)=8.036e-01, rscale\u22482.357e+00\n  Expectation: phi'(0)=0, smooth quadratic rise; numerical curve should be regular.\n</code></pre> <p>Figure</p> <p></p> <p></p>"},{"location":"modules/tunneling1D/tests_single_field/#test-2-local-solution-near-the-barrier-top-unstable-curvature","title":"Test 2 \u2014 Local solution near the barrier top (unstable curvature)","text":"<p>What it shows</p> <ul> <li>At the barrier top \\((\\phi_{\\text{top}})\\), \\((V'(\\phi_{\\text{top}})\\approx 0)\\) and \\((V''(\\phi_{\\text{top}})&lt;0)\\).</li> <li><code>exactSolution</code> switches to the \\((J_\\nu)\\) branch; the solution remains regular at (r=0) with \\((\\phi'(0)=0)\\), </li> <li>but the local shape reflects the inverted curvature.</li> </ul> <p>Expected result</p> <ul> <li>Printed curvature satisfies \\((d^2V(\\phi_{\\text{top}})&lt;0)\\) (up to near-flat numerical cases).</li> <li>Plots show a small-(r) \u201cinverted\u201d profile relative to \\((\\phi_{\\text{top}})\\), still smooth at the origin.</li> </ul> <p>Console excerpts (typical)</p> <pre><code>=== Test 2: Local solution near barrier top (d2V &lt; 0) ===\n Thin: phi_top=0.470000, dV(phi_top)=-1.268e-10, d2V(phi_top)=-2.491e-01\n  Expectation: d2V &lt; 0 \u2192 oscillatory (J_\u03bd) behavior; still regular at r=0 with phi'(0)=0.\n\n Thick: phi_top=0.200000, dV(phi_top)=-2.250e-11, d2V(phi_top)=-1.600e-01\n  Expectation: d2V &lt; 0 \u2192 oscillatory (J_\u03bd) behavior; still regular at r=0 with phi'(0)=0.\n</code></pre> <p>Figure</p> <p></p> <p></p>"},{"location":"modules/tunneling1D/tests_single_field/#test-4-initialconditions-pick-r_0phir_0phir_0-and-visualize-the-short-path","title":"Test 4 \u2014 <code>initialConditions</code>: pick \\(((r_0,\\phi(r_0),\\phi'(r_0)))\\) and visualize the short path","text":"<p>What it shows</p> <ul> <li>Given an interior offset \\((\\Delta\\phi_0)\\) and a target cutoff \\((|\\Delta\\phi(r_0)|)\\), we solve for a practical \\((r_0)\\).</li> <li>The short trajectory from (r=0) to \\((r=r_0)\\) is plotted using the same local quadratic solution; the chosen starting point is marked.</li> </ul> <p>Expected result</p> <ul> <li>$|\\phi(r_0)-\\phi_{\\text{abs}}|\\gtrsim $ cutoff.</li> <li>\\(sign(\\phi'(r_0))=\\operatorname{sign}(\\Delta\\phi_0)\\).</li> </ul> <p>Console excerpts (typical)</p> <pre><code>=== Test 4: initialConditions (r0, phi(r0), phi'(r0)) ===\n Thin: r0=1.667709e-03, phi(r0)=1.018316e+00, phi'(r0)=5.685050e-06\n  Expectation: |phi(r0)-phi_absMin| \u2273 cutoff, and phi'(r0) has the same sign as delta_phi0.\n\n Thick: r0=2.357023e-03, phi(r0)=1.018316e+00, phi'(r0)=1.199135e-05\n  Expectation: |phi(r0)-phi_absMin| \u2273 cutoff, and phi'(r0) has the same sign as delta_phi0.\n</code></pre> <p>Figure</p> <p></p> <p></p>"},{"location":"modules/tunneling1D/tests_single_field/#test-5-initialconditions-error-path-unreachable-cutoff","title":"Test 5 \u2014 <code>initialConditions</code> error path (unreachable cutoff)","text":"<p>What it shows</p> <ul> <li>If \\((\\Delta\\phi_0=0)\\) exactly (starting right at the true minimum) and the cutoff is strictly positive, </li> <li>the local model never reaches the cutoff; the function raises a clear <code>IntegrationError</code>.</li> </ul> <p>Expected result</p> <ul> <li>A caught <code>IntegrationError</code> with an informative message.</li> </ul> <p>Console excerpts (typical)</p> <pre><code>=== Test 5: initialConditions error (unreachable cutoff) ===\n Thin: Caught expected IntegrationError:\n   initialConditions: failed to bracket r0 (no crossing found).\n\n Thick: Caught expected IntegrationError:\n   initialConditions: failed to bracket r0 (no crossing found).\n\n---------- END OF TESTS: Lot SF-3 ----------\n</code></pre> <ul> <li>For more context (potential, barrier, and scaling) see Lots SF1 and SF2 above.</li> </ul>"},{"location":"modules/tunneling1D/tests_single_field/#lot-sf-4-ode-core-eom-event-detection-sampler","title":"Lot SF-4 \u2014 ODE core (EOM, event detection, sampler)","text":"<p>Goal. Exercise the heart of the solver:</p> <ul> <li>The equation of motion (EOM) used everywhere:</li> </ul> \\[\\frac{d^2\\phi}{dr^2} + \\frac{\\alpha}{r}\\frac{d\\phi}{dr} = b\\frac{dV}{d\\phi}(\\phi)\\] <p>written as a first-order system in \\((y=(\\phi,\\phi'))\\). * The adaptive RKQS driver that advances the solution and classifies steps as   undershoot (turning point before reaching the false vacuum) or overshoot   (crosses \\((\\phi_{\\rm meta})\\) within the step). * The sampler that records \\(((\\phi,\\phi'))\\) on a user grid (R) using cubic   Hermite interpolation between accepted RK steps.</p> <p>Physics intuition.</p> <ul> <li>For the bounce, the field starts near the true minimum \\((\\phi_{\\rm abs})\\) and tries to \u201cclimb\u201d toward the false minimum \\((\\phi_{\\rm meta})\\).</li> <li>If it turns around \\(((\\phi'\\to 0))\\) before it ever reaches \\((\\phi_{\\rm meta})\\), we say undershoot.</li> <li>If it crosses \\((\\phi_{\\rm meta})\\) at finite radius, that\u2019s an overshoot.</li> <li>The friction term \\((\\alpha,\\phi'/r)\\) is large at small (r), so the outcome depends delicately on the starting offset and slope.</li> </ul> <p>Script: <code>tests/tunneling1D/single_field/Lot_SF4.py</code> Run all examples in this lot:</p> <pre><code>python -m tests.tunneling1D.single_field.Lot_SF4\n</code></pre> <p>We keep the same toy potentials as before:</p> \\[\\textbf{THIN}: \\quad \\tfrac14\\phi^4 - 0.49\\phi^3 + 0.235\\phi^2\\] \\[\\textbf{THICK}: \\quad \\tfrac14\\phi^4 - \\tfrac{2}{5}\\phi^3 + \\tfrac{1}{10}\\phi^2\\] <p>Notes on tolerances. In the examples we build \\((\\texttt{epsfrac}=[\\texttt{phitol},\\texttt{phitol}])\\) and \\((\\texttt{epsabs}=[\\texttt{phitol}\\cdot|\\Delta\\phi|,\\texttt{phitol}\\cdot|\\Delta\\phi|/r_{\\rm scale}])\\). If you see a \u201cstep size underflow\u201d in thin-wall cases, relaxing to <code>phitol=1e-4</code> is often enough.</p>"},{"location":"modules/tunneling1D/tests_single_field/#test-b-thin-wall-event-detection-two-undershoots","title":"Test B \u2014 Thin-wall: event detection (two undershoots)","text":"<p>What this shows</p> <ul> <li>How <code>integrateProfile</code> detects turning points on a thin-wall potential.</li> <li>Two runs with different \u201cshooting\u201d parameters (x) (mapped internally to the initial offset \\((\\Delta\\phi_0 = e^{-x}(\\phi_{\\rm meta}-\\phi_{\\rm abs})))\\).</li> <li>For this potential and the chosen cutoff, both choices typically undershoot (large friction and small initial energy).</li> </ul> <p>Expected outcome</p> <ul> <li>Printed classification: <code>undershoot</code> in both panels, with an event radius \\((r_{\\rm evt})\\) where \\((\\phi'(r_{\\rm evt})\\approx 0)\\).</li> <li>Plots show \\((\\phi(r))\\) decreasing from near (\\phi_{\\rm abs}), then flattening at the turning point before reaching \\((\\phi_{\\rm meta})\\) (dashed line).</li> </ul> <p>How the figure is built</p> <ul> <li>We integrate until the event is detected, then call <code>integrateAndSaveProfile</code> to sample \\((\\phi(r))\\) densely up to \\((r_{\\rm evt})\\).</li> <li>The event is marked with a vertical dotted line and a dot at \\(((r_{\\rm evt},\\phi(r_{\\rm evt})))\\).</li> </ul> <p>Console excerpt</p> <pre><code>=== Test B: Event detection on thin-wall potential ===\n[thin-wall :: x=6.00] event = undershoot at r=1.566617e+01 (phi=2.441311e-01, dphi=6.852158e-17)\n[thin-wall :: x=0.20] event = undershoot at r=1.046569e-02 (phi=1.812700e-01, dphi=1.498745e-04)\n</code></pre> <p>Figure Thin-wall: two trajectories that undershoot (turning point before the false vacuum).</p> <p></p>"},{"location":"modules/tunneling1D/tests_single_field/#test-c-thick-wall-one-undershoot-one-overshoot","title":"Test C \u2014 Thick-wall: one undershoot, one overshoot","text":"<p>What this shows</p> <ul> <li> <p>On the thick-wall potential, different (x) give opposite outcomes:</p> </li> <li> <p>A smaller initial offset (low energy) \u2192 undershoot;</p> </li> <li>A larger offset (high energy) \u2192 overshoot (crossing of \\(\\phi_{meta}\\) ).</li> </ul> <p>Expected outcome</p> <ul> <li>Left panel: <code>undershoot</code> with \\((\\phi'(r_{\\rm evt})\\approx 0)\\) at finite (r), and \\((\\phi(r))\\) still above \\((\\phi_{\\rm meta})\\).</li> <li>Right panel: <code>overshoot</code> with a detected root of \\((\\phi(r)-\\phi_{\\rm meta}=0)\\); the crossing point is annotated.</li> </ul> <p>Console excerpt</p> <pre><code>=== Test C: Event detection on thick-wall potential ===\n[thick-wall :: x=0.20] event = undershoot at r=4.714045e-03 (phi=1.812693e-01, dphi=4.642159e-06)\n[thick-wall :: x=6.00] event =  overshoot at r=1.218941e+01 (phi=-4.989932e-15, dphi=-1.713411e-01)\n</code></pre> <p>Figure Thick-wall: undershoot (left) and overshoot (right); both events detected and marked. </p>"},{"location":"modules/tunneling1D/tests_single_field/#test-d-sampling-with-integrateandsaveprofile-on-a-user-grid","title":"Test D \u2014 Sampling with <code>integrateAndSaveProfile</code> on a user grid","text":"<p>What this shows</p> <ul> <li>You provide a monotone grid \\((R={r_i})\\) and a starting state \\(((r_0,\\phi(r_0),\\phi'(r_0)))\\).</li> <li>The solver advances with adaptive RK and fills every requested point using cubic Hermite interpolation (the same shape preserved internally for events).</li> </ul> <p>Expected outcome</p> <ul> <li>A smooth curve \\((\\phi(r))\\) across the whole user grid.</li> <li><code>Rerr</code> is <code>None</code> in typical runs; if the step would fall below <code>drmin</code>, the step is clamped and <code>Rerr</code> reports the first radius where this happened.</li> </ul> <p>Console excerpt (paste your run)</p> <pre><code>=== Test D: integrateAndSaveProfile on a user R-grid ===\nProfile sampled at 300 points.\nRerr (first clamped step radius) = None\n</code></pre> <p>Figure \u201cSampling \\(\\phi(r)\\) on a fixed grid provided by the user. </p>"},{"location":"modules/tunneling1D/tests_single_field/#test-f-explicit-initial-conditions-thin-wall","title":"Test F \u2014 Explicit initial conditions (thin-wall)","text":"<p>What this shows</p> <ul> <li>Instead of deriving \\(((r_0,\\phi(r_0),\\phi'(r_0)))\\) from a shooting parameter (x), we set them explicitly to demonstrate that the event classification logic does not depend on how the initial state was chosen.</li> <li> <p>Two examples:</p> </li> <li> <p>A gentle start near the true minimum with a small negative slope \u2192 often undershoot.</p> </li> <li>A more aggressive start with sizable downhill slope \u2192 tends to overshoot (depending on details of the potential and tolerances).</li> </ul> <p>Expected outcome</p> <ul> <li>Clear printed event classification with the detected \\((r_{\\rm evt})\\).</li> <li>Plots up to the event look consistent with the classification (turning point vs. crossing).</li> </ul> <p>Console excerpt (paste your run)</p> <pre><code>=== Test F: Explict Initial Conditions on thin-wall potential ===\n[thin-wall :: x=[0.001, [0.9, -0.1]]] event = undershoot at r=1.045860e+01 (phi=3.544355e-01, dphi=0.000000e+00)\n[thin-wall :: x=[1, [0.3, -2]]] event =  overshoot at r=1.176781e+00 (phi=-1.040834e-17, dphi=-1.439106e+00)\n---------- END: Lot SF-4 examples ----------\n</code></pre> <p>Figure Thin-wall with explicit initial states: undershoot (left) and overshoot (right). </p> <p>See more: full executable script at <code>tests/single_field/Lot_SF4.py</code>.</p>"},{"location":"modules/tunneling1D/tests_single_field/#lot-sf-5-profile-search-findprofile","title":"Lot SF-5 \u2014 Profile search (<code>findProfile</code>)","text":"<p>Goal. Demonstrate the full overshoot/undershoot shooting procedure that determines the instanton profile \\(( \\phi(r) )\\), and show how two knobs\u2014<code>thinCutoff</code> and the optional \u201cinterior fill\u201d\u2014affect only the very small-( r ) part of the curve in thin-wall situations.</p> <p>Solver recap (physics): We want the regular (non-singular) solution that starts near the true minimum \\(( \\phi_{\\rm abs} )\\) at ( r=0 ) and asymptotes to the false minimum \\(( \\phi_{\\rm meta} )\\) as \\(( r\\to\\infty )\\).  <code>findProfile</code> varies the \u201cshooting\u201d parameter ( x ) (equivalently \\(( \\Delta\\phi_0 \\propto e^{-x} )\\) )  and repeatedly integrates the ODE.</p> <ul> <li>If the trajectory crosses \\(( \\phi_{\\rm meta} )\\) within a step \u21d2 overshoot (initial kick too large).</li> <li>If it turns around (hits \\(( \\phi'(r)=0 )\\) ) before reaching \\(( \\phi_{\\rm meta} )\\) \u21d2 undershoot (kick too small).   Bisection on ( x ) lands on the unique critical trajectory; then the profile is sampled densely.</li> </ul> <p>See the full, executable script here: <code>tests/tunneling1D/single_field/Lot_SF5.py</code>.</p> <p>For all examples we reuse the same toy potentials:</p> \\[\\textbf{THIN:}\\quad \\tfrac{1}{4}\\phi^4 - 0.49,\\phi^3 + 0.235,\\phi^2\\] \\[\\textbf{THICK:}\\quad \\tfrac{1}{4}\\phi^4 - \\tfrac{2}{5}\\phi^3 + \\tfrac{1}{10}\\phi^2\\] <p>with \\(( \\phi_{\\rm abs}=1 )\\) and \\(( \\phi_{\\rm meta}=0 )\\), and \\(( \\alpha=2 )\\) (O(3) bounce).</p> <p>Script: <code>tests/tunneling1D/single_field/Lot_SF5.py</code> How to run just this lot</p> <pre><code>python -m tests.tunneling1D.single_field.Lot_SF5\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#test-1-legacy-demo-thin-thick-walls-default-settings","title":"Test 1 \u2014 Legacy demo: thin &amp; thick walls (default settings)","text":"<p>What this shows</p> <ul> <li>A faithful reproduction of the legacy quick-start: one call per potential,</li> </ul> <pre><code>  profile = SingleFieldInstanton(1.0, 0.0, V, dV).findProfile()\n</code></pre> <p>and a plot of \\(( \\phi(r) )\\). * Horizontal guides at \\(( \\phi_{\\rm abs} )\\) and \\(( \\phi_{\\rm meta} )\\) for context. * Console diagnostics: start/end radii, terminal residual \\(( |\\phi(r_f)-\\phi_{\\rm meta}| )\\).</p> <p>Physical expectations</p> <ul> <li>Thin-wall: The field sits near \\(( \\phi_{\\rm abs} )\\) until a relatively sharp transition (\u201cthin\u201d wall) then approaches \\(( \\phi_{\\rm meta} )\\).</li> <li>Thick-wall: Transition is more gradual; the wall is \u201cthicker.\u201d</li> <li>Both runs should converge without manual tuning (defaults are chosen to be robust).</li> </ul> <p>Paste your console excerpt here</p> <pre><code>=== Test 1: Legacy demo \u2014 thin &amp; thick walls ===\n=== Test 1: Legacy demo \u2014 thin &amp; thick walls ===\n[thin-wall] profile: R[0]=0.000000e+00, R[-1]=6.193054e+01\n         \u03c6(r0)=1.000000e+00, \u03c6(rf)=-1.857581e-04, |\u03c6(rf)-\u03c6_meta|=1.858e-04, \u03c6'(rf)=-1.679e-04\n         Rerr=None\n\n[thick-wall] profile: R[0]=0.000000e+00, R[-1]=2.089406e+01\n         \u03c6(r0)=7.420233e-01, \u03c6(rf)=9.449128e-06, |\u03c6(rf)-\u03c6_meta|=9.449e-06, \u03c6'(rf)=-1.251e-04\n         Rerr=None\n</code></pre> <p>Figure \u201cfindProfile \u2014 legacy thin/thick demos; horizontal guides at \\(\\phi_{abs}\\) and \\(\\phi_{meta}\\).\u201d </p>"},{"location":"modules/tunneling1D/tests_single_field/#test-2-sensitivity-to-thincutoff-and-interior-fill-thin-wall","title":"Test 2 \u2014 Sensitivity to <code>thinCutoff</code> and interior fill (thin wall)","text":"<p>What this shows</p> <ul> <li> <p>Two thin-wall profiles with identical physics but different handling of the tiny-radius region:</p> </li> <li> <p>Case A: <code>thinCutoff=0.01</code>, <code>max_interior_pts=None</code> (default). The solver places synthetic points inside the bubble using the local quadratic solution to illustrate the smooth \\(( r\\to0 )\\) behavior.</p> </li> <li>Case B: <code>thinCutoff=0.15</code>, <code>max_interior_pts=0</code>. We start farther from the origin (bigger cutoff) and disable interior fill, so the curve begins at \\(( r=r_0&gt;0 )\\).</li> </ul> <p>Physical expectations</p> <ul> <li>The two curves should match once ( r ) is beyond the artificially chosen \\(( r_0 )\\). Only the very small-( r ) portion differs\u2014this is numerical bookkeeping, not different physics.</li> <li>The terminal residual and action should be essentially unchanged; only \\(( r_0 )\\) and the early segment of \\(( \\phi(r) )\\) shift.</li> </ul> <p>Paste your console excerpt here</p> <pre><code>=== Test 2: Sensitivity to thinCutoff and interior fill (thin wall) ===\n[thin (A: thinCutoff=0.01, interior ON)] profile: R[0]=0.000000e+00, R[-1]=6.323233e+01\n         \u03c6(r0)=1.000000e+00, \u03c6(rf)=-2.498747e-20, |\u03c6(rf)-\u03c6_meta|=2.499e-20, \u03c6'(rf)=-1.572e-05\n         Rerr=None\n\n[thin (B: thinCutoff=0.15, interior OFF)] profile: R[0]=3.469565e+01, R[-1]=5.052437e+01\n         \u03c6(r0)=8.500000e-01, \u03c6(rf)=1.395670e-04, |\u03c6(rf)-\u03c6_meta|=1.396e-04, \u03c6'(rf)=4.599e-18\n         Rerr=None\n</code></pre> <p>Figure Effect of <code>thinCutoff</code> &amp; interior fill in a thin-wall case \u2014 curves overlay for \\(r \\gtrsim r_0\\). </p>"},{"location":"modules/tunneling1D/tests_single_field/#lot-sf-6-action-post-processing","title":"Lot SF-6 \u2014 Action &amp; post-processing","text":"<p>Goal. Take a computed bounce profile and extract physically meaningful, easy-to-compare summaries:</p> <ul> <li>Total Euclidean action via <code>findAction</code>.</li> <li>A full action breakdown (kinetic, potential, interior bulk) and per-r densities via <code>actionBreakdown</code>.</li> <li>A uniform \u03c6-grid view of the wall via <code>evenlySpacedPhi</code>.</li> <li>Wall geometry (location and thickness) via <code>wallDiagnostics</code>.</li> <li>Order-of-magnitude \u03b2-proxies via <code>betaEff</code> (<code>rscale</code>, <code>curvature</code>, <code>wall</code>).</li> </ul> <p>We continue to use the same benchmark potentials as in earlier lots:</p> \\[\\textbf{THIN:}\\quad V(\\phi)=\\tfrac14\\phi^4 - 0.49\\phi^3 + 0.235\\phi^2 \\] \\[ \\textbf{THICK:}\\quad V(\\phi)=\\tfrac14\\phi^4 - 0.40\\phi^3 + 0.10\\phi^2 \\] <p>with \\((\\phi_{\\rm abs}=1)\\) (true vacuum) and \\((\\phi_{\\rm meta}=0)\\) (false vacuum).</p> <p>Script: <code>tests/tunneling1D/single_field/Lot_SF6.py</code> Run all examples:</p> <pre><code>python -m tests.tunneling1D.single_field.Lot_SF6\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#test-a-action-density-breakdown","title":"Test A \u2014 Action &amp; density breakdown","text":"<p>What this shows</p> <ul> <li> <p>For each potential, we compute the profile, then:</p> </li> <li> <p><code>findAction(profile)</code> \u2192 total Euclidean action (S).</p> </li> <li><code>actionBreakdown(profile)</code> \u2192 numerical values of (S_{\\rm kin}), (S_{\\rm pot}), interior bulk, and arrays of per-r densities:</li> </ul> \\[\\text{kin density}=\\tfrac12(\\phi')^2r^{\\alpha}\\Omega_\\alpha \\] \\[\\text{pot density}=\\big[V(\\phi)-V(\\phi_{\\rm meta})\\big]r^{\\alpha}\\Omega_\\alpha\\] <ul> <li>Plots of the densities vs (r) highlight where the action accumulates (typically in the wall).</li> </ul> <p>Expected outcome (physics)</p> <ul> <li>The thin-wall case shows a narrow, high density peak (sharper wall).</li> <li>The thick-wall case shows a broader distribution (wall spread out).</li> <li>Console check: \\((S_{\\rm total}\\approx S_{\\rm kin}+S_{\\rm pot}+S_{\\rm interior})\\) (within numerical accuracy).</li> </ul> <p>Example console excerpt</p> <pre><code>=== Test A: Actions and density breakdown ===\n[thin-wall]\n  S_total    = 1.093093e+03\n   S_kin     = 1.639021e+03\n   S_pot     = -5.459281e+02\n   S_interior= 0.000000e+00\n  (check) S_kin + S_pot + S_interior = 1.093093e+03\n[thick-wall]\n  S_total    = 6.630329e+00\n   S_kin     = 9.946114e+00\n   S_pot     = -3.315785e+00\n   S_interior= 0.000000e+00\n  (check) S_kin + S_pot + S_interior = 6.630329e+00\n</code></pre> <p>Figure \u201cAction densities vs (r): thin (left) and thick (right). The peak localizes around the wall.\u201d </p>"},{"location":"modules/tunneling1D/tests_single_field/#test-b-uniform-grid-resampling-evenlyspacedphi","title":"Test B \u2014 Uniform \u03c6-grid resampling (<code>evenlySpacedPhi</code>)","text":"<p>What this shows</p> <ul> <li> <p>We resample \\(((\\phi,\\phi'))\\) on an evenly spaced grid in \\((\\phi)\\) rather than (r):</p> </li> <li> <p>This gives a clean, potential-centric view of the wall: \\((d\\phi/dr)\\) vs \\((\\phi)\\).</p> </li> <li>Helpful to compare how quickly the field sweeps through field space.</li> </ul> <p>Expected outcome (physics)</p> <ul> <li>Thin-wall: a sharper feature in \\((d\\phi/dr)\\) near mid-\\((\\phi)\\) (rapid transition).</li> <li>Thick-wall: a smoother, broader shape in \\((d\\phi/dr)\\) across \\((\\phi)\\).</li> </ul> <p>Figure \u201cResampled \\((d\\phi/dr)\\) vs \\((\\phi)\\): thin and thick. Both curves start/end with zero slope at the vacua.\u201d </p> <p></p>"},{"location":"modules/tunneling1D/tests_single_field/#test-c-wall-diagnostics-location-thickness","title":"Test C \u2014 Wall diagnostics (location &amp; thickness)","text":"<p>What this shows</p> <ul> <li> <p><code>wallDiagnostics(profile, frac=(0.1,0.9))</code> reports:</p> </li> <li> <p><code>r_peak</code>: where \\((|\\phi'|)\\) is maximal (wall center),</p> </li> <li><code>r_lo</code>/<code>r_hi</code>: radii where \\((\\phi)\\) reaches 10% and 90% of the total excursion,</li> <li><code>thickness</code> = \\((|r_{\\rm hi}-r_{\\rm lo}|)\\)</li> <li><code>r_mid</code>: where \\((\\phi)\\) is halfway between the vacua.</li> </ul> <p>Expected outcome (physics)</p> <ul> <li>Thin-wall \u2192 smaller thickness; <code>r_peak</code> between <code>r_lo</code> and <code>r_hi</code>.</li> <li>Thick-wall \u2192 larger thickness; markers spaced farther apart.</li> </ul> <p>Example console excerpt</p> <pre><code>=== Test C: Wall diagnostics (location &amp; thickness) ===\n[thin-wall] r_peak=4.706284e+01, r_mid=4.707676e+01, r_lo=4.396172e+01, r_hi=5.019140e+01, thickness=6.229675e+00 (phi_lo=0.900, phi_hi=0.100)\n[thick-wall] r_peak=4.399554e+00, r_mid=3.787229e+00, r_lo=0.000000e+00, r_hi=7.990970e+00, thickness=7.990970e+00 (phi_lo=0.900, phi_hi=0.100)\n</code></pre> <p>Figure \u201c(\\phi(r)) with vertical markers at <code>r_lo</code>, <code>r_mid</code>, <code>r_hi</code>, and <code>r_peak</code>.\u201d </p> <p></p>"},{"location":"modules/tunneling1D/tests_single_field/#test-d-beta_rm-eff-proxies-rscale-vs-curvature-vs-wall","title":"Test D \u2014 \\((\\beta_{\\rm eff})\\) proxies: <code>rscale</code> vs <code>curvature</code> vs <code>wall</code>","text":"<p>What this shows</p> <p>We compare three quick inverse-length scales (proxies for a nucleation timescale):</p> <ol> <li><code>rscale</code>: \\((\\beta_{\\rm eff}=1/r_{\\rm scale})\\) (always defined, robust).</li> <li><code>curvature</code>: \\((\\beta_{\\rm eff}=\\sqrt{|V''(\\phi_{\\rm top})|})\\) (requires a well-defined barrier top).</li> <li><code>wall</code>: \\((\\beta_{\\rm eff}=1/\\text{thickness})\\) (from <code>wallDiagnostics</code>).</li> </ol> <p>Expected outcome (physics)</p> <ul> <li>Thin-wall: larger \\((\\beta_{\\rm eff}(\\text{wall}))\\) (thinner wall \u2192 shorter scale).</li> <li><code>rscale</code> and <code>curvature</code> are often comparable within \\((\\mathcal{O}(1))\\) factors.</li> <li>Thick-wall: all three proxies tend to be smaller.</li> </ul> <p>Example console excerpt</p> <pre><code>=== Test D: \u03b2_eff proxies (rscale, curvature, wall) ===\n[thin-wall] \u03b2_rscale=5.996249e-01, \u03b2_curv=4.990992e-01, \u03b2_wall=1.605220e-01\n[thick-wall] \u03b2_rscale=4.242641e-01, \u03b2_curv=4.000000e-01, \u03b2_wall=1.251412e-01\n---------- END: Lot SF-6 examples ----------\n</code></pre> <p>Figure \u201cGrouped bars of \\((\\beta_{\\rm eff})\\) for thin vs thick, comparing the three proxies.\u201d </p> <p>See the full, executable script for this lot here: <code>tests/single_field/Lot_SF6.py</code></p> <p>Tip: When comparing different models or temperatures, keep the same plotting and diagnostics so differences in actions, wall thickness, and \\((\\beta_{\\rm eff})\\) are immediately visible and quantitatively comparable.</p>"}]}