{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"CosmoTransitions (modernized)","text":"<p>A modern, test-driven update of CosmoTransitions for studying first-order phase transitions (FOPTs) and their gravitational-wave signatures \u2014 now in Python 3.13, with clearer APIs, numerical utilities, examples, and documentation.</p> <p>Original project by Carroll L. Wainwright (MIT). Modernization by Igor Almeida da Silva Gouv\u00eaa Stellet (advisor: Felipe Tovar Falciano).</p>"},{"location":"#quick-links","title":"Quick links","text":"<ul> <li>\ud83e\udded Roadmap &amp; Schedule \u2192 roadmap.md </li> <li>\ud83e\udde9 Architecture &amp; Module Flow \u2192 architecture.md</li> </ul>"},{"location":"#examples-core-modules-only","title":"Examples (Core modules only)","text":"<p>If you are only interested in learning how to use the main modules and obtain the results/graphs for the phase transition, here is the place. Below are links to explanations of only the most important aspects needed to use each main function and get the respective results/plots.</p> <p>The main explanation of the codes used and all images can be found in the example folder.</p>"},{"location":"#tunneling-1d","title":"Tunneling 1D","text":"<ul> <li>Single Field Instaton \u2192 example_single_field.md</li> </ul>"},{"location":"#index-of-all-functions","title":"Index of all functions","text":""},{"location":"#helper-functions","title":"Helper Functions","text":"<ul> <li>Miscellaneous Functions \u2192 miscellaneous_functions.md</li> <li>Numerical integration Functions \u2192 Numerical_integration.md</li> <li>Numerical Derivatives Functions \u2192 Numerical_derivatives.md</li> <li>Interpolation Functions \u2192 intepolation_functions.md</li> </ul>"},{"location":"#finite-t-functions","title":"Finite T Functions","text":"<ul> <li>Exact Thermal Integrals \u2192 Exact_Thermal_Integrals.md</li> <li>Spline Thermal Integrals \u2192  Spline_Thermal_Integrals.md</li> <li>Approx Thermal Integrals \u2192  Approx_Thermal_Integrals.md</li> <li>Short Hand for all Thermal Integrals \u2192 Short_Hand_Jb&amp;Jf.md</li> </ul>"},{"location":"#tunneling1d-functions","title":"Tunneling1D Functions","text":"<ul> <li>Single Field functions: modules/tunneling1D/single_field</li> <li>Tests of SF functions: modules/tunneling1D/tests_single_field</li> </ul>"},{"location":"#transitionfinder-functions","title":"transitionFinder Functions","text":"<ul> <li>Transition Finder Complete: modules/transitionFinder/</li> <li>Tests of TF functions: modules/transitionFinder/tests_</li> </ul>"},{"location":"#install-dev-quick-start","title":"Install (dev) &amp; Quick Start","text":"<p>Requires Python 3.11+ (targeting 3.13). We recommend a fresh virtualenv.</p> <pre><code>python -m pip install -U pip\npip install -e .[dev]   # editable install with dev deps (pytest, ruff, black)\n</code></pre>"},{"location":"architecture/","title":"Architecture &amp; Module Flow","text":"<p>This page summarizes how modules relate and call each other during typical workflows.</p> <p>See also: per-module pages under Docs \u2192 Modules.</p>"},{"location":"architecture/#flowchart-of-the-modules","title":"Flowchart of the modules","text":"<pre><code>graph TD\n    %% ========== MAIN MODULES ==========\n    subgraph \"MAIN MODULES\"\n        T1D[Tunneling1D&lt;br/&gt;Bounce solution in 1 field]\n        PD[pathDeformation&lt;br/&gt;Bounce solution in multiple fields]\n        TF[transitionFinder&lt;br/&gt;Locate Tn and phase structure]\n        GP[generic_potential&lt;br/&gt;Model definition and potential plotting]\n\n        T1D --&gt; PD\n        T1D --&gt; TF\n        T1D --&gt; GP\n        PD --&gt; TF\n        PD --&gt; GP\n        TF --&gt; GP\n    end\n\n    %% ========== AUXILIARY MODULES ==========\n    subgraph \"AUXILIARY MODULES\"\n        HF[helper_functions&lt;br/&gt;Utility functions]\n        FT[finiteT&lt;br/&gt;Finite-temperature corrections]\n        MFP[multi_field_plotting&lt;br/&gt;Visualization for 3+ fields]\n    end\n\n    %% ========== DEPENDENCIES ==========\n    AUX --&gt; MAIN\n\n    %% ========== STYLES ==========\n    style T1D fill:#357a38,color:white\n    style PD fill:#d32f2f,color:white\n    style TF fill:#357a38,color:white\n    style GP fill:#357a38,color:white\n    style HF fill:#1565c0,color:white\n    style FT fill:#1565c0,color:white\n    style MFP fill:#d32f2f,color:white\n\n    linkStyle 0 stroke:#1b5e20,stroke-width:2px\n    linkStyle 1 stroke:#1b5e20,stroke-width:2px\n    linkStyle 2 stroke:#1b5e20,stroke-width:2px\n    linkStyle 3 stroke:#1b5e20,stroke-width:2px\n    linkStyle 4 stroke:#1b5e20,stroke-width:2px\n    linkStyle 5 stroke:#1b5e20,stroke-width:2px\n    linkStyle 6 stroke:#0d47a1,stroke-width:3px</code></pre>"},{"location":"architecture/#main-modules","title":"\ud83d\udce6 Main Modules","text":"Module Description Methods &amp; Functionality Links Tunneling1D Computes bounce (instanton) solution for a single scalar field. Uses the overshoot/undershoot method to solve the Euclidean equation of motion and find the tunneling profile Module page pathDeformation Computes instantons for multiple scalar fields. First finds a 1D solution constrained to an initial path in field space. Then iteratively deforms this path until transverse forces vanish, yielding the correct multi-dimensional solution. None transitionFinder Computes the phase structure of the potential at finite temperature. Locates potential minima as a function of temperature, determines critical temperatures (degenerate vacua), and computes the nucleation temperature for phase transitions Module page generic_potential Abstract class that defines the physical model of interest. The user provides a subclass implementing the specific effective potential \\(V(\\phi, T)\\). Also provides methods to plot the potential and visualize its phase structure. Module page"},{"location":"architecture/#auxiliary-modules","title":"\ud83d\udd27 Auxiliary Modules","text":"Module Description Purpose Links helper_functions Numerical utilities (e.g., numerical integration, interpolation, numerical differentiation). Called by all core modules. Module page finiteT Finite-temperature effective-potential corrections (boson/fermion thermal pieces). Feeds generic_potential and transition_finder. Module page multi_field_plotting Visualization helpers for 3+ field landscapes and paths. Used mainly with pathDeformation and generic_potential. None"},{"location":"roadmap/","title":"\ud83d\udcc5 Roadmap &amp; Schedule","text":"<p>Approach: The project\u2019s timeline and flowchart are presented below. The main idea is to split this long task into four primary phases, each lasting up to ~2 weeks, while running consistency tests throughout development and after finishing each phase. Each phase follows the cycle: Modification \u2192 Testing \u2192 Fixes \u2192 Validation.</p> <ul> <li>See also: Architecture &amp; Module Flow</li> </ul>"},{"location":"roadmap/#phases-overview","title":"Phases (overview)","text":"<p>The first phase aims to update CosmoTransition's auxiliary modules, which are called by the main modules. The second phase and third phase, the codes that find the bounce solution and the thermodynamic parameters (two main modules). Finally, the fourth and final phase aims to modify the functions that create the generic potential and the plots generated given the initial parameters. Everything will be done for the 1D part for now; the 2D part will remain as before.</p> <p>Depending on the progress of the project, a fifth phase will be carried out to add new plots and graphs to the code, as well as update the part that calculates multiple fields.</p>"},{"location":"roadmap/#documentation-recommended-reading-pre-modifications","title":"\ud83d\udcd6 Documentation &amp; Recommended Reading (pre-modifications)","text":"<p>Before modifying any module, consult the official documentation and/or the original paper to understand the algorithms:</p> <ul> <li>Official Documentation:https://clwainwright.net/CosmoTransitions/index.html</li> <li>Original Paper (arXiv): arXiv:1109.4189</li> <li>Computer Physics Communications: 10.1016/j.cpc.2012.04.004</li> </ul>"},{"location":"roadmap/#project-timeline","title":"Project Timeline","text":"<pre><code>gantt\n    %%%%%%%%\n    title Development Timeline - CosmoTransitions\n    dateFormat  YYYY-MM-DD\n    axisFormat  %d/%m\n\n    section Phase 0: Planning\n    Flowchart and Timeline          :done, 2025-08-27, 7d\n    Methodology Definition          :done, 2025-09-05, 10d\n\n    section Phase 1: Auxiliar Functions Update\n    Modify helper_function.py       :done, 2025-09-08, 12d\n    Modify finiteT.py               :done, 2025-09-20, 12d\n\n    section Phase 1.5: Testing the Modifications of Auxiliar Functions\n    Testing all modifications       :done,2025-10-02, 4d\n    Fixes and Adjustments           :done,2025-10-02, 4d\n\n    section Phase 2: Tunneling 1D Module\n    Modify/tests Tunneling1D.py     :done,2025-10-07, 12d\n    Examples Tunneling1D.py         :done,2025-10-20, 3d\n\n    section Phase 3: Transtions Finder Module\n    Modify/tests transitionFinder.py :done,2025-10-24, 12d      \n    Examples transitionFinder        :done,2025-11-06, 3d\n\n    section Phase 4: Generic Potential Module\n    Modify/tests generic_potential.py  :2025-11-10, 12d\n    Examples generic_potential.py      :2025-11-25, 5d\n\n    section Phase 5: Extras (Optional)\n    Additional Plots                :2025-12-01, 10d\n    Multi-field Solution            :2025-12-10, 10d\n    Final Optimizations             :2025-12-10, 10d</code></pre>"},{"location":"roadmap/#milestones-checklist","title":"Milestones &amp; Checklist","text":"<ul> <li> Phase 0: Planning and first meeting </li> <li> Create dependency flowchart </li> <li> <p> Create refactoring schedule </p> </li> <li> <p> Phase 1: Auxiliary functions </p> </li> <li> Refactor <code>helper_functions.py</code></li> <li> <p> Refactor <code>finiteT.py</code></p> </li> <li> <p> Phase 1.5: Modification tests </p> </li> <li> Validate isolated functions with simple analytic examples  </li> <li> <p> exercise error paths and validations</p> </li> <li> <p> Phase 2: Tunneling 1D Core Module </p> </li> <li> Refactor <code>tunneling1D.py</code> </li> <li> <p> Examples modernized <code>tunneling1D.py</code> </p> </li> <li> <p> Phase 3: Transtions Finder Core Module </p> </li> <li> Refactor <code>transtionFinder.py</code> </li> <li> <p> Test modernized <code>transtionFinder.py</code></p> </li> <li> <p> Phase 4: Generic Potential Core Module  </p> </li> <li>Refactor <code>generic_potential.py</code> </li> <li>Test modernized <code>generic_potential.py</code></li> <li> <p>Run all old examples and validate cosistency between versions</p> </li> <li> <p> Phase 5 (optional): Extensions</p> </li> <li>Update plotting, add energy density and other figures useful for paper/thesis and other parameters</li> <li>New plot types (e.g., direct GW spectrum, GW energy density vs T, etc.) </li> <li>Modernize multi-field plotting codes <code>mult_field_plotting.py</code> and <code>path_deformation.py</code></li> </ul> <pre><code>graph TD\n    Start[Project Start] --&gt; Phase1[Phase 1: Auxiliar Functions]\n    Start --&gt; Phase2[Phase 2: Tunneling 1d]\n    Start --&gt; Phase3[Phase 3: Transition Finder]    \n    Start --&gt; Phase4[Phase 4: Generic Potential]\n\n    Phase1 --&gt; Test1[Consistency Tests]\n    Phase2 --&gt; Test2[Consistency Tests]\n    Phase3 --&gt; Test3[Consistency Tests]\n    Phase4 --&gt; Test4[Consistency Tests]\n\n    Test1 --&gt; Adjust1[Adjustments, Documentation &amp; Fixes]\n    Test2 --&gt; Adjust2[Adjustments, Documentation &amp; Fixes]\n    Test3 --&gt; Adjust3[Adjustments, Documentation &amp; Fixes]\n    Test4 --&gt; Adjust4[Adjustments, Documentation &amp; Fixes]\n\n    Adjust1 --&gt; FinalValidation[Final Validation]\n    Adjust2 --&gt; FinalValidation\n    Adjust3 --&gt; FinalValidation\n    Adjust4 --&gt; FinalValidation\n\n    FinalValidation --&gt; Decision{Satisfactory progress?}\n\n    Decision -- Yes --&gt; Phase5[Phase 5: New Plots and Figures, 3D+ &amp; More parameters]\n    Decision -- No --&gt; Review[Review and Optimizations]\n\n    Phase5 --&gt; ProjectEnd[Project Completed]\n    Review --&gt; ProjectEnd\n\n    style Start fill:#e1f5fe\n    style Phase1 fill:#e8f5e8\n    style Phase2 fill:#fff3e0\n    style Phase3 fill:#f3e5f5\n    style Phase4 fill:#ffebee\n    style Phase5 fill:#ffebee\n    style ProjectEnd fill:#c8e6c9</code></pre>"},{"location":"examples/example_transitionFinder/","title":"<code>example_transitionFinder.md</code>","text":"<p>Pedagogical showcase for <code>CosmoTransitions.transitionFinder</code> with a 1D Landau\u2013Ginzburg potential.</p> <p>This example is meant to do for <code>transitionFinder</code> what <code>example_tunneling1D.py</code> does for <code>tunneling1D</code>:</p> <p>Take you from the bare potential \\(V(\\phi, T)\\) all the way to a coherent thermal history with - traced phases, - critical (degeneracy) temperatures, - spinodal points, and - the nucleation temperature \\(T_n\\) that satisfies \\(S(T_n)/T_n \\simeq 140\\).</p> <p>Everything is intentionally kept 1D in field space so that every plot can be read in a glance. The logic, however, is exactly what you would use in a real multi-field model.</p>"},{"location":"examples/example_transitionFinder/#quick-start","title":"Quick start","text":"<p>From the root of the repository:</p> <pre><code>python docs/examples/example_transitionFinder.py\n````\n\nWhat you will get:\n\n1. A **configuration block** summarizing all model and numerical parameters.\n\n2. A **Block A** section:\n\n   * seeds used to start the tracing;\n   * phases traced with `traceMultiMin` and cleaned with `removeRedundantPhases`.\n\n3. A **Block B** section:\n\n   * critical temperatures from `findCriticalTemperatures`;\n   * nucleation temperatures and actions from `findAllTransitions`\n     (internally calling `tunnelFromPhase` and the bounce solvers).\n\n4. Three plotted examples:\n\n   * **Example A** \u2013 Potential snapshots at low and high T.\n   * **Example B** \u2013 $T_{\\text{spin}}$, $T_{\\text{crit}}$, $T_{\\text{nuc}}$\n     with V(\\phi, T) at those special temperatures.\n   * **Example C** \u2013 Evolution of the minima $\\phi_{\\min}(T)$ and the\n     curvature $m^2(T) = \\partial^2 V / \\partial \\phi^2$ along each phase.\n\n5. A **final compact summary** with all key numbers:\n   $T_n, T_{\\text{crit}}, S(T_n)$ and $S(T_n)/T_n$.\n\nAll figures are saved under:\n\n```text\ndocs/examples/assets_transitionFinder/\n    figA_&lt;case&gt;.png\n    figB_&lt;case&gt;.png\n    figC_phi_&lt;case&gt;.png\n    figC_m2_&lt;case&gt;.png\n</code></pre> <p>where <code>&lt;case&gt;</code> is <code>LG1D</code> by default.</p>"},{"location":"examples/example_transitionFinder/#1-the-model-1d-landauginzburg-finite-t-potential","title":"1. The model: 1D Landau\u2013Ginzburg finite-T potential","text":"<p>The whole example is built around a textbook finite-temperature Landau\u2013Ginzburg potential in one scalar field:</p> \\[ V(\\phi, T) = D(T^2 - T_0^2)\\phi^2 - ET\\phi^3 + \\frac{\\lambda}{4}\\phi^4. \\] <p>In the script, the parameters are:</p> <pre><code># Model parameters: simple Landau\u2013Ginzburg finite-T potential\nD: float = 0.1\nE: float = 0.02\nlambda_: float = 0.1\nT0: float = 100.0\n</code></pre> <p>Physical interpretation (schematically):</p> <ul> <li><code>D</code>, <code>\u03bb</code> control the quadratic and quartic pieces \u2192 overall shape.</li> <li><code>E</code> controls the cubic term \u2192 strength of the barrier between phases.</li> <li><code>T0</code> is the temperature where the quadratic coefficient changes sign,   setting the rough scale for symmetry restoration.</li> </ul> <p>In the example, we work over a temperature interval:</p> <pre><code>T_LOW:  float = 0.0\nT_HIGH: float = 200.0\n</code></pre> <p>and a field range for scans/plots:</p> <pre><code>PHI_MIN: float = -5.0\nPHI_MAX: float =  5.0\nN_PHI:   int   = 1000\n</code></pre>"},{"location":"examples/example_transitionFinder/#2-the-minimal-interface-to-transitionfinder","title":"2. The minimal interface to <code>transitionFinder</code>","text":""},{"location":"examples/example_transitionFinder/#21-what-transitionfinder-actually-needs","title":"2.1 What <code>transitionFinder</code> actually needs","text":"<p>At the core, <code>transitionFinder</code> wants two kinds of information:</p> <ol> <li> <p>For tracing minima as a function of T (Block A):</p> </li> <li> <p>a scalar free-energy density      <code>f(x, T)</code>;</p> </li> <li>its mixed derivative      <code>d2f_dxdt(x, T) = \u2202/\u2202T (\u2202f/\u2202x)</code>;</li> <li> <p>its Hessian      <code>d2f_dx2(x, T)  = \u2202\u00b2f/\u2202x\u00b2</code>.</p> </li> <li> <p>For tunneling and critical temperatures (Block B/C):</p> </li> <li> <p>the potential (or free energy) itself      <code>V(x, T)</code>;</p> </li> <li>its gradient with respect to the fields      <code>dV(x, T)</code>.</li> </ol> <p>In our 1D example we simply take:</p> <pre><code>def free_energy(x: np.ndarray, T: float) -&gt; float:\n    return float(V(x, T))\n</code></pre> <p>so \u201cfree energy\u201d and \u201cpotential\u201d coincide.</p>"},{"location":"examples/example_transitionFinder/#22-potential-and-derivatives-1d-but-vector-friendly","title":"2.2 Potential and derivatives: 1D but vector-friendly","text":"<p>The showcase potential <code>V</code> is written in a way that:</p> <ul> <li>works with scalar \u03c6 for simple plots,</li> <li>and also with batched inputs of shape <code>(n, 1)</code> for   <code>findApproxLocalMin</code> inside <code>traceMultiMin</code>.</li> </ul> <pre><code>def V(phi: np.ndarray | float, T: float) -&gt; np.ndarray | float:\n    phi_arr = np.asarray(phi, dtype=float)\n\n    if phi_arr.ndim == 0:\n        phi_val = phi_arr                  # scalar\n    elif phi_arr.ndim == 1:\n        # 1D field space: treat as array of \u03c6 values\n        phi_val = phi_arr                  # shape (n,)\n    elif phi_arr.ndim == 2:\n        # batched samples: (n_samples, 1)\n        if phi_arr.shape[1] != 1:\n            raise ValueError(\"For batched evaluation, use shape (n_samples, 1).\")\n        phi_val = phi_arr[:, 0]\n    else:\n        raise ValueError(f\"Unsupported phi shape {phi_arr.shape} for this test potential.\")\n\n    V_val = (\n        D * (T**2 - T0**2) * phi_val**2\n        - E * T * phi_val**3\n        + 0.25 * lambda_ * phi_val**4\n    )\n    return V_val\n</code></pre> <p>The first derivative (gradient) is:</p> \\[ \\frac{\\partial V}{\\partial \\phi} = 2D(T^2 - T_0^2)\\phi - 3ET\\phi^2 + \\lambda\\phi^3. \\] <p>In code, with shapes chosen to be compatible with both <code>transitionFinder</code> and <code>tunneling1D</code>:</p> <pre><code>def dV(phi: np.ndarray | float, T: float) -&gt; np.ndarray:\n    phi_arr = np.asarray(phi, dtype=float)\n\n    if phi_arr.ndim == 0:\n        phi_val = phi_arr\n        dV_val = (\n            2.0 * D * (T**2 - T0**2) * phi_val\n            - 3.0 * E * T * phi_val**2\n            + lambda_ * phi_val**3\n        )\n        return np.array([dV_val], dtype=float)\n\n    if phi_arr.ndim == 1:\n        if phi_arr.size != 1:\n            raise ValueError(\"This showcase gradient assumes a single scalar field.\")\n        phi_val = phi_arr[0]\n        dV_val = (\n            2.0 * D * (T**2 - T0**2) * phi_val\n            - 3.0 * E * T * phi_val**2\n            + lambda_ * phi_val**3\n        )\n        return np.array([dV_val], dtype=float)\n\n    if phi_arr.ndim == 2:\n        if phi_arr.shape[1] != 1:\n            raise ValueError(\"For batched evaluation, use shape (n_samples, 1).\")\n        phi_val = phi_arr[:, 0]\n        dV_val = (\n            2.0 * D * (T**2 - T0**2) * phi_val\n            - 3.0 * E * T * phi_val**2\n            + lambda_ * phi_val**3\n        )\n        return dV_val.reshape(-1, 1)\n\n    raise ValueError(f\"Unsupported phi shape {phi_arr.shape} in dV.\")\n</code></pre> <p>The second derivative entering the Hessian is:</p> \\[ \\frac{\\partial^2 V}{\\partial \\phi^2} = 2D(T^2 - T_0^2) - 6ET\\phi + 3\\lambda\\phi^2. \\] <pre><code>def d2V_dphi2(phi: np.ndarray | float, T: float) -&gt; np.ndarray | float:\n    phi_arr = np.asarray(phi, dtype=float)\n    m2 = 2.0 * D * (T**2 - T0**2) - 6.0 * E * T * phi_arr + 3.0 * lambda_ * phi_arr**2\n    return m2\n</code></pre> <p>From this we build the mixed derivative and Hessian required by <code>traceMinimum</code> / <code>traceMultiMin</code>:</p> <pre><code>def free_energy(x: np.ndarray, T: float) -&gt; float:\n    # In this 1D example, x is a length-1 array with x[0] = \u03c6\n    return float(V(x, T))\n\n\ndef d2f_dxdt(x: np.ndarray, T: float) -&gt; np.ndarray:\n    # \u2202/\u2202T (\u2202V/\u2202\u03c6) = 4D T \u03c6 - 3E \u03c6\u00b2\n    x_arr = np.atleast_1d(np.asarray(x, dtype=float))\n    if x_arr.size != 1:\n        raise ValueError(\"d2f_dxdt assumes a single scalar field.\")\n    phi = x_arr[0]\n    val = 4.0 * D * T * phi - 3.0 * E * phi**2\n    return np.array([val], dtype=float)\n\n\ndef d2f_dx2(x: np.ndarray, T: float) -&gt; np.ndarray:\n    # 1\u00d71 Hessian containing \u2202\u00b2V/\u2202\u03c6\u00b2\n    x_arr = np.atleast_1d(np.asarray(x, dtype=float))\n    if x_arr.size != 1:\n        raise ValueError(\"d2f_dx2 assumes a single scalar field.\")\n    phi = x_arr[0]\n    m2 = d2V_dphi2(phi, T)\n    return np.array([[float(m2)]], dtype=float)\n</code></pre> <p>Take-away: To plug your own model into <code>transitionFinder</code>, you need to provide exactly these five callbacks: <code>V</code>, <code>dV</code>, <code>free_energy</code>, <code>d2f_dxdt</code>, <code>d2f_dx2</code>. Everything else in the example is there to make the physics transparent.</p>"},{"location":"examples/example_transitionFinder/#3-block-a-building-phases-with-tracemultimin","title":"3. Block A \u2013 Building phases with <code>traceMultiMin</code>","text":""},{"location":"examples/example_transitionFinder/#31-seeds-where-to-start-tracing","title":"3.1 Seeds: where to start tracing?","text":"<p>We construct simple seeds by scanning the potential at fixed T:</p> <pre><code>def scan_minimum_1D(T: float) -&gt; float:\n    phi_grid = np.linspace(PHI_MIN, PHI_MAX, N_PHI)\n    V_vals   = np.asarray(V(phi_grid, T), dtype=float)\n    idx_min  = int(np.argmin(V_vals))\n    return float(phi_grid[idx_min])\n</code></pre> <p>Then we pick:</p> <pre><code># High-T symmetric-phase seed\nT_seed_high = 180.0\nphi_high    = scan_minimum_1D(T_seed_high)\n\n# Low-T broken-phase seed\nT_seed_low  = 20.0\nphi_low     = scan_minimum_1D(T_seed_low)\n\nseeds = [\n    (np.array([phi_high], dtype=float), T_seed_high),\n    (np.array([phi_low],  dtype=float), T_seed_low),\n]\n</code></pre> <p>When you run the script you will see:</p> <pre><code>[Seeds] Initial seed points for traceMultiMin:\n  (T = 180.000, phi =   ... )  V = ...\n  (T =  20.000, phi =   ... )  V = ...\n</code></pre> <p>Idea:</p> <ul> <li>One seed for the symmetric minimum at high T (around \\(\\phi \\approx 0\\)).</li> <li>One seed for the broken minimum at low T \\(|(\\phi)| &gt; 0\\).</li> <li><code>traceMultiMin</code> plus the internal <code>findApproxLocalMin</code> will figure out   additional branches if needed.</li> </ul>"},{"location":"examples/example_transitionFinder/#32-tracing-parameters-what-really-matters","title":"3.2 Tracing parameters: what really matters","text":"<p>Core numerical knobs:</p> <pre><code># traceMultiMin / traceMinimum controls\nDELTA_X_TARGET: float = 0.05   # target step in field space\nDTSTART_FRAC:   float = 1e-4   # dtstart as fraction of (T_HIGH - T_LOW)\nTJUMP_FRAC:     float = 1e-4   # temperature jump between traces\n</code></pre> <p>They are interpreted as:</p> <ul> <li> <p><code>DELTA_X_TARGET</code> \u2013 the target displacement in field space between   consecutive accepted points on the branch. Smaller \u2192 more points in T,   smoother phases, but more work.</p> </li> <li> <p><code>DTSTART_FRAC</code> \u2013 the initial step size in T, as a fraction of   <code>(T_HIGH - T_LOW)</code>. The effective <code>dtstart</code> is:</p> </li> </ul> <pre><code>dt_scale   = T_HIGH - T_LOW\ndtstart_abs = DTSTART_FRAC * dt_scale\n</code></pre> <ul> <li><code>TJUMP_FRAC</code> \u2013 how far in T to jump beyond the last point of a trace   to look for new phases using <code>findApproxLocalMin</code>.</li> </ul> <p>These are passed directly to <code>traceMultiMin</code>:</p> <pre><code>phases = TF.traceMultiMin(\n    f=free_energy,\n    d2f_dxdt=d2f_dxdt,\n    d2f_dx2=d2f_dx2,\n    points=seeds,\n    tLow=T_LOW,\n    tHigh=T_HIGH,\n    deltaX_target=DELTA_X_TARGET,\n    # given as fractions; rescaled internally to absolute \u0394T\n    dtstart=DTSTART_FRAC,\n    tjump=TJUMP_FRAC,\n    single_trace_args={\n        \"dtabsMax\": 20.0,\n        \"dtfracMax\": 0.25,\n        \"dtmin\": 1e-4,\n        \"minratio\": 1e-2,\n    },\n    local_min_args={\"n\": 200, \"edge\": 0.05},\n)\n</code></pre> <p><code>single_trace_args</code> are forwarded to <code>traceMinimum</code>:</p> <ul> <li><code>dtabsMax</code>, <code>dtfracMax</code> \u2013 ceiling on the step size in T, both in absolute   and relative terms.</li> <li><code>dtmin</code> \u2013 minimal |\u0394T| before the trace is considered stalled.</li> <li><code>minratio</code> \u2013 criterion for Hessian degeneracy (when the phase \u201cdies\u201d).</li> </ul> <p><code>local_min_args</code> go to <code>findApproxLocalMin</code> and control how densely we scan for hidden minima along straight segments in field space.</p> <p>After tracing we clean duplicates:</p> <pre><code>phases_mut = dict(phases)\nTF.removeRedundantPhases(f=free_energy, phases=phases_mut)\nphases_clean = dict(phases_mut)\n</code></pre> <p>The script prints a compact summary:</p> <pre><code>[Block A] Phases after removeRedundantPhases: N\n  Phase 0: T in [T_min, T_max]  phi in [\u03c6_min, \u03c6_max]  (N_points support points)\n  ...\n</code></pre> <p>If you only care about phases: Up to here you already have the full phase structure encoded in the <code>Phase</code> objects returned by <code>traceMultiMin</code>.</p>"},{"location":"examples/example_transitionFinder/#4-block-b-critical-temperatures-and-nucleation","title":"4. Block B \u2013 Critical temperatures and nucleation","text":"<p>Once the phases exist, Block B asks:</p> <ol> <li>Where are different phases degenerate in free energy?</li> <li>When does tunneling actually become efficient?</li> </ol>"},{"location":"examples/example_transitionFinder/#41-critical-temperatures-findcriticaltemperatures","title":"4.1 Critical temperatures: <code>findCriticalTemperatures</code>","text":"<p>Minimal usage:</p> <pre><code>crit_transitions = TF.findCriticalTemperatures(\n    phases_clean,\n    V,\n    start_high=False,\n)\n</code></pre> <p>Each entry in <code>crit_transitions</code> is a dictionary with:</p> <ul> <li><code>\"Tcrit\"</code> \u2013 critical temperature where two phases are degenerate;</li> <li><code>\"high_phase\"</code>, <code>\"low_phase\"</code> \u2013 keys of the corresponding <code>Phase</code> objects;</li> <li><code>\"high_vev\"</code>, <code>\"low_vev\"</code> \u2013 VEVs at (T_{\\text{crit}});</li> <li><code>\"trantype\" = 1</code> (by construction).</li> </ul> <p>The example prints something like:</p> <pre><code>[Critical temperatures] Found 1 degeneracy points.\n  # 1: Tcrit =  98.123  high_phase = 0, low_phase = 1\n</code></pre> <p>Interpretation:</p> <ul> <li>The high-T branch is stable above <code>Tcrit</code>.</li> <li>Below <code>Tcrit</code>, the low-T branch is energetically favored.</li> </ul>"},{"location":"examples/example_transitionFinder/#42-nucleation-findalltransitions-and-nuclcriterion","title":"4.2 Nucleation: <code>findAllTransitions</code> and <code>nuclCriterion</code>","text":"<p>The nucleation criterion used in the example is the standard</p> \\[\\frac{S(T)}{T} \\simeq 140\\] <p>implemented as:</p> <pre><code>TARGET_S_OVER_T: float = 140.0\n\ndef nuclCriterion(S: float, T: float, target: float = TARGET_S_OVER_T) -&gt; float:\n    return S / (T + 1e-100) - target\n</code></pre> <p>and passed to <code>findAllTransitions</code> via <code>tunnelFromPhase_args</code>:</p> <pre><code>tunnel_args = {\n    \"Ttol\": 1e-2,\n    \"maxiter\": 80,\n    \"phitol\": 1e-6,\n    \"overlapAngle\": 45.0,\n    \"nuclCriterion\": nuclCriterion,\n    \"verbose\": False,\n    \"fullTunneling_params\": {},\n}\n\nfull_transitions = TF.findAllTransitions(\n    phases_clean,\n    V,\n    dV,\n    tunnelFromPhase_args=tunnel_args,\n)\n</code></pre> <p>What these arguments control:</p> <ul> <li><code>Ttol</code> \u2013 absolute tolerance on the nucleation temperature (root finder);</li> <li><code>maxiter</code> \u2013 maximum number of function evaluations;</li> <li><code>phitol</code> \u2013 tolerance in the local minimizations at fixed T;</li> <li><code>overlapAngle</code> \u2013 prune target phases whose directions in field space   are too aligned with each other (irrelevant in 1D but useful in   multi-field models);</li> <li><code>nuclCriterion</code> \u2013 your condition for \u201cefficient nucleation\u201d;</li> <li><code>fullTunneling_params</code> \u2013 forwarded to <code>pathDeformation.fullTunneling</code>,   when available.</li> </ul> <p>Each element of <code>full_transitions</code> is a dictionary with keys:</p> <ul> <li><code>\"Tnuc\"</code> \u2013 nucleation temperature;</li> <li><code>\"low_vev\"</code>, <code>\"high_vev\"</code> \u2013 minima connected by the bounce;</li> <li><code>\"low_phase\"</code>, <code>\"high_phase\"</code> \u2013 keys of the corresponding phases;</li> <li><code>\"action\"</code> \u2013 Euclidean action (S(T_n));</li> <li><code>\"instanton\"</code> \u2013 backend-dependent instanton object;</li> <li><code>\"trantype\" = 1</code> (first-order).</li> </ul> <p>If no tunneling solution is found, <code>full_transitions</code> is empty and the script warns you.</p>"},{"location":"examples/example_transitionFinder/#43-marrying-t_textcrit-and-t_n","title":"4.3 Marrying (T_{\\text{crit}}) and (T_n)","text":"<p>The last piece of Block B is:</p> <pre><code>TF.addCritTempsForFullTransitions(\n    phases_clean,\n    crit_transitions,\n    full_transitions,\n)\n</code></pre> <p>This analyzes the graph of phases, their critical transitions, and the supercooled transitions returned by <code>findAllTransitions</code> in order to attach, to each nucleation transition, the corresponding critical temperature (if one exists) under the key <code>\"crit_trans\"</code>.</p> <p>From that point on, a single <code>tdict</code> in <code>full_transitions</code> gives you:</p> <ul> <li><code>Tcrit</code> through <code>tdict[\"crit_trans\"][\"Tcrit\"]</code> (if any),</li> <li><code>Tnuc</code>  through <code>tdict[\"Tnuc\"]</code>,</li> <li>their associated phases and VEVs.</li> </ul>"},{"location":"examples/example_transitionFinder/#5-minimal-recipe-using-transitionfinder-with-your-own-model","title":"5. Minimal recipe: using <code>transitionFinder</code> with your own model","text":"<p>If you want the shortest possible checklist, here it is:</p> <ol> <li>Write your model:</li> </ol> <pre><code>def V(x: np.ndarray, T: float) -&gt; float: ...\ndef dV(x: np.ndarray, T: float) -&gt; np.ndarray: ...\n</code></pre> <ol> <li>Wrap it for Block A:</li> </ol> <pre><code>def free_energy(x, T): return float(V(x, T))\ndef d2f_dxdt(x, T):    # \u2202/\u2202T (\u2202V/\u2202x)\n    ...\ndef d2f_dx2(x, T):     # Hessian w.r.t. x\n    ...\n</code></pre> <ol> <li>Choose seeds (field values and temperatures) where you are sure    there is a minimum:</li> </ol> <pre><code>seeds = [\n    (x_seed1, T_seed1),\n    (x_seed2, T_seed2),\n    ...\n]\n</code></pre> <ol> <li>Trace phases:</li> </ol> <pre><code>phases = TF.traceMultiMin(\n    free_energy,\n    d2f_dxdt,\n    d2f_dx2,\n    points=seeds,\n    tLow=T_LOW,\n    tHigh=T_HIGH,\n    deltaX_target=DELTA_X_TARGET,\n)\nTF.removeRedundantPhases(f=free_energy, phases=phases)\n</code></pre> <ol> <li>Critical temperatures:</li> </ol> <pre><code>crit_transitions = TF.findCriticalTemperatures(phases, V)\n</code></pre> <ol> <li>Nucleation temperatures:</li> </ol> <pre><code>full_transitions = TF.findAllTransitions(\n    phases,\n    V,\n    dV,\n    tunnelFromPhase_args={\"nuclCriterion\": nuclCriterion},\n)\nTF.addCritTempsForFullTransitions(phases, crit_transitions, full_transitions)\n</code></pre> <p>The example script does all of this, but with extra diagnostics, prints and plots so that you can see what is going on.</p>"},{"location":"examples/example_transitionFinder/#6-the-four-examples-ad","title":"6. The four examples A\u2013D","text":""},{"location":"examples/example_transitionFinder/#61-example-a-potential-snapshots-at-low-and-high-t","title":"6.1 Example A \u2013 Potential snapshots at low and high T","text":"<p>Function: <code>example_A_potential_snapshots(case)</code></p> <p>What it does:</p> <ul> <li> <p>Plots \\(V(\\phi, T)\\) at:</p> </li> <li> <p><code>T_lo = 0.0</code>,</p> </li> <li> <p><code>T_hi = 200.0</code>.</p> </li> <li> <p>Marks the minima obtained by a crude scan (<code>scan_minimum_1D</code>).</p> </li> </ul> <p>Physically:</p> <ul> <li>At very high T, only the symmetric minimum near \\(\\phi \\simeq 0\\) survives.</li> <li>At very low T, the broken minimum appears at \\(|\\phi| &gt; 0\\).</li> </ul> <p>This is the \u201czeroth-order picture\u201d: what phases exist at the extremes of the thermal history.</p>"},{"location":"examples/example_transitionFinder/#62-example-b-t_textspin-t_textcrit-and-t_n","title":"6.2 Example B \u2013 (T_{\\text{spin}}), (T_{\\text{crit}}) and (T_n)","text":"<p>Function: <code>example_B_transition_temperatures(...)</code></p> <p>Steps:</p> <ol> <li> <p>Pick the \u201cmain\u201d first-order transition:</p> </li> <li> <p>the one with largest nucleation temperature among <code>full_transitions</code>.</p> </li> <li> <p>Extract characteristic temperatures:</p> </li> <li> <p><code>T_spin(high phase)</code> \u2013 lowest T where the high-T phase is still traced      (symmetric minimum disappears below this).</p> </li> <li><code>T_crit</code> \u2013 degeneracy temperature attached by      <code>addCritTempsForFullTransitions</code> (if available).</li> <li><code>T_nuc</code> \u2013 nucleation temperature from <code>findAllTransitions</code>.</li> <li> <p><code>T_spin(low phase)</code> \u2013 highest T where the low-T phase first appears      (broken minimum ceases to exist above this).</p> </li> <li> <p>Print them in a compact table, together with:</p> </li> <li> <p>the action \\(S(T_n)\\),</p> </li> <li> <p>the ratio \\(S(T_n)/T_n\\) and the target <code>TARGET_S_OVER_T</code>.</p> </li> <li> <p>Plot four panels of \\(V(\\phi, T)\\), one for each characteristic T:</p> </li> <li> <p>high-phase spinodal,</p> </li> <li>critical,</li> <li>nucleation,</li> <li>low-phase spinodal.</li> </ol> <p>In each panel, the \u03c6-range is chosen adaptively so that the relevant minima sit nicely inside the x-axis, and the corresponding minima are marked with different markers (high-phase vs low-phase branch).</p>"},{"location":"examples/example_transitionFinder/#63-example-c-evolution-of-minima-and-curvature","title":"6.3 Example C \u2013 Evolution of minima and curvature","text":"<p>Function: <code>example_C_minima_evolution(...)</code></p> <p>This example is about seeing the phases breathe as the Universe cools.</p> <p>For each <code>Phase</code> in <code>phases</code>:</p> <ul> <li>sample its temperature grid <code>phase.T</code>;</li> <li>extract the field values at the minimum <code>phase.X[:, 0]</code>;</li> <li>compute the curvature \\(m^2(T) = \\partial^2 V / \\partial \\phi^2\\) at each   of those points.</li> </ul> <p>We then produce two figures:</p> <ol> <li> <p>A combined figure with two stacked panels:</p> </li> <li> <p>Top: \\(\\phi_{\\min}(T)\\) for all phases (each phase as a colored line).</p> </li> <li>Bottom: \\(m^2(T)\\) along the same phases, with horizontal line at <code>m\u00b2 = 0</code>.</li> </ol> <p>On both panels we mark:</p> <ul> <li><code>T_spin(high)</code>,</li> <li><code>T_crit</code>,</li> <li><code>T_nuc</code>,</li> <li><code>T_spin(low)</code>,</li> </ul> <p>whenever they are available.</p> <p>This lets you visually track how the minimum moves in \u03c6 and how the    curvature goes to zero at the spinodals.</p> <ol> <li>A second figure with only \\(m^2(T)\\), but zoomed in the interval between    the two spinodals (plus a small margin). This is your \u201cmagnifying glass\u201d    for the region where the phase becomes metastable and then unstable.</li> </ol>"},{"location":"examples/example_transitionFinder/#64-where-to-go-from-here","title":"6.4 Where to go from here?","text":"<p>There is no dedicated others examples, like <code>example_D</code> yet, but the idea is to encourage the next steps of de CosmoTransition code. Here are a few natural directions that we need to do:</p> <ul> <li> <p>Move beyond 1D.   Replace the single scalar with a genuine multi-field potential and   turn on the <code>pathDeformation</code> backend. In that regime the pruning controlled   by <code>overlapAngle</code> becomes very useful.</p> </li> <li> <p>Gravitational waves     Build the gravitational waves params of the transition and see how strong they     are, how is the respective power spectrum and save all the relevant params for     the FOPT</p> </li> <li>Scan over model parameters.   Loop over different <code>(D, E, \u03bb, T0)</code> and record how   \\(T_{\\text{crit}}, T_n, S(T_n)/T_n\\) shift.   This is essentially a 1D \u201cphase diagram\u201d in parameter space, especially if we want to see  which params effects how strong de FOPT really is.</li> </ul> <p>The current example is designed to be a clean starting point for these explorations.</p>"},{"location":"examples/example_transitionFinder/#7-final-summary-and-how-to-read-it","title":"7. Final summary and how to read it","text":"<p>At the end of <code>run_all</code>, we build a compact <code>summary</code> dictionary:</p> <pre><code>summary = {\n    \"model\": {...},\n    \"tracing\": {...},\n    \"nucleation\": {...},\n    \"phases\": {\n        \"0\": {\"T_min\": ..., \"T_max\": ..., \"phi_min\": ..., \"phi_max\": ..., \"n_points\": ...},\n        ...\n    },\n    \"transitions\": [\n        {\n            \"high_phase\": \"...\",\n            \"low_phase\":  \"...\",\n            \"Tnuc\":       ...,\n            \"S_Tn\":       ...,\n            \"S_over_Tn\":  ...,\n            \"Tcrit\":      ... or None,\n        },\n        ...\n    ],\n}\n</code></pre> <p>and print it with <code>print_final_summary(summary)</code>.</p> <p>Typical output:</p> <pre><code>Final compact summary (temperatures and actions)\n===============================================\n\n  Transition #1: 0 \u2192 1\n    Tnuc        =   ...\n    Tcrit       =   ...\n    S(Tn)       =   ...\n    S(Tn)/Tn    =   ... (target = 140.0)\n\n  (All parameters controlling the behaviour of the example are listed\n   at the beginning of the run in print_configuration().)\n</code></pre> <p>This is the \u201cone-look\u201d view of your thermal history: which phase you start in, which phase you end up in, the key temperatures, and how well the nucleation condition is satisfied.</p>"},{"location":"examples/example_transitionFinder/#8-checklist-parameters-you-actually-want-to-touch","title":"8. Checklist: parameters you actually want to touch","text":"<p>When adapting this example to your own model, the most important knobs are:</p>"},{"location":"examples/example_transitionFinder/#model","title":"Model","text":"<ul> <li><code>D</code>, <code>E</code>, <code>lambda_</code>, <code>T0</code> (or whatever defines your potential)</li> <li><code>T_LOW</code>, <code>T_HIGH</code> \u2013 the temperature window where you expect interesting   physics.</li> </ul>"},{"location":"examples/example_transitionFinder/#tracing-block-a","title":"Tracing (Block A)","text":"<ul> <li><code>DELTA_X_TARGET</code> \u2013 smaller \u2192 more points in T, smoother phases.</li> <li><code>DTSTART_FRAC</code>   \u2013 how aggressively you start stepping in T.</li> <li><code>TJUMP_FRAC</code>     \u2013 how far you jump in T to search for new phases.</li> <li> <p><code>single_trace_args</code> \u2013 especially:</p> </li> <li> <p><code>dtmin</code> \u2013 too small and you might prematurely stop a trace;</p> </li> <li><code>minratio</code> \u2013 controls when the Hessian is considered singular.</li> </ul>"},{"location":"examples/example_transitionFinder/#nucleation-block-b","title":"Nucleation (Block B)","text":"<ul> <li><code>TARGET_S_OVER_T</code> or more generally <code>nuclCriterion</code>.</li> <li><code>Ttol</code>, <code>maxiter</code> \u2013 precision and robustness of the search for \\(T_n\\).</li> <li><code>phitol</code> \u2013 local minimization tolerance at fixed T.</li> <li><code>overlapAngle</code> \u2013 only relevant for multi-field potentials.</li> </ul>"},{"location":"examples/example_transitionFinder/#9-conclusion","title":"9. Conclusion","text":"<p><code>example_transitionFinder.py</code> is designed as a bridge between the abstract API of <code>CosmoTransitions.transitionFinder</code> and what a cosmologist actually wants to know:</p> <ul> <li>Which phases exist as the Universe cools?</li> <li>When do they become degenerate?</li> <li>When does tunneling really start to happen?</li> <li>How do the minima and curvatures behave near the spinodals?</li> </ul> <p>By keeping the potential 1D and fully analytic, every plot and every number can be checked by hand if you wish. Once you are happy with how <code>traceMultiMin</code>, <code>findCriticalTemperatures</code> and <code>findAllTransitions</code> behave in this controlled environment, you can safely upgrade to your full model and re-use exactly the same logic.</p> <p>--</p>"},{"location":"examples/example_transitionFinder/#10-images","title":"10. Images","text":""},{"location":"examples/example_tunneling1D/","title":"Tunneling 1D - All that you need to know","text":"<p>This page aims to teach you only what's necessary for someone to use and call the functions that find the bounce solution in the single-field (1D) case.</p> <p>If you're not interested in seeing how each function works separately, with clear examples fore every sub-fuctions, this is the place. However, if you have questions about a specifc functions or want to inspect one in detail, I recommend checking the folder modules/tunneling1D.</p>"},{"location":"examples/example_tunneling1D/#single-field-instaton","title":"Single Field Instaton","text":""},{"location":"examples/example_tunneling1D/#introduction-and-minimal-params","title":"Introduction and minimal params","text":"<p>In this module we solve the differential equation </p> \\[\\frac{d^2 \\phi}{dr^2}+\\frac{\\alpha}{r}\\frac{d\\phi}{dr} = \\frac{dV}{d\\phi} \\] <p>This comes from writing the Laplacian in spherical coordinates and assuming spherical symmetry.  More importantly, we are already in Euclidean signature: after the Wick rotation in the time  coordinate  \\(t\\rightarrow -i\\tau\\), the field equation becomes:</p> \\[\\nabla^2 \\phi = V'(\\phi) \\quad (\\text{with }\\nabla \\text{ in 4D}); \\qquad \\rho\\equiv \\sqrt{\\tau^2+x^2+y^2+z^2}\\] <p>Semiclassical picture. This is a semiclassical approximation valid for tunneling. It governs the part where the field transition through classically forbidden paths. After tunneling, we switch back to real time and evolve classically. At (t=0) what we \"see\" in space is the radial bounce profile \\(\\phi_b(\\rho)\\) we just solved for, and them the Minkowski evolution follows:</p> \\[\\ddot{\\phi} -\\nabla^2 \\phi \\equiv\\Box \\phi = -V'(\\phi) \\qquad \\dot{\\phi}=0; \\quad \\phi(x,t=0)=\\phi_{bounce}(r)  \\] <p>This point is quite crucial; we can imagine a timeline from \\(\\tau \\rightarrow \\infty\\) until \\(\\tau=0\\)  that has the semiclassical description made here. </p> <p>Remembering that \\(\\tau \\gg\\) 1 are high temperatures (we are closer to the beginning of the universe)  and \\(\\tau\\) = 0 would be more towards the \"future\". At \\(\\tau=0\\) we return to real time and return to the classical description with the equation above</p> <p>About \\(\\alpha\\). The \u201cfriction\u201d coefficient is \\(\\alpha=d-1\\), where (d)  Thermal effects compactify Euclidean time with period \\(\\beta=1/T\\). At high temperature the time circle is small,  the solution is effectively 3D, and \\(\\alpha=2\\) O(3). In the zero-temperature limit the solution is O(4) and \\(\\alpha=3\\).  In practice, transitions are often high-(T), so we default to \\(\\alpha=2\\).</p> <p>With that minimal intro, here\u2019s what you must provide for the solver (three parameters):</p> <ul> <li>\\(\\phi_{\\text{true}}\\): field value at the true (stable) minimum</li> <li>\\(\\phi_{\\text{meta}}\\): field value at the false/metastable minimum</li> <li>\\(V(\\phi)\\): the scalar potential</li> </ul> <p>If you also have analytic \\(V'(\\phi)\\) or \\(V''(\\phi)\\), you can pass them too. Likewise, set \\(\\alpha\\) if you want something different from the default.</p> <pre><code>from CosmoTransitions.tunneling1D import SingleFieldInstanton\n\nphi_abs = 1.0\nphi_meta = 0.0\nalpha = 2 # O(3) \ndef V ... # Define your potential here\n\ninst = SingleFieldInstanton(\n        phi_absMin= phi_abs,\n        phi_metaMin=phi_meta,\n        V=V,\n        alpha=alpha,\n        phi_eps=1e-3)\n</code></pre> <p>How to run this example</p> <pre><code>python -m docs.examples.example_tunneling1D\n</code></pre> <p>In all examples the potentials chosen was:</p> \\[\\text{THIN}: \\frac{1}{4}\\phi ^4 - 0.49\\phi ^3 + 0.235 \\phi ^2 \\] \\[\\text{THICK}:  \\frac{1}{4}\\phi ^4 - \\frac{2}{5}\\phi^3 + \\frac{1}{10}\\phi^2 \\]"},{"location":"examples/example_tunneling1D/#about-the-boundary-conditions","title":"About the boundary conditions","text":"<p>What we want from a bounce is simple to state: the solution starts at rest at the center and, as \\(r\\to\\infty\\),  it asymptotically approaches the false vacuum and stops on it.</p> <p>Keep in mind the inverted-potential picture. After the Wick rotation \\(t\\to -i\\tau\\), the Euclidan equation reads \\(\\phi''+frac{\\alpha}{r}\\phi'=V'(\\phi)\\). </p> <p>This is equivalent to a particle moving in the inverted potential (-V) with a time dependent friction \\(\\alpha/r\\): the particle is realeased near the \"top\" corresponding to the true vacuum (a maximum of -V) and must roll, losing energy to friction, to the other \"top\" at the false vacuum, arriving there with zero velocity.  There is a unique \"just-right\" starting point \\(\\phi_0\\) for which this happens.</p> <p>Therefore, the boundary contions are:</p> <ul> <li>\\(\\phi'(0)=0\\)</li> <li>\\(\\lim_{r \\to \\infty} \\phi'(r) = 0\\)</li> <li>\\(\\lim_{r \\to \\infty} \\phi(r) = \\phi_{meta}\\)</li> </ul> <p>Notice none of these impose something on \\(\\phi_0\\) (\\(\\equiv \\phi(0)\\)).  The initial field value in Euclidean \"time\" can be anywhere between the true and false vacua, as long as  it is the one that makes the particle land and stop at \\(\\phi_{meta}\\) as \\(r\\to \\infty\\).</p> <p>And how do we ever reach the true vacuum? After tunneling, we go back to real time. At (t=0) the initial data are \\(\\dot\\phi(x,0)=0,\\quad \\phi(x,0)=\\phi_{\\text{bounce}}(r).\\) The bubble expands and the field relaxes toward \\(\\phi_{true}\\) (that's the phenomelogy we usually expects). It's always good to keep in mind that the classical model governs the dynamics after the transition,  and it will determine what will happen to the field after the transition.</p> <p>Why \\(\\phi'(0)=0\\) * Radial symmetry and Regularity at the origin forces \\(\\phi' _0=0\\) and more precisely, a smooth Taylor expansion \\(\\phi(r) = \\phi_0 +\\mathcal{O}(r^2)\\). * The friction term \\(\\alpha/r \\phi'\\) would be singular at r=0 unless \\(\\phi'\\) vanishes there * It is important to note that radial symmetry alone guarantees that the derivative will be 0 at r=0</p> <p>Real time echo of this: At t=0 we set \\(\\dot{\\phi} = 0\\). After that, \\(\\dot{\\phi}\\) generally becomes nonzero as the bubble grows. The configuration remains spherically symmetric (no angular dependence), but spatial gradients (\\partial_r \\phi) are zero only at the center (r=0), not everywhere. </p> <p>That's the whole boundary condition story resume. With this in place, we can move on to the key diagnostics the code computes</p>"},{"location":"examples/example_tunneling1D/#other-imporants-params-in-vphi-lot-2-of-the-code","title":"Other imporants params in \\(V(\\phi)\\) | Lot 2 of the code","text":"<p>There are two especially useful landmarks \\(V(\\phi)\\). </p> <p>1) The \"bar\" point \\(\\phi_{bar}\\)</p> <p>In the inverted potential (-V) picture, we can think that, for \\(\\phi_0\\) reach the false vacuum level, energy must be at least equal to \\(V(\\phi_{meta})\\). </p> <p>Therefore, the field value \\(\\phi_{bar}\\) is defined on the true-vaccum side of the barrier by:</p> \\[V(\\phi_{bar})= V(\\phi_{meta}) \\quad (\\text{with} \\phi_{bar} \\text{located beyond the barrier peak})\\] <p>This gives a clean search window for the correct initial value \\(\\phi_0\\):</p> \\[V(\\phi_{bar}) \\geq V(\\phi_0) \\geq V(\\phi_{True}) \\] <p>Intuitively: \\(\\phi_{bar}\\) marks the lowest energy starting point (on the true side) that still has the same Euclidean \"energy\" as the false vacuum; anything bellow it cannot reach \\(\\phi_{meta}\\) once friction is included.</p> <p>Small clarification on commom mental image: sometimes people describe \\(\\phi_{bar}\\) as a \"turning point\" if realeased from \\(\\phi_{meta}\\)  in the inverted potential. Strictly speaking, if you start exactly at \\(\\phi_{meta}\\) with  zero velocity you just sit there and just go for the other side by thermal fluctuations or quantum tunneling.</p> <p>2) The barrier top \\(\\phi_{top}\\) and the curvature scale \\(\\phi_{top}\\) is simply the maximum of \\(V(\\phi)\\) (the peak of the barrier). Near this point we  can approximate: </p> \\[ V(\\phi) \\approx V_{top}-\\frac{1}{2} k^2 (\\phi-\\phi_{top})^2\\] <p>This motivates a curvature length scale</p> \\[r_{scale} \\equiv \\frac{1}{\\sqrt{|V''(\\phi_{top})|}} \\] <p>It is a very handy measure of how \"step\" the barrier is and shows up in several numerical limits and diagnostics. In thin-wall situations the barrier is steep \\(\\Rightarrow |V''|\\) large \\(\\Rightarrow\\) \\(r_{scale}\\) small. In thick-wall cases the top is shallow \\(\\Rightarrow |V''|\\) small \\(\\Rightarrow\\) \\(r_{scale}\\) large; which matches each name.</p> <p>Practical note (used in the code): When the curvature at ther top is extremly small, dectyly using \\(V''(\\phi_{top})\\) can be noisy. In that case we fall back to more robust proxies, a cubic fit across the wall region.</p>"},{"location":"examples/example_tunneling1D/#visualizing-potential-and-its-inversion","title":"Visualizing potential and its inversion","text":"<p>Here is a plot for thin wall and thick wall with all the interesting points.</p> <p>Thin-wall \u2014 Potential with marks </p> <p>Thick-wall \u2014 Potential with marks </p> <p>And now the inverted plots (-V) with the founded \\(\\phi_0\\) solution:</p> <p>Thin-wall \u2014 \\(-V(\\phi)\\) </p> <p>Thick-wall \u2014 \\(-V(\\phi)\\) </p>"},{"location":"examples/example_tunneling1D/#near-solutions-and-initial-conditions-lot-3","title":"Near solutions and initial conditions| Lot 3","text":"<p>For any field value \\(\\phi(r)\\) taken near some arbitraty \\(\\phi_0\\), we can rewrite the ODE in a locally linearized form and solve it exactly. Around \\(\\phi_0\\)</p> \\[V'(\\phi)\\approx V'(\\phi_0)+V''(\\phi_0)(\\phi-\\phi_0)\\] <p>The solution reads  </p> \\[\\phi(r)-\\phi_0 = \\frac{V'(\\phi_0)}{V''(\\phi_0)}\\Bigg[\\Gamma(\\nu+1)\\Big(\\tfrac{t}{2}\\Big)^{-\\nu} I_\\nu(t)-1\\Bigg]\\] <p>where \\(I_\\nu\\) is the modified Bessel functions.</p> <p>The key point: This expressing is valid whenever the field is sitting near a point with \\(\\phi' \\approx 0\\). It doesn't matter if \\(r\\) is tiny or moderately large - if the derivative stays small, the approximation keeps tracking. In practice we use it around the chosen \\(\\phi_0\\); if you need it elsewhere, re-exapand around a new \\(\\phi_0\\).</p> <p>Because the equation has a formal singularaty at \\(r=0\\), we start the numerical integration a little away from the origin, at \\(r=r_{min}&gt;0\\). To do that cleanly we introduce a lower bound \\(\\Delta\\phi_{cutoff}\\) and choose \\(r_{min}\\) such that:</p> \\[|\\phi(r_{min})-\\phi_{true}| \\gtrsim \\Delta \\phi_{cutoff} \\] <p>evaluating \\(phi(r_{min})\\) with the exact small-r formula above.</p> <p>We also need an inatial guess for \\(\\phi_0\\). Internally this is handled, but it's worth sating explicitly:</p> \\[\\phi_0 = \\phi_{true} + \\Delta \\phi, qquad \\text{with} \\phi_0 \\in [\\phi_{true}, \\phi_{bar}\\] <p>The algorthm procceds as follows (conceptually):</p> <ol> <li>Pick a trial \\(\\phi_0\\) in [\\(\\phi_{true}, \\phi_{bar}\\)]</li> <li>Use the exact small-r solution to evaluate \\(\\phi(r)\\) at an initial \\(r_{min}\\)</li> <li>If \\(|\\phi(r_{min})-\\phi_{true}| &lt; \\Delta \\phi_{cutoff}\\) increase \\(r_{min}\\) (keeping the same \\(\\phi_0\\)) and check again.    Otherwise, start the full integration from that \\(r_{min}\\).</li> <li>If the boundary condition at infinity is not met (overshoot/undershoot), update \\(\\phi_0\\) and repeat</li> </ol> <p>Heuristic that i follow: choose \\(\\Delta \\phi_{cutoff}\\) as small as makes the code stable, so we don't sart too far from \\(\\phi_{true}\\). This matters even more in the thin-wall regime, where the correct \\(phi_0\\) typically sits very close to \\(\\phi_{true}\\)</p> <p>Note that if we choose a very high cutoff we may find a wrong solution that would still converge!</p> <p>Bellow are one example of a bad use of the \\(\\Delta \\phi_{cutoff}\\) in a thin wall case:</p> <p>Error case Thin-wall \u2014 \\(\\Delta \\phi_{cutoff} =0.15\\) </p> <p>So how do I know I've found the right one cutoff? I had the same question, but the key is to realize that if  your cutoff was too high, then your \\(\\phi\\) is below what it should be, and its derivative pulls it towards the correct value  (i.e., \\(\\phi'_0 \\neq 0\\)). A good practice is to check your graph, as in the one above,  to see if \\(\\phi_0\\) (pink dot) is increasing towards some value going towards r=0; this shouldn't happen, as we expect \\(\\phi'_0=0\\).</p> <p>In the case above: $\\phi'_0 = -1.05e-01 $</p> <p>The correct thing is that going to r=0 there is a plateau at \\phi_0 (not so much grow)</p> <p>In the end  are the correct solutions with \\(\\Delta \\phi_{cutoff}=0.01\\).</p> <p>Bellow are the plots for \\(\\phi\\) and \\(\\phi'\\) near \\(r=0\\)</p> <p>Thin-wall - \\(\\phi\\) near r=0 </p> <p>Thick-wall \u2014 \\(\\phi\\) near r=0 </p> <p>We can clearly see that both prevent the singularity of the friction term at the origin.</p> <p>Thin wall with \\(\\phi'\\) = 0 and thick with \\(\\phi' \\propto r\\), as we expected.</p>"},{"location":"examples/example_tunneling1D/#odeintegrate-saveprofile","title":"ODE/Integrate &amp; Saveprofile","text":"<p>Inside the ODE the state is package as \\((\\phi,y)\\) with</p> \\[\\phi'=y;\\quad  \\phi''=V'(\\phi)- \\alpha/r \\dot{\\phi}\\] <p>(Here primes mean derivatives with respect to the radial coordinate r. I stick to primes to avoid confusion with time-dots used later in real time evolution).</p> <p>Given the initial conditions and this ODE, we integrate with RKCK and look for a solution that satisfies</p> \\[|\\phi(\\infty)-\\phi_{metamin}|&lt; \\epsilon_{\\phi}; \\qquad |\\phi'(\\infty)| &lt; \\epsilon_{d\\phi} \\] <p>What <code>integrate</code> actually does is evolve from the chosen initial condition until one of the following stopping criteria triggers:</p> <ol> <li>Converged-- Both tolerances above are met. We return the arrays \\(r, \\phi(r)\\), and \\(\\phi'(r)\\)</li> <li>Undershoot-- The field strts turning back before reaching the false vacuum. In practice this show up as \\(\\phi'(r)\\) changing sign to positive whle \\(\\phi(r)&gt;\\phi_{meta}\\).  Physically: friction wins, not enough energy to climb all the way. We stop at the first turning point where \\(\\phi'(r)=0\\) and return \\(r,\\phi,\\phi'\\) there.</li> <li>Overshoot-- The trajectory crosses the false vacuum, i.e., \\(\\phi(r)-\\phi_{meta}&lt;0\\) within a step. Too much energy: it blows past the target. We stop at (or bracket to) the point where \\(\\phi=\\phi_{meta}\\)</li> </ol> <p>On undershoot/overshoot, the code adjusts the initial field value \\(\\phi_0\\) and repeats (classic shooting), until the exact solution is found.</p> <p>Once the correct initial condition is locked in, we run integrate-and-save to build the full bounce profile: we evaluate and store \\(\\phi(r)\\) on a user-controlled radius grid R. If the adaptive RKCK steps are coarser than the requested spacing, we fill in the missing samples by cubic interpolation between the integrator outputs (and, when available, we use the stored \\(\\phi'(r)\\) to do Hermit-quality interpolation). This produces a clean (\\(R\\), \\(\\phi(R),\\phi'(R)\\)) profile ready for diagnostics and plots.</p>"},{"location":"examples/example_tunneling1D/#find-profile","title":"Find profile","text":"<p>This is the most important part of the module\u2014the place where a few internally chosen parameters are worth knowing  (and sometimes tweaking).</p> <p>Minimum radius. The seach starts near the true vacuum at</p> \\[r_{\\min}=10^{-4} r_{\\text{scale}}\\] <p>Tolerances. <code>phi_tol</code> defaults to \\(10^{-4}\\).  From it  build the relative end point tolerances \\(\\varepsilon_\\phi\\) and \\(\\varepsilon_{\\phi'}\\) that the solution must satisfy at large r, as \\(\\phi\\) reachs the false vacuum.</p> <p>Cutoff. Used</p> \\[\\texttt{cutoff}=10^{-2}|\\phi_{\\text{meta}}-\\phi_{\\text{true}}|\\] <p>as the lower bound for the initial displacement needed to leave the immediate vicinity of  \\((\\phi_{\\text{true}})\\).</p> <p>How the initial condition is guessed</p> <p>Because \\(\\phi_0 \\equiv \\phi(0)\\) is not known a priori, the code parametrizes it  with a single shooting variable (x):</p> \\[\\phi_0(x)=\\phi_{\\text{true}}+e^{-x}\\bigl(\\phi_{\\text{meta}}-\\phi_{\\text{true}}\\bigr)\\] <ul> <li>Large (x)  \\(\\Rightarrow \\phi_0\\) close to the true vacuum.</li> <li>Small (x)  \\(\\Rightarrow \\phi_0\\) close to the false (meta) vacuum.</li> </ul> <p>The code starts from the conservative side: pick (x) such that  \\(\\phi_0=\\phi_{\\text{bar}}\\) (remember \\(\\phi_0\\ge \\phi_{\\text{bar}}\\)). Then:</p> <ol> <li>Try to find an admissible starting radius for this \\((\\phi_0)\\). Otherwise, if can\u2019t find any  , increase (x) (move \\(\\phi_0\\) a bit toward \\(\\phi_{\\text{true}}\\)) and try again.</li> <li>Integrate until we either converge or detect undershoot/overshoot (see below).</li> </ol> <p>What undershoot / overshoot mean here (and how x gets update)</p> <ul> <li> <p>Undershoot: friction wins and the field turns around before reaching \\(\\phi_{\\text{meta}}\\)   (\\(\\phi'(r)\\) flips to positive while \\(\\phi&gt;\\phi_{\\text{meta}}\\)).   \u2192 We started too close to \\(\\phi_{\\text{bar}}\\) (not enough energy).   \u2192 Set \\(x_{\\min}=x\\) and increase (x): \\(x\\leftarrow \\tfrac{1}{2}(x_{\\min}+x_{\\max})\\).</p> </li> <li> <p>Overshoot: the trajectory crosses \\(\\phi_{\\text{meta}}\\).   \u2192 We started too close to \\(\\phi_{\\text{true}}\\) (too much energy).   \u2192 Set \\(x_{\\max}=x\\) and decrease (x): \\(x\\leftarrow \\tfrac{1}{2}(x_{\\min}+x_{\\max})\\).</p> </li> </ul> <p>This bisection on (x) repeats until both end-point tolerances are satisfied.</p> <p>After the correct \\((\\phi_0)\\) is found</p> <p>Builds a radius grid</p> \\[R={r_0,\\dots,r_f}\\quad\\text{with}\\quad \\text{n_points}\\] <p>starting at the found \\(r_0\\) from the initial-condition logic and going out to \\(r_f\\).  Note that \\(r_0\\) can be well above zero (especially in thin wall): the field may  sit almost flat before it \u201cdecides\u201d to roll.</p> <p>For the interior \\(r\\) &lt; \\(r_0\\), The code fills the bubble by the exact small-(r) expansion  around \\(\\phi_0\\) (we effectively have \\(\\phi'\\approx 0\\) there), which gives a smooth and  physically correct core.</p> <p>Good practice. Always sanity-check that \\(\\phi'_0\\approx 0\\); if it\u2019s not,  you\u2019re likely starting a bit too far out or with an inconsistent \\(\\phi_0\\).</p> <p>Bellow are all the plots for thin and thick wall with the correct solution for this simple case.</p> <pre><code># To get the profile\ninst = SingleFieldInstanton(\n        phi_absMin= phi_abs,\n        phi_metaMin=phi_meta,\n        V=V,\n        alpha=alpha,\n        phi_eps=1e-3)\n\nprofile = inst.findProfile(\n        xguess=None, phitol=phitol,\n        thinCutoff=thinCutoff, npoints=npoints,\n        max_interior_pts=max_interior_pts,\n        _MAX_ITERS= _MAX_ITERS\n    )\nR= profile.R\nphi = profile.Phi\ndphi = profile.dPhi\n</code></pre> <p>Thin-wall - Path of \\(\\phi(r)\\) on \\(V(\\phi)\\) </p> <p>Thin-wall - Path of \\(\\phi(r)\\) on \\(V(\\phi)\\) </p> <p>Thin-wall - Bounce Solution (\\(\\phi_b(r)\\)) \\(\\phi(r)\\)x r </p> <p>Thick-wall - Bounce Solution (\\(\\phi_b(r)\\)) \\(\\phi(r)\\)x r </p> <p>Some plots to represent what we would see in 3D space,  at the moment after the bubble nucleation (t=0)</p> <p>Thin-wall - Cartesian slice </p> <p>Thick-wall - Cartesian slice </p> <p>Thin-wall - Surface 3D </p> <p>Thick-wall - Surface 3D </p>"},{"location":"examples/example_tunneling1D/#action-beta-and-terms-contributions","title":"Action, \\(\\beta\\) and terms contributions","text":"<p>Inside the class SingleFieldInstaton there is also a function to evaluate the action of the founded solution. </p> <p>The action (with the false-vacuum constant removed) is</p> \\[S = \\int_{r_0}^{\\infty}\\Big[\\tfrac12(\\partial_r\\phi)^2+\\big(V(\\phi)-V(\\phi_{\\rm meta})\\big)\\Big]  r^\\alpha dr\\Omega_\\alpha +\\] \\[+\\underbrace{ \\int_{0}^{r_0} \\big(V(\\phi(r_0)) - V(\\phi_{\\rm meta})\\big),d^dr }_{\\text{\u201cinterior bulk\u201d}}\\] <p>because thin-wall integrations start at \\((r=r_0&gt;0)\\). Regularity implies$ (\\phi'(r)\\sim\\mathcal{O}(r))$, so the gradient contribution from \\(([0,r_0])\\) is negligible, but the potential offset must be accounted for via the (d)-ball volume:</p> \\[{\\rm Vol}_d(r_0)=\\frac{\\pi^{d/2}}{\\Gamma(d/2+1)}r_0^d\\] <p>The function <code>inst.actionBreakdown(profile)</code> returns</p> <p>A named tuple with:</p> <ul> <li><code>S_total</code>: valued with <code>findAction(profile)</code>.</li> <li><code>S_kin</code>, <code>S_pot</code>: line integrals of the kinetic and potential pieces separately.</li> <li><code>S_interior</code>: the interior bulk correction.</li> <li>Copies of <code>r</code>, <code>phi</code>, <code>dphi</code>.</li> <li> <p><code>density</code>: a dict with arrays</p> </li> <li> <p><code>density[\"kin\"]</code> = \\(\\frac{1}{2}\\Phi'^2 r^\\alpha \\Omega_\\alpha\\),</p> </li> <li><code>density[\"pot\"]</code> = \\((V(\\Phi)-V_{\\rm meta}) r^\\alpha \\Omega_\\alpha\\)</li> <li><code>density[\"tot\"] = density[\"kin\"] + density[\"pot\"]</code>.</li> </ul> <p>From this we can see how the action density varies with r.</p> <p>The code also includes a function to calculate an approximate inverse  time scale \\((\\beta)\\). This function uses 1/rscale or thickness.</p> <p>To understand this further or see everything the code can do,  see the complete code in docs/examples/tunneling1D  or the full .md explanation of each function in docs/modules/tunneling1D/single_field</p> <p>Bellow are the plots made and the full diagnostics;</p> <p>Thin-wall -  ODE Terms contributions </p> <p>Thick-wall -  ODE Terms contributions </p> <p>Thin-wall -  Action </p> <p>Thick-wall - Action </p> <pre><code>Wall diagnostics:\n\n{\n  \"label\": \"thin-wall\",\n  \"phi_metaMin\": 0.0,\n  \"phi_absMin\": 1.0,\n  \"phi_bar\": 0.8371714313771578,\n  \"phi_top\": 0.4699999983395586,\n  \"V(phi_meta)\": 0.0,\n  \"V(phi_true)\": -0.0050000000000000044,\n  \"V(phi_top)\": 0.013237432499999993,\n  \"DeltaV_true_minus_meta\": -0.0050000000000000044,\n  \"r0\": 40.55284169790182,\n  \"phi0\": 0.9900000000000001,\n  \"dphi0\": -0.007033518046022252,\n  \"rscale_cubic\": 1.6677093050224265,\n  \"rscale_curv\": 2.003609750059915,\n  \"wall_r_hi\": 50.18104547208761,\n  \"wall_thickness\": 6.229542940963725,\n  \"S_total\": 1093.4288131878518,\n  \"S_kin\": 1638.3947831914747,\n  \"S_pot\": -544.9659700036232,\n  \"S_interior\": 0.0,\n  \"beta_rscale\": 0.5996248848575876,\n  \"beta_curvature\": 0.49909918859817576,\n  \"beta_wall\": 0.16052542048057503\n}\n\n{\n  \"label\": \"thick-wall\",\n  \"phi_metaMin\": 0.0,\n  \"phi_absMin\": 1.0,\n  \"phi_bar\": 0.31010205014581543,\n  \"phi_top\": 0.20000000196657425,\n  \"V(phi_meta)\": 0.0,\n  \"V(phi_true)\": -0.05000000000000002,\n  \"V(phi_top)\": 0.0011999999999999992,\n  \"DeltaV_true_minus_meta\": -0.05000000000000002,\n  \"r0\": 0.0002357022627131459,\n  \"phi0\": 0.7421401843117063,\n  \"dphi0\": -8.151238531343361e-06,\n  \"rscale_cubic\": 2.357022627131459,\n  \"rscale_curv\": 2.499999981574293,\n  \"wall_r_hi\": 7.990901987734343,\n  \"wall_thickness\": 7.990901987734343,\n  \"S_total\": 6.6298736618724545,\n  \"S_kin\": 9.943318384815374,\n  \"S_pot\": -3.3134447229429216,\n  \"S_interior\": 0.0,\n  \"beta_rscale\": 0.42426406454019444,\n  \"beta_curvature\": 0.4000000002104124,\n  \"beta_wall\": 0.1251423182933482\n}\n</code></pre>"},{"location":"examples/example_tunneling1D/#notes","title":"Notes","text":"<p>It's important to emphasize that within this example, you can apply your own potential and test it to obtain all these graphs.  Note that so far, there are no temperature corrections or anything like that; we're doing everything very simply.  The rest will be covered in the next modules.</p> <p>Go to: docs/examples/example_tunneling1D.py</p> <ol> <li>At the beginning of the code, define your potential.</li> </ol> <p><pre><code>def V_mine(phi: float) -&gt;float:\n    return 0.25 * phi ** 4 - 0.49 * phi ** 3 + 0.235 * phi ** 2\n</code></pre> 2. Go to the end of the code and uncomment the line with</p> <pre><code>run_all(case=\"mine\", xguess=None, phitol=1e-5,thinCutoff=0.01,\n             phi_abs= 1.0, phi_meta =0.0, save_dir=None)\n</code></pre> <p>Note that you need to know a priori what \\(\\phi_{true}\\) and  \\(\\phi_{meta}\\) are, and you may need to adjust some parameters depending  on the error encountered raised throughout the code.</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/","title":"Approx Thermal Integrals (Jb, Jf)","text":""},{"location":"modules/finiteT/Approx_Thermal_Integrals/#low-x-high-t-approximate-thermal-integrals","title":"Low-x (High-T) Approximate Thermal Integrals","text":"<p>This page documents the small (x) (high temperature) asymptotic expansions for the 1 loop thermal integrals:</p> \\[J_b(x)=\\int_0^\\infty dy y^2\\ln\\bigl(1-e^{-\\sqrt{y^2+x^2}}\\bigr)\\qquad J_f(x)=\\int_0^\\infty dy -y^2\\ln\\bigl(1+e^{-\\sqrt{y^2+x^2}}\\bigr)\\] <p>with (x = m/T). The functions below implement the low (x) series used ubiquitously in finite temperature QFT.</p> <p>Purpose (for both): provide fast, vectorized approximations valid for (\\(|x|\\ll 1\\)). They return types (scalar-in \u2192 scalar-out; array-in \u2192 array-out), using modern numerics and clear error handling.</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#signatures","title":"Signatures","text":"<pre><code>Jb_low(x: float | array_like, n: int = 20) -&gt; float | np.ndarray\nJf_low(x: float | array_like, n: int = 20) -&gt; float | np.ndarray\n</code></pre>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#formulas","title":"Formulas","text":"<p>For small (|x|), the bosonic and fermionic integrals admit the asymptotic series</p> \\[\\boxed{ \\begin{aligned} J_b(x) &amp;= -\\frac{\\pi^4}{45} +\\frac{\\pi^2}{12} x^2 -\\frac{\\pi}{6} x^3 -\\frac{1}{32} x^4\\Big(\\ln x^2 - C_b\\Big) +\\sum_{i=1}^{n} g^{(b)}*i x^{2i+4} \\\\ J_f(x) &amp;= -\\frac{7\\pi^4}{360} +\\frac{\\pi^2}{24}x^2 +\\frac{1}{32}x^4\\Big(\\ln x^2 - C_f\\Big) +\\sum_{i=1}^{n} g^{(f)}_i x^{2i+4} \\end{aligned}}\\] <p>where</p> \\[C_b = \\tfrac{3}{2}-2\\gamma_E + 2\\ln(4\\pi)\\qquad C_f = \\tfrac{3}{2}-2\\gamma_E + 2\\ln(\\pi) \\] <p>and (\\(\\gamma_E\\)) is the Euler Mascheroni constant. The tail coefficients (\\(g^{(b)}_i, g^{(f)}_i\\)) are precomputed from combinations of the Riemann zeta and Gamma functions (as in the literature), and we truncate the tail at order (n) (default (n=20), capped at 50).</p> <p>Implementation notes</p> <ul> <li>The (\\(x^4\\ln x^2\\)) piece has a removable singularity at (x=0). We evaluate it as exactly zero at (\\(x=0\\)) to avoid \\((0\\times(-\\infty))\\) numerics.</li> <li>The tail (\\(\\sum_{i=1}^{n}g_i x^{2i+4}\\)) is accumulated as (\\(x^4 \\sum_i g_i (x^2)^i\\)) for stability and performance.</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#parameters-returns-errors","title":"Parameters, Returns &amp; Errors","text":"<p>Parameters (both)</p> <ul> <li><code>x</code> (<code>float | array_like</code>): argument (x=m/T). Intended for the small (x) regime.</li> <li><code>n</code> (<code>int</code>, default <code>20</code>): number of tail terms to add. Clipped to the available (50) precomputed terms.</li> </ul> <p>Returns (both)</p> <ul> <li><code>float | np.ndarray</code>: \\((J_{b,f}(x))\\) with the chosen truncation; preserves scalar/array shape.</li> </ul> <p>Raises (both)</p> <ul> <li><code>ValueError</code> if <code>n &lt; 0</code>.</li> <li><code>TypeError</code> if <code>x</code> is complex. (Low (x) expansions are defined for real (x). For complex/imaginary mass, use the exact or spline implementations.)</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#when-to-use","title":"When to use","text":"<ul> <li>Use <code>Jb_low</code> / <code>Jf_low</code> for fast high-T evaluations with (\\(|x|\\ll 1\\)) when you don\u2019t need the full integral and want smooth dependence near the origin.</li> <li>Prefer the exact or spline versions outside the small (x) window or when high accuracy is required globally.</li> </ul> <p>Caveats (asymptotic series):</p> <ul> <li>Adding more terms (<code>n</code>) usually improves accuracy for sufficiently small (x), but for fixed (x) the series is asymptotic\u2014there is an optimal truncation beyond which errors grow.</li> <li>Not suitable for complex (x) (no physical meaning for mixed real+imag parts here; use exact/spline branches instead).</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#usage-hints","title":"Usage hints","text":"<pre><code># Small-x grid (e.g., up to x ~ 0.5)\nx = np.linspace(0.0, 0.5, 200)\n\n# Fast approximations\nJb_approx = Jb_low(x, n=20)\nJf_approx = Jf_low(x, n=20)\n\n# Cross-check near the origin (optional)\nJb0 = Jb_low(0.0)   # \u2248 -\u03c0^4/45\nJf0 = Jf_low(0.0)   # \u2248 -7\u03c0^4/360\n</code></pre> <p>For full validation plots and quantitative error checks against the exact integrals, see the test suite for this sub-module.</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#test-low-x-high-t","title":"Test - Low-x (High-T)","text":"<p>Comparison: exact vs. low-x series</p> <p>Setup: (\\(x \\in [0,,1.5]\\)). We intentionally go beyond the strictly small-(x) window to show where the series starts to degrade. Truncation length (n=20) (can be tuned).</p> <p>Note: If you change the grid one can see that for \\(x \\geq 3\\), \\(J_f\\) diverges quickly. The same thing happens for \\(x \\geq 5.5\\) in \\(J_b\\). </p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#plots","title":"Plots","text":"<ul> <li> <p>Boson: exact vs. low-x approximation   </p> </li> <li> <p>Fermion: exact vs. low-x approximation   </p> </li> <li> <p>Relative error (both species on one panel; log scale)   </p> </li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#expected-behavior","title":"Expected behavior","text":"<ul> <li>Near (\\(x\\approx 0\\)), the low (x) series is excellent for both (\\(J_b\\)) and (\\(J_f\\)).</li> <li>Accuracy gradually decreases as (x) grows; with \\((n\\approx 20)\\), the series is typically more reliable up to (\\(x\\sim 1.5{-}2\\)).</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#console-output","title":"Console output","text":"<pre><code>=== Test 1: LOW-x (high-T) comparison: exact vs low-x series ===\nBoson  (low-x)  n=20: max abs err=9.492e-10, max rel err=7.029e-10\nFermion(low-x)  n=20: max abs err=9.492e-10, max rel err=7.411e-10\n  threshold 1e-03: max x with rel err &lt; thr \u2192  J_b: 1.500,  J_f: 1.500\n  threshold 1e-04: max x with rel err &lt; thr \u2192  J_b: 1.500,  J_f: 1.500\nExpectation: The low-x series is excellent near x\u22480 and degrades gradually;\n             truncation at n\u224820 is typically sufficient up to x~1.5\u20132.\n</code></pre> <ul> <li>see tests/finiteT/Approx_Thermal_Integrals for more</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#high-x-low-t-approximate-thermal-integrals","title":"High-x (Low-T) Approximate Thermal Integrals","text":"<p>This page documents the large (x) (low temperature) asymptotic expansions of the 1 loop thermal integrals,</p> \\[J_b(x)=\\int_0^\\infty dy y^2\\ln \\bigl(1-e^{-\\sqrt{y^2+x^2}}\\bigr)\\qquad J_f(x)=\\int_0^\\infty dy -y^2\\ln \\bigl(1+e^{-\\sqrt{y^2+x^2}}\\bigr)\\] <p>with (x=m/T). For (\\(x\\gg 1\\)), both integrals admit rapidly convergent series in terms of the modified Bessel functions (\\(K_\\nu\\)).</p> <p>Purpose (for all functions in this block): provide fast, vectorized, and numerically stable high (x) approximations (and up to 3 derivatives) using sums of (\\(K_\\nu\\)).</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#signatures_1","title":"Signatures","text":"<pre><code># Term (single-k) building blocks\nx2K2(k: int, x: float | array_like)  -&gt; float | np.ndarray\ndx2K2(k: int, x: float | array_like) -&gt; float | np.ndarray\nd2x2K2(k: int, x: float | array_like)-&gt; float | np.ndarray\nd3x2K2(k: int, x: float | array_like)-&gt; float | np.ndarray\n\n# High-x sums (public)\nJb_high(x: float | array_like, deriv: int = 0, n: int = 8) -&gt; float | np.ndarray\nJf_high(x: float | array_like, deriv: int = 0, n: int = 8) -&gt; float | np.ndarray\n</code></pre>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#formulation","title":"Formulation","text":"<p>The expansions are built from the \u201csingle (k)\u201d terms</p> \\[T_k(x)\\equiv -\\frac{x^2}{k^2}K_2\\big(k|x|\\big)\\] <p>whose derivatives w.r.t. (x) (accounting for the even/odd symmetry through (|x|)) are:</p> <ul> <li>0th: \\((T_k(x)= -\\dfrac{x^2}{k^2}K_2\\big(k|x|\\big))\\).</li> <li>1st: \\((\\dfrac{dT_k}{dx} = \\dfrac{x|x|}{k}K_1\\big(k|x|\\big))\\) (odd, vanishes at (x=0)).</li> <li>2nd: \\((\\dfrac{d^2T_k}{dx^2} = |x|\\left(\\dfrac{K_1(k|x|)}{k}-|x|K_0(k|x|)\\right))\\) (even).</li> <li>3rd: \\((\\dfrac{d^3T_k}{dx^3} = x\\left(|x|k K_1(k|x|)-3K_0(k|x|)\\right))\\) (odd).</li> </ul> <p>Then:</p> \\[\\boxed{J_b^{\\text{high}}(x) \\approx \\sum_{k=1}^{n} \\frac{d^{\\text{deriv}}}{dx^{\\text{deriv}}}T_k(x)}\\] \\[\\boxed{J_f^{\\text{high}}(x) \\approx \\sum_{k=1}^{n} (-1)^{k-1}\\frac{d^{\\text{deriv}}}{dx^{\\text{deriv}}}T_k(x)} \\] <p>The alternating sign for (\\(J_f\\)) reflects Fermi\u2013Dirac statistics. Each term decays (\\(\\sim e^{-k|x|}\\)), so only a few terms are needed for (\\(x\\gtrsim\\mathcal{O}(1)\\)).</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#small-x-limits-for-single-k-terms","title":"Small-(x) limits for single-(k) terms","text":"<p>Used to avoid numerical issues and ensure smoothness at (x=0):</p> \\[\\lim_{x\\to 0} T_k(x) = -\\frac{2}{k^4}\\qquad \\lim_{x\\to 0} \\frac{dT_k}{dx} = 0\\qquad \\lim_{x\\to 0} \\frac{d^2T_k}{dx^2} = \\frac{1}{k^2}\\qquad \\lim_{x\\to 0} \\frac{d^3T_k}{dx^3} = 0\\]"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#parameters-returns-errors_1","title":"Parameters, Returns &amp; Errors","text":"<p>Parameters (all):</p> <ul> <li><code>x</code> (<code>float | array_like</code>, real): argument (x=m/T). These high-(x) series target real (x).</li> <li><code>deriv</code> (<code>int</code>, default <code>0</code> for <code>J*_high</code>): order of derivative to return (<code>0</code>, <code>1</code>, <code>2</code>, <code>3</code>).</li> <li><code>n</code> (<code>int</code>, default <code>8</code> for <code>J*_high</code>): number of exponential terms in the truncated sum; must be \u2265 1.</li> </ul> <p>Returns (all):</p> <ul> <li><code>float | np.ndarray</code>: the requested approximation, preserving scalar/array shape.</li> </ul> <p>Raises (all):</p> <ul> <li><code>TypeError</code> if <code>x</code> is complex (no physical meaning for mixed real+imag here; use exact/spline branches for complex analyses).</li> <li><code>ValueError</code> if <code>deriv \u2209 {0,1,2,3}</code> or if <code>n &lt; 1</code>.</li> <li><code>ValueError</code> if a term helper is called with <code>k \u2264 0</code> (internal guard).</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#when-to-use_1","title":"When to use","text":"<ul> <li>Use <code>Jb_high</code> / <code>Jf_high</code> (and derivatives) when (x) is moderately to very large (e.g. (\\(x \\gtrsim 2\\))), where the series converges exponentially fast.</li> <li> <p>For small or intermediate (x), prefer:</p> </li> <li> <p><code>Jb_low</code> / <code>Jf_low</code> (low (x) series, high T),</p> </li> <li><code>Jb_exact</code> / <code>Jf_exact</code> (direct quadrature),</li> <li>or <code>Jb_spline</code> / <code>Jf_spline</code> (global interpolation).</li> <li>Complex (x) has no direct physical interpretation here and is not supported by the high (x) series.</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#usage-hints_1","title":"Usage hints","text":"<pre><code># Example: values (no derivatives), n=8 terms\nx = np.linspace(2.0, 8.0, 60)\nJb = Jb_high(x, deriv=0, n=8)\nJf = Jf_high(x, deriv=0, n=8)\n\n# First derivatives\ndJb = Jb_high(x, deriv=1, n=8)\ndJf = Jf_high(x, deriv=1, n=8)\n\n# Scalar input \u2192 scalar output\nval_b = Jb_high(5.0)        # float\nval_f = Jf_high(5.0, 2, 10) # d\u00b2/dx\u00b2 with 10 terms\n</code></pre> <p>Convergence tip: increase <code>n</code> until your observable stops changing at the precision you need. Because terms scale as (\\(e^{-k|x|}\\)), a modest <code>n</code> (6\u201312) is usually enough for (\\(x \\gtrsim 2\\)).</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#numericalimplementation-notes","title":"Numerical/Implementation Notes","text":"<ul> <li>We evaluate Bessel functions with SciPy (<code>scipy.special.kv</code>), always using (k|x|) in the argument to maintain the correct even/odd symmetry of derivatives.</li> <li>At <code>x == 0</code>, we insert the analytic limits listed above to avoid underflow/overflow and ensure smoothness.</li> <li>Functions are fully vectorized (array-in \u2192 array-out) while preserving scalar behavior (scalar-in \u2192 scalar-out), consistent with the legacy API.</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#high-x-low-t-test","title":"High-x (Low-T) - Test","text":"<p>comparison: exact vs. high x series</p> <p>Setup: (\\(x \\in [2,,10]\\)). We compare the exact integrals against the high (x) sums with (\\(n\\in{4,8,12}\\)) terms to illustrate exponential convergence.</p>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#plots_1","title":"Plots","text":"<ul> <li> <p>Boson: (\\(|J_b|\\)) semilog \u2014 exact vs. high-(x) (n=4,8,12)   </p> </li> <li> <p>Fermion: (\\(|J_f|\\)) semilog \u2014 exact vs. high-(x) (n=4,8,12)   </p> </li> <li> <p>Boson: relative error vs. (x) (n=4,8,12)   </p> </li> <li> <p>Fermion: relative error vs. (x) (n=4,8,12)   </p> </li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#expected-behavior_1","title":"Expected behavior","text":"<ul> <li>Both (\\(|J_b|\\)) and (\\(|J_f|\\)) decay roughly (\\(\\sim e^{-x}\\)); the high-(x) sums track the exact curves closely on semilog axes.</li> <li>Relative error drops rapidly with increasing (n) and (x); \\((n\\approx 8{-}12)\\) is usually very accurate for (\\(x\\gtrsim 2\\)).</li> </ul>"},{"location":"modules/finiteT/Approx_Thermal_Integrals/#console-output_1","title":"Console output","text":"<pre><code>=== Test 2: HIGH-x (low-T) comparison: exact vs high-x series ===\n\nHigh-x error summary (boson):\n  n= 4: max rel err=1.619e-04, median rel err=3.945e-12\n  n= 8: max rel err=6.351e-07, median rel err=3.778e-16\n  n=12: max rel err=4.527e-09, median rel err=2.949e-16\n\nHigh-x error summary (fermion):\n  n= 4: max rel err=1.113e-04, median rel err=3.929e-12\n  n= 8: max rel err=3.878e-07, median rel err=3.485e-16\n  n=12: max rel err=2.618e-09, median rel err=2.686e-16\n\nExpectation: High-x sums converge exponentially fast with n and x;\n             even n\u22488\u201312 is typically very accurate for x\u22732.\n\n---------- END OF TESTS: Approx Thermal Integrals ----------\n</code></pre> <ul> <li>see tests/finiteT/Approx_Thermal_Integrals for more</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/","title":"Exact Thermal Integrals (Jb, Jf)","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_asarray","title":"<code>_asarray</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature","title":"Signature","text":"<pre><code>_asarray(x: ArrayLike) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose","title":"Purpose","text":"<p>Convert input to a NumPy array without copying when possible (thin wrapper around <code>np.asarray</code>). Normalizes heterogeneous inputs (lists, tuples, scalars) into an <code>ndarray</code> for downstream vectorized code.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>x</code> (<code>array_like</code>): Any object that can be interpreted as an array (e.g., list, tuple, scalar, or <code>ndarray</code>).</li> </ul> <p>Returns</p> <ul> <li><code>np.ndarray</code>: A NumPy view of <code>x</code> if <code>x</code> is already an <code>ndarray</code>; otherwise a newly allocated array.</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Propagates exceptions from <code>np.asarray</code> if <code>x</code> cannot be interpreted as an array.</li> </ul> <p>Notes</p> <ul> <li>Internal helper only, used by other functions</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_is_scalar","title":"<code>_is_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_1","title":"Signature","text":"<pre><code>_is_scalar(x: ArrayLike) -&gt; bool\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_1","title":"Purpose","text":"<p>Check whether <code>x</code> is a scalar (Python/NumPy numeric scalar or a 0-D <code>ndarray</code>). Useful to preserve the contract \u201cscalar-in \u2192 scalar-out\u201d from legacy.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_1","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>x</code> (<code>array_like</code>): Object to inspect.</li> </ul> <p>Returns</p> <ul> <li><code>bool</code>: <code>True</code> if <code>x</code> is scalar (including 0-D arrays), otherwise <code>False</code>.</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Never raises by design; if <code>np.ndim(x)</code> errors for exotic objects, the function safely returns <code>False</code>.</li> </ul> <p>Notes</p> <ul> <li>Internal helper only, used by other functions</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_apply_elementwise","title":"<code>_apply_elementwise</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_2","title":"Signature","text":"<pre><code>_apply_elementwise(f: Callable[[Number], Number],x: ArrayLike,*,dtype: np.dtype = np.float64,) -&gt; Union[Number, np.ndarray]\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_2","title":"Purpose","text":"<p>Apply a scalar function <code>f</code> to <code>x</code> (scalar or array) element wise, preserving scalar-in \u2192 scalar-out like legacy version. Mirrors the legacy behavior: any element that causes an exception during evaluation is mapped to <code>NaN</code> (instead of raising). Supports real or complex outputs via <code>dtype</code>.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_2","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>f</code> (<code>callable</code>): Function of a single numeric argument returning a numeric value.</li> <li><code>x</code> (<code>array_like</code>): Input value(s); scalar or array-like of any shape.</li> <li><code>dtype</code> (<code>np.dtype</code>, optional): Output dtype when <code>x</code> is array-like (use <code>np.complex128</code> for complex results). Default <code>np.float64</code>.</li> </ul> <p>Returns</p> <ul> <li> <p><code>number | np.ndarray</code>:</p> </li> <li> <p>If <code>x</code> is scalar: the scalar result <code>f(x)</code> (or <code>NaN</code>/<code>NaN+0j</code> on failure).</p> </li> <li>If <code>x</code> is array-like: an array with the same shape as <code>x</code>, containing element-wise results (or <code>NaN</code> where evaluation fails).</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Designed not to raise for per-element failures (they become <code>NaN</code>).</li> <li>May propagate errors only if <code>dtype</code> is invalid or memory allocation fails.</li> </ul> <p>Notes</p> <ul> <li>Preserves shape for array inputs and scalar semantics for scalar inputs.</li> <li>For complex outputs, pass <code>dtype=np.complex128</code> to avoid down-casting.</li> <li>Internal helper; used by other functions</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_jf_exact_scalar","title":"<code>_Jf_exact_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_3","title":"Signature","text":"<pre><code>_Jf_exact_scalar(x: Number) -&gt; Number\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_3","title":"Purpose","text":"<p>Evaluate the exact one-loop fermionic thermal integral (\\(J_f(x)\\)) for a scalar input (x) (real or complex),</p> \\[J_f(x) = \\int_{0}^{\\infty}  dy \\big(-y^2\\big)\\ln\\Big(1 + e^{-\\sqrt{y^2+x^2}}\\Big)\\] <p>where (\\(x \\equiv m/T\\)) and (\\(E=\\sqrt{y^2+x^2}\\)) is the dimensionless energy. This scalar kernel is used internally by the vectorized public wrapper <code>Jf_exact</code>.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#where-the-formula-comes-from-qft-background","title":"Where the formula comes from (QFT background)","text":"<p>At one loop in finite-temperature field theory, the thermal correction for fermionic modes is proportional to \\((\\int d^3 p \\ln \\big (1+e^{-E_p/T}\\big))\\). After factoring constants and using spherical coordinates (\\(p/T \\to y\\)), the angular integration yields (\\(4\\pi\\)), and the radial part becomes exactly the integral above with the weight (\\(y^2\\)).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#real-argument-path-direct-integral","title":"Real-argument path (direct integral)","text":"<p>For real (x), the integrand is real and we integrate directly:</p> \\[J_f(x)=\\int_0^\\infty -y^2\\ln\\big(1+e^{-E}\\big)dy \\qquad E=\\sqrt{y^2+x^2}\\] <p>We use the numerically stable identity \\((ln(1+e^{-E})=\\mathrm{log1p} (e^{-E}))\\).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#pore-complex-argument-path-domain-split","title":"Pore Complex-argument path (domain split)","text":"<p>If (x) carries an imaginary part only, then for (\\(0\\le y \\le |x|\\)) the principal branch energy becomes purely imaginary:</p> <p>(E= iz) with \\((z=\\sqrt{|x|^2-y^2})\\). In this regime,</p> \\[1+e^{-E} = 1+e^{-i z} = 2e^{-i z/2}\\cos(z/2)\\quad\\Rightarrow\\quad \\big|1+e^{-E}\\big| = 2|\\cos(z/2)|.\\] <p>Therefore, we split the integral at (\\(a_x=|x|\\)) and evaluate</p> \\[\\boxed{ \\begin{aligned} J_f(x)=\\int_0^{a_x}-y^2\\ln\\Big(2\\big|\\cos\\big(\\tfrac{\\sqrt{a_x^2-y^2}}{2}\\big)\\big|\\Big)dy \\quad +\\int_{a_x}^{\\infty}-y^2,\\ln\\Big(1+e^{-\\sqrt{y^2+x^2}}\\Big)dy \\end{aligned}}\\] <p>so that both pieces are real valued integrands, suitable for high accuracy quadrature.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_3","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>x</code> (<code>Number</code>): Scalar input, real or complex.</li> </ul> <p>Returns</p> <ul> <li><code>Number</code>: The value of \\((J_f(x))\\). For real <code>x</code>, the result is real. For complex <code>x</code>, the value is computed via real integrands on both pieces and is real as well (principal-branch prescription).</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Assumes the principal square root branch. Numerical quadrature tolerances are set to <code>epsabs=1e-10</code>, <code>epsrel=1e-8</code>, <code>limit=200</code>.</li> </ul> <p>Notes</p> <ul> <li>This is an internal scalar kernel. Use the public <code>Jf_exact</code> for array inputs (vectorized and with dtype control).</li> <li>The use of <code>log1p</code> improves robustness near (\\(E\\approx 0\\)).</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_jb_exact_scalar","title":"<code>_Jb_exact_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_4","title":"Signature","text":"<pre><code>_Jb_exact_scalar(x: Number) -&gt; Number\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_4","title":"Purpose","text":"<p>Evaluate the exact one-loop bosonic thermal integral \\((J_b(x))\\) for a scalar input (x) (real or complex),</p> \\[J_b(x) = \\int_{0}^{\\infty} dy y^2\\ln\\Big(1 - e^{-\\sqrt{y^2+x^2}}\\Big)\\] <p>where (\\(x=m/T\\)) and (\\(E=\\sqrt{y^2+x^2}\\)).</p> <p>This scalar kernel is used internally by the vectorized public wrapper <code>Jb_exact</code>.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#where-the-formula-comes-from-qft-background_1","title":"Where the formula comes from (QFT background)","text":"<p>For bosonic modes, the finite (T) one-loop contribution is proportional to \\((\\int d^3p \\ln(1-e^{-E_p/T}))\\). After the angular integral and rescaling (\\(p/T\\to y\\)), we obtain the radial integral above with weight (\\(y^2\\)).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#real-argument-path-direct-integral_1","title":"Real-argument path (direct integral)","text":"<p>For real (x),</p> \\[J_b(x)=\\int_0^\\infty y^2\\ln\\big(1-e^{-E}\\big)dy\\qquad E=\\sqrt{y^2+x^2}\\] <p>We employ the stable identity \\((\\ln(1-e^{-E})=\\mathrm{log1p}(-e^{-E}))\\).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#pure-complex-argument-path-domain-split","title":"Pure Complex-argument path (domain split)","text":"<p>If (x) has an imaginary component, then for (\\(0\\le y \\le |x|\\)), (E=iz) with (\\(z=\\sqrt{|x|^2-y^2}\\)) and</p> \\[1-e^{-E} = 1-e^{-i z} = 2e^{-i z/2}i\\sin(z/2)\\quad\\Rightarrow\\quad  \\big|1-e^{-E}\\big| = 2|\\sin(z/2)|\\] <p>Thus, we split at (\\(a_x=|x|\\)) and evaluate</p> \\[\\boxed{ \\begin{aligned} J_b(x) &amp;=\\int_0^{a_x}y^2\\ln\\Big(2\\big|\\sin\\big(\\tfrac{\\sqrt{a_x^2-y^2}}{2}\\big)\\big|\\Big)dy\\ \\quad +\\int_{a_x}^{\\infty}y^2\\ln\\Big(1-e^{-\\sqrt{y^2+x^2}}\\Big)dy \\end{aligned}}\\] <p>which again yields real integrands in both intervals.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_4","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>x</code> (<code>Number</code>): Scalar (real or complex).</li> </ul> <p>Returns</p> <ul> <li><code>Number</code>: The value of ($J_b(x) $). For real <code>x</code> the result is real; with complex <code>x</code>, the split formulas ensure a real valued integral (principal branch choice).</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Principal square-root branch. Quadrature settings: <code>epsabs=1e-10</code>, <code>epsrel=1e-8</code>, <code>limit=200</code>.</li> </ul> <p>Notes</p> <ul> <li>Internal scalar kernel; the vectorized public API is <code>Jb_exact</code>.</li> <li><code>log1p(-exp(-E))</code> mitigates loss of significance near (\\(E\\approx 0\\)) for bosons.</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_jf_exact2_scalar","title":"<code>_Jf_exact2_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_5","title":"Signature","text":"<pre><code>_Jf_exact2_scalar(theta: Number) -&gt; float\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_5","title":"Purpose","text":"<p>Evaluate the exact one-loop fermionic thermal integral (J_f) as a function of the real scalar (\\(\\theta \\equiv x^2 = (m/T)^2\\)) equivalent to the functions above:</p> \\[J_f(\\theta) = \\int_{0}^{\\infty} dy \\big(-y^2\\big)\\ln\\Big(1 + e^{-\\sqrt{y^2+\\theta}}\\Big) \\] <p>This is the scalar kernel used internally by the vectorized public wrapper <code>Jf_exact2(theta)</code>.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#why-a-based-api-and-why-keep-it-alongside-the-x-based-one","title":"Why a \u03b8-based API (and why keep it alongside the x based one)?","text":"<ul> <li>Physics-first variable. In finite-T QFT the natural scalar entering the thermal integrals is (\\(\\theta=m^2/T^2\\)) (a real quantity that may be negative in symmetry-broken/tachyonic regions).</li> <li>Numerical stability. With (\\(\\theta\\in\\mathbb{R}\\)) the integrand is always chosen real-valued, even for (\\(\\theta&lt;0\\)) (see splitting below). Quadrature is typically faster and more robust.</li> <li>Interpolation/caching. Tabulating in (\\(\\theta\\)) is convenient for splines (next block) and reuse across scans.</li> <li>Compatibility. Remains legacy code that supplies (\\(x=m/T\\)) directly. Both compute the same physics when (x) is real or purely imaginary ((\\(\\theta=x^2\\)) real).</li> </ul> <p>Implementation detail: this function takes the real part of <code>theta</code> internally (<code>th = float(np.real(theta))</code>) to enforce (\\(\\theta\\in\\mathbb{R}\\)) as used in physics.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#positive-branch-thetage-0","title":"Positive-\u03b8 branch \\((\\theta\\ge 0)\\)","text":"\\[J_f(\\theta)=\\int_0^\\infty -y^2\\ln\\big(1+e^{-\\sqrt{y^2+\\theta}}\\big)dy\\] <p>computed directly with the numerically stable identity \\((\\ln(1+e^{-E})=\\mathrm{log1p}(e^{-E}))\\).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#negative-branch-theta0-domain-split-with-real-integrands","title":"Negative-\u03b8 branch \\((\\theta&lt;0)\\) \u2014 domain split with real integrands","text":"<p>Write \\((\\theta=-\\mu^2) ((\\mu&gt;0))\\). Then</p> \\[E=\\sqrt{y^2+\\theta}=\\sqrt{y^2-\\mu^2}= \\begin{cases} i\\sqrt{\\mu^2-y^2}\\equiv i z &amp; 0\\le y&lt;\\mu  \\sqrt{y^2-\\mu^2}\\in\\mathbb{R}*+  &amp; y\\ge \\mu. \\end{cases}\\] <p>For (E=iz), (\\(1+e^{-E}=2e^{-iz/2}\\cos(z/2)\\)) and (\\(\\big|1+e^{-E}\\big|=2|\\cos(z/2)|\\)). Thus we split:</p> \\[\\boxed{ \\begin{aligned} J_f(\\theta) &amp;=\\int_{0}^{\\mu}-y^2\\ln\\Big(2\\big|\\cos!\\big(\\tfrac{\\sqrt{\\mu^2-y^2}}{2}\\big)\\big|\\Big)dy\\ \\quad+\\int_{\\mu}^{\\infty}-y^2\\ln\\Big(1+e^{-\\sqrt{y^2-\\mu^2}}\\Big)dy \\end{aligned}}\\] <p>Both pieces are real, ensuring stable high-accuracy quadrature.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_5","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>theta</code> (<code>Number</code>): Scalar; only its real part is used internally.</li> </ul> <p>Returns</p> <ul> <li><code>float</code>: \\((J_f(\\theta))\\) as a real number.</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Principal square-root branch. Quadrature tolerances are <code>epsabs=1e-10</code>, <code>epsrel=1e-8</code>, <code>limit=200</code>.</li> </ul> <p>Notes</p> <ul> <li>Prefer the \u03b8 API in new code (it is what the spline based approximations will use).</li> <li>For (x) real or (\\(x=i\\mu\\)) (pure imaginary), <code>_Jf_exact_scalar(x)</code> and <code>_Jf_exact2_scalar(\\theta=x^2)</code> coincide.</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_jb_exact2_scalar","title":"<code>_Jb_exact2_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_6","title":"Signature","text":"<pre><code>_Jb_exact2_scalar(theta: Number) -&gt; float\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_6","title":"Purpose","text":"<p>Evaluate the exact one-loop bosonic thermal integral (\\(J_b\\)) as a function of the real scalar (\\(\\theta \\equiv x^2 = (m/T)^2\\)):</p> \\[J_b(\\theta) = \\int_{0}^{\\infty} dy y^2\\ln\\Big(1 - e^{-\\sqrt{y^2+\\theta}}\\Big)\\] <p>This is the scalar kernel used internally by the vectorized public wrapper <code>Jb_exact2(theta)</code>.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#why-a-based-api-and-why-keep-it-alongside-the-x-based-one_1","title":"Why a \u03b8 based API (and why keep it alongside the x-based one)?","text":"<p>Same rationale as fermions:</p> <ul> <li>(\\(\\theta=m^2/T^2\\)) is the natural real control variable (possibly negative).</li> <li>Splitting at (\\(\\theta&lt;0\\)) yields real integrands everywhere \u21d2 more stable and faster quadrature.</li> <li>Ideal for spline tables and caching; x API kept for compatibility with legacy callers providing (x).</li> </ul> <p>Implementation detail: only the real part of <code>theta</code> is used internally.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#positive-branch-thetage-0_1","title":"Positive-\u03b8 branch \\((\\theta\\ge 0)\\)","text":"\\[J_b(\\theta)=\\int_0^\\infty y^2\\ln\\big(1-e^{-\\sqrt{y^2+\\theta}}\\big)dy\\] <p>computed via the stable \\((\\ln(1-e^{-E})=\\mathrm{log1p}(-e^{-E}))\\).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#negative-branch-theta0-domain-split-with-real-integrands_1","title":"Negative-\u03b8 branch \\((\\theta&lt;0)\\) \u2014 domain split with real integrands","text":"<p>Let (\\(\\theta=-\\mu^2\\)) \\((\\mu&gt;0)\\). For (\\(y&lt;\\mu\\)), (E=i z) with (\\(z=\\sqrt{\\mu^2-y^2}\\)) and</p> \\[1-e^{-E}=2e^{-iz/2}i\\sin(z/2)\\quad\\Rightarrow\\quad \\big|1-e^{-E}\\big|=2|\\sin(z/2)|.\\] <p>Therefore,</p> \\[\\boxed{ \\begin{aligned} J_b(\\theta) &amp;=\\int_{0}^{\\mu}y^2\\ln\\Big(2\\big|\\sin\\big(\\tfrac{\\sqrt{\\mu^2-y^2}}{2}\\big)\\big|\\Big)dy\\ \\quad+\\int_{\\mu}^{\\infty}y^2\\ln\\Big(1-e^{-\\sqrt{y^2-\\mu^2}}\\Big)dy \\end{aligned}}\\] <p>Again, both integrands are real.</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_6","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>theta</code> (<code>Number</code>): Scalar; only its real part is used internally.</li> </ul> <p>Returns</p> <ul> <li><code>float</code>: \\((J_b(\\theta))\\) as a real number.</li> </ul> <p>Raises / Assumptions</p> <ul> <li>Principal square-root branch. Quadrature settings as above.</li> </ul> <p>Notes</p> <ul> <li>Prefer the \u03b8-API for new code and for spline approximation.</li> <li>For (x) real or (\\(x=i\\mu\\)), <code>_Jb_exact_scalar(x)</code> and <code>_Jb_exact2_scalar(\\theta=x^2)</code> agree.</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#relationship-between-the-x-and-based-functions","title":"Relationship between the x- and \u03b8 based functions","text":"<ul> <li>If (x) is real or purely imaginary \\(((x=i\\mu\\Rightarrow \\theta=-\\mu^2))\\), both APIs are equivalent and yield the same physics.</li> <li>The \u03b8-API enforces (\\(\\theta\\in\\mathbb{R}\\)) and constructs real integrands in all regimes, which improves numerical behavior and matches how downstream interpolation/approximations will operate.</li> <li>The x API remains for backward compatibility with callers that already supply (\\(x=m/T\\)).</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_djf_exact_scalar","title":"<code>_dJf_exact_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_7","title":"Signature","text":"<pre><code>_dJf_exact_scalar(x: Number) -&gt; float\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_7","title":"Purpose","text":"<p>Compute the exact derivative \\((\\dfrac{dJ_f}{dx})\\) for a scalar (x) with a numerically stable integrand. For fermions,</p> \\[J_f(x)=\\int_0^\\infty -y^2\\ln\\Big(1+e^{-\\sqrt{y^2+x^2}}\\Big)dy \\qquad E\\equiv\\sqrt{y^2+x^2}.\\]"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#differentiating-under-the-integral-sign","title":"Differentiating under the integral sign","text":"<p>Under standard regularity conditions (smooth, absolutely integrable integrand), we may exchange derivative and integral:</p> \\[\\frac{dJ_f}{dx} =\\int_0^\\infty \\frac{\\partial}{\\partial x}\\left[-y^2\\ln\\big(1+e^{-E}\\big)\\right]dy.\\] <p>Using</p> \\[\\frac{d}{dE}\\Big[-\\ln\\big(1+e^{-E}\\big)\\Big] =\\frac{e^{-E}}{1+e^{-E}} =\\frac{1}{e^{E}+1}\\equiv  n_F(E) \\qquad \\frac{dE}{dx}=\\frac{x}{E}\\] <p>we obtain the fermionic derivative kernel</p> \\[\\boxed{ \\frac{dJ_f}{dx}  =\\int_0^\\infty y^2 n_F(E) \\frac{x}{E} dy =\\int_0^\\infty y^2\\frac{x}{E}\\frac{1}{e^{E}+1}dy \\qquad E=\\sqrt{y^2+x^2}}\\]"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#numerical-stability-choices","title":"Numerical stability choices","text":"<ul> <li>We implement ( \\(n_F(E)=\\dfrac{1}{e^{E}+1}\\) ) as <code>special.expit(-E)</code> (the logistic function), which is stable for large (E).</li> <li>By parity, \\((J_f(x))\\) is even in (x) (i.e., \\((J_f(-x)=J_f(x))\\) ), hence ( $\\tfrac{dJ_f}{dx}\\big|_{x=0}=0 $). The function returns 0 exactly at (x=0).</li> <li>Internally we form (\\(E=\\sqrt{y^2+x_r^2}\\)) with (\\(x_r=|x|\\ge 0\\)) to guarantee (\\(E\\ge 0\\)). In physical use (\\(x=m/T\\ge 0\\)).   (For explicit sign handling: \\((\\tfrac{dJ_f}{dx}(-x)=-\\tfrac{dJ_f}{dx}(x))\\) ).</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_7","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>x</code> (<code>Number</code>): Scalar (real or complex). In physical applications (\\(x\\in\\mathbb{R}_{\\ge 0}\\)).</li> </ul> <p>Returns</p> <ul> <li><code>float</code>: The real value of \\((\\dfrac{dJ_f}{dx})\\).</li> </ul> <p>Notes</p> <ul> <li>Quadrature settings: <code>epsabs=1e-10</code>, <code>epsrel=1e-8</code>, <code>limit=200</code>.</li> <li>Integration domain \\((y\\in[0,\\infty))\\) with stable integrand \\((y^2,\\dfrac{x}{E},n_F(E))\\).</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#_djb_exact_scalar","title":"<code>_dJb_exact_scalar</code>","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signature_8","title":"Signature","text":"<pre><code>_dJb_exact_scalar(x: Number) -&gt; float\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_8","title":"Purpose","text":"<p>Compute the exact derivative \\((\\dfrac{dJ_b}{dx})\\) for a scalar (x). For bosons,</p> \\[ J_b(x)=\\int_0^\\infty y^2\\ln\\Big(1-e^{-\\sqrt{y^2+x^2}}\\Big)dy \\qquad E\\equiv\\sqrt{y^2+x^2}.\\]"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#differentiating-under-the-integral-sign_1","title":"Differentiating under the integral sign","text":"\\[\\frac{dJ_b}{dx} =\\int_0^\\infty \\frac{\\partial}{\\partial x}\\left[y^2\\ln\\big(1-e^{-E}\\big)\\right]dy\\] <p>Using</p> \\[\\frac{d}{dE}\\ln\\big(1-e^{-E}\\big) =\\frac{e^{-E}}{1-e^{-E}}  =\\frac{1}{e^{E}-1}\\equiv n_B(E)\\qquad \\frac{dE}{dx}=\\frac{x}{E} \\] <p>we obtain the bosonic derivative kernel</p> \\[\\boxed{ \\frac{dJ_b}{dx} =\\int_0^\\infty y^2 n_B(E)\\frac{x}{E}dy =\\int_0^\\infty y^2\\frac{x}{E}\\frac{1}{e^{E}-1}dy \\qquad E=\\sqrt{y^2+x^2} }\\]"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#numerical-stability-choices_1","title":"Numerical stability choices","text":"<ul> <li>We implement ( \\(n_B(E)=\\dfrac{1}{e^{E}-1}\\) ) as <code>1/np.expm1(E)</code>, which is stable as (\\(E\\to 0^+\\)).</li> <li>By parity, \\((J_b(x))\\) is even in (x) (i.e., \\((J_b(-x)=J_b(x))\\) ), hence \\((\\tfrac{dJ_b}{dx}\\big|_{x=0}=0)\\). The function returns 0 at (x=0).</li> <li>Internally (\\(E=\\sqrt{y^2+x_r^2}\\)) with (\\(x_r=|x|\\ge 0\\)), consistent with the physical case (\\(x=m/T\\ge 0\\)).   (For sign handling: ( $\\tfrac{dJ_b}{dx}(-x)=-\\tfrac{dJ_b}{dx}(x) $).)</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters-returns-and-raises_8","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>x</code> (<code>Number</code>): Scalar (real or complex). In physical applications (\\(x\\in\\mathbb{R}_{\\ge 0}\\)).</li> </ul> <p>Returns</p> <ul> <li><code>float</code>: The real value of \\((\\dfrac{dJ_b}{dx})\\).</li> </ul> <p>Notes</p> <ul> <li>Quadrature settings: <code>epsabs=1e-10</code>, <code>epsrel=1e-8</code>, <code>limit=200</code>.</li> <li>Integration domain \\((y\\in[0,\\infty))\\) with stable integrand \\((y^2,\\dfrac{x}{E}n_B(E))\\).</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#jf_exact-jf_exact2-jb_exact-jb_exact2-djf_exact-djb_exact","title":"Jf_exact; Jf_exact2; Jb_exact; Jb_exact2; dJf_exact; dJb_exact","text":""},{"location":"modules/finiteT/Exact_Thermal_Integrals/#purpose_9","title":"Purpose","text":"<p>These functions are vectorized, user-facing wrappers around the exact scalar kernels for the one-loop thermal integrals (\\(J_b\\)), (\\(J_f\\)) and their derivatives. They:</p> <ul> <li>preserve the legacy cosmoTransitions API (same names/behavior),</li> <li>accept scalars or arrays and apply the scalar kernels element-wise (scalar-in \u2192 scalar-out),</li> <li>offer both x-based ((\\(x=m/T\\))) and \u03b8 based \\((\\theta=x^2=m^2/T^2\\in\\mathbb{R})\\) entry points.</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#signatures","title":"Signatures","text":"<pre><code>Jf_exact(x: ArrayLike) -&gt; Union[Number, np.ndarray]\nJf_exact2(theta: ArrayLike) -&gt; Union[float, np.ndarray]\n\nJb_exact(x: ArrayLike) -&gt; Union[float, np.ndarray]\nJb_exact2(theta: ArrayLike) -&gt; Union[float, np.ndarray]\n\ndJf_exact(x: ArrayLike) -&gt; Union[float, np.ndarray]\ndJb_exact(x: ArrayLike) -&gt; Union[float, np.ndarray]\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#parameters","title":"Parameters","text":"<ul> <li> <p>For x based functions (<code>Jf_exact</code>, <code>Jb_exact</code>, <code>dJf_exact</code>, <code>dJb_exact</code>):</p> </li> <li> <p><code>x</code> (<code>float | complex | array-like</code>): argument(s) (\\(x=m/T\\)).     \u2022 Real inputs are treated as <code>abs(x)</code> (legacy).     \u2022 Complex inputs are accepted for backward compatibility only; see Notes.</p> </li> <li> <p>For \u03b8 based functions (<code>Jf_exact2</code>, <code>Jb_exact2</code>):</p> </li> <li> <p><code>theta</code> (<code>float | array-like</code>): (\\(\\theta=x^2=m^2/T^2\\)) (its real part is used).     May be negative; the implementation splits the domain to keep the integrand real.</p> </li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#returns","title":"Returns","text":"<ul> <li>Scalar if the input is scalar; <code>ndarray</code> with the same shape as the input otherwise.</li> <li>On array inputs, any element that fails to evaluate returns NaN (legacy behavior preserved).</li> </ul>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#notes-apply-to-all","title":"Notes (apply to all)","text":"<ul> <li>Vectorization &amp; semantics. All functions act element-wise on arrays and preserve shapes.</li> <li> <p>Numerical stability. Internally use stable forms:</p> </li> <li> <p><code>log1p</code> / <code>log1p(-exp(-E))</code> for the logs,</p> </li> <li><code>special.expit(-E)</code> for the Fermi factor \\((1/(e^E+1))\\),</li> <li><code>1/np.expm1(E)</code> for the Bose factor \\((1/(e^E-1))\\).</li> <li> <p>Branching / complex inputs.</p> </li> <li> <p>For \u03b8-API (<code>*_exact2</code>): (\\(\\theta\\in\\mathbb{R}\\)). If (\\(\\theta&lt;0\\)) the integral is split at (\\(y=\\sqrt{|\\theta|}\\)) and expressed with (\\(\\cos\\)) / (\\(\\sin\\)), yielding real integrands throughout.</p> </li> <li>For x-API (<code>*_exact</code>): complex (x) triggers the legacy branch splitting (over (\\([0,|x|]\\))) to keep the integrals numerically real/stable.     Physical note: a general complex (x) has no standard physical meaning here; it is supported only for backward compatibility. In physics workflows, (\\(x=m/T\\)) is real (or equivalently (\\(\\theta\\)) is real).</li> <li>Recommended usage. Prefer the \u03b8 based functions (<code>Jf_exact2</code>, <code>Jb_exact2</code>) in new code (better for interpolation/splines and uniformly real integrands). Use x based names for seamless drop in replacement in legacy pipelines.</li> <li>Derivatives. <code>dJf_exact</code>, <code>dJb_exact</code> implement the differentiated kernels:</li> </ul> <p>\\(\\(\\frac{dJ_f}{dx}=\\int_0^\\infty y^2\\frac{x}{E}\\frac{1}{e^E+1}dy\\qquad  \\frac{dJ_b}{dx}=\\int_0^\\infty y^2\\frac{x}{E}\\frac{1}{e^E-1}dy \\quad E=\\sqrt{y^2+x^2}\\)\\)   and return 0 exactly at <code>x==0</code> (removable singularity; evenness in (x)).</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#exact-thermal-integrals-examples","title":"Exact Thermal Integrals \u2014 Examples","text":"<p>This page documents progressive sanity/consistency checks for the exact one-loop thermal integrals and their derivatives:</p> <p>\\(\\(J_b(x)=\\int_0^\\infty y^2\\ln\\bigl(1-e^{-\\sqrt{y^2+x^2}}\\bigr)dy\\quad J_f(x)=\\int_0^\\infty -y^2\\ln\\bigl(1+e^{-\\sqrt{y^2+x^2}}\\bigr)dy\\)\\) We test the public API: <code>Jb_exact</code>, <code>Jf_exact</code>, <code>Jb_exact2</code>, <code>Jf_exact2</code>, <code>dJb_exact</code>, <code>dJf_exact</code>.</p> <p>All figures below are produced by the script <code>tests/finiteT/Exact_Thermal_Integrals.py</code>. see tests/finiteT/Exact_Thermal_Integrals for more</p>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-1-small-x-physics-sanity-constants-at-x0-and-near-zero-behavior","title":"Test 1 \u2014 Small-x physics sanity: constants at (x=0) and near-zero behavior","text":"<p>What it checks</p> <ul> <li>The known limits:</li> <li> <p>\\(\\(J_b(0)=-\\frac{\\pi^4}{45},\\qquad   J_f(0)=-\\frac{7\\pi^4}{360}.\\)\\)</p> </li> <li> <p>For small positive (x), both (J_b) and (J_f) increase toward 0, as mass/temperature (\\(x=m/T\\)) grows.</p> </li> </ul> <p>Figure</p> <ul> <li>Small-x behavior: </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 1: Small-x sanity (x \u2192 0) ===\nJ_b(0): num=-2.164646467421e+00, expected=-2.164646467422e+00, |\u0394|=1.60e-12\nJ_f(0): num=-1.894065658994e+00, expected=-1.894065658994e+00, |\u0394|=6.66e-16\nExpectation: For both bosons and fermions, J(x) starts negative and increases toward 0 as x grows. \nAs we can see in the image above, this expectation is met.\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-2-consistency-jx-vs-jthetax2-for-xge-0","title":"Test 2 \u2014 Consistency: (J(x)) vs (J(\\(\\theta=x^2\\))) for (\\(x\\ge 0\\))","text":"<p>What it checks</p> <ul> <li>Numerical agreement between the x-API (<code>J*_exact</code>) and the \u03b8-API (<code>J*_exact2</code>) when (\\(\\theta=x^2\\)) with (\\(x\\ge 0\\)).</li> <li>Differences should be at quadrature noise level.</li> </ul> <p>Figure</p> <ul> <li>Direct consistency, (J(x)-J(\\(\\theta\\))): </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 2: Consistency J(x) vs J(theta=x^2) (x \u2265 0) ===\nMax |J_b(x) - J_b(theta)| over grid: 0.000e+00\nMax |J_f(x) - J_f(theta)| over grid: 0.000e+00\nExpectation: differences ~ 0 within quadrature noise. \nThis expectation its valid as we can see in the image above\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-2b-negative-theta-branch-and-imaginary-x-cross-check","title":"Test 2b \u2014 Negative-(\\(\\theta\\)) branch and imaginary (x) cross-check","text":"<p>What it checks</p> <ul> <li>For (\\(\\theta&lt;0\\)), compare the \u03b8-API values (J(\\(\\theta=-\\mu^2\\))) with the x-API evaluated at (\\(x=i\\mu\\)) (dashed).   This confirms that our real, piecewise integrands for negative (\\(\\theta\\)) match the legacy branch split for purely imaginary (x).</li> </ul> <p>Figure</p> <ul> <li>(\\(\\theta&lt;0\\)) (solid) vs (\\(x=i\\mu\\)) (dashed): </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 2b: Negative-\u03b8 branch and imaginary-x consistency ===\nMax |J_b(\u03b8&lt;0) - J_b(x=i\u03bc)| over grid: 5.551e-13\nMax |J_f(\u03b8&lt;0) - J_f(x=i\u03bc)| over grid: 5.596e-12\nExpectation: solid and dashed curves overlap within quadrature accuracy.\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-3-derivatives-shape-and-sign-djdx-ge-0-for-xge-0","title":"Test 3 \u2014 Derivatives: shape and sign (\\((dJ/dx \\ge 0)\\) for (\\(x\\ge 0\\)))","text":"<p>What it checks</p> <ul> <li>From the derivative formulas,</li> </ul> <p>\\(\\(\\frac{dJ_f}{dx}=\\int_0^\\infty y^2\\frac{x}{E}\\frac{1}{e^E+1}dy\\qquad   \\frac{dJ_b}{dx}=\\int_0^\\infty y^2\\frac{x}{E}\\frac{1}{e^E-1}dy\\quad E=\\sqrt{y^2+x^2}\\)\\)</p> <p>we expect non negative derivatives for (\\(x\\ge 0\\)). * Plots should show both (\\(dJ_b/dx\\)) and (\\(dJ_f/dx\\)) positive and decreasing toward 0 as (x) increases.</p> <p>Figure</p> <ul> <li>Derivatives vs (x): </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 3: Derivative sign/shape (dJ/dx \u2265 0 for x \u2265 0) ===\nMin dJ_b/dx on grid: 0.000e+00  (expected \u2265 0)\nMin dJ_f/dx on grid: 0.000e+00  (expected \u2265 0)\nExpectation: derivatives are positive (curves move up toward 0). As we can see this is satisfied\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-4-cross-check-djdx-via-finite-difference-gradientfunction-order4","title":"Test 4 \u2014 Cross-check (dJ/dx) via finite-difference <code>gradientFunction</code> (order=4)","text":"<p>What it checks</p> <ul> <li>Independent numerical differentiation (order-4 central differences) reproduces <code>dJ*_exact</code> closely.</li> </ul> <p>Figures</p> <ul> <li> <p>Boson derivative cross-check: </p> </li> <li> <p>Fermion derivative cross-check: </p> </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 4: Cross-check dJ/dx using gradientFunction (order=4) ===\nMax |dJ_b (FD) - dJ_b (exact)|: 1.318e-10\nMax |dJ_f (FD) - dJ_f (exact)|: 1.705e-11\nExpectation: order-4 finite differences should track the exact derivative closely (small max absolute error).\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-5a-global-trend-x-from-0-to-large-approach-to-0","title":"Test 5A \u2014 Global trend: (x) from 0 to large (approach to 0)","text":"<p>What it checks</p> <ul> <li>Over a wide range (\\(x\\in[0,10]\\)), both (\\(J_b\\)) and (\\(J_f\\)) approach 0 as (x) grows (heavier mass over temperature).</li> <li>The plot includes a (y=0) reference line.</li> </ul> <p>Figure</p> <ul> <li>Global trend with (y=0) guide: </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 5A: Global trend (x from 0 to large) with y=0 reference ===\nExpectation: as x increases (heavier over T), both J_b and J_f approach 0 exponentially.\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-5b-large-x-tails-semilog-and-bessel-proxy-x2-k_2x","title":"Test 5B \u2014 Large-(x) tails (semilog) and Bessel proxy \\((x^2 K_2(x))\\)","text":"<p>What it checks</p> <ul> <li>On a semilog scale, (|J|) decays roughly like \\((\\exp(-x))\\).</li> <li>The empirical proxy \\((-x^2 K_2(x))\\) captures the qualitative tail behavior.</li> </ul> <p>Figures</p> <ul> <li> <p>Semilog magnitudes: </p> </li> <li> <p>Tail ratio vs proxy: </p> </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n=== Test 5B: Large-x tail (semilog plots) ===\nTail check (medians):\n median[ J_b / ( -x^2 K2 ) ] = 1.000\n median[ J_f / ( -x^2 K2 ) ] = 1.000\nExpectation: both |J| decay ~exp(-x); the Bessel proxy captures the trend qualitatively.\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#test-6-physical-illustration-thermal-piece-v_tpropto-sum_i-n_ij_pmm_it","title":"Test 6 \u2014 Physical illustration: thermal piece \\((V_T\\propto \\sum_i n_i,J_{\\pm}(m_i/T))\\)","text":"<p>What it checks</p> <ul> <li>With illustrative degeneracies (n_b, n_f) and (T=1), thermal contributions built from (\\(J_b\\)) and (\\(J_f\\)) are largest near (x=0) and vanish for (\\(x\\gg 1\\)).</li> </ul> <p>Figure</p> <ul> <li>Illustrative thermal potential piece: </li> </ul> <p>Console output</p> <pre><code>\"\"\"\n# For illustration only (not a strict unit test):\nT = 1.0  # set T=1 to focus on x=m/T\ndeg_b, deg_f = 2.0, 4.0  # example degeneracies\nx_phys = np.linspace(0.0, 10.0, 160)\nVb = (T**4 / (2*np.pi**2)) * deg_b * Jb_exact(x_phys)\nVf = (T**4 / (2*np.pi**2)) * deg_f * Jf_exact(x_phys).real\n\n=== Test 6: Thermal contribution V_T \u221d J(x) with x = m/T ===\nExpectation: contributions are largest near x\u22480 and vanish exponentially for x\u226b1.\n---------- END OF TESTS: Exact Thermal Integrals ----------\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Exact_Thermal_Integrals/#reproducibility-notes","title":"Reproducibility notes","text":"<ul> <li>Quadrature tolerances used internally: <code>epsabs=1e-10</code>, <code>epsrel=1e-8</code>, <code>limit=200</code>.</li> <li>Small differences across machines/BLAS/SciPy versions are expected at the \\((10^{-9})\\)-\\((10^{-7})\\) level in these tests.</li> </ul>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/","title":"Short Hand for All Thermal Integrals","text":"<p># Dispatcher Helpers \u2014 <code>Jb</code> and <code>Jf</code> Short Hands</p>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#purpose","title":"Purpose","text":"<p>Thin, user friendly wrappers that dispatch to the implementations of the Jb &amp; Jf modernized:</p> <ul> <li><code>exact</code> (numerical quadrature),</li> <li><code>low</code> (small-(x), high-T series),</li> <li><code>high</code> (large-(x), low-T Bessel-(K) sum),</li> <li><code>spline</code> (cubic spline in (\\(\\theta=x^2\\)), allowing (\\(\\theta&lt;0\\))).</li> </ul> <p>They preserve the legacy API and defaults, validate inputs consistently, and keep scalar-in \u2192 scalar-out behavior (vectorized over arrays).</p>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#signatures","title":"Signatures","text":"<pre><code>Jb(x, approx: str = \"high\", deriv: int = 0, n: int = 8) -&gt; float | np.ndarray\nJf(x, approx: str = \"high\", deriv: int = 0, n: int = 8)  -&gt; float | complex | np.ndarray\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#parameters-common","title":"Parameters (common)","text":"<ul> <li><code>x</code> (<code>float | array-like</code>):   For <code>approx in {\"exact\",\"low\",\"high\"}</code> this is the usual real (x=m/T).   For <code>approx==\"spline\"</code>, <code>x</code> is (\\(\\theta = (m/T)^2\\)) (can be negative; legacy behavior).</li> <li><code>approx</code> (<code>\"exact\"|\"high\"|\"low\"|\"spline\"</code>): Which evaluator to use (default <code>\"high\"</code>).</li> <li><code>deriv</code> (<code>int</code>): Derivative order \u2014 allowed per mode:   <code>exact</code>: 0 or 1 \u2022 <code>low</code>: 0 \u2022 <code>high</code>: 0..3 \u2022 <code>spline</code>: 0..3.</li> <li><code>n</code> (<code>int</code>): Truncation \u2014 used only in series/sum modes:   <code>low</code>: number of tail terms (\u2264 50) \u2022 <code>high</code>: number of Bessel-sum terms.</li> </ul>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#returns","title":"Returns","text":"<ul> <li><code>Jb</code>: <code>float | ndarray</code></li> <li><code>Jf</code>: <code>float | complex | ndarray</code> (in <code>exact</code> mode, legacy complex dtype is preserved; use <code>.real</code> if you only need the physical value for real (x)).</li> </ul>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#notes","title":"Notes","text":"<ul> <li>Spline mode uses (\\(\\theta\\)), not (x), by design. This allows (\\(\\theta&lt;0\\)) (tachyonic curvature) and matches the legacy spline tables.</li> <li>Complex (x) has no physical meaning here and is not supported by these wrappers; if you truly need complex analysis, call the exact scalar routines directly.</li> <li>Validation mirrors each backend\u2019s capability (<code>low</code> supports values only; <code>high</code> supports up to 3rd derivative; etc.).</li> </ul>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#see-also-all-details","title":"See also (all details)","text":"<ul> <li>Exact integrals and derivatives: Exact Thermal Integrals (J_b, J_f)</li> <li>Spline construction &amp; use: Spline Thermal Integrals (J_b, J_f)</li> <li>Low-(x) (high-T) series: Approx \u2014 Low-x Series</li> <li>High-(x) (low-T) series: Approx \u2014 High-x Series</li> </ul>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#tests-jb-jf-all-plots","title":"Tests (<code>Jb</code>, <code>Jf</code>) - All plots","text":""},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-a-exact-j_b-j_f-on-010","title":"Test A \u2014 Exact (\\(J_b\\), \\(J_f\\)) on (\\([0,10]\\))","text":"<p>What it checks: Baseline curves from numerical quadrature; values at (x=0) match \\((J_b(0)=-\\pi^4/45)\\) and \\((J_f(0)=-7\\pi^4/360)\\). Expectation: Both start negative and monotonically approach 0 as (x) grows.</p> <p>Figure </p> <p>Console output</p> <pre><code>=== Test A: exact J_b, J_f on [0,10] ===\nAt x=0: J_b=-2.164646467421e+00, J_f=-1.894065658994e+00.\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-b-spline-j_b-j_f-on-010-with-thetax2","title":"Test B \u2014 Spline (\\(J_b\\), \\(J_f\\)) on ([0,10]) with (\\(\\theta=x^2\\))","text":"<p>What it checks: Spline evaluation agrees with exact on the same (x)-grid (using (\\(\\theta=x^2\\))). Expectation: Small max relative differences, consistent with spline accuracy.</p> <p>Figure </p> <p>Console output</p> <pre><code>=== Test B: spline J_b, J_f on [0,10] (\u03b8 = x^2) ===\nMax relative diff spline vs exact on [0,10]:  J_b: 5.564e-04,  J_f: 2.479e-05\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-c-exact-first-derivatives-mathrm-djmathrm-dx-on-010","title":"Test C \u2014 Exact first derivatives \\((\\mathrm dJ/\\mathrm dx)\\) on ([0,10])","text":"<p>What it checks: Direct quadrature of (dJ/dx). Expectation: (dJ/dx) is (0) at (x=0) (removable singularity handled), positive for (x&gt;0), and decays with (x).</p> <p>Figure </p> <p>Console output</p> <pre><code>=== Test C: exact derivatives dJ/dx on [0,10] ===\ndJ_b/dx at x=0: 0.000e+00 (expected 0);  dJ_f/dx at x=0: 0.000e+00 (expected 0)\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-d-spline-first-derivative-mapped-to-x-via-chain-rule","title":"Test D \u2014 Spline first derivative mapped to (x) via chain rule","text":"<p>What it checks: Spline derivatives (computed in \\((\\theta))\\) correctly mapped to (x): \\((\\frac{dJ}{dx} = 2x,\\frac{dJ}{d\\theta})\\). Expectation: Close agreement with exact (dJ/dx).</p> <p>Figure </p> <p>Console output</p> <pre><code>=== Test D: spline first derivative (chain rule to dJ/dx) on [0,10] ===\nMax relative diff (spline\u2192x) vs exact dJ/dx:  J_b: 3.758e-02,  J_f: 2.851e-03\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-e-spline-second-derivative-mapped-to-x","title":"Test E \u2014 Spline second derivative mapped to (x)","text":"<p>What it checks: Chain rule for the second derivative:</p> \\[\\frac{d^2J}{dx^2} = 2,\\frac{dJ}{d\\theta} + 4x^2\\frac{d^2J}{d\\theta^2}\\] <p>Expectation: Smooth, sensible curvature; finite at (x=0).</p> <p>Figure </p>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-f-low-x-series-vs-exact-with-relative-error","title":"Test F \u2014 Low-(x) series vs exact (with relative error)","text":"<p>What it checks: High-T (small (x)) series accuracy windows.</p> <p>Ranges: (\\(J_b\\)) on ([0,7]), (J_f) on ([0,3.7]).</p> <p>Expectation: Low relative error in these windows; error grows as (x) leaves the intended regime.</p> <p>Figures</p> <ul> <li>Boson: series vs exact \u2014 </li> <li>Boson: relative error \u2014 </li> <li>Fermion: series vs exact \u2014 </li> <li>Fermion: relative error \u2014 </li> </ul> <p>Console output</p> <pre><code>=== Test F: low-x series vs exact (with relative error) ===\nBoson low-x: max rel err = 1.183e+02\nFermion low-x: max rel err = 1.422e+01\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#test-g-high-x-series-vs-exact-on-110-with-relative-error","title":"Test G \u2014 High-(x) series vs exact on ([1,10]) (with relative error)","text":"<p>What it checks: Low-T (large (x)) Bessel-sum accuracy. Expectation: Semilog plot shows exponential tails; series tracks exact well with modest (n) (here (n=8)).</p> <p>Figures</p> <ul> <li>Semilog magnitude \u2014 </li> <li>Relative error \u2014 </li> </ul> <p>Console output</p> <pre><code>=== Test G: high-x series vs exact (x in [1,10]) ===\nHigh-x: max rel err  J_b: 6.351e-07,  J_f: 3.878e-07\n\n---------- END OF TESTS: Dispatcher (Jb, Jf) ----------\n</code></pre>"},{"location":"modules/finiteT/Short_Hand_Jb%26Jf/#notes_1","title":"Notes","text":"<ul> <li>Spline mode input: remember that the dispatcher expects (\\theta=x^2) as input in <code>\"spline\"</code> mode; chain rule conversions are used for derivatives in (x).</li> <li>Relative error definition: (\\(\\mathrm{rel}=\\frac{|A-B|}{\\max(|B|,10^{-12})}\\)).</li> <li>For quicker runs, reduce grid sizes or narrow (x)-ranges during development.</li> <li>see tests/finiteT/Short_Hand for more</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/","title":"Spline Thermal Integrals (Jb, Jf)","text":"<p>The advantage of these functions is that, after creating a spline from the exact function's placement points,  we can quickly obtain a value for any desired point x on the curve without having to go through the integration process directly required by the exact method. Furthermore, we can expect good compatibility between the values. This is one of the spline's main uses.</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#spline-thermal-integrals-j_f","title":"Spline Thermal Integrals (J_f)","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#purpose","title":"Purpose","text":"<p>Provide a fast, differentiable surrogate for the exact fermionic thermal integral</p> \\[J_f(\\theta)\\equiv J_f\\bigl(x^2\\bigr)\\quad \\theta=(m/T)^2\\in\\mathbb{R}\\] <p>by fitting a cubic B-spline to samples of the exact function \\((J_f(\\theta))\\) on a non-uniform grid. The spline preserves the legacy API/behavior:</p> <ul> <li>Input is (\\(\\theta=x^2\\)) (not (x)); (\\(\\theta\\)) can be negative (imaginary (x) branch).</li> <li>For (\\(\\theta &lt; \\theta_{\\min}\\)): returns the clamped value \\((J_f(\\theta_{\\min}))\\).</li> <li>For (\\(\\theta &gt; \\theta_{\\max}\\)): returns 0 (and its derivatives 0), matching the physical larg -mass suppression in the legacy code.</li> <li>Supports derivatives w.r.t. (\\(\\theta\\)) via <code>n</code> (uses <code>BSpline.derivative(n)</code>).</li> </ul> <p>Domain used: (\\(\\theta_{\\min} = -6.82200203,\\quad \\theta_{\\max} = 1.35\\times 10^3.\\))</p> <p>Notes: * The spline is built from <code>Jf_exact2(theta)</code> (exact quadrature) and cached to disk for reproducibility/speed. * Physically meaningful inputs here are real (\\(\\theta\\)). A complex and real (x) (thus complex (\\(\\theta\\))) has no direct meaning in this spline API\u2014use the exact routines if you need analytic continuation details.</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#jf_spline","title":"<code>Jf_spline</code>","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#signature","title":"Signature","text":"<pre><code>Jf_spline(X: float | np.ndarray, n: int = 0) -&gt; float | np.ndarray\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#parameters","title":"Parameters","text":"<ul> <li><code>X</code> (<code>float | array_like</code>): Input theta values (\\(\\theta=(m/T)^2\\)). Scalar-in \u2192 scalar-out.</li> <li><code>n</code> (<code>int</code>, default <code>0</code>): Derivative order w.r.t. (\\theta) (0 for the function value, 1 for first derivative, etc).</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#returns","title":"Returns","text":"<ul> <li> <p><code>out</code> (<code>float | ndarray</code>): \\((J_f(\\theta))\\) (or its (n)-th (\\(\\theta\\))-derivative) evaluated by the spline.   Behavior outside the fit domain:</p> </li> <li> <p>If (\\(\\theta &lt; \\theta_{\\min}\\)): returns the constant value at \\((\\theta_{\\min})\\).</p> </li> <li>If (\\(\\theta &gt; \\theta_{\\max}\\)): returns 0.0 (derivatives also 0.0), per legacy behavior.</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#notes","title":"Notes","text":"<ul> <li>Backend: <code>scipy.interpolate.BSpline</code> (created via <code>make_interp_spline(..., k=3)</code>).</li> <li>The grid is denser near (\\(\\theta\\le 0\\)) and small positive (\\(\\theta\\)), and sparser on the large-(\\(\\theta\\)) tail.</li> <li>Accuracy is typically at the few \u00d7 \\(10^{-6}\u201310^{-8}\\) level relative to the exact integral over the intended domain (depends on the internal grid sizes).</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#_ensure_jf_spline","title":"<code>_ensure_Jf_spline</code>","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#signature_1","title":"Signature","text":"<pre><code>_ensure_Jf_spline() -&gt; scipy.interpolate.BSpline\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#purpose_1","title":"Purpose","text":"<p>Construct (once) and return the global <code>BSpline</code> object for \\((J_f(\\theta))\\). First tries to load a cached spline; if not found, it builds the dataset with <code>Jf_exact2()</code>, fits a cubic spline, and saves the spline parameters to disk.</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#notes_1","title":"Notes","text":"<ul> <li>The cache file (by default) is <code>Jf_spline_v1.npz</code>, containing the knot vector <code>t</code>, coefficients <code>c</code>, and degree <code>k</code>.</li> <li>If the directory is read-only, the code silently skips saving (still works in-memory).</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#_build_jf_dataset","title":"<code>_build_Jf_dataset</code>","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#signature_2","title":"Signature","text":"<pre><code>_build_Jf_dataset(n_neg: int = 420, n_pos_lin: int = 380, n_pos_log: int = 300) -&gt; tuple[np.ndarray, np.ndarray]\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#purpose_2","title":"Purpose","text":"<p>Generate a non-uniform theta grid and its exact values \\((J_f(\\theta))\\) used to fit the spline.</p> <ul> <li>Negative branch: linear grid on (\\([\\theta_{\\min}, 0]\\)) (dense).</li> <li>Positive small: linear grid on (\\([0, 50]\\)).</li> <li>Positive tail: log grid on \\((50, \\theta_{\\max}])\\).</li> </ul> <p>Returns <code>(theta, y)</code> with <code>y = Jf_exact2(theta)</code>.</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#_load_jf_cache-_save_jf_cache","title":"<code>_load_Jf_cache</code> / <code>_save_Jf_cache</code>","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#signatures","title":"Signatures","text":"<pre><code>_load_Jf_cache() -&gt; None | tuple[np.ndarray, np.ndarray, int]\n_save_Jf_cache(theta: np.ndarray, coeffs: np.ndarray, t: np.ndarray, k: int) -&gt; None\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#purpose-brief","title":"Purpose (brief)","text":"<ul> <li><code>_load_Jf_cache</code>: try to load a previously saved spline <code>(t, c, k)</code>. Returns <code>None</code> if not available.</li> <li><code>_save_Jf_cache</code>: best-effort save of spline parameters to disk so subsequent runs are instantaneous.</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#reproducibility-performance","title":"Reproducibility &amp; Performance","text":"<ul> <li>The spline is deterministic given the internal grid sizes and the exact integrator tolerances (in <code>Jf_exact2</code>).</li> <li>First build takes ~seconds (quadrature over a few hundred points), thereafter ~milliseconds per call thanks to evaluation of a cubic B-spline (and its derivatives).</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#spline-thermal-integrals-j_b","title":"Spline Thermal Integrals (J_b)","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#purpose_3","title":"Purpose","text":"<p>Provide a fast, differentiable surrogate for the exact bosonic thermal integral \\((J_b(\\theta) \\equiv J_b(x^2))\\) with (\\(\\theta=(m/T)^2\\in\\mathbb{R}\\)), by fitting a cubic B-spline to samples of the exact function \\((J_b(\\theta))\\) on a non-uniform grid. The spline preserves the legacy API/behavior:</p> <ul> <li>Input is (\\(\\theta=x^2\\)) (not (x)); (\\(\\theta\\)) may be negative (imaginary-mass branch handled via the exact routine during fitting).</li> <li>For (\\(\\theta &lt; \\theta_{\\min}\\)): return the clamped value \\((J_b(\\theta_{\\min}))\\).</li> <li>For (\\(\\theta &gt; \\theta_{\\max}\\)): return 0.0 (and derivatives 0.0), matching the legacy tail suppression.</li> <li>Support derivatives w.r.t. \\((\\theta)\\) via parameter <code>n</code> (uses <code>BSpline.derivative(n)</code>).</li> </ul> <p>Domain used (legacy-compatible): (\\(\\displaystyle \\theta_{\\min} = -3.72402637,\\qquad \\theta_{\\max} = 1.41\\times 10^3.\\))</p> <p>Physically meaningful inputs here are real (\\(\\theta\\)). Complex (x) (thus complex (\\(\\theta\\))) is not used in this spline API; for analytic-continuation details use the exact routines.</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#jb_spline","title":"<code>Jb_spline</code>","text":""},{"location":"modules/finiteT/Spline_Thermal_Integrals/#signature_3","title":"Signature","text":"<pre><code>Jb_spline(X: float | np.ndarray, n: int = 0) -&gt; float | np.ndarray\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#parameters_1","title":"Parameters","text":"<ul> <li><code>X</code> (<code>float | array_like</code>): Input theta values (\\(\\theta=(m/T)^2\\)). Scalar-in \u2192 scalar-out.</li> <li><code>n</code> (<code>int</code>, default <code>0</code>): Derivative order w.r.t. \\((\\theta)\\) (0 for the function value, 1 for first derivative, etc.).</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#returns_1","title":"Returns","text":"<ul> <li> <p><code>out</code> (<code>float | ndarray</code>): \\((J_b(\\theta))\\) (or its (n)-th (\\(\\theta\\))-derivative) evaluated by the spline.   Outside the fitted domain:</p> </li> <li> <p>If (\\(\\theta &lt; \\theta_{\\min}\\)): returns the constant value at (\\(\\theta_{\\min}\\)).</p> </li> <li>If (\\(\\theta &gt; \\theta_{\\max}\\)): returns 0.0 (derivatives also 0.0), per legacy behavior.</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#notes_2","title":"Notes","text":"<ul> <li>Backend: <code>scipy.interpolate.BSpline</code> (created via <code>make_interp_spline(..., k=3)</code>).</li> <li>The grid used for fitting is denser near (\\(\\theta\\le 0\\)) and small positive (\\(\\theta\\)), and sparser on the large-(\\(\\theta\\)) tail.</li> <li>Choice of (\\(\\theta_{\\min}\\)) coincides with the minimum of (\\(J_b\\)), so the clamp at the left boundary plus the vanishing right tail makes the evaluated curve monotonic increasing and (\\(C^1\\))-continuous (matching the legacy intent).</li> </ul>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#spline-construction-caching-same-pattern-as-jf_spline","title":"Spline construction &amp; caching (same pattern as Jf_spline)","text":"<p>The internal helpers follow the same design as for <code>Jf_spline</code>:</p> <ul> <li>Dataset build: generate a non-uniform \\((\\theta)\\) grid   (linear on (\\([\\theta_{\\min},0]\\)), linear on (\\([0,50]\\)), logarithmic on \\(((50,\\theta_{\\max}]))\\) and compute ground-truth values via <code>Jb_exact2(theta)</code>.   (Function: <code>_build_Jb_dataset</code>.)</li> <li>Spline fit: build a cubic interpolating spline (<code>make_interp_spline</code>) with <code>extrapolate=False</code>.   (Created inside <code>_ensure_Jb_spline</code>.)</li> <li>Caching: first try to load a cached spline <code>(t, c, k)</code> from   <code>Jb_spline_v1.npz</code> under <code>spline_data_path</code>; if not present, fit and then save best-effort.   (Functions: <code>_load_Jb_cache</code>, <code>_save_Jb_cache</code>, called by <code>_ensure_Jb_spline</code>.)</li> </ul> <p>Performance: first build takes seconds (due to exact quadrature at a few hundred (\\theta) nodes); subsequent runs are milliseconds (BSpline evaluation).</p> <p>Reproducibility: the cache pins the fitted spline; if the directory is read-only, the code still works (keeps the spline in memory).</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#spline-thermal-integrals-j_b-j_f-tests","title":"Spline Thermal Integrals (\\(J_b, J_f\\)) \u2014 Tests","text":"<p>This page documents the verification suite for the Spline Thermal Integrals. We validate that the spline surrogates <code>Jb_spline(\u03b8)</code> and <code>Jf_spline(\u03b8)</code> (with \\((\\theta=x^2=(m/T)^2)\\) ) reproduce the exact one-loop integrals and their \u03b8-derivatives,  and that the spline implementation is consistent with the B-spline basis from <code>helper_functions.Nbspl</code>.</p> <p>Plot styling used below</p> <ul> <li>Solid: exact curve (as a function of (x), with (\\(\u03b8=x^2\\))).</li> <li>Dashed: spline curve.</li> <li>Dots: collocation nodes (subset with (\\(x\\le 10\\))) used to fit the spline.</li> <li>see tests/finiteT/Spline_Thermal_Integrals for more</li> </ul> <p>We also print simple error metrics for quick checks.</p>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#test-1-spline-vs-exact-for-xin010","title":"Test 1 \u2014 Spline vs exact for (\\(x\\in[0,10]\\))","text":"<p>Compare <code>Jb_spline(\u03b8=x^2)</code> and <code>Jf_spline(\u03b8=x^2)</code> against <code>Jb_exact(x)</code> and <code>Jf_exact(x)</code> on the same (x)-grid.</p> <p>Expectation: curves overlap within quadrature/spline noise; max absolute error across the grid should be small.</p> <p>Boson \\((J_b)\\): exact vs spline (with nodes)</p> <p></p> <p>Fermion \\((J_f)\\): exact vs spline (with nodes)</p> <p></p> <pre><code>\"\"\"\n=== Test 1: Spline vs Exact for x \u2208 [0, 10] ===\nMax |J_b (spline) - J_b (exact)| over x\u2208[0,10]: 1.180e-03\nMax |J_f (spline) - J_f (exact)| over x\u2208[0,10]: 4.638e-05\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#test-2-derivatives-partial-jpartial-spline-vs-exact-via-chain-rule","title":"Test 2 \u2014 Derivatives: ( $\\partial J/\\partial \u03b8 $) (spline) vs exact via chain rule","text":"<p>The spline returns derivatives with respect to (\u03b8). We compare against the exact derivative with respect to (x) using the chain rule:</p> \\[\\frac{\\partial J}{\\partial \u03b8} = \\frac{\\partial J}{\\partial x}\\frac{\\partial x}{\\partial \u03b8} =  \\frac{1}{2\\sqrt{\u03b8}},\\frac{\\partial J}{\\partial x} \\quad(\\text{with } x=\\sqrt{\u03b8} \u03b8&gt;0)\\] <p>We avoid (x=0) (singularity in (1/(2x))) and take (\\(x\\in(10^{-3},10]\\)).</p> <p>Expectation: close agreement; small deviations can appear near the very small-(x) end where the chain rule magnifies numerical noise.</p> <p>Boson (\\(dJ_b/d\u03b8\\)): exact vs spline (with nodes)</p> <p></p> <p>Fermion (\\(dJ_f\\)/d\u03b8): exact vs spline (with nodes)</p> <p></p> <pre><code>\"\"\"\n=== Test 2: Derivatives \u2014 spline dJ/dtheta vs exact (chain rule) ===\nMax |dJ_b/d\u03b8 (spline) - dJ_b/d\u03b8 (exact)| over x\u2208(1e-3,10]: 3.156e-02\nMax |dJ_f/d\u03b8 (spline) - dJ_f/d\u03b8 (exact)| over x\u2208(1e-3,10]: 1.240e-03\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#test-3-compatibility-with-helper_functionsnbspl","title":"Test 3 \u2014 Compatibility with <code>helper_functions.Nbspl</code>","text":"<p>We reconstruct the spline value using the B-spline basis:</p> \\[s(\u03b8) = \\sum_i c_i,N_{i,k}(\u03b8)\\] <p>where (t) (knots), (c) (coefficients) and (k) (degree) come from the fitted <code>BSpline</code>. We evaluate <code>Nbspl(t, \u03b8, k) @ c</code> and compare to the direct <code>J*_spline(\u03b8)</code> evaluation for (\\(\u03b8\\in[0,100]\\)).</p> <p>Expectation: the two evaluations should match to near machine precision.</p> <p>Boson (\\(J_b\\)): BSpline vs Nbspl reconstruction</p> <p></p> <p>Fermion (\\(J_f\\)): BSpline vs Nbspl reconstruction</p> <p></p> <pre><code>\"\"\"\n=== Test 3: Compatibility with helper_functions.Nbspl ===\nMax |J_f (spline) - J_f (Nbspl rebuild)| on \u03b8\u2208[0,100]: 4.441e-16\nMax |J_b (spline) - J_b (Nbspl rebuild)| on \u03b8\u2208[0,100]: 2.220e-16\n\"\"\"\n</code></pre>"},{"location":"modules/finiteT/Spline_Thermal_Integrals/#notes-plotting-details","title":"Notes &amp; plotting details","text":"<ul> <li>Input to the splines is always (\\(\u03b8=x^2\\)). For Tests 1\u20132, we limit the x-axis to ([0,10]) and filter the node dots to (\\(x\\le 10\\)) to avoid automatic axis expansion by far-right collocation nodes (which can reach (\\(x\\sim\\sqrt{\u03b8_{\\max}}\\))).</li> <li>Left boundary handling is clamp at (\\(\u03b8_{\\min}\\)); right boundary is zero for (\\(\u03b8&gt;\u03b8_{\\max}\\)), matching the legacy API (this is visible only if you probe beyond the fitted domain).</li> <li><code>Jf_exact(x)</code> returns complex (legacy); in the plots we show its real part, which is the physically relevant branch for real (x).</li> </ul>"},{"location":"modules/helper_functions/Miscellaneous_functions/","title":"Miscellaneous functions","text":""},{"location":"modules/helper_functions/Miscellaneous_functions/#set_default_args","title":"<code>set_default_args</code>","text":""},{"location":"modules/helper_functions/Miscellaneous_functions/#signature","title":"Signature","text":"<pre><code>set_default_args(func: Callable, inplace: bool = True, **kwargs) -&gt; Callable\n</code></pre>"},{"location":"modules/helper_functions/Miscellaneous_functions/#purpose","title":"Purpose","text":"<p>Update the default values of a function\u2019s parameters without changing its external behavior for explicit arguments. This is handy when a top-level API calls deeply nested functions but you want to tweak defaults of those inner functions without touching every call site. When placing the desired function you can create a new one (wrapper) or keep the existing one with the new default parameters.</p> <p>\u26a0\ufe0f Unlike <code>functools.partial</code>, this does not bind/force arguments at call time; it only changes what the function uses when an argument is omitted by the caller.</p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#parameters-returns-and-raises","title":"Parameters, returns and Raises","text":"<p>Parameters - func: the function (or unbound method) whose defaults will be updated.</p> <ul> <li>inplace:</li> <li> <p>True \u2014 mutate func in place by editing defaults (positional/positional-or-keyword) and kwdefaults (keyword-only).</p> </li> <li> <p>False \u2014 return a wrapper that applies the new defaults but leaves the original func untouched; the wrapper\u2019s signature is updated to show the new defaults.</p> </li> <li> <p>**kwargs: mapping of parameter_name=new_default_value.</p> </li> </ul> <p>Returns - If inplace=True: the same (possibly bound) object you passed (so existing references still work).</p> <ul> <li>If inplace=False: a new callable wrapper with updated signature.</li> </ul>"},{"location":"modules/helper_functions/Miscellaneous_functions/#raises","title":"Raises","text":"<ul> <li> <p>TypeError if func is not callable.</p> </li> <li> <p>ValueError if a passed name does not exist in func\u2019s signature.</p> </li> <li> <p>ValueError if a passed name exists but does not have a default (you cannot create a default where none exists).</p> </li> <li> <p>ValueError if you try to target args or *kwargs (variadics have no defaults).</p> </li> </ul>"},{"location":"modules/helper_functions/Miscellaneous_functions/#when-to-use-and-examples","title":"When to use and Examples","text":"<p>Use when you control a pipeline with deep calls and want different defaults globally for a nested function. Or when you want to expose a variant of a function with new defaults while keeping the original intact (use inplace=False).</p> <p>see tests/helper_functions/Miscellaneouys for more Examples <pre><code># 1) Positional + keyword-only defaults (in-place)\ndef f(a, b=2, c=3, *, d=4):\n    return a, b, c, d\n\nprint(f(10))           # -&gt; (10, 2, 3, 4)\n\n# Mutate the original defaults\nset_default_args(f, b=20, d=40)\n\nprint(f(10))           # -&gt; (10, 20, 3, 40)\n\n#2) Non in-place: return a wrapper with update defaults\ndef g(a, b=2, c=3, *, d=4):\n    return a, b, c, d\n\ng2 = set_default_args(g, inplace=False, b=99, d=111)\n\nprint(g(1))            # -&gt; (1, 2, 3, 4)   (original unchanged)\nprint(g2(1))           # -&gt; (1, 99, 3, 111) (wrapper uses new defaults)\n\n#3) Exapected errors (bad names / no default present)\ndef h(a, b, c=3):\n    return a, b, c\n\ntry:\n    set_default_args(h, x=1)          # No parameter `x` in `h`\nexcept ValueError as e:\n    print(\"Error:\", e)\n\ntry:\n    set_default_args(h, b=10)         # `b` exists but has NO default in the signature\nexcept ValueError as e:\n    print(\"Error:\", e)\n####################################\n</code></pre></p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#monotonic_indices","title":"<code>monotonic_indices</code>","text":""},{"location":"modules/helper_functions/Miscellaneous_functions/#signature_1","title":"Signature","text":"<pre><code>monotonic_indices(x: array_like) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Miscellaneous_functions/#purpose_1","title":"Purpose","text":"<p>Return the indices of a strictly increasing subsequence of x, always including the first and last elements. This is useful to \"repair\" a nearly-monotonic grid(e.g., a few spurious downward spikes) without sorting or regridding\u2014a common need before calling routines that require  strictly increasing coordinates (e.g., numerical differentiation or interpolation).  This function removes non-increasing points between the start and end of the array</p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#parameters-returns-and-raises_1","title":"Parameters, returns and Raises","text":"<p>Parameters - <code>x</code>: (array_like): Input 1D sequence (Numpy array).</p> <p>Returns - <code>np.ndaary</code> of shape (m,): Indices I such that <code>x[I]</code> is strictly increasing and <code>I[0]==0</code>, <code>I[-1]==len(x)-1</code> if x is increasing and the opposite if x is decreasing</p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#raises-assumptions","title":"Raises / Assumptions","text":"<ul> <li>If the overall trend is decreasing (<code>x[0] &gt; x[-1]</code>), the function works by reversing internally and then mapping the indices back</li> <li>assumes <code>len(x)&gt;=1</code> and that x is a ndarray.</li> </ul>"},{"location":"modules/helper_functions/Miscellaneous_functions/#when-to-use-and-examples_1","title":"When to use and Examples","text":"<ul> <li>Before calling finite difference derivatives which require strictly monotonic coordinate arrays.</li> <li>Before interpolation on grids that should be increasing but contain small gliches</li> <li>To quickly visualize or compute on a clean, mnotone subset of a noise 1D grid withoud sorting or re-sampling</li> </ul> <p>see the full test script in tests/helper_functions/Miscellaneouys for more</p> <p>Examples <pre><code># 1) Clean a mostly-increasing sequence with one bad spike\nx = [1, 2, 3, -1, 20, 19, 50]  # overall increasing, but has local decreases\nidx = monotonic_indices(x)\nx_clean = [x[i] for i in idx]\nprint(idx)      # e.g., [0, 1, 2, 4, 6]\nprint(x_clean)  #     -&gt; [1, 2, 3, 20, 50]  (strictly increasing, kept endpoints)\n\n# 3) Pre-conditioning before derivatives (deriv14, deriv23, deriv1n)\n# Suppose x is supposed to be increasing, but isn\u2019t strictly so due to noise.\nx = np.array([0.0, 0.1, 0.21, 0.20, 0.4, 0.5])  # small non-monotonic blip at 0.21 -&gt; 0.20\ny = np.sin(x)\n\nidx = monotonic_indices(x)\nx_mono = x[idx]\ny_mono = y[idx]\n# Now x_mono is strictly increasing and safe for derivative/interpolation routines.\n####################################\n</code></pre></p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#clamp_val","title":"<code>clamp_val</code>","text":""},{"location":"modules/helper_functions/Miscellaneous_functions/#signature_2","title":"Signature","text":"<pre><code>clamp_val(x: np.array, a: int, b: int) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Miscellaneous_functions/#purpose_2","title":"Purpose","text":"<p>Force (or \"clip\") all values of <code>x</code> to lie inside the closed interval <code>[min(a,b), max[a,b]]</code> This is useful to eliminate non-physical or unstable values (e.g., negative densities, probabilites outside <code>[0,1]</code>, or arguments to <code>log/sqrt</code> that must stay positive)</p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#parameters-returns-and-raises_2","title":"Parameters, returns and Raises","text":"<p>Parameters - <code>x</code> (array_like): Values to clamp. Any shape; will be returned as a NumPy array - <code>a,b</code>(int or array): Lower and upper bounds. Can be a scalar or a array. Bounds can be given in any order</p> <p>Returns - <code>np.ndaary</code>: Array with the same shape as <code>x</code>, where every entry is clipped to <code>[a,b]</code> interval. </p>"},{"location":"modules/helper_functions/Miscellaneous_functions/#raises_1","title":"Raises","text":"<ul> <li>No custom exceptions.</li> </ul>"},{"location":"modules/helper_functions/Miscellaneous_functions/#when-to-use-and-examples_2","title":"When to use and Examples","text":"<ul> <li>When you want to enforce physical constraints, like negative densities, probabilites outside <code>[0,1]</code>, or arguments to <code>log/sqrt</code> that must stay positive</li> <li>To avoid numerical pathologies in interative algorithms</li> <li>Sanitizing imputs for pltting or interpolation routines</li> </ul> <p>see the full test script in tests/helper_functions/Miscellaneouys for more</p> <p>Examples <pre><code># 1) Simple clamping with scalar bounds\nx = [1, 2, 3, -1, 20, 19, 50]\ny = clamp_val(x, a=1, b=20)\nprint(y)  # -&gt; [ 1  2  3  1 20 19 20]\n\n# 3) Array bounds with broadcasting (per-column limits)\nX = np.array([[ -5.0, 0.2,  9.0],\n              [  0.5, 2.5, 11.0]])\nlow  = np.array([0.0, 0.0,  1.0])   # shape (3,)\nhigh = np.array([1.0, 2.0, 10.0])   # shape (3,)\nprint(clamp_val(X, low, high))\n# -&gt; [[0.  0.2 9. ]\n#     [0.5 2.  10.]]\n\n# 4) Prevent non-physical negatives before a sqrt\ndata = np.array([1e-6, -1e-8, 4.0])\nsafe = clamp_val(data, 0.0, np.inf)\nprint(np.sqrt(safe))  # well-defined\n</code></pre></p>"},{"location":"modules/helper_functions/Numerical_derivatives/","title":"Numerical Derivatives functions","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#fd_weights_1d","title":"<code>fd_weights_1d</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature","title":"Signature","text":"<pre><code>fd_weights_1d(x_nodes: np.ndarray, x0: float, der: int) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose","title":"Purpose","text":"<p>Computes the finite difference weithts that approximate the <code>der</code>-th derivatie of a function at point <code>x0</code> using an aribtraty stencil <code>x_nodes</code> (they do not need to be uniform or ordered). see fw_weights_jornal  if you want to know more.</p> <p>It is the \u201cengine\u201d that the derivative routines use to form linear combinations of the type</p> \\[f^{der}(x_0) \\approx \\sum_j w_j f(x_j) \\]"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises","title":"Parameters, returns and Raises","text":"<p>Parameters - <code>x_nodes</code> (<code>array like</code>, shape <code>(m,)</code>): Distinct stencil nodes; not required to be uniform or sorted - <code>x0</code> (<code>float</code>): Expansion point where the derivatie is approximated - <code>der</code> (<code>int</code>): Derivative order (0,1,2,...) Claim: In this project we typically use <code>der \u2208 {1,2}</code>, but the algorithm supports <code>0 &lt;= der &lt;= m-1</code></p> <p>Returns - <code>w</code> (<code>np,ndarray</code>, shape (<code>m,</code>)): Weights such that <code>f^(der)(x0) = \\sum_j w[j]*f(x_nodes[j])</code> </p>"},{"location":"modules/helper_functions/Numerical_derivatives/#raises","title":"Raises","text":"<ul> <li><code>ValueError</code> if <code>der&lt;0</code> or if <code>m-1&lt;der</code> (need at least <code>m=der+1</code> nodes)</li> <li><code>ZeroDivisionError</code> if two stencil nodes coincide (nodes must be distinct)</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#how-to-use-and-intuition","title":"How to use and Intuition","text":"<p>This function has no examples because it is called by others (e.g., deriv14, deriv1n, ...)</p> <p>intuition (Where the coefficients come from): Build the Lagrange interpolant \\(p(x)=\\sum_j f(x_j)L_j(x)\\) The weiths are precisely \\(w_j = L_j ^{der}(x_0)\\). Fornberg's algorithm computes these derivatives recuservely and stably filling a table <code>c[j,k]</code> (node j, derivative order k) and returning the column k=der chosen.</p> <p>Notes</p> <ul> <li>Typical accuracy (near-uniform stencils): \\((\\mathcal{O}(h^{m-der}))\\) for smooth functions, with h a characteristic spacing</li> <li>Polynomial exactness: Exact for all polynomials up do degree <code>m-1</code></li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#_stencil_indices","title":"<code>_stencil_indices</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_1","title":"Signature","text":"<pre><code>_stencil_indices(n: int, k: int, m: int) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_1","title":"Purpose","text":"<p>Returns a contiguos, length- <code>m</code> window of indices insied <code>[0,n-1]</code> that is as centered around <code>k</code> as possible. Near the boundaries is falls back to left or right aligned windowns. For even <code>m</code>, the window is biased one step to the left of perfect centering. Internal helper to choose the stencil for finite-difference weights/derivatives use it to obtain a centered window in the interior and one-sided windows near the boundaries.</p>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_1","title":"Parameters, returns and Raises","text":"<p>Parameters - <code>n (int)</code>: Total number of samples (valid indices are <code>0..n-1</code>) - <code>k (int)</code>: Target center index - <code>m (int)</code>: Stencil lenght (window size)</p> <p>Returns - <code>idx (np.ndarray[int])</code>, shape <code>(m,)</code>: Monotonically increasing, contiguous indices <code>start...start+m+1</code></p>"},{"location":"modules/helper_functions/Numerical_derivatives/#deriv14_const_dx","title":"<code>deriv14_const_dx</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_2","title":"Signature","text":"<pre><code>deriv14_const_dx(y: np.ndarray, dx: float = 1.0) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_2","title":"Purpose","text":"<p>Compute the first derivative along the last axis of <code>y</code> sampled on a uniform grid, using the 5-point, 4th-order finite-difference scheme. The routine is fully vectorized (no Python loops) and preserves the shape of <code>y</code>, making the function faster than <code>deriv14</code>.</p> <p>\u26a0\ufe0f Unlike <code>deriv14</code>, This function doesn't call <code>fd_weights_1d</code>, so it doesn't go through any loops and therefore calculates derivatives much faster.  The price to pay for this is providing a uniform grid</p> <ul> <li>Interior (k = 2..n\u22123): centered 5-point, 4th-order</li> </ul> \\[f'(x_k)\\ \\approx\\ \\frac{f_{k-2}-8f_{k-1}+8f_{k+1}-f_{k+2}}{12h}\\] <ul> <li>Boundaries: standard one-sided 5-point formulas (also 4th-order) for <code>k\u2208{0,1,n\u22122,n\u22121}</code>.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_2","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>y</code> (<code>array_like</code>, shape <code>(..., n)</code>): Samples on a uniform grid along the last axis.</li> <li><code>dx</code> (<code>float</code>, optional): Uniform spacing <code>h</code> between consecutive samples (default <code>1.0</code>).</li> </ul> <p>Returns</p> <ul> <li><code>dy</code> (<code>np.ndarray</code>, same shape as <code>y</code>): Numerical approximation to \u2202y/\u2202x along the last axis.</li> </ul> <p>Raises / Assumptions</p> <ul> <li><code>ValueError</code> if <code>y.shape[-1] &lt; 5</code> (needs at least five points).</li> <li>Assumes uniform spacing with finite <code>dx</code> and monotonic (increasing or decreasing).</li> <li>\u26a0\ufe0f Error is \\(\\mathcal{O}(h^4)\\) in the interior; at the ends it remains 4th-order but with typically larger constants.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples","title":"When to use and Examples","text":"<p>Use when your data are on a uniform grid and you want a high-accuracy first derivative with a small, explicit stencil and fast vectorized implementation.</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples</p> <ul> <li> <p>Derivative of (sin) using deriv14_const_dx </p> </li> <li> <p>Error of the derivative </p> </li> </ul> <pre><code>'''\n=== Test derivative: Uniform grid, first derivative (sin profile) ===\nGrid: N=201, dx=3.142e-02, function: sin(kx), k=1.0\nMax abs error (dy): 1.945e-07  (expected ~O(h^4) ~ 9.7e-07)\nNote: boundary stencils are one-sided; error is typically larger at the ends than in the interior.\n'''\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#deriv14","title":"<code>deriv14</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_3","title":"Signature","text":"<pre><code>deriv14(y: np.ndarray, x: np.ndarray) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_3","title":"Purpose","text":"<p>Compute the first derivative along the last axis of <code>y</code> sampled at non-uniform coordinates <code>x</code>, using 5-point finite-difference stencils. The routine builds Fornberg weights per local stencil, yielding 4th-order accuracy in the interior on smooth data (with one-sided high-order stencils at the boundaries). Works for strictly increasing or decreasing <code>x</code>!! .</p> <p>\u26a0\ufe0f Unlike <code>deriv14_const_dx</code>, This function call <code>fd_weights_1d</code>, so it goes through many loops and therefore calculates derivatives slower. What gains in return is the ability to compute on an arbitrary non-uniform grid</p>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_3","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>y</code> (<code>array_like</code>, shape <code>(..., n)</code>): Function values along the last axis.</li> <li><code>x</code> (<code>array_like</code>, shape <code>(n,)</code>): Sample locations, strictly monotonic (increasing or decreasing). Requires <code>n \u2265 5</code>.</li> </ul> <p>Returns</p> <ul> <li><code>dy</code> (<code>np.ndarray</code>, same shape as <code>y</code>): Numerical approximation to \u2202y/\u2202x along the last axis.</li> </ul> <p>Raises / Assumptions</p> <ul> <li><code>ValueError</code> if <code>x</code> is not 1D, if <code>n &lt; 5</code>, or if <code>x</code> is not strictly monotonic.</li> <li>Interior uses centered windows <code>[k-2..k+2]</code>; endpoints use one-sided 5-point stencils.</li> <li>Interior truncation error is typically \\(\\mathcal{0}(h^4)\\) on near-uniform meshes (with \\(h\\) a typical spacing), while boundary errors have larger constants.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#notes","title":"Notes","text":"<ul> <li>Uses <code>fd_weights_1d</code> to obtain exact polynomial reproductions up to degree 4 on each stencil.</li> <li>Vectorized accumulation via <code>np.tensordot</code> along the last axis.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples_1","title":"When to use and Examples","text":"<p>Use when your samples lie on a non-uniform 1D grid and you want high order interior accuracy without resampling to a uniform mesh.</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples (same structure as <code>deriv14_const_dx</code>; you can adapt the <code>x</code> grid to be non-uniform):</p> <p>Examples</p> <ul> <li>Derivative of (exp) using deriv14 </li> </ul> <pre><code>'''\n=== Test 3: Non-uniform grid, first derivatives (exp profile) ===\nNon-uniform grid size: N=161\nMax abs error (dy):  6.659e-09\n=== Test 6: Expected error cases ===\nToo few points (deriv14): deriv14 requires at least 5 samples.\nx not 1D (deriv14): x must be 1D\nNon-monotonic x (deriv14): x must be strictly monotonic (increasing or decreasing).\n'''\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#deriv23","title":"<code>deriv23</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_4","title":"Signature","text":"<pre><code>deriv23(y: np.ndarray, x: np.ndarray) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_4","title":"Purpose","text":"<p>Same algorithmic idea, assumptions, and stencil policy as <code>deriv14</code>, but for the second derivative on a non-uniform 1D grid. Uses 5-point stencils with Fornberg weights (<code>der=2</code>): centered in the interior, one-sided near boundaries. Accuracy in smooth problems is typically 3rd\u20134th order in the interior (exact for polynomials up to degree 4 on uniform stencils).</p>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_4","title":"Parameters, returns and Raises","text":"<ul> <li>Parameters, shape constraints, monotonicity checks, and error handling are the same pattern as <code>deriv14</code>, with <code>der=2</code>.</li> <li>Returns an array with the same shape as <code>y</code>, containing \\(\\partial y^2/ \\partial x^2\\) along the last axis.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples_2","title":"When to use and Examples","text":"<p>Use when you need second derivatives on non-uniform grids with high-order interior accuracy and robust boundary handling.</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples</p> <ul> <li>Second Derivative of (exp) using deriv23 </li> </ul> <pre><code>'''\n=== Test 3: Non-uniform grid, second derivatives (exp profile) ===\nNon-uniform grid size: N=161\nMax abs error (d2y): 2.625e-06\n\n=== Test 6: Expected error cases ===\nToo few points (deriv23): deriv23 requires at least 5 samples.\nx not 1D (deriv23): x must be 1D\nNon-monotonic x (deriv23): x must be strictly monotonic (increasing or decreasing).\n'''\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#deriv23_const_dx","title":"<code>deriv23_const_dx</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_5","title":"Signature","text":"<pre><code>deriv23_const_dx(y: np.ndarray, dx: float = 1.0) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_5","title":"Purpose","text":"<p>Same idea as <code>deriv14_const_dx</code>, but computing the second derivative on a uniform grid using the 5-point, 4th-order scheme. Interior uses the standard centered 5-point formula,</p> \\[ f''(x_k)\\approx\\frac{-f_{k-2}+16f_{k-1}-30f_k+16f_{k+1}-f_{k+2}}{12\\,h^2}, \\] <p>with one-sided 5-point stencils at the boundaries</p>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_5","title":"Parameters, returns and Raises","text":"<ul> <li>Parameters and return shape mirror <code>deriv14_const_dx</code> (but for \\(\\partial y^2/ \\partial x^2\\)). Requires at least 5 points along the last axis; raises <code>ValueError</code> otherwise.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples_3","title":"When to use and Examples","text":"<p>Use for uniform grids when you want a fast, vectorized second derivative with high accuracy and small stencil.</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples</p> <ul> <li> <p>Second Derivative of (sin) using deriv23_const_dx </p> </li> <li> <p>Error of the second derivative </p> </li> </ul> <pre><code>'''\n=== Test 2: Uniform grid, second derivative (sin profile) ===\nMax abs error (d2y): 2.580e-05  (expected ~O(h^3) at edges ~ 3.1e-05)\nNotes: The interior is still O(h^4) (see graph)\n'''\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#deriv1n","title":"<code>deriv1n</code>","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_6","title":"Signature","text":"<pre><code>deriv1n(y: np.ndarray, x: np.ndarray, n: int) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_6","title":"Purpose","text":"<p>General first-derivative on a non-uniform 1D grid using an (n+1)-point stencil with Fornberg weights. Same overall idea/policies as <code>deriv14</code> (centered interior, one-sided near boundaries), but here the stencil size is configurable via <code>n</code> (so <code>m = n+1</code> points).  For smooth data on near-uniform meshes, interior truncation error scales \\((\\approx \\mathcal{O}(h^n))\\) (e.g., <code>n=4</code> \u2192 5-point, ~4th-order like <code>deriv14</code>).</p> <p>What\u2019s different vs. <code>deriv14</code> / <code>deriv14_const_dx</code>:</p> <ul> <li>You choose accuracy/stencil size with <code>n</code> (recommended 4 \u2264 n \u2264 8: good accuracy vs. stability).</li> <li>Larger stencils can be more sensitive to noise and wider spacing; extremely irregular nodes may degrade conditioning.</li> <li>Uses <code>_stencil_indices</code> to pick a centered window when possible, otherwise one-sided near edges.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises-briefly","title":"Parameters, returns and Raises (briefly)","text":"<ul> <li><code>y</code>: values along the last axis <code>(..., N)</code>.</li> <li><code>x</code>: strictly monotonic 1D array <code>(N,)</code>; requires <code>N \u2265 n+1</code>.</li> <li><code>n</code>: desired accuracy order; stencil size is <code>m = n+1</code>.</li> <li>Returns <code>dy</code> with the same shape as <code>y</code> (\u2202y/\u2202x along the last axis).</li> <li>Raises <code>ValueError</code> if <code>x</code> not 1D/monotonic, if <code>N &lt; n+1</code>, or if <code>n &lt; 2</code>.</li> <li>Internally: Fornberg weights with <code>der=1</code>, accumulated via <code>np.tensordot</code>.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples_4","title":"When to use and Examples","text":"<p>When you want to dial precision (and stencil width) for first derivatives on non-uniform grids without resampling.</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples</p> <pre><code>\"\"\"\n=== Test 4: Accuracy vs stencil size (deriv1n on sin) ===\nn=4 (stencil m=5): max abs error = 2.964e-07\nn=6 (stencil m=7): max abs error = 2.573e-10\nn=8 (stencil m=9): max abs error = 2.558e-13\nExpected: error generally decreases as stencil size increases (for smooth functions).\n\"\"\"\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#gradientfunction-callable-class","title":"<code>gradientFunction</code> (callable class)","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_7","title":"Signature","text":"<pre><code>ArrayLike = Union[np.ndarray, float]\n\nclass gradientFunction:\n    def __init__(self, f: Callable, eps: ArrayLike, Ndim: int, order: int = 4) -&gt; None: ...\n    def __call__(self, x: ArrayLike, *args, **kwargs) -&gt; np.ndarray: ...\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_7","title":"Purpose","text":"<p>Build a callable gradient operator for a scalar field \\(f:\\mathbb{R}^{N}\\to\\mathbb{R}\\) using finite differences of order 2 or 4, with per-axis steps <code>eps</code>. Once constructed, <code>gradientFunction(...)</code> behaves like a function: <code>df(x) \u2192 \u2207f(x)</code>.</p> <p>Intuition: along each coordinate \\(i\\), evaluate \\(f\\) at symmetrically shifted points \\(x \\pm \\alpha\\,\\varepsilon_i\\,\\hat e_i\\) (second or fourth-order central differences).  Combine the batched evaluations with the precomputed coefficients to get the \\(i\\)-th partial derivative. All axes are processed in one vectorized call.</p>"},{"location":"modules/helper_functions/Numerical_derivatives/#why-a-class-not-just-a-function","title":"Why a class (not just a function)?","text":"<ul> <li>Precomputation &amp; reuse: offsets and peraxis coefficients depend only on <code>(eps, Ndim, order)</code>. The class builds them once and reuses across many calls \u2192 less Python overhead in tight loops (optimization, sampling, PDE steps).</li> <li>Stateful configuration: keeps <code>f</code>, <code>Ndim</code>, <code>eps</code>, <code>order</code> together; the result is a callable object that plugs cleanly anywhere a function is expected.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_6","title":"Parameters, returns and Raises","text":"<p><code>__init__(f, eps, Ndim, order=4)</code></p> <ul> <li><code>f</code> (<code>callable</code>): scalar field; must accept arrays with last axis of length <code>Ndim</code> (any leading batch axes allowed) and return an array of the same leading shape (scalar per point).</li> <li><code>eps</code> (<code>float | array_like</code>): FD step(s). Scalar is broadcast to all axes; or pass a length-<code>Ndim</code> array for peraxis steps.</li> <li><code>Ndim</code> (<code>int</code>): dimensionality of the input points.</li> <li><code>order</code> (<code>{2,4}</code>): FD accuracy. <code>2</code> uses \\([-1,+1]\\) with coefficients \\([-1/2,+1/2]\\); <code>4</code> uses ([-2,-1,+1,+2]/12<code>with coefficients</code>[+1,-8,+8,-1]/12`.</li> </ul> <p><code>__call__(x, *args, **kwargs)</code></p> <ul> <li><code>x</code> (<code>array_like</code>, shape <code>(..., Ndim)</code>): evaluation points (1 or many).</li> <li>Returns <code>grad</code> (<code>np.ndarray</code>, shape <code>(..., Ndim)</code>): gradient \\(\\nabla f(x)\\).</li> <li>Any extra <code>*args/**kwargs</code> are forwarded to <code>f</code>.</li> </ul> <p>Raises / Assumptions</p> <ul> <li><code>ValueError</code> if <code>order \u2209 {2,4}</code>, if <code>eps</code> is not scalar or <code>(Ndim,)</code>, if <code>x</code>\u2019s last axis \u2260 <code>Ndim</code>, or if <code>Ndim</code> is inconsistent.</li> <li><code>f</code> must be vectorized enough to broadcast over the added stencil axes; the class constructs inputs of shape <code>(..., order, Ndim, Ndim)</code> and expects outputs <code>(..., order, Ndim)</code> (scalar per displaced point).</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#notes_1","title":"Notes","text":"<ul> <li>Accuracy vs. step size: truncation error decreases with smaller <code>eps</code>, but round off grows pick <code>eps</code> consistent with the scale of <code>x</code> and <code>f</code> (a common rule of thumb: start near \\(\\sqrt{\\varepsilon_\\text{mach}} \\times \\text{scale}\\) for order-2, and somewhat larger for order-4).</li> <li>Anisotropic steps: use an <code>eps</code> vector to reflect different physical scales per axis.</li> <li>Performance/memory: very large <code>Ndim</code> or huge batches may increase temporary array sizes; if needed, evaluate in tiles.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples_5","title":"When to use and Examples","text":"<p>Use when you need a drop-in gradient for a black-box scalar function (e.g., potentials \\(V(\\phi)\\) in multi-field models, without deriving/maintaining analytic gradients. It\u2019s especially handy inside optimizers, line searches, or field evolution steps).</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples</p> <ul> <li> <p>Gradient of \\(V(x,y)=\\sin(x)*\\cos(y) [order=4]\\) </p> </li> <li> <p>Gradient field for intuition </p> </li> </ul> <pre><code>\"\"\"\n=== Test 7: Gradient on V(x,y) = sin(x) * cos(y) (order=4) ===\nGrid: 101x101, eps=1e-4 (per axis), order=4\nMax |grad error| = 4.145e-12,  Mean |grad error| = 1.757e-12\nNotes: O(h^3) at edges\n\"\"\"\n</code></pre> <ul> <li>Convergence with eps (1D) </li> </ul> <p><pre><code># Convergence is faster with higher order, as expected\n</code></pre> - Physical example: Electrostatic Field </p> <ul> <li>Physical example: 2D anisotropic harmonic oscillator </li> </ul> <pre><code>\"\"\"\n=== Test 11: Electrostatic potential (softened) and field via gradientFunction ===\nRel. error stats away from charges: max=1.394e-09, mean=2.493e-11\n\n=== Test 12 (bonus): 2D anisotropic harmonic oscillator with rkqs and \u2207V ===\nEnergy stats: Emin=1.000000, Emax=1.000001, \u0394E=6.510e-07```\n\"\"\"\n</code></pre> <pre><code>\"\"\"\n=== Test 13: Expected error cases (gradient) ===\nInvalid order (gradientFunction): order must be 2 or 4\nWrong eps shape (gradientFunction): `eps` must be scalar or have shape (2,)\nx last axis mismatch (gradientFunction): Last axis of x must have length Ndim=2\nNon-scalar f (gradientFunction): ValueError('operands could not be broadcast together with shapes (4,4,2,2) (4,2) ')\n\"\"\"\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#hessianfunction-callable-class","title":"<code>hessianFunction</code> (callable class)","text":""},{"location":"modules/helper_functions/Numerical_derivatives/#signature_8","title":"Signature","text":"<pre><code>class hessianFunction:\n    def __init__(self, f: Callable, eps: ArrayLike, Ndim: int, order: int = 4) -&gt; None: ...\n    def __call__(self, x: ArrayLike, *args, **kwargs) -&gt; np.ndarray: ...\n</code></pre>"},{"location":"modules/helper_functions/Numerical_derivatives/#purpose_8","title":"Purpose","text":"<p>Build a callable Hessian operator for a scalar field \\(f:\\mathbb{R}^N\\!\\to\\!\\mathbb{R}\\) using finite differences of order 2 or 4 with per-axis steps <code>eps</code>. Once constructed, <code>hessianFunction(...)</code> acts like a function: <code>hf(x) \u2192 H(x)</code> with shape <code>(..., Ndim, Ndim)</code>.</p> <p>Intuition (how entries are formed): \u2022 Diagonal terms \\(H_{ii}\\) use 1D second-derivative stencils along axis \\(i\\) (order-2: 3-point; order-4: 5-point). \u2022 Off-diagonal terms \\(H_{ij}\\) with \\(i\\neq j\\) use the tensor product of two first-derivative stencils (one in \\(i\\), one in \\(j\\)), i.e.</p> \\[ \\frac{\\partial^2 f}{\\partial x_i\\,\\partial x_j}(x) \\;\\approx\\; \\sum_{a,b}\\frac{c^{(1)}_a}{\\varepsilon_i}\\,\\frac{c^{(1)}_b}{\\varepsilon_j}\\; f\\!\\big(x + a\\,\\varepsilon_i\\,\\hat e_i + b\\,\\varepsilon_j\\,\\hat e_j\\big), \\] <p>where \\(c^{(1)}\\) are the central-difference coefficients of order 2 or 4. The class precomputes all shifts and weights and then evaluates <code>f</code> in batched fashion.</p>"},{"location":"modules/helper_functions/Numerical_derivatives/#why-a-class-not-just-a-function_1","title":"Why a class (not just a function)?","text":"<ul> <li>Precomputation &amp; reuse: shifts/weights depend only on <code>(eps, Ndim, order)</code>. The class builds them once and reuses across many calls \u2192 less overhead in inner loops (optimizers, Newton steps, variational solvers).</li> <li>Stateful configuration: keeps <code>f</code>, <code>Ndim</code>, <code>eps</code>, <code>order</code> together; exposes a clean callable API.</li> <li>Vectorized batching: each diagonal/off-diagonal block is evaluated by feeding a whole bundle of shifted points to <code>f</code> at once, then combining with the stored weights.</li> <li>Symmetry by construction: it sets \\(H_{ij}\\!=\\!H_{ji}\\) after computing \\(i&gt;j\\).</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#parameters-returns-and-raises_7","title":"Parameters, returns and Raises","text":"<p><code>__init__(f, eps, Ndim, order=4)</code></p> <ul> <li><code>f</code> (<code>callable</code>): scalar field; must accept arrays with last axis size <code>Ndim</code> (any leading batch dims allowed) and return a scalar per point (same leading shape).</li> <li><code>eps</code> (<code>float | array_like</code>): FD step size(s). Scalar broadcasts to all axes; or pass a length-<code>Ndim</code> array for anisotropic steps.</li> <li><code>Ndim</code> (<code>int</code>): dimensionality of the input points.</li> <li><code>order</code> (<code>{2,4}</code>): finite-difference accuracy (order-2 or order-4 central stencils).</li> </ul> <p><code>__call__(x, *args, **kwargs)</code></p> <ul> <li><code>x</code> (<code>array_like</code>, shape <code>(..., Ndim)</code>): evaluation points.</li> <li>Returns <code>H</code> (<code>np.ndarray</code>, shape <code>(..., Ndim, Ndim)</code>): the Hessian at <code>x</code>.</li> <li>Any extra <code>*args/**kwargs</code> are forwarded to <code>f</code>.</li> </ul> <p>Raises / Assumptions</p> <ul> <li><code>ValueError</code> if <code>order \u2209 {2,4}</code>, if <code>eps</code> is not scalar or <code>(Ndim,)</code>, or if <code>x</code>\u2019s last axis \u2260 <code>Ndim</code>.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#notes_2","title":"Notes","text":"<ul> <li>Stencils used:   \u2022 Order-2: first-deriv offsets \\([-1,+1]\\) with coeffs \\([-1/2,+1/2]\\); second-deriv offsets \\([-1,0,+1]\\) with coeffs \\([1,-2,1]\\).   \u2022 Order-4: first-deriv offsets \\([-2,-1,+1,+2]\\) with coeffs \\([+1,-8,+8,-1]/12\\); second-deriv offsets \\([-2,-1,0,+1,+2]\\) with coeffs \\([-1,16,-30,16,-1]/12\\).</li> <li>Work per call (per point): roughly \\(\\sum_i m_2\\) (diagonals) + \\(\\sum_{i&gt;j} m_1^2\\) (off-diagonals) function evaluations, where \\(m_1\\) and \\(m_2\\) are the first/second-derivative stencil lengths (2 or 4 \u2192 \\(m_1=2,4\\); \\(m_2=3,5\\)). These are batched per block to reduce Python overhead.</li> <li>Accuracy vs step size: smaller <code>eps</code> reduces truncation error but increases round-off sensitivity; pick <code>eps</code> commensurate with scales of <code>x</code> and <code>f</code>.</li> <li>Anisotropic physics: per-axis <code>eps</code> is useful when coordinates have different natural scales.</li> </ul>"},{"location":"modules/helper_functions/Numerical_derivatives/#when-to-use-and-examples_6","title":"When to use and Examples","text":"<p>Use when you need a drop-in Hessian for a black-box scalar potential\u2014e.g., multi-field potentials \\(V(\\phi)\\) in phase-transition scans\u2014without deriving analytic second derivatives. Useful in Newton/Quasi-Newton methods, curvature analysis, and stability checks.</p> <p>see the full test script in tests/helper_functions/Numerical_derivatives for more</p> <p>Examples</p> <pre><code>\"\"\"\n=== Test 8: Hessian exactness on quadratic form (order=4) ===\nMax |H - A| = 1.426e-06,  Mean |H - A| = 7.628e-08\nExpected: near machine precision for smooth quadratics with small eps.\n=== Test 9: Hessian with mixed terms (order=4) ===\nGrid 60x60, eps=[1e-4,3e-4]: max |H_num - H_ex| = 7.461e-07\n=== Test 13: Expected error cases (hessian) ===\nInvalid order (hessianFunction): order must be 2 or 4\nNon-scalar f (hessianFunction): ValueError('operands could not be broadcast together with shapes (4,16,2) (16,) ')\n\"\"\"\n</code></pre>"},{"location":"modules/helper_functions/Numerical_integration/","title":"Numerical Integration functions","text":""},{"location":"modules/helper_functions/Numerical_integration/#_rkck","title":"<code>_rkck</code>","text":""},{"location":"modules/helper_functions/Numerical_integration/#signature","title":"Signature","text":"<pre><code>_rkck(y: np.ndarray, dydt: np.ndarray, t: float,f: Callable, dt: float, args: tuple = ()) -&gt; Tuple[np.ndarray, np.ndarray]\n</code></pre>"},{"location":"modules/helper_functions/Numerical_integration/#purpose","title":"Purpose","text":"<p>Perform one embedded Runge-Kutta Cash-Karp step (the classic 5th-order method with a 4th-order ebedded estimate)</p>"},{"location":"modules/helper_functions/Numerical_integration/#parameters-returns-and-raises","title":"Parameters, returns and Raises","text":"<p>Parameters - y  (array_like): Current state at time <code>t</code>. - dydt (array_like): Derivative <code>dy/dt</code> at (y, t), usually <code>f(y, t)</code>. - t (float): Current integration variable (independent variable). - f (callable): Derivative function with signature <code>f(y, t, *args)</code>. - dt (float): Step size. - args (tuple, optional) Extra positional arguments for f (usualy defaults)</p> <p>Returns - <code>dyout</code> (ndarray): The 5th-order increment \u0394y to update the state: y_next \u2248 y + dyout. - <code>yerr</code> (ndarray): An estimate of the local truncation error for the increment (the difference between 5th and 4th order formulas)</p>"},{"location":"modules/helper_functions/Numerical_integration/#raises","title":"Raises","text":"<ul> <li>No custom exceptions.</li> </ul>"},{"location":"modules/helper_functions/Numerical_integration/#when-to-use","title":"When to use","text":"<p>This function is used by the function below (<code>rkqs</code>) to solve the desired ODE and therefore is not called directly.  (That's why there are no examples of it)</p>"},{"location":"modules/helper_functions/Numerical_integration/#rkqs","title":"<code>rkqs</code>","text":""},{"location":"modules/helper_functions/Numerical_integration/#signature_1","title":"Signature","text":"<pre><code>rkqs(y: np.ndarray, dydt: np.ndarray, t: float, f: callable, dt_try: float, epsfrac: float, epsabs: float, args: tuple = ()) -&gt; _rkqs_rval\n</code></pre>"},{"location":"modules/helper_functions/Numerical_integration/#purpose_1","title":"Purpose","text":"<p>Perform one adpative step of the (RKCK) method with error control It's the acceptance/rejection + step control wrapper around the low-leve <code>_rkck</code> step. The function has larger steps when the error is very small and decreases the step when the error becomes large.  This ensures accuracy and speed in solving the integral.</p>"},{"location":"modules/helper_functions/Numerical_integration/#parameters-returns-and-raises_1","title":"Parameters, returns and Raises","text":"<p>Parameters - Same as _rkck (y, dydt, t, f, dt and args) plus: - dt_try  (float): Initial step-size guess  - epsfrac (float): Relative error tolerance (dimensionless) - epsabs (float): Absolute error tolerance (same units as <code>y</code>)</p> <p>Returns - named tuple <code>_rkqs_rval[Delta)y, Delta_t, dtxt]</code> - <code>Delta_y</code> (ndarray): 5th-order increment to advance the state: y_next \u2248 y + Delta_y.  - <code>Delta_t</code> (float): The actual step size used on the accepted step (may be smaller than dt_try). - <code>dtxt</code> (float): A suggested step size for the next call (based on the observed error)</p>"},{"location":"modules/helper_functions/Numerical_integration/#raises_1","title":"Raises","text":"<ul> <li><code>IntegrationError</code>: If the step size underflows numerically (i.e., <code>t+dt==t</code>) after repeated shrinking)</li> </ul>"},{"location":"modules/helper_functions/Numerical_integration/#how-to-use-and-examples","title":"How to use and Examples","text":"<ul> <li>The error is handled as follows:</li> <li>With the relative error <code>epsfrac</code> evaluate <code>denom = y * epsfrac</code></li> <li>With the absolute error <code>epsabs</code> evaluate <code>err_ratio = |yerr| / max(denom, epsabs)</code></li> <li>Then take errmax = max(err_ratio) and <code>if errmax &lt;1</code> accept pace. Otherwise compute a reduced dt until accepted</li> <li> <p>After acceptance, propose dtnxt (x5 if the step was extremely accurate and reduced if the error was not so accurate)</p> </li> <li> <p>Start with <code>epsfrac ~ 1e-6</code> (relative) and <code>epsfrac ~ 1e-9</code> (absolute) for typical float64 runs.</p> </li> <li>There is no predefined formula for errors, just trial and error with the desired ODE</li> </ul> <p>see the full test script in tests/helper_functions/Numerical_integration for more There are one more image and two more prints examples there. Examples <pre><code># Minimal usage pattern (pseudo-code)\ny = y0.copy()\nt = t0\ndt = dt_try\nwhile t &lt; t_end:\n    dydt = f(y, t, *args)\n    Delta_y, Delta_t, dtnxt = rkqs(y, dydt, t, f, dt, epsfrac, epsabs, args)\n    y += Delta_y\n    t += Delta_t\n    dt = dtnxt\n</code></pre> - Harmonic oscillator test images </p> <ul> <li>Adaptive step sizes </li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/","title":"Interpolation Functions","text":""},{"location":"modules/helper_functions/interpolation_functions/#makeinterpfuncs","title":"<code>makeInterpFuncs</code>","text":""},{"location":"modules/helper_functions/interpolation_functions/#signature","title":"Signature","text":"<pre><code>makeInterpFuncs(y0, dy0, d2y0, y1, dy1, d2y1) -&gt; Tuple[Callable, Callable]\n</code></pre>"},{"location":"modules/helper_functions/interpolation_functions/#purpose","title":"Purpose","text":"<p>Build a quintic (5th-degree) interpolant on the normalized domain x \u2208 [0,1] that matches value, first, and second derivatives at both endpoints:</p> \\[ f(0)=y_0,\\quad f'(0)=d y_0,\\quad f''(0)=d^2 y_0,\\qquad f(1)=y_1,\\quad f'(1)=d y_1,\\quad f''(1)=d^2 y_1. \\] <p>It returns two callables:</p> <ul> <li><code>f(x)</code>: the interpolating polynomial,</li> <li><code>df(x)</code>: its first derivative.</li> </ul> <p>Intuition: a quintic has 6 coefficients, exactly the number of endpoint constraints (value/slope/curvature at 0 and 1). We fix three coefficients from the left-end constraints and solve a small 3\u00d73 linear system for the remaining ones using the right-end constraints. This is the classic Hermite-type two-point interpolation with up to second derivatives.</p>"},{"location":"modules/helper_functions/interpolation_functions/#parameters-returns-and-raises","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>y0, dy0, d2y0</code>: value, 1st and 2nd derivative at <code>x=0</code>.</li> <li><code>y1, dy1, d2y1</code>: value, 1st and 2nd derivative at <code>x=1</code>.</li> </ul> <p>Returns</p> <ul> <li><code>f</code> (<code>callable</code>): evaluates the quintic at scalar/array <code>x</code> in <code>[0,1]</code>.</li> <li><code>df</code> (<code>callable</code>): evaluates the first derivative at the same <code>x</code>.</li> </ul> <p>(No custom exceptions; the internal 3\u00d73 system has a fixed, well-conditioned matrix.)</p>"},{"location":"modules/helper_functions/interpolation_functions/#notes","title":"Notes","text":"<ul> <li> <p>The polynomial is \\(p(x)=a_0+a_1 x+a_2 x^2+a_3 x^3+a_4 x^4+a_5 x^5\\).</p> </li> <li> <p>From the left endpoint:</p> \\[a_0=y_0,\\quad a_1= d y_0,\\quad a_2=\\tfrac{1}{2} d^2 y_0\\] </li> <li> <p>The remaining \\((a_3,a_4,a_5)\\) come from the right endpoint via     a fixed 3\u00d73 system (hard-coded matrix), solved against the residuals     after subtracting the known \\(a_0,a_1,a_2\\).</p> </li> <li>Both <code>f</code> and <code>df</code> use Horner\u2019s scheme for numeric stability and speed.</li> <li>To interpolate over an arbitrary interval \\([x_a,x_b]\\), map \\(x\\) to   \\(s=(x-x_a)/(x_b-x_a)\\in[0,1]\\). Endpoint derivatives must be scaled:</li> </ul> \\[\\frac{df}{dx}\\Big|_{x_a} = \\frac{1}{h}\\frac{df}{ds}\\Big|_{s=0}\\quad \\frac{d^2 f}{dx^2}\\Big|_{x_a} = \\frac{1}{h^2}\\frac{d^2 f}{ds^2}\\Big|_{s=0}\\] <p>with \\(h=x_b-x_a\\) (same at the right end).</p>"},{"location":"modules/helper_functions/interpolation_functions/#when-to-use-and-examples","title":"When to use and examples","text":"<p>Use when you need a smooth segment with continuous value, slope, and curvature at both ends (e.g., path stitching, potential profiles, or boundary-matched trajectories, without overshoot typical of low-order polynomials).</p> <p>see the full test script in tests/helper_functions/interpolation_functions for more</p> <p>Example</p> <pre><code># Endpoint constraints on x in [0,1]\ny0, dy0, d2y0 = 1.0, -0.5,  0.75\ny1, dy1, d2y1 = 2.0,  0.8, -0.25\nf, df = makeInterpFuncs(y0, dy0, d2y0, y1, dy1, d2y1)\n</code></pre> <ul> <li>Quintic Interpolation </li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#cubicinterpfunction","title":"<code>cubicInterpFunction</code>","text":""},{"location":"modules/helper_functions/interpolation_functions/#signature_1","title":"Signature","text":"<pre><code>class cubicInterpFunction:\n    def __init__(self, y0, dy0, y1, dy1) -&gt; None: ...\n    def __call__(self, t) -&gt; np.ndarray: ...\n</code></pre>"},{"location":"modules/helper_functions/interpolation_functions/#purpose_1","title":"Purpose","text":"<p>Cubic two-point interpolant on the normalized parameter t \u2208 [0,1] that matches value and first derivative at both ends. Implements the B\u00e9zier form that is algebraically equivalent to Hermite interpolation with endpoint slopes.</p> <p>Intuition: a cubic has 4 degrees of freedom\u2014exactly the endpoint value/tangent pair at t=0 and t=1. Writing it in B\u00e9zier form makes the geometry transparent: the middle control points are just the endpoints nudged in the tangent directions.</p>"},{"location":"modules/helper_functions/interpolation_functions/#parameters-returns-and-raises_1","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>y0, dy0</code>: value and slope at <code>t=0</code>.</li> <li><code>y1, dy1</code>: value and slope at <code>t=1</code>.   All can be scalar or array-like (vectors/fields); shapes must be broadcastable to a common shape.</li> </ul> <p>Returns</p> <ul> <li>Calling the instance: <code>y = cubic(t)</code> evaluates the interpolant at scalar/array <code>t</code>; the output shape follows <code>t</code> and the shapes of <code>y0/y1</code>.</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#notes_1","title":"Notes","text":"<ul> <li>B\u00e9zier control points (from Hermite data):</li> </ul> <p>$$P_0 = y_0,\\quad P_1 = y_0 + \\tfrac{1}{3}\\,d y_0,\\quad P_2 = y_1 - \\tfrac{1}{3}\\,d y_1,\\quad P_3 = y_1 $$</p> <p>and</p> <p>$$B(t)=(1-t)^3P_0+3(1-t)^2 t P_1+3(1-t)t^2 P_2+t^3 P_3 $$</p> <ul> <li>Endpoint slopes &amp; reparameterization: if you want slopes with respect to a physical coordinate \\(x\\in[x_a,x_b]\\) (not \\(t\\)), map \\(t=(x-x_a)/h\\) with \\(h=x_b-x_a\\) and set   <code>dy0 = (dy/dx at x_a) * h</code>, <code>dy1 = (dy/dx at x_b) * h</code>.</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#when-to-use-and-examples_1","title":"When to use and examples","text":"<p>Use when you need a compact, slope controlled segment between two states\u2014great for smooth paths, schedules, or boundary-matched profiles\u2014without the extra curvature constraints of the quintic.</p> <p>see the full test script in tests/helper_functions/interpolation_functions.py for more</p> <p>Example</p> <p><pre><code># 2) Cubic two-point interpolation (Bezier/Hermite): slope control\ny0, y1 = 0.0, 1.0\ndy0, dy1 = 2.0, -1.0\ncubic = cubicInterpFunction(y0, dy0, y1, dy1)\nts = np.linspace(0, 1, 400)\nys = cubic(ts)\n# Expected: curve starts rising fast (positive dy0) and ends with negative slope (dy1).\n</code></pre> - Cubic Interpolation </p>"},{"location":"modules/helper_functions/interpolation_functions/#_safe_div","title":"<code>_safe_div</code>","text":""},{"location":"modules/helper_functions/interpolation_functions/#signature_2","title":"Signature","text":"<pre><code>_safe_div(num, den) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/interpolation_functions/#purpose_2","title":"Purpose","text":"<p>Elementwise division with broadcasting that returns 0 where <code>den == 0</code>. Used inside the Cox\u2013de Boor recursion to safely handle repeated knots (zero denominators) without producing NaNs.</p> <p>Returns</p> <ul> <li>Array with the broadcasted shape of <code>num</code> and <code>den</code>, containing <code>num/den</code> where <code>den\u22600</code> and <code>0</code> where <code>den=0</code>.</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#nbspl","title":"<code>Nbspl</code>","text":""},{"location":"modules/helper_functions/interpolation_functions/#signature_3","title":"Signature","text":"<pre><code>Nbspl(t, x, k: int = 3) -&gt; np.ndarray\n</code></pre>"},{"location":"modules/helper_functions/interpolation_functions/#purpose_3","title":"Purpose","text":"<p>Evaluate the B-spline basis functions of degree <code>k</code> for a given knot vector <code>t</code> at points <code>x</code>, using the Cox\u2013de Boor recursion. This returns the basis matrix \\(N\\) so you can build a spline curve or field as</p> \\[ S(x_j)\\;=\\;\\sum_{i=0}^{\\text{nb}-1} c_i\\,N_{i,k}(x_j), \\] <p>where \\(\\text{nb} = m - k - 1\\) is the number of degree-<code>k</code> basis functions (with m=len(t)) and \\(c_i\\) are your control coefficients.</p> <p>Intuition (how it works): \u2022 Degree 0 (piecewise constants): each \\(N_{i,0}\\) is 1 on the knot interval \\((t_i, t_{i+1}]\\) and 0 elsewhere (this code uses a right-closed convention to mirror the legacy behavior). \u2022 Elevate degree recursively: for \\(p=1..k\\),</p> \\[ N_{i,p}(x)\\;=\\;\\frac{x-t_i}{t_{i+p}-t_i}\\,N_{i,p-1}(x)\\;+\\;\\frac{t_{i+p+1}-x}{t_{i+p+1}-t_{i+1}}\\,N_{i+1,p-1}(x). \\] <p>The helper <code>_safe_div</code> makes each fraction zero if its denominator vanishes (e.g., repeated knots), which is the standard convention.</p>"},{"location":"modules/helper_functions/interpolation_functions/#parameters-returns-and-raises_2","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <ul> <li><code>t</code> (<code>array_like</code>, shape <code>(m,)</code>): Non-decreasing knot vector. Repeated knots are allowed (lower continuity).</li> <li><code>x</code> (<code>array_like</code>, shape <code>(n,)</code>): Points where you want the basis evaluated.</li> <li><code>k</code> (<code>int</code>, default <code>3</code>): Degree of the spline (cubic by default). Must satisfy <code>k &lt;= len(t) - 2</code>.</li> </ul> <p>Returns</p> <ul> <li><code>N</code> (<code>np.ndarray</code>, shape <code>(n, m-k-1)</code>):   Basis matrix with rows = evaluation points and columns = basis functions. Entry <code>N[j, i]</code> is \\(N_{i,k}(x_j)\\).</li> </ul> <p>Raises / Assumptions</p> <ul> <li><code>ValueError</code> if <code>k &gt; len(t) - 2</code>.</li> <li>Assumes <code>t</code> is non-decreasing. If many knots are identical, the corresponding denominators are zero and the code returns 0 for those fractions (as desired).</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#notes-properties-useful-facts","title":"Notes &amp; properties (useful facts)","text":"<ul> <li>Local support: \\(N_{i,k}(x)\\) is nonzero only on the interval \\([t_i,\\,t_{i+k+1}]\\). Hence each row of <code>N</code> has at most <code>k+1</code> nonzeros.</li> <li> <p>Partition of unity: for \\(x\\) strictly inside the knot span, \\(\\sum_i N_{i,k}(x)=1\\). At exact knot locations the right-closed convention assigns the mass to the right interval:</p> </li> <li> <p>At \\(x = t_0\\): all zeros (no interval to the left),</p> </li> <li>At \\(x = t_{m-1}\\): the last basis evaluates to 1.</li> <li>Continuity: with simple knots (no repetition), splines are \\(C^{k-1}\\). A knot of multiplicity <code>r</code> reduces continuity to \\(C^{k-r}\\).</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#when-to-use-and-examples_2","title":"When to use and examples","text":"<p>Use B-splines when you need smooth, local-control interpolation/approximation with tunable continuity via the knot vector\u2014ideal for smooth paths, potentials, or any 1D field where you want stability and partition-of-unity behavior.</p> <p>see the full test script in tests/helper_functions/Interpolation_functions for more</p> <p>Examples</p> <ul> <li>B-spline bases: partition of unity, non-negativity, local support</li> </ul> <pre><code>\"\"\"\"\n=== Test 3: B-spline bases (partition of unity &amp; local support) ===\nknots =  [0.  0.  0.  0.  0.2 0.4 0.6 0.8 1.  1.  1.  1. ]\nPartition of unity: max|sum_i N_i(x)-1| = 1.0\nNon-negativity: min(N) = 0.0  (should be &gt;= 0)\n\"\"\"\n</code></pre> <p></p> <p>What the figure shows:</p> <ul> <li>Partition of unity: at every <code>x</code>, the colored curves sum to 1 (visually, one \u201cstack\u201d fills the unit height).</li> <li>Non-negativity: each basis is \u2265 0.</li> <li> <p>Local support: at any <code>x</code> only <code>k+1=4</code> curves are nonzero (for cubic). This is why changing one coefficient <code>c_i</code> only affects a small neighborhood in the final spline.</p> </li> <li> <p>Exact interpolation via <code>N($x_i$) c = y</code> (Greville collocation)</p> </li> </ul> <pre><code>f  = lambda x: np.sin(2*np.pi*x) + 0.2*x\ny  = f(Xi)\n\n# Square collocation system (nb x nb)\nN_colloc = Nbspl(t, Xi, k=k)\nc = np.linalg.solve(N_colloc, y)             # exact at Xi\n\n# Evaluate on a fine grid\nxf = np.linspace(0, 1, 600)\nNf = Nbspl(t, xf, k=k)\nSf = Nf @ c\n\"\"\"\n=== Test 5: Exact interpolation via B-splines (solve for coefficients) ===\nMax residual at collocation points (should be ~1e-12): 2.220e-16\nMax abs error on fine grid (approx. quality, not necessarily tiny): 2.234e-03\n\"\"\"\n</code></pre> <p></p> <p>What the figure shows (caption/notes):</p> <ul> <li>The red dashed spline matches the black target exactly at the blue Greville points (interpolation).</li> <li> <p>Between collocation points the match is approximate (still very good here because we used 10 cubic bases on <code>[0,1]</code>).</p> </li> <li> <p>For exact interpolation, use Greville points to build a square, well-conditioned system and solve <code>N @ c = y</code>.</p> </li> <li>For fitting/denoising, solve <code>min_c ||N c \u2212 y||</code> (possibly with a smoothness regularizer).</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#nbspld1","title":"<code>Nbspld1</code>","text":""},{"location":"modules/helper_functions/interpolation_functions/#signature_4","title":"Signature","text":"<pre><code>Nbspld1(t: np.ndarray, x: np.ndarray, k: int = 3) -&gt; Tuple[np.ndarray, np.ndarray]\n</code></pre>"},{"location":"modules/helper_functions/interpolation_functions/#purpose_4","title":"Purpose","text":"<p>Same idea as <code>Nbspl</code>, but also returns the first derivatives of the degree-<code>k</code> B-spline basis with respect to <code>x</code>.  Internally it builds and caches all bases up to degree <code>k</code>, then uses the closed-form derivative:</p> \\[\\frac{d}{dx}N_{i,k}(x) = \\frac{k}{t_{i+k}-t_i}\\,N_{i,k-1}(x) - \\frac{k}{t_{i+k+1}-t_{i+1}}\\,N_{i+1,k-1}(x) \\] <p>with the convention that any term with zero denominator contributes 0 (repeated knots).</p>"},{"location":"modules/helper_functions/interpolation_functions/#parameters-returns-and-raises_3","title":"Parameters, returns and Raises","text":"<p>Parameters \u2014 same as <code>Nbspl(t, x, k)</code>.</p> <p>Returns</p> <ul> <li><code>N</code>  (<code>ndarray</code>, shape <code>(n, m-k-1)</code>): basis values \\(N_{i,k}(x_j)\\).</li> <li><code>dN</code> (<code>ndarray</code>, shape <code>(n, m-k-1)</code>): first derivatives \\(\\partial_x N_{i,k}(x_j)\\).</li> </ul> <p>Raises / Notes</p> <ul> <li><code>ValueError</code> if <code>k &gt; len(t) - 2</code>.</li> <li>Uses the same right-closed seed for the degree-0 basis as <code>Nbspl</code>.</li> <li>At clamped ends (<code>open</code> knots), derivatives near the extreme knots are well-defined but finite-difference checks must avoid crossing the boundary row (see fix below).</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#nbspld2","title":"<code>Nbspld2</code>","text":""},{"location":"modules/helper_functions/interpolation_functions/#signature_5","title":"Signature","text":"<pre><code>Nbspld2(t: np.ndarray, x: np.ndarray, k: int = 3) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]\n</code></pre>"},{"location":"modules/helper_functions/interpolation_functions/#purpose_5","title":"Purpose","text":"<p>As above, but also returns the second derivatives. It first computes all first-derivative tables for degrees <code>0..k</code>, then applies the same closed-form again on <code>dN_{*,k-1}</code>:</p> \\[\\frac{d^2}{dx^2}N_{i,k}(x)= \\frac{k}{t_{i+k}-t_i}\\,\\frac{d}{dx}N_{i,k-1}(x)- \\frac{k}{t_{i+k+1}-t_{i+1}}\\,\\frac{d}{dx}N_{i+1,k-1}(x), \\] <p>with the same zero-denominator convention.</p>"},{"location":"modules/helper_functions/interpolation_functions/#parameters-returns-and-raises_4","title":"Parameters, returns and Raises","text":"<p>Parameters \u2014 same as <code>Nbspl</code>.</p> <p>Returns</p> <ul> <li><code>N</code>   (<code>ndarray</code>, shape <code>(n, m-k-1)</code>): basis values.</li> <li><code>dN</code>  (<code>ndarray</code>, shape <code>(n, m-k-1)</code>): first derivatives.</li> <li><code>d2N</code> (<code>ndarray</code>, shape <code>(n, m-k-1)</code>): second derivatives.</li> </ul> <p>Raises / Notes</p> <ul> <li><code>ValueError</code> if <code>k &gt; len(t) - 2</code>.</li> <li>For <code>k=0</code> or <code>k=1</code>, the second derivative is identically 0 (as expected).</li> </ul>"},{"location":"modules/helper_functions/interpolation_functions/#examples","title":"Examples","text":"<p>see the full test script in tests/helper_functions/Interpolation_functions for more</p> <ul> <li>Basis Functions derivatives (first and second)</li> </ul> <pre><code>\"\"\"\n=== Test 4: dN/dx and d\u00b2N/dx\u00b2 vs finite differences (sanity) ===\nMax |dN - FD|  = 1.374e-03\nMax |d2N - FD| = 3.208e-01\nExpected: small (method consistent); edges less accurate (central FD not applicable).\n\"\"\"\n</code></pre> <p></p> <ul> <li>Basis Functions with repeated knots (reduce smoothness)</li> </ul> <pre><code>\"\"\"\n=== Test 6: Repeated interior knot reduces smoothness (see jump in derivatives) ===\nInterior knot at x\u22480.5: left slope=-11.423134, right slope=-11.644709\nExpected: visible change in slope at the repeated knot (reduced continuity).\n\"\"\"\n</code></pre> <p></p> <pre><code>\"\"\"\n=== Test 7: Expected error cases ===\nk too large (Nbspl): Nbspl: require k &lt;= len(t)-2\nx not 1D (may raise/behave unexpectedly): ValueError('operands could not be broadcast together with shapes (2,1,3) (9,) ')\nknot length invalid (Nbspl): Nbspl: require k &lt;= len(t)-2\n\n(Equal for Nbspl, Nbspld1 and Nbspld2)\n\"\"\"\n</code></pre>"},{"location":"modules/transitionFinder/tests_transitionFinder/","title":"tests Transition Finder","text":"<p>This document summarizes the tutorial-style tests for the <code>transitionFinder</code> module, focusing on the visual outputs (plots) and the physical intuition behind them.</p> <p>The goal is that, by reading this file and looking at the figures, a user can understand what the Block A primitives (<code>traceMinimum</code>, <code>Phase</code>, <code>traceMultiMin</code>, <code>findApproxLocalMin</code>, <code>removeRedundantPhases</code>, <code>getStartPhase</code>) are doing in a concrete, finite-temperature scalar-field model.</p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#block-a-landauginzburg-toy-model-and-phase-tracing","title":"Block A \u2013 Landau\u2013Ginzburg toy model and phase tracing","text":"<p>All tests in Block A use the same 1D finite-temperature potential</p> \\[ V(\\phi, T) = D (T^2 - T_0^2)\\phi^2 - ET\\phi^3 + \\frac{\\lambda}{4}\\phi^4 \\] <p>with \\(D &gt; 0\\), \\(\\lambda &gt; 0\\), and a small cubic term \\(E &gt; 0\\). This is the standard Landau\u2013Ginzburg toy model for a first-order phase transition:</p> <ul> <li>At high temperature, there is a unique minimum at \\(\\phi = 0\\) (symmetric phase).</li> <li>At lower temperature, non-trivial minima at \\(\\phi \\neq 0\\) appear   (broken phase).</li> <li>In an intermediate range, symmetric and broken phases coexist, separated by a barrier.</li> <li>Below a spinodal temperature, the symmetric minimum disappears.</li> </ul> <p>The tests are organized to show how Block A routines reconstruct this structure.</p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#test-1-potential-shape-and-minima-at-high-and-low-temperature","title":"Test 1 \u2013 Potential shape and minima at high and low temperature","text":"<p>Script: <code>test_blockA_1_potential_shape_and_minima</code></p> <p>What it does</p> <ul> <li>Evaluates \\(V(\\phi, T)\\) on a grid in \\(\\phi\\) for two temperatures:</li> <li>\\(T_\\text{high} = 200\\) (well above \\(T_0\\)),</li> <li>\\(T_\\text{low} = 50\\) (well below \\(T_0\\)).</li> <li>Finds numerically:</li> <li>the minimum near \\(\\phi \\simeq 0\\) at high T,</li> <li>the broken minimum at low T.</li> <li>Checks the curvature \\(m^2 = d^2V/d\\phi^2\\) at these points to verify stability.</li> </ul> <p>Expected plot</p> <p>A single figure with two curves:</p> <ul> <li>Horizontal axis: \\(\\phi\\).</li> <li>Vertical axis: \\(V(\\phi, T)\\).</li> <li>Curves:</li> <li>\\(V(\\phi, T_\\text{high})\\): single well at \\(\\phi \\approx 0\\).</li> <li>\\(V(\\phi, T_\\text{low})\\): double-well structure with a deeper minimum at \\(\\phi \\neq 0\\).</li> </ul> <p>What to look for</p> <ul> <li>At high T:</li> <li>the curve has a single minimum at (or extremely close to) \\(\\phi = 0\\).</li> <li>At low T:</li> <li>the origin becomes unstable (local maximum or shallow region),</li> <li>a new broken minimum appears at \\(\\phi &gt; 0\\).</li> </ul> <p>Placeholder for figure</p> <p></p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#test-2-traceminimum-on-the-symmetric-phase-descending-in-t","title":"Test 2 \u2013 <code>traceMinimum</code> on the symmetric phase (descending in T)","text":"<p>Script: <code>test_blockA_2_traceMinimum_symmetric_phase_downwards</code></p> <p>What it does</p> <ul> <li> <p>Starts from the symmetric minimum:</p> </li> <li> <p>initial condition: \\(\\phi = 0\\) at (T = 200).</p> </li> <li>Uses <code>traceMinimum</code> to follow this minimum downwards in temperature until it   becomes unstable.</li> <li> <p>Records:</p> </li> <li> <p>the temperature grid <code>T</code>,</p> </li> <li>the traced minimum \\(\\phi_{\\min}(T)\\),</li> <li>the curvature \\(m^2(T) = \\frac{d^2V}{d\\phi^2}|_{\\phi_{\\min}(T)}\\).</li> <li>Compares the numerically extracted spinodal temperature <code>res.overT</code> with the   analytic spinodal (for the symmetric phase) at \\(T_\\text{spin} = T_0\\).</li> </ul> <p>Expected plots</p> <ol> <li> <p>Symmetric branch \\(\\phi_{\\min}(T)\\)</p> </li> <li> <p>Horizontal axis: (T).</p> </li> <li>Vertical axis: \\(\\phi_{\\min}(T)\\).</li> <li>Markers along the traced points from <code>traceMinimum</code>.</li> <li>Vertical dashed line at \\(T = T_0\\) (analytic spinodal).</li> </ol> <p>Behaviour:</p> <ul> <li>\\(\\phi_{\\min}(T)\\) should stay very close to 0 at all temperatures where      the symmetric minimum exists.</li> <li> <p>Near \\(T \\approx T_0\\), the branch ends (spinodal).</p> </li> <li> <p>Curvature \\(m^2(T)\\) along the symmetric trace</p> </li> <li> <p>Horizontal axis: (T).</p> </li> <li>Vertical axis: \\(m^2(T) = d^2V/d\\phi^2|_{\\phi_{\\min}(T)}\\).</li> <li>A horizontal line at \\(m^2 = 0\\) indicating the stability threshold.</li> </ul> <p>Behaviour:</p> <ul> <li>For \\(T \\gg T_0\\), \\(m^2 &gt; 0\\): the symmetric minimum is stable.</li> <li>As \\(T \\to T_0\\), \\(m^2 \\to 0\\).</li> <li>This signals the spinodal point where the symmetric phase loses stability.</li> </ul> <p>Placeholders for figures</p> <p></p> <p></p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#test-3-traceminimum-on-the-broken-phase-ascending-in-t","title":"Test 3 \u2013 <code>traceMinimum</code> on the broken phase (ascending in T)","text":"<p>Script: <code>test_blockA_3_traceMinimum_broken_phase_upwards</code></p> <p>What it does</p> <ul> <li> <p>First finds a broken minimum at low temperature:</p> </li> <li> <p>\\(\\phi_b(T=50)\\) via a 1D minimization.</p> </li> <li>Uses <code>traceMinimum</code> starting from \\(\\phi_b(50)\\) at (T = 50), and follows this   broken minimum upwards in temperature.</li> <li>Records the branch until the broken phase disappears or becomes unstable.</li> <li>Computes the curvature \\(m^2(T)\\) along the broken branch.</li> </ul> <p>Expected plot</p> <ol> <li> <p>Broken branch \\(\\phi_{\\min}(T)\\)</p> </li> <li> <p>Horizontal axis: (T).</p> </li> <li>Vertical axis: \\(\\phi_{\\min}(T)\\) for the broken phase.</li> <li>A horizontal line at \\(\\phi = 0\\).</li> </ol> <p>Behaviour:</p> <ul> <li>At low T, \\(\\phi_{\\min}(T)\\) is significantly away from 0      (spontaneous symmetry breaking).</li> <li>As T increases, \\(|\\phi_{\\min}(T)|\\) decreases, tending towards 0 as you      approach the region where the symmetric phase dominates.</li> <li>The branch ends near the broken-phase spinodal temperature <code>res.overT</code>.</li> </ul> <p>Placeholder for figure</p> <p></p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#test-5-tracemultimin-and-phase-global-phase-structure","title":"Test 5 \u2013 <code>traceMultiMin</code> and <code>Phase</code>: global phase structure","text":"<p>Script: <code>test_blockA_5_traceMultiMin_and_Phase_structure</code></p> <p>What it does</p> <ul> <li> <p>Builds the phase structure in the interval \\(T \\in [50, 200]\\) using:</p> </li> <li> <p>seeds at \\((\\phi = 0, T = 200)\\) (symmetric),</p> </li> <li> <p>and \\((\\phi_b(T=50), T = 50)\\) (broken).</p> </li> <li> <p>Runs <code>traceMultiMin</code> to trace all minima that arise from these seeds, and   then <code>removeRedundantPhases</code> to clean up duplicates.</p> </li> <li> <p>Constructs <code>Phase</code> objects for each branch and checks that:</p> </li> <li> <p>there is exactly one symmetric-like phase (with \\(\\phi \\approx 0\\) at high T),</p> </li> <li> <p>at least one broken-like phase.</p> </li> <li> <p>Uses <code>getStartPhase</code> to identify the high-temperature phase.</p> </li> <li> <p>For each <code>Phase</code>, compares the spline-based <code>valAt(T)</code> with a direct   minimization of \\(V(\\phi, T)\\) at a few T values (sanity check).</p> </li> </ul> <p>Expected plot</p> <p>Phase structure: \\(\\phi_{\\min}(T)\\) from <code>Phase</code> splines</p> <ul> <li>Horizontal axis: (T).</li> <li>Vertical axis: \\(\\phi_{\\min}(T)\\).</li> <li>One curve per <code>Phase</code> object, plotted as a function of T over its domain.</li> </ul> <p>Behaviour:</p> <ul> <li> <p>A symmetric branch:</p> </li> <li> <p>stays near \\(\\phi \\approx 0\\) over a wide range of temperatures,</p> </li> <li>is present at the highest T.</li> <li> <p>A broken branch:</p> </li> <li> <p>exists at lower T with \\(\\phi \\neq 0\\),</p> </li> <li>bends towards \\(\\phi \\to 0\\) as T increases,</li> <li>terminates at its own spinodal.</li> </ul> <p>This plot is the closest thing to a \u201cphase diagram in T\u201d in Block A: it shows how each phase\u2019s vacuum expectation value evolves with temperature.</p> <p>Placeholder for figure</p> <p></p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#test-6-findapproxlocalmin-on-a-simple-segment","title":"Test 6 \u2013 <code>findApproxLocalMin</code> on a simple segment","text":"<p>Script: <code>test_blockA_6_findApproxLocalMin_on_simple_segment</code></p> <p>What it does</p> <ul> <li> <p>Focuses on a fixed temperature \\(T = 150 &gt; T_0\\), where the potential has a   unique minimum at \\(\\phi = 0\\).</p> </li> <li> <p>Considers a straight segment in field space:</p> </li> </ul> \\[\\phi \\in [-3, +3]\\] <p>and calls <code>findApproxLocalMin</code> along this segment.</p> <ul> <li><code>findApproxLocalMin</code> samples the segment, looks for discrete local minima in   \\(V(\\phi, T)\\), and returns approximate positions of minima between the   segment endpoints.</li> </ul> <p>Expected plot</p> <p>Potential along the segment and found approximate minima</p> <ul> <li>Horizontal axis: \\(\\phi\\).</li> <li>Vertical axis: \\(V(\\phi, T)\\) for fixed (T = 150).</li> <li>Curve: \\(V(\\phi, 150)\\) over \\(\\phi \\in [-3, 3]\\).</li> <li>Markers: positions returned by <code>findApproxLocalMin</code> (approximate minima).</li> </ul> <p>Behaviour:</p> <ul> <li>The curve should be a single well centred at \\(\\phi = 0\\).</li> <li><code>findApproxLocalMin</code> should identify minima very close to \\(\\phi = 0\\).</li> <li>If it finds more than one minimum, they should cluster around the origin,   reflecting the discrete sampling.</li> </ul> <p>Placeholder for figure</p> <p></p> <p>If you want to see the full test script of this block go to tests/transitionFInder</p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#block-b-tunneling-core-bounce-solutions-and-nucleation","title":"Block B \u2013 Tunneling core: bounce solutions and nucleation","text":"<p>In Block A we only described where the phases lie along \\(T\\). Block B goes one level deeper: given this phase panorama, what does the theory do with it? It tunnels.</p> <p>Here we test exactly that:</p> <ul> <li>how to identify the critical temperature at which two phases become   degenerate;</li> <li>how to solve the 1D bounce corresponding to a false \u2192 true tunnel;</li> <li>how to stitch everything into a high-level function that provides the   nucleation temperature with the standard criterion   \\(S_3(T_n)/T_n \\simeq 140\\).</li> </ul> <p>All tests still use the same Landau\u2013Ginzburg potential from Block A, so that we can connect directly:</p> <p>\u201cThis phase curve I saw in Block A is the same one that is now nucleating a bubble with some action at \\(T_n\\).\u201d</p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#test-b1-critical-temperature-and-free-energy-differences","title":"Test B1 \u2013 Critical temperature and free-energy differences","text":"<p>Script: <code>test_blockB_1_potential_diff_and_Tcrit</code></p> <p>Physical goal</p> <p>Given a <code>start_phase</code> (here, the symmetric high-temperature phase), we want to identify the temperature at which some other phase becomes energetically degenerate with it:</p> \\[ \\Delta V(T) \\equiv V_\\text{other}(T) - V_\\text{start}(T) = 0. \\] <p>This point defines a critical temperature for that phase \u2014 the boundary where it ceases to be the most favorable in free energy.</p> <p>What the test does</p> <ol> <li>Builds the phases with <code>traceMultiMin</code> (as in Block A) and identifies the    high-\\(T\\) phase with <code>getStartPhase</code>.</li> <li>Uses <code>_maxTCritForPhase</code> to find the temperature \\(T_\\text{crit}\\)    at which the <code>start_phase</code> ties with some competing phase.</li> <li>Evaluates <code>_potentialDiffForPhase(T, start_phase, other_phases, V)</code> at    \\(T_\\text{crit}\\) to check that \\(\\Delta V(T_\\text{crit}) \\approx 0\\).</li> <li>Scans an interval in \\(T\\) and plots \\(\\Delta V(T)\\), marking the point    where it crosses zero.</li> </ol> <p>Interpretation</p> <ul> <li>For \\(T &gt; T_\\text{crit}\\) we expect \\(\\Delta V(T) &gt; 0\\):   the starting phase is still energetically preferred.</li> <li>For \\(T &lt; T_\\text{crit}\\) some other minimum is deeper:   the starting phase becomes metastable or unstable.</li> <li>The test numerically ensures that:</li> </ul> <pre><code>DV(Tcrit) = V(other) - V(start) \u2248 0\n Critical temperature T_c  \u2248 102.0621\n\u0394V(T_c) = V(other) - V(start) \u2248 3.5406e-01 (should be ~ 0)\n</code></pre> <p>within the specified tolerance.</p> <p>Expected plot</p> <ul> <li>Horizontal: \\(T\\)</li> <li>Vertical: \\(\\Delta V(T) = V_\\text{other} - V_\\text{start}\\).</li> <li>A smooth curve \\(\\Delta V(T)\\) crossing the zero axis.</li> <li>A horizontal line at \\(\\Delta V = 0\\).</li> <li>A vertical line at \\(T = T_\\text{crit}\\).</li> </ul> <p>Visually, you are seeing the moment when the two phases \u201ctie\u201d in free energy.</p> <p>Placeholder for figure</p> <p></p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#test-b2-_solve_bounce-in-a-1d-metastable-configuration","title":"Test B2 \u2013 <code>_solve_bounce</code> in a 1D metastable configuration","text":"<p>Script: <code>test_blockB_2_solve_bounce_single_field_example</code></p> <p>Physical goal</p> <p>Before using the full nucleation machinery, we want to look closely at the numerical core: given a false vacuum and a true vacuum in 1D, does the backend <code>_solve_bounce</code> actually find a bounce with finite action?</p> <p>More concretely, we look for a \\(T\\) such that:</p> <ul> <li>\\(\\phi = 0\\) is still a local minimum (metastable),</li> <li>there exists a deeper minimum at \\(\\phi = \\phi_\\text{true} &gt; 0\\),</li> <li>the two are separated by a barrier.</li> </ul> <p>This is the classic scenario for a first-order tunnel.</p> <p>What the test does</p> <ol> <li> <p>Scans \\(T\\) values slightly above \\(T_0\\) until it finds:</p> </li> <li> <p>\\(m^2(\\phi=0,T) &gt; 0\\) (positive curvature \u2192 local minimum),</p> </li> <li> <p>an analytic minimum \\(\\phi_\\text{true} &gt; 0\\) with      \\(V(\\phi_\\text{true},T) &lt; V(0,T)\\).</p> </li> <li> <p>Defines:</p> </li> <li> <p><code>x_high = [0.0]</code> as the false vacuum,</p> </li> <li> <p><code>x_low = [phi_true]</code> as the true vacuum.</p> </li> <li> <p>Builds scalar wrappers:</p> </li> </ol> <pre><code>def V_fixed(x): return V(x, T_test)\ndef dV_fixed(x): return dV_dphi(x, T_test)\n</code></pre> <ol> <li> <p>Calls <code>_solve_bounce(...)</code>, which internally:</p> </li> <li> <p>tries to use <code>pathDeformation</code> if available,</p> </li> <li> <p>otherwise falls back to <code>tunneling1D.SingleFieldInstanton</code> in the 1D direction.</p> </li> <li> <p>Checks that:</p> </li> <li> <p><code>trantype == 1</code> (first-order transition),</p> </li> <li>the returned <code>action</code> is finite and positive,</li> <li> <p>a valid <code>instanton</code> object is returned.</p> </li> <li> <p>Plots the potential at \\(T_\\text{test}\\) with both minima highlighted.</p> </li> </ol> <p>Interpretation</p> <ul> <li> <p>If <code>trantype = 1</code> and <code>action &gt; 0</code>:</p> </li> <li> <p>the backend successfully solved the bounce equation with the correct     boundary conditions,</p> </li> <li> <p>the result is consistent with the physical interpretation of a     false \u2192 true tunnel.</p> </li> <li> <p>This is the local check that SingleFieldInstanton is really delivering   a physical solution for the test potential.</p> </li> </ul> <p>Expected plot</p> <ul> <li>Horizontal: \\(\\phi\\) (region between \\(0\\) and slightly above   \\(\\phi_\\text{true}\\)).</li> <li>Vertical: \\(V(\\phi, T_\\text{test})\\).</li> <li>Curve: \\(V(\\phi, T_\\text{test})\\).</li> <li> <p>Vertical lines marking:</p> </li> <li> <p>\\(\\phi = 0\\): false vacuum,</p> </li> <li>\\(\\phi = \\phi_\\text{true}\\): true vacuum.</li> </ul> <p>This plot lets you see the \u201clandscape\u201d in which the bounce lives: two basins separated by a little hill (the barrier).</p> <p>Placeholder for figure</p> <p></p> <p>Space for important prints</p> <p>Importants Terminal output:</p> <pre><code>  Chosen T_test = 100.2000\n  V(false, T_test) at phi=0         = 0.0000e+00\n  V(true,  T_test) at phi=58.7571 = -9.4718e+04\n  m^2(phi=0, T_test) = 8.0080e+00 (&gt; 0 \u21d2 metastable origin)\n  _solve_bounce returned trantype = 1\n  Bounce action S3(T_test)        \u2248 2.9944e+01\n  instanton object type           = &lt;class 'CosmoTransitions.tunneling1D.SingleFieldInstanton'&gt;\n</code></pre> <p>to reinforce that the scenario is genuinely metastable with a nontrivial bounce.</p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#test-b3-tunnelfromphase-and-the-nucleation-temperature-t_n","title":"Test B3 \u2013 <code>tunnelFromPhase</code> and the nucleation temperature \\(T_n\\)","text":"<p>Script: <code>test_blockB_3_tunnelFromPhase_default_criterion</code></p> <p>Physical goal</p> <p>Now we use the high-level tool <code>tunnelFromPhase</code> to:</p> <ul> <li> <p>take the phase panorama from Block A,</p> </li> <li> <p>search in \\(T\\) for possible bounces between the symmetric and broken phases,</p> </li> <li> <p>apply a nucleation criterion of the form</p> </li> </ul> \\[\\text{nuclCriterion}(S_3(T), T)= \\frac{S_3(T)}{T} - 140 \\approx 0\\] <ul> <li>and identify the nucleation temperature \\(T_n\\).</li> </ul> <p>In other words: here we see the passage \u201cmetastable phase + bounce \u2192 cosmological phase transition\u201d.</p> <p>What the test does</p> <ol> <li> <p>Reconstructs the phases with <code>_build_phases()</code> and uses <code>getStartPhase</code> to    take the high-\\(T\\) symmetric phase as <code>start_phase</code>.</p> </li> <li> <p>Calls <code>tunnelFromPhase(...)</code> with:</p> </li> <li> <p><code>V</code>, <code>dV_dphi</code>,</p> </li> <li><code>Tmax \u2243 200</code>,</li> <li><code>overlapAngle = 45\u00b0</code> (pruning of nearly collinear directions in field      space),</li> <li> <p>explicit nucleation criterion \\(S_3/T - 140\\).</p> </li> <li> <p><code>tunnelFromPhase</code> internally:</p> </li> <li> <p>scans temperatures between the lower bound of the phase and <code>Tmax</code>      looking for bounce solutions via <code>_tunnelFromPhaseAtT</code>,</p> </li> <li>at each \\(T\\), uses <code>_solve_bounce</code> (which in turn uses <code>pathDeformation</code>      or <code>SingleFieldInstanton</code>),</li> <li> <p>stores in a dictionary <code>outdict[T]</code> the best (lowest-action) bounce      found.</p> </li> <li> <p>If it finds a first-order transition (<code>trantype == 1</code>):</p> </li> <li> <p>it returns a dictionary with:</p> <ul> <li><code>Tnuc</code>,</li> <li><code>low_vev</code>, <code>high_vev</code>,</li> <li><code>low_phase</code>, <code>high_phase</code>,</li> <li><code>action</code> (i.e. \\(S_3(T_n)\\)),</li> <li><code>instanton</code> (object from the bounce routine).</li> </ul> </li> <li> <p>The test then:</p> </li> <li> <p>prints \\(T_n\\), \\(S_3(T_n)\\) and \\(S_3(T_n)/T_n\\),</p> </li> <li>checks that <code>trantype == 1</code>,</li> <li>verifies that \\(S_3/T\\) is close to \\(140\\) (it need not be millimetric),</li> <li>compares \\(T_n\\) with \\(T_\\text{crit}\\) from Test B1, requiring      \\(T_n \\lesssim T_\\text{crit}\\)      (moderate supercooling, as expected in a first-order transition),</li> <li> <p>checks that, at \\(T_n\\), the \u201clow\u201d phase indeed has smaller free energy      than the \u201chigh\u201d one.</p> </li> <li> <p>For visual intuition, it plots the potential at \\(T = T_n\\) with both    minima marked.</p> </li> </ol> <p>Interpretation</p> <ul> <li> <p><code>tunnelFromPhase</code> is the \u201cglue\u201d between:</p> </li> <li> <p>phase vs. \\(T\\) information (Block A),</p> </li> <li>bounce solving (SingleFieldInstanton / pathDeformation),</li> <li> <p>cosmological nucleation criterion (here, \\(S_3/T \\sim 140\\)).</p> </li> <li> <p>The test shows that:</p> </li> <li> <p>the code finds a \\(T\\) where the bounce is efficient enough to satisfy     the criterion;</p> </li> <li>this temperature is indeed below the critical degeneracy temperature;</li> <li>at \\(T_n\\), the \u201clow\u201d minimum is physically the true one (smaller     free energy).</li> </ul> <p>Expected plot</p> <ul> <li>Horizontal: \\(\\phi\\) in the neighborhood of both minima at \\(T_n\\).</li> <li>Vertical: \\(V(\\phi, T_n)\\).</li> <li>Curve: \\(V(\\phi, T_n)\\).</li> <li> <p>Vertical lines marking:</p> </li> <li> <p><code>high_vev</code> (false vacuum),</p> </li> <li><code>low_vev</code> (true vacuum).</li> </ul> <p>This is the analogue of Test B2, but now at the \u201cspecial\u201d temperature \\(T_n\\) defined by the nucleation criterion instead of an arbitrary \\(T\\).</p> <p>Placeholder for figure</p> <p></p> <p>Space for important prints</p> <p>It is worth recording something like:</p> <pre><code> --- tunnelFromPhase result ---\n  T_nuc              \u2248 101.8969\n  S3(T_nuc)          \u2248 14191.6326\n  S3(T_nuc) / T_nuc  \u2248 139.2744\n  low_phase key      = 0\n  high_phase key     = 1\n  trantype           = 1 (1 = first order)\n  S3/T - 140 \u2248 -0.726\n  Critical temperature T_crit \u2248 102.0621\n  We expect T_nuc &lt; T_crit for a supercooled first-order transition.\n  V(false, T_nuc) at phi=-0.0000 = 1.2320e-35\n  V(true,  T_nuc) at phi=43.5502  = -5.7643e+03\n</code></pre> <p>to illustrate numerically:</p> <ul> <li>how close \\(S_3/T\\) is to \\(140\\),</li> <li>how far below \\(T_\\text{crit}\\) the \\(T_n\\) sits,</li> <li>and that the \u201clow\u201d phase is indeed the energetically favored one.</li> </ul>"},{"location":"modules/transitionFinder/tests_transitionFinder/#demo-alternative-nucleation-criterion-pedagogical-example","title":"Demo \u2013 Alternative nucleation criterion (pedagogical example)","text":"<p>Functions: <code>ew_like_nuclCriterion</code>, <code>demo_blockB_alternative_nucleation_criterion</code></p> <p>Besides the tests, the file includes a non-pytest demo that shows how to replace the standard nucleation criterion with another one, for example:</p> \\[ \\frac{S_3(T)}{T} = 4 \\ln\\left(\\frac{M_\\text{eff}}{T}\\right) \\] <p>with some arbitrary scale \\(M_\\text{eff}\\). The goal here is not to be realistic for the toy model, but rather to:</p> <ul> <li>show the signature that <code>nuclCriterion(S,T)</code> must have;</li> <li>illustrate how the choice of criterion can shift \\(T_n\\).</li> </ul> <p>The function <code>demo_blockB_alternative_nucleation_criterion()</code>:</p> <ol> <li>calls <code>tunnelFromPhase</code> with the standard criterion \\(S/T - 140\\);</li> <li>calls it again with <code>ew_like_nuclCriterion</code>;</li> <li>prints both \\(T_n\\) values and both \\(S_3/T\\) values, allowing a comparison.</li> </ol> <p>This demo is useful as a template for plugging in your favorite nucleation criterion without touching the main code.</p> <p>If you want to see the full script for these tests (Block B), see tests/transitionFinder</p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#block-c-transition-history-from-phase-structure-to-cosmic-history","title":"Block C \u2013 Transition history: from phase structure to cosmic history","text":"<p>Block C takes everything we built in Blocks A and B and pushes it one step further:</p> <ul> <li>From phase structure (<code>Phase</code> objects, traced minima),</li> <li>Plus tunneling information (bounce actions and nucleation temperatures),</li> <li>To a full thermal history: a sequence of phase transitions as the Universe cools.</li> </ul> <p>The central routines are:</p> <ul> <li><code>secondOrderTrans</code> \u2013 convenience wrapper for second-order transitions.</li> <li><code>findAllTransitions</code> \u2013 builds the actual transition history using bounces.</li> <li><code>findCriticalTemperatures</code> \u2013 finds all degeneracy temperatures <code>Tcrit</code>.</li> <li><code>addCritTempsForFullTransitions</code> \u2013 matches <code>Tcrit</code> to <code>Tnuc</code> to quantify supercooling.</li> </ul> <p>All tests in this block still use the same 1D Landau\u2013Ginzburg potential as Blocks A and B.</p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#test-0-secondordertrans-dictionary-layout-and-conventions","title":"Test 0 \u2013 <code>secondOrderTrans</code>: dictionary layout and conventions","text":"<p>Script: <code>test_blockC_0_secondOrderTrans_basic_structure</code></p> <p>What it does</p> <ul> <li> <p>Builds the phase structure using <code>traceMultiMin</code> (symmetric + broken branches).</p> </li> <li> <p>Picks two phases and constructs a \u201csecond-order transition\u201d dictionary by calling:</p> </li> </ul> <pre><code>tdict = secondOrderTrans(high_phase, low_phase, Tstr=\"Tnuc\")\n</code></pre> <ul> <li> <p>Checks that:</p> </li> <li> <p>The dictionary contains the expected keys: <code>Tnuc</code>, <code>high_vev</code>, <code>low_vev</code>,     <code>high_phase</code>, <code>low_phase</code>, <code>action</code>, <code>instanton</code>, <code>trantype</code>.</p> </li> <li><code>trantype == 2</code> (second order).</li> <li><code>action == 0.0</code> and <code>instanton is None</code> (no barrier, no bounce).</li> <li><code>Tnuc</code> is defined as the midpoint between the end of the high-T branch     and the start of the low-T branch:     $$     T_\\text{nuc} = \\tfrac12\\bigl(T_\\text{high}(T_0) + T_\\text{low}(T_\\text{end})\\bigr).     $$</li> <li><code>high_vev</code> and <code>low_vev</code> coincide with the high-T phase vev at its upper end.</li> </ul> <p>Physical intuition</p> <p>For a strictly second-order transition, there is no tunneling and no action; the order parameter changes continuously and the \u201ccritical temperature\u201d is where the curvature changes sign. <code>secondOrderTrans</code> encodes this in a simple dictionary so that second-order steps can live in the same pipeline as first-order (bounce-driven) transitions.</p> <p>Placeholder for output</p> <pre><code>[Block C / Test 0] secondOrderTrans: basic structure and fields\nTracing phase starting at x = [138.38962553], T = 50.0\n  Tracing minimum up in T\nTracing phase starting at x = [1.35525272e-19], T = 102.47832031250125\n  Tracing minimum down in T\n  Tracing minimum up in T\n  Constructed second-order transition dictionary:\n          Tnuc : 125.0\n       low_vev : [138.38962553]\n      high_vev : [138.38962553]\n     low_phase : 1\n    high_phase : 0\n        action : 0.0\n     instanton : None\n      trantype : 2\n</code></pre>"},{"location":"modules/transitionFinder/tests_transitionFinder/#test-1-findalltransitions-full-thermal-history-with-nucleation","title":"Test 1 \u2013 <code>findAllTransitions</code>: full thermal history with nucleation","text":"<p>Script: <code>test_blockC_1_findAllTransitions_full_history</code></p> <p>What it does</p> <ul> <li> <p>Rebuilds the phase structure (<code>Phase</code> objects) with <code>traceMultiMin</code>.</p> </li> <li> <p>Uses <code>getStartPhase(phases, V)</code> to identify the high-temperature phase.</p> </li> <li> <p>Calls</p> </li> </ul> <pre><code>transitions = findAllTransitions(phases, V, dV_dphi, tunnelFromPhase_args=...)\n</code></pre> <p>which internally:</p> <ol> <li>Starts from the high-T phase.</li> <li>Attempts tunneling via <code>tunnelFromPhase</code> to all lower-energy phases.</li> <li>Chooses the lowest-action transition and moves to that phase.</li> <li>Repeats from the new phase, stepping down in temperature, until no further      transitions occur.</li> <li> <p>Falls back to <code>secondOrderTrans</code> if there is a continuous (second-order) branch.</p> </li> <li> <p>Prints a compact table:</p> </li> <li> <p><code>idx</code> \u2013 index in the history (0 = earliest, highest T).</p> </li> <li><code>Tnuc</code> \u2013 nucleation temperature.</li> <li><code>type</code> \u2013 <code>1</code> (first order, tunneling) or <code>2</code> (second order).</li> <li><code>high_phase \u2192 low_phase</code> \u2013 phase labels.</li> <li> <p><code>S(Tnuc)</code> \u2013 bounce action at nucleation.</p> </li> <li> <p>Checks that:</p> </li> <li> <p>There is at least one transition.</p> </li> <li><code>Tnuc</code> is non-increasing along the history (Universe cools).</li> <li>Phase keys in the table are valid entries of the <code>phases</code> dictionary.</li> </ol> <p>Expected plot</p> <p>Phase structure with nucleation markers</p> <ul> <li> <p>Horizontal axis: <code>T</code>.</p> </li> <li> <p>Vertical axis: \\(\\phi_{\\min}(T)\\) for each <code>Phase</code>.</p> </li> <li> <p>For each phase:</p> </li> <li> <p>A smooth curve \\(\\phi_{\\min}(T)\\) from the spline representation.</p> </li> <li> <p>For each transition in <code>transitions</code>:</p> </li> <li> <p>A vertical line at <code>Tnuc</code>.</p> </li> <li>A circle marker at <code>(Tnuc, high_vev)</code>.</li> <li>A square marker at <code>(Tnuc, low_vev)</code>.</li> </ul> <p>What to look for</p> <ul> <li>At high T, the symmetric phase (\\(\\phi \\approx 0\\)) is occupied.</li> <li>As T decreases, at some <code>Tnuc</code> the code jumps from the symmetric branch   to the broken branch (or to another low-T phase).</li> <li>The printed <code>S(Tnuc)</code> values tell you whether nucleation happens close to the   \u201ccanonical\u201d criterion (e.g. <code>S/T \u2248 140</code>) or at a different strength,   depending on the chosen <code>nuclCriterion</code>.</li> </ul> <p>Placeholder for figure</p> <p></p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#test-2-findcriticaltemperatures-degeneracy-temperatures-tcrit","title":"Test 2 \u2013 <code>findCriticalTemperatures</code>: degeneracy temperatures <code>Tcrit</code>","text":"<p>Script: <code>test_blockC_2_findCriticalTemperatures_degeneracies</code></p> <p>What it does</p> <ul> <li> <p>Reuses the same <code>phases</code> dictionary.</p> </li> <li> <p>Calls</p> </li> </ul> <pre><code>crit_trans = findCriticalTemperatures(phases, V, start_high=False)\n</code></pre> <p>which:</p> <ul> <li>Loops over all ordered pairs of phases <code>(phase1, phase2)</code> with overlapping     temperature ranges.</li> <li>For each pair, defines</li> </ul> \\[\\Delta V(T) = V(\\phi_1(T), T) - V(\\phi_2(T), T),\\] <p>where \\(\\phi_i(T) = \\text{phase}_i.\\text{valAt}(T)\\).   * Uses a 1D root finder (<code>brentq</code>) to find <code>Tcrit</code> such that     \\(\\Delta V(Tcrit) = 0\\) whenever the sign of \\(\\Delta V\\) changes across the overlap.   * Assembles a dictionary</p> <pre><code>```text\n{\n  \"Tcrit\": Tcrit,\n  \"high_vev\": phase1.valAt(Tcrit),\n  \"low_vev\" : phase2.valAt(Tcrit),\n  \"high_phase\": phase1.key,\n  \"low_phase\" : phase2.key,\n  \"trantype\": 1,\n}\n```\n</code></pre> <ul> <li> <p>Prints a summary table:</p> </li> <li> <p><code>Tcrit</code>, <code>trantype</code>, <code>high_phase \u2192 low_phase</code>,</p> </li> <li>and the free-energy difference</li> </ul> \\[\\Delta V = V(\\phi_\\text{high}, T_\\text{crit}) - V(\\phi_\\text{low}, T_\\text{crit}),\\] <pre><code>which should be numerically close to zero.\n</code></pre> <ul> <li>Asserts that for each first-order entry <code>abs(\u0394V) &lt; 1e-3</code> (degeneracy).</li> </ul> <p>Physical interpretation</p> <p><code>findCriticalTemperatures</code> ignores dynamics and nucleation rates. It simply asks:</p> <p>For which temperatures do two phases have identical free energy?</p> <p>This is the equilibrium notion of a first-order transition line <code>Tcrit</code>, which is then compared with the actual nucleation temperature <code>Tnuc</code> in Test 3.</p> <p>Expected plot</p> <p>Phase structure with <code>Tcrit</code> markers</p> <ul> <li>Same background curves \\(\\phi_{\\min}(T)\\) for each <code>Phase</code>.</li> <li> <p>For each critical transition dictionary in <code>crit_trans</code>:</p> </li> <li> <p>A vertical dashed line at <code>Tcrit</code>.</p> </li> </ul> <p>This plot is the purely thermodynamic \u201cphase diagram in T\u201d: the vertical lines show where phases swap their free-energy ordering.</p> <p>Placeholder for figure</p> <p></p>"},{"location":"modules/transitionFinder/tests_transitionFinder/#test-3-addcrittempsforfulltransitions-matching-tcrit-and-tnuc","title":"Test 3 \u2013 <code>addCritTempsForFullTransitions</code>: matching <code>Tcrit</code> and <code>Tnuc</code>","text":"<p>Script: <code>test_blockC_3_addCritTemps_match_Tcrit_and_Tnuc</code></p> <p>What it does</p> <ul> <li> <p>Rebuilds <code>phases</code>.</p> </li> <li> <p>Computes:</p> </li> <li> <p><code>full_trans</code> = <code>findAllTransitions(...)</code>     \u2192 actual transition history with nucleation temperatures <code>Tnuc</code>.</p> </li> <li> <p><code>crit_trans</code> = <code>findCriticalTemperatures(...)</code>     \u2192 thermodynamic degeneracy temperatures <code>Tcrit</code>.</p> </li> <li> <p>Calls</p> </li> </ul> <pre><code>addCritTempsForFullTransitions(phases, crit_trans, full_trans)\n</code></pre> <p>which:</p> <ul> <li>Analyses the ancestry of phases (<code>parents_dict</code>) in terms of sequences of     critical transitions.</li> <li>For each full transition (nucleation step) in <code>full_trans</code>, searches for a     compatible critical transition in <code>crit_trans</code> (matching high/low branches     up to common parents).</li> <li> <p>Attaches the best match as <code>tdict[\"crit_trans\"]</code> (or <code>None</code> if no match).</p> </li> <li> <p>Prints a detailed table:</p> </li> <li> <p>For each full transition:</p> <ul> <li><code>type</code> (<code>trantype</code>),</li> <li><code>Tcrit</code> (if found),</li> <li><code>Tnuc</code>,</li> <li><code>\u0394T = Tcrit \u2212 Tnuc</code>,</li> <li>phase labels <code>high_phase \u2192 low_phase</code>.</li> </ul> </li> <li> <p>For first-order transitions with a matched <code>Tcrit</code>, checks that <code>Tcrit &gt;= Tnuc</code>   (you cannot nucleate before degeneracy).</p> </li> </ul> <p>Physical interpretation</p> <p>This test quantifies supercooling in a clean way:</p> <ul> <li><code>Tcrit</code> \u2013 the temperature at which phases are thermodynamically degenerate.</li> <li><code>Tnuc</code>  \u2013 the temperature at which bubbles actually nucleate efficiently.</li> <li><code>\u0394T = Tcrit \u2212 Tnuc</code> \u2013 how far below the equilibrium transition temperature   the Universe cools before tunneling kicks in.</li> </ul> <p>In strongly first-order transitions, <code>\u0394T</code> can be substantial, which is precisely what controls the strength of the phase transition and many gravitational-wave signatures.</p> <p>Expected plot</p> <p>Phase structure with both <code>Tcrit</code> and <code>Tnuc</code></p> <ul> <li> <p>Background: \\(\\phi_{\\min}(T)\\) curves for all phases.</p> </li> <li> <p>From <code>crit_trans</code>:</p> </li> <li> <p>Vertical dashed lines at each <code>Tcrit</code>.</p> </li> <li> <p>From <code>full_trans</code>:</p> </li> <li> <p>Vertical solid lines at each <code>Tnuc</code>.</p> </li> <li>Circle and square markers for <code>high_vev</code> and <code>low_vev</code> at <code>Tnuc</code>.</li> </ul> <p>What to look for</p> <ul> <li> <p>For each first-order transition:</p> </li> <li> <p>a dashed line at <code>Tcrit</code>,</p> </li> <li>a solid line (with markers) at <code>Tnuc</code>,</li> <li> <p>with <code>Tnuc</code> at or below <code>Tcrit</code> (supercooling or equality).</p> </li> <li> <p>The size of <code>\u0394T</code> gives you an immediate, visually intuitive measure of how   strong the supercooling is in this toy model.</p> </li> </ul> <p>Placeholder for figure</p> <p></p> <pre><code>[Block C / Test 2] findCriticalTemperatures \u2013 phase degeneracies\nTracing phase starting at x = [138.38962553], T = 50.0\n  Tracing minimum up in T\nTracing phase starting at x = [1.35525272e-19], T = 102.47832031250125\n  Tracing minimum down in T\n  Tracing minimum up in T\n  Number of critical-temperature transitions found: 1\n\n  Summary of critical transitions (sorted by decreasing Tcrit):\n    idx |  Tcrit   | type | high_phase -&gt; low_phase | \u0394V(high-low)\n    ----+----------+------+-------------------------+--------------\n      0 |  102.062 |  1   | 1 -&gt;        0 |    3.347e-10\n\n[Block C / Test 3] addCritTempsForFullTransitions \u2013 matching Tcrit and Tnuc\nTracing phase starting at x = [138.38962553], T = 50.0\n  Tracing minimum up in T\nTracing phase starting at x = [1.35525272e-19], T = 102.47832031250125\n  Tracing minimum down in T\n  Tracing minimum up in T\n  Number of full transitions: 1\n  Number of critical transitions: 1\n\n  Matching Tcrit and Tnuc for each full transition:\n    idx |  type |  Tcrit   |  Tnuc    |  \u0394T=Tcrit-Tnuc | high_phase -&gt; low_phase\n    ----+-------+----------+----------+----------------+------------------------\n      0 |  1    |  102.062 |  101.895 |          0.167 | 1 -&gt; 0\n\n[Block C] All example tests executed.\n</code></pre> <p>If you want to see the full Block C test script, including all prints and plots, see <code>tests/transitionFinder/Lot_C.py</code>.</p>"},{"location":"modules/transitionFinder/transitionFinder/","title":"Transition finder","text":""},{"location":"modules/transitionFinder/transitionFinder/#block-a-following-minima-and-building-phases","title":"Block A \u2014 Following minima and building phases","text":"<p>In this section we focus on the \u201ckinematics\u201d of phases as a function of temperature:</p> <ul> <li>what the code does numerically (so you can read it without fear), and</li> <li>what it means physically (as if a sharp physicist were staring at a phase diagram).</li> </ul> <p>We follow this order:</p> <ol> <li>Physical overview of the module.</li> <li><code>traceMinimum</code>.</li> <li><code>Phase</code>.</li> <li><code>traceMultiMin</code>.</li> <li><code>findApproxLocalMin</code>.</li> <li><code>_removeRedundantPhase</code> and <code>removeRedundantPhases</code>.</li> <li><code>getStartPhase</code>.</li> </ol>"},{"location":"modules/transitionFinder/transitionFinder/#1-physical-overview-of-the-module","title":"1. Physical overview of the module","text":"<p>Context: you have a finite-temperature effective potential \\(V(\\phi, T)\\) (written as \\(f(x,T)\\) in the code), possibly with several field components.</p> <ul> <li>For each fixed (T) there are local minima (phases) \u2014 some stable, some metastable.</li> <li> <p>As (T) changes:</p> </li> <li> <p>those minima move in field space,</p> </li> <li>some disappear (turn into saddles or spinodals),</li> <li>new minima can appear (new phases),</li> <li>in some temperature ranges two (or more) phases coexist and phase transitions become possible.</li> </ul> <p>The <code>transitionFinder</code> module bridges between:</p> <ul> <li>the microscopic potential \\(V(\\phi, T)\\), and</li> <li>the macroscopic phase history: which minima exist at each T, how they connect, and which are involved in 1st/2nd-order transitions.</li> </ul> <p>The pieces in Block A are:</p> <ul> <li><code>traceMinimum</code> + <code>Phase</code>: follow a single minimum as a function of temperature.</li> <li><code>traceMultiMin</code>: reconstruct all relevant phases in a given temperature interval and link them.</li> <li><code>findApproxLocalMin</code>: detect intermediate minima that may correspond to new phases.</li> <li><code>removeRedundantPhases</code>: \u201cdeduplicate\u201d multiple copies of the same phase.</li> <li><code>getStartPhase</code>: choose the high-temperature phase.</li> </ul> <p>Physically, this gives you something like a 1D phase diagram in T, but with the full information about the location of the minimum in \\(\\phi\\) and how it evolves.</p>"},{"location":"modules/transitionFinder/transitionFinder/#2-traceminimum-following-a-minimum-as-t-changes","title":"2. <code>traceMinimum</code>: following a minimum as T changes","text":""},{"location":"modules/transitionFinder/transitionFinder/#21-the-mathematical-problem","title":"2.1. The mathematical problem","text":"<p>We want to follow a solution \\(x_{\\min}(T)\\) such that</p> \\[ \\frac{\\partial f}{\\partial x}\\bigl(x_{\\min}(T), T\\bigr) = 0 \\] <p>where \\(x \\in \\mathbb{R}^{N_\\text{fields}}\\).</p> <p>Differentiating this condition with respect to T:</p> \\[ \\frac{d}{dT} \\left( \\frac{\\partial f}{\\partial x} \\right) = \\frac{\\partial^2 f}{\\partial x^2}\\frac{dx_{\\min}}{dT}+ \\frac{\\partial}{\\partial T}\\left(\\frac{\\partial f}{\\partial x}\\right)   = 0. \\] <p>Define</p> <ul> <li>\\(H = \\partial^2 f / \\partial x^2\\) (the Hessian),</li> <li>\\(b = \\partial/\\partial T \\left(\\partial f/\\partial x\\right)\\).</li> </ul> <p>Then we have the implicit equation</p> \\[ H \\cdot \\frac{dx_{\\min}}{dT} = -b. \\] <p>If the minimum is well defined (Hessian invertible and positive definite), we can write</p> \\[ \\frac{dx_{\\min}}{dT} = -H^{-1} b. \\] <p><code>traceMinimum</code> acts as an ODE integrator in T for this equation, but with periodic corrections using numerical minimization,  so that it stays glued to the actual minimum of (f).</p>"},{"location":"modules/transitionFinder/transitionFinder/#22-signature-and-main-inputs","title":"2.2. Signature and main inputs","text":"<pre><code>def traceMinimum(\n    f,\n    d2f_dxdt,\n    d2f_dx2,\n    x0,\n    t0,\n    tstop,\n    dtstart,\n    deltaX_target,\n    dtabsMax=20.0,\n    dtfracMax=0.25,\n    dtmin=1e-3,\n    deltaX_tol=1.2,\n    minratio=1e-2,\n) -&gt; TraceMinimumResult:\n</code></pre> <p>Physical reading:</p> <ul> <li><code>f(x, T)</code>: the effective potential \\(V(\\phi, T)\\).</li> <li><code>d2f_dxdt(x, T)</code>: \\(\\partial/\\partial T (\\partial f / \\partial x)\\), the right-hand side in the linear system.</li> <li><code>d2f_dx2(x, T)</code>: Hessian \\(H = \\partial^2 f / \\partial x^2\\).</li> <li><code>x0</code>, <code>t0</code>: a known minimum at some initial temperature (you must start at a minimum).</li> <li><code>tstop</code>: final temperature you want to reach.</li> <li><code>dtstart</code>: initial step in T (its sign sets the direction: positive \u2192 going to higher (T); negative \u2192 to lower (T)).</li> <li><code>deltaX_target</code>: target displacement in field space per accepted step (the adaptive step controller tries to keep the actual motion \u201cof this order\u201d).</li> </ul> <p>The other arguments are safety knobs for the integrator:</p> <ul> <li><code>dtabsMax</code>, <code>dtfracMax</code>: cap the maximum allowed \\(|\\Delta T|\\).</li> <li><code>dtmin</code>: if \\(|\\Delta T|\\) becomes smaller than this, the routine gives up.</li> <li><code>deltaX_tol</code>: relative tolerance to decide whether a step is \u201cgood\u201d.</li> <li><code>minratio</code>: criterion to say \u201cthe Hessian is becoming degenerate/negative \u2192 we are near a saddle/instability\u201d.</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#23-main-steps-in-the-code","title":"2.3. Main steps in the code","text":"<p>High-level view of the internal logic:</p>"},{"location":"modules/transitionFinder/transitionFinder/#231-initial-setup","title":"2.3.1. Initial setup","text":"<pre><code>x = np.atleast_1d(np.asarray(x0, dtype=float))\nNdim = x.size\n\nM0 = np.asarray(d2f_dx2(x, t0), dtype=float)\neig0 = linalg.eigvalsh(M0)\n...\nminratio = float(minratio) * float(\n    np.min(np.abs(eig0)) / np.max(np.abs(eig0))\n)\n</code></pre> <ul> <li>Convert <code>x0</code> into a 1D array: uniform handling of one or many fields.</li> <li>Compute the initial Hessian and its eigenvalues.</li> <li>If all eigenvalues are zero, the minimum is singular \u2192 error.</li> <li> <p>Rescale <code>minratio</code> according to the local conditioning:</p> </li> <li> <p>if the Hessian is already poorly conditioned, the \u201calmost singular\u201d threshold is relaxed;</p> </li> <li>if it is very well conditioned, you can afford a stricter ratio before declaring trouble.</li> </ul> <p>Physical interpretation: this is a quasi-theoretical check that you are really at a stable minimum (all eigenvalues positive and not tiny).</p>"},{"location":"modules/transitionFinder/transitionFinder/#232-auxiliary-function-dxmindt","title":"2.3.2. Auxiliary function <code>dxmindt</code>","text":"<pre><code>def dxmindt(x_now, t_now):\n    M = np.asarray(d2f_dx2(x_now, t_now), dtype=float)\n    if np.abs(linalg.det(M)) &lt; (1e-3 * np.max(np.abs(M))) ** Ndim:\n        return None, False\n    b = -np.asarray(d2f_dxdt(x_now, t_now), dtype=float).reshape(Ndim)\n    eigs = linalg.eigvalsh(M)\n    try:\n        dxdt_local = linalg.solve(M, b, overwrite_a=False, overwrite_b=False)\n        isneg = (eigs &lt;= 0).any() or (\n            np.min(eigs) / np.max(eigs) &lt; minratio\n        )\n    except linalg.LinAlgError:\n        dxdt_local = None\n        isneg = False\n    return dxdt_local, isneg\n</code></pre> <p>What it does:</p> <ol> <li>Grab the Hessian <code>M</code> at <code>(x_now, T_now)</code>.</li> <li> <p>Rough singularity check via determinant:</p> </li> <li> <p>if <code>det(M)</code> is smaller than a threshold \u2192 return <code>dxdt=None</code>.</p> </li> <li>Form <code>b = - d2f_dxdt</code> as the right-hand side.</li> <li>Solve <code>M * dxdt_local = b</code> for <code>dx/dT</code>.</li> <li> <p>Compute eigenvalues <code>eigs</code> and define</p> </li> <li> <p><code>isneg = True</code> if there is any non-positive eigenvalue or if <code>min/max</code> falls below <code>minratio</code>, signaling a nearly flat/negative direction.</p> </li> </ol> <p>Physical meaning:</p> <ul> <li>When <code>dxdt</code> exists and all eigenvalues are positive and reasonable, you are in a well-defined phase, with positive mass squared in every direction.</li> <li> <p>If any eigenvalue becomes zero or negative:</p> </li> <li> <p>a massless or tachyonic mode appears \u2192 you are at the end of that phase (spinodal) or at a second-order/continuous transition.</p> </li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#233-local-minimization-fmin","title":"2.3.3. Local minimization <code>fmin</code>","text":"<pre><code>xeps = float(deltaX_target) * 1e-2\n\ndef fmin(x_guess, t_now):\n    x_guess = np.asarray(x_guess, dtype=float).reshape(Ndim)\n    res = optimize.fmin(\n        f,\n        x_guess,\n        args=(t_now,),\n        xtol=xeps,\n        ftol=np.inf,\n        disp=False,\n    )\n    return np.asarray(res, dtype=float).reshape(Ndim)\n</code></pre> <ul> <li>Given an initial guess <code>x_guess</code> (coming from the ODE integration), this function slides down to the actual local minimum of <code>f</code> at that temperature.</li> <li><code>xtol = xeps</code>: position tolerance proportional to <code>deltaX_target</code>.</li> <li><code>ftol = np.inf</code>: the minimizer does not care about the value of <code>f</code>, only about convergence in (x).</li> </ul> <p>Why re-minimize?</p> <p>Because integrating only the ODE <code>dx/dT = -H^{-1} b</code> accumulates error: you are following an approximate equation. The <code>fmin</code> correction keeps the trajectory stuck to the true minimum at each step.</p>"},{"location":"modules/transitionFinder/transitionFinder/#234-scales-and-initial-state","title":"2.3.4. Scales and initial state","text":"<pre><code>tscale = abs(float(dtstart))\ndtabsMax = float(dtabsMax) * tscale\ndtmin = float(dtmin) * tscale\ndeltaX_tol_abs = float(deltaX_tol) * float(deltaX_target)\n\nt = float(t0)\ndt = float(dtstart)\ndxdt, negeig = dxmindt(x, t)\n\nX_list = [x.copy()]\nT_list = [t]\ndXdT_list = [np.zeros_like(x) if dxdt is None else dxdt.copy()]\noverX = x.copy()\noverT = t\n</code></pre> <ul> <li> <p>Convert <code>dtstart</code> into an absolute scale and define:</p> </li> <li> <p><code>dtabsMax</code> = maximum allowed \\(|\\Delta T|\\),</p> </li> <li> <p><code>dtmin</code> = minimum allowed \\(|\\Delta T|\\).</p> </li> <li> <p>Compute the first <code>dxdt</code> at the initial point.</p> </li> <li> <p>Initialize the output lists with the starting point.</p> </li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#235-main-loop-in-t","title":"2.3.5. Main loop in T","text":"<p>Skeleton of the update:</p> <pre><code>while dxdt is not None:\n    tnext = t + dt\n    x_pred = x + dxdt * dt\n    xnext = fmin(x_pred, tnext)\n    dxdt_next, negeig = dxmindt(xnext, tnext)\n\n    if dxdt_next is None or negeig:\n        dt *= 0.5\n        overX, overT = xnext.copy(), float(tnext)\n    else:\n        err1 = np.linalg.norm(x + dxdt * dt - xnext)\n        err2 = np.linalg.norm(xnext - dxdt_next * dt - x)\n        xerr = max(err1, err2)\n\n        if xerr &lt; deltaX_tol_abs:\n            # accept step\n            ...\n        else:\n            # step too aggressive\n            dt *= 0.5\n            overX, overT = xnext.copy(), float(tnext)\n    ...\n</code></pre> <p>Step-by-step:</p> <ol> <li> <p>Prediction:</p> </li> <li> <p><code>tnext = t + dt</code>,</p> </li> <li> <p><code>x_pred = x + dxdt * dt</code>: ODE prediction.</p> </li> <li> <p>Minimum correction:</p> </li> <li> <p><code>xnext = fmin(x_pred, tnext)</code> refines to the nearest minimum at the new temperature.</p> </li> <li> <p>New dx/dT:</p> </li> <li> <p><code>dxdt_next, negeig = dxmindt(xnext, tnext)</code>.</p> </li> <li> <p>If there is trouble (<code>dxdt_next is None</code> or <code>negeig</code>):</p> </li> <li> <p>reduce the step: <code>dt *= 0.5</code>,</p> </li> <li> <p>update <code>overX, overT</code> to this \u201cproblematic\u201d point (where the minimum disappears or becomes unstable).</p> </li> <li> <p>If everything is OK, estimate the error:</p> </li> <li> <p><code>err1</code>: difference between the ODE prediction <code>x + dxdt * dt</code> and the refined minimum <code>xnext</code>;</p> </li> <li> <p><code>err2</code>: consistency check of going forward and then backward in T using local slopes;</p> </li> <li> <p><code>xerr = max(err1, err2)</code>, compare with <code>deltaX_tol_abs</code>.</p> </li> <li> <p>If <code>xerr</code> is small \u2192 accept the step:</p> <ul> <li> <p>append <code>tnext</code>, <code>xnext</code>, <code>dxdt_next</code> to the lists,</p> </li> <li> <p>adapt <code>dt</code>:</p> </li> </ul> <pre><code>dt *= deltaX_target / (xerr + 1e-100)\n</code></pre> <ul> <li>update <code>(x, t, dxdt)</code> to the new point.</li> </ul> </li> <li> <p>If <code>xerr</code> is large \u2192 reject the step, cut <code>dt</code> in half.</p> </li> <li> <p>Stopping criteria:</p> </li> <li> <p>If <code>|dt| &lt; dtmin</code> \u2192 we found a transition (or at least a point where further evolution is impractical) and stop.</p> </li> <li>If we are crossing or reaching <code>tstop</code>, force a final step exactly up to <code>tstop</code> and then exit.</li> <li>If <code>|dt|</code> grows beyond the allowed maximum, clip it back.</li> </ol> <p>At the end, the lists <code>X_list</code>, <code>T_list</code>, <code>dXdT_list</code> are turned into arrays and returned together with <code>overX</code>, <code>overT</code>.</p>"},{"location":"modules/transitionFinder/transitionFinder/#24-physical-interpretation-of-traceminimum","title":"2.4. Physical interpretation of <code>traceMinimum</code>","text":"<p>Think of a simple temperature-dependent double-well:</p> <ul> <li>at very high T, only a minimum at \\(\\phi = 0\\) exists;</li> <li>as you cool down, broken-symmetry minima at \\(\\phi \\neq 0\\) appear;</li> <li>following one of these minima, you reach a point where the solution ceases to exist (spinodal) or the Hessian develops a negative mode (loss of stability).</li> </ul> <p><code>traceMinimum</code>:</p> <ul> <li>gives you the curve \\(x_{\\min}(T)\\) for one of these minima;</li> <li>tells you where it ceases to be stable/metastable, via <code>overT</code>;</li> <li> <p>this curve is the basis for</p> </li> <li> <p>building \\(V(\\phi_{\\min}(T), T)\\),</p> </li> <li>computing thermodynamic quantities along the phase,</li> <li>providing boundary conditions for tunneling (e.g. in <code>tunneling1D</code>).</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#3-phase-encapsulating-a-minimum-as-a-physical-object","title":"3. <code>Phase</code>: encapsulating a minimum as a physical object","text":"<p><code>Phase</code> takes the output of <code>traceMinimum</code> and packages it as an object that holds</p> <ul> <li>the arrays <code>X(T)</code>, <code>T</code>, <code>dXdT</code>,</li> <li>a spline \\(T \\mapsto X(T)\\),</li> <li>and second-order links to other phases (<code>low_trans</code> / <code>high_trans</code>).</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#31-construction","title":"3.1. Construction","text":"<pre><code>class Phase:\n    def __init__(self, key, X, T, dXdT) -&gt; None:\n        self.key = key\n        T = np.asarray(T, dtype=float).reshape(-1)\n        X = np.asarray(X, dtype=float)\n        dXdT = np.asarray(dXdT, dtype=float)\n\n        order = np.argsort(T)\n        self.T = T[order]\n        self.X = X[order]\n        self.dXdT = dXdT[order]\n\n        k = 3 if self.T.size &gt; 3 else 1\n        tck, _ = interpolate.splprep(self.X.T, u=self.T, s=0.0, k=k)\n        self.tck = tck\n\n        self.low_trans: set = set()\n        self.high_trans: set = set()\n</code></pre> <p>Details:</p> <ul> <li>Everything is sorted by temperature (to fix any small ordering issues from the tracing routine).</li> <li> <p>A parametric B-spline is constructed, \\(T \\mapsto X(T)\\), via <code>splprep</code>:</p> </li> <li> <p><code>k=3</code> (cubic) when enough points are available,</p> </li> <li>otherwise <code>k=1</code> (linear).</li> <li><code>low_trans</code> and <code>high_trans</code> are initialized as empty sets.</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#32-valat-inspecting-the-phase-at-arbitrary-t","title":"3.2. <code>valAt</code>: inspecting the phase at arbitrary T","text":"<pre><code>def valAt(self, T, deriv: int = 0) -&gt; np.ndarray:\n    if deriv &lt; 0:\n        raise ValueError(\"deriv must be non-negative.\")\n    T_arr = np.asanyarray(T)\n    y = interpolate.splev(T_arr, self.tck, der=deriv)\n    arr = np.asanyarray(y).T\n    return arr\n</code></pre> <ul> <li><code>deriv = 0</code>: returns \\(x_{\\min}(T)\\).</li> <li><code>deriv = 1</code>: returns \\(dx_{\\min}/dT\\) from the spline (a smooth approximation to the discrete <code>dXdT</code>).</li> <li>For scalar T, the result has shape <code>(n_fields,)</code>; for an array of temperatures, <code>(n_T, n_fields)</code>.</li> </ul> <p>Physical use case:</p> <ul> <li>This allows you to evaluate, for instance, \\(V(\\phi_{\\min}(T), T)\\) on a fine (T) grid without re-minimizing:</li> </ul> <pre><code>T_grid = np.linspace(50.0, 200.0, 500)\nphi_grid = phase.valAt(T_grid)\nV_grid = V(phi_grid, T_grid)\n</code></pre>"},{"location":"modules/transitionFinder/transitionFinder/#33-addlinkfrom-marking-second-order-connections","title":"3.3. <code>addLinkFrom</code>: marking second-order connections","text":"<pre><code>def addLinkFrom(self, other_phase: \"Phase\") -&gt; None:\n    if np.min(self.T) &gt;= np.max(other_phase.T):\n        self.low_trans.add(other_phase.key)\n        other_phase.high_trans.add(self.key)\n    if np.max(self.T) &lt;= np.min(other_phase.T):\n        self.high_trans.add(other_phase.key)\n        other_phase.low_trans.add(self.key)\n</code></pre> <p>Logic:</p> <ul> <li> <p>If this phase only exists at lower temperatures than <code>other_phase</code> (i.e. it starts where the other ends), then:</p> </li> <li> <p><code>self.low_trans</code> includes <code>other_phase.key</code>,</p> </li> <li> <p><code>other_phase.high_trans</code> includes <code>self.key</code>.</p> </li> <li> <p>If this phase only exists at higher temperatures, the opposite happens.</p> </li> </ul> <p>This is a criterion purely based on temperature overlap: when two phases \u201ctouch\u201d in temperature without a window of coexistence with a barrier, they are candidates for a second-order/continuous transition.</p> <p>Physically:</p> <ul> <li> <p>You build a graph of phases:</p> </li> <li> <p>edges in <code>low_trans</code> / <code>high_trans</code> represent smooth connections (no barrier),</p> </li> <li>first-order transitions (with tunneling) will be handled elsewhere (e.g. via <code>tunneling1D</code>).</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#4-tracemultimin-reconstructing-all-phases","title":"4. <code>traceMultiMin</code>: reconstructing all phases","text":"<p><code>traceMinimum</code> follows one minimum. <code>traceMultiMin</code> orchestrates this into a global algorithm that:</p> <ul> <li>starts from several seeds,</li> <li>traces each phase up and down in temperature,</li> <li>when a phase disappears, looks for new minima nearby,</li> <li>and builds a dictionary of <code>Phase</code> objects.</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#41-key-inputs","title":"4.1. Key inputs","text":"<pre><code>def traceMultiMin(\n    f,\n    d2f_dxdt,\n    d2f_dx2,\n    points,\n    tLow,\n    tHigh,\n    deltaX_target,\n    dtstart=1e-3,\n    tjump=1e-3,\n    forbidCrit=None,\n    single_trace_args=None,\n    local_min_args=None,\n) -&gt; Dict[Hashable, Phase]:\n</code></pre> <ul> <li> <p><code>points</code>: list of seeds \\((x_\\text{seed}, T_\\text{seed})\\):</p> </li> <li> <p>each should be near a minimum \u2014 typically minima at very high and very low temperatures.</p> </li> <li> <p><code>tLow</code>, <code>tHigh</code>: temperature interval of interest.</p> </li> <li> <p><code>deltaX_target</code>: same philosophy as in <code>traceMinimum</code>.</p> </li> <li> <p><code>dtstart</code>, <code>tjump</code>: fractions of <code>(tHigh - tLow)</code>:</p> </li> <li> <p><code>dtstart_abs = dtstart * (tHigh - tLow)</code> is the initial temperature step for <code>traceMinimum</code>,</p> </li> <li> <p><code>tjump_abs = tjump * (tHigh - tLow)</code> is the temperature offset beyond the end of a phase used for probing new minima.</p> </li> <li> <p><code>forbidCrit(x)</code>: function that says \u201cthis point in field space is forbidden\u201d.</p> </li> <li> <p><code>single_trace_args</code>: extra keyword arguments forwarded to <code>traceMinimum</code>.</p> </li> <li> <p><code>local_min_args</code>: extra keyword arguments for <code>findApproxLocalMin</code> (except <code>args</code>, which is always the temperature).</p> </li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#42-high-accuracy-local-minimization","title":"4.2. High-accuracy local minimization","text":"<p>Internally there is another <code>fmin</code>, now with even tighter tolerances:</p> <pre><code>xeps = deltaX_target * 1e-2\n\ndef fmin(x, t):\n    x = np.asarray(x, dtype=float)\n    xmin = optimize.fmin(\n        f,\n        x + xeps,\n        args=(t,),\n        xtol=xeps * 1e-3,\n        ftol=np.inf,\n        disp=False,\n    )\n    return np.asarray(xmin, dtype=float)\n</code></pre> <p>Note the small shift <code>x + xeps</code>: this can help escape pathological flat points.</p>"},{"location":"modules/transitionFinder/transitionFinder/#43-seed-queue-next_points","title":"4.3. Seed queue (<code>next_points</code>)","text":"<pre><code>phases: Dict[Hashable, Phase] = {}\nnext_points: List[List[Any]] = []\n\nfor x_seed, t_seed in points:\n    x_seed = np.asarray(x_seed, dtype=float)\n    next_points.append([float(t_seed), dtstart_abs, fmin(x_seed, t_seed), None])\n</code></pre> <p>Each element of <code>next_points</code> is:</p> <ol> <li><code>T_current</code> \u2013 temperature of the seed.</li> <li><code>dt_current</code> \u2013 base step to use in <code>traceMinimum</code> from that seed.</li> <li><code>x_current</code> \u2013 refined minimum at that temperature.</li> <li><code>linked_from_key</code> \u2013 which phase (if any) generated this seed (for second-order linking).</li> </ol>"},{"location":"modules/transitionFinder/transitionFinder/#44-exploration-loop","title":"4.4. Exploration loop","text":"<p>The main <code>while next_points:</code> loop does:</p> <ol> <li> <p>Pop a seed from the queue.</p> </li> <li> <p>Refine again <code>x1 = fmin(x1, t1)</code> to ensure we really start at a minimum.</p> </li> <li> <p>Check if:</p> </li> <li> <p>it lies within <code>[tLow, tHigh]</code>,</p> </li> <li> <p>it is allowed by <code>forbidCrit</code>.</p> </li> <li> <p>Check redundancy against phases already found:</p> </li> </ol> <pre><code>for key, phase in phases.items():\n    ...\n    x_phase = fmin(phase.valAt(t1), t1)\n    if np.linalg.norm(x_phase - x1) &lt; 2 * deltaX_target:\n        # already covered\n</code></pre> <p>If some existing <code>Phase</code> has almost the same minimum at <code>t1</code>, this is not a new phase; the seed can be discarded (or used only to adjust links).</p> <ol> <li> <p>If not redundant:</p> </li> <li> <p>print <code>Tracing phase starting at ...</code>,</p> </li> <li>set <code>phase_key = len(phases)</code> for the new phase,</li> <li>trace that phase downwards and upwards in T using <code>traceMinimum</code>.</li> </ol>"},{"location":"modules/transitionFinder/transitionFinder/#45-tracing-to-lower-and-higher-t","title":"4.5. Tracing to lower and higher T","text":"<p>Downwards:</p> <pre><code>if t1 &gt; tLow:\n    down_trace = traceMinimum(\n        f=f,\n        d2f_dxdt=d2f_dxdt,\n        d2f_dx2=d2f_dx2,\n        x0=x1,\n        t0=t1,\n        tstop=tLow,\n        dtstart=-abs(dt1),\n        deltaX_target=deltaX_target,\n        **single_trace_kwargs,\n    )\n    X_down, T_down, dXdT_down = down_trace.X, down_trace.T, down_trace.dXdT\n    nX_down, nT_down = down_trace.overX, down_trace.overT\n\n    t2 = nT_down - tjump_abs\n    dt2 = 0.1 * tjump_abs\n    x2 = fmin(nX_down, t2)\n    next_points.append([t2, dt2, x2, phase_key])\n\n    if np.linalg.norm(X_down[-1] - x2) &gt; deltaX_target:\n        for point in findApproxLocalMin(\n            f,\n            X_down[-1],\n            x2,\n            args=(t2,),\n            **local_min_kwargs,\n        ):\n            next_points.append([t2, dt2, fmin(point, t2), phase_key])\n\n    X_down = X_down[::-1]\n    T_down = T_down[::-1]\n    dXdT_down = dXdT_down[::-1]\n</code></pre> <p>Physical picture:</p> <ul> <li> <p>You take the minimum at <code>T = t1</code> and follow it down to <code>T = tLow</code>.</p> </li> <li> <p><code>traceMinimum</code> stops when the phase ceases to exist (Hessian issues, etc.).</p> </li> <li> <p>The point <code>overX, overT</code> is where the phase \u201cdies\u201d.</p> </li> <li> <p>You then step further in temperature (<code>t2 = overT - tjump_abs</code>), minimize again, and use this as a new seed.</p> </li> <li> <p>If a new phase has nucleated beyond the end of the old one, this seed will fall into its minimum.</p> </li> <li> <p><code>findApproxLocalMin</code> between <code>X_down[-1]</code> and <code>x2</code> searches for additional minima along that straight segment (potential hidden intermediate phases).</p> </li> </ul> <p>Upwards:</p> <p>The upward block is analogous:</p> <pre><code>if t1 &lt; tHigh:\n    up_trace = traceMinimum(\n        ...,\n        tstop=tHigh,\n        dtstart=+abs(dt1),\n        ...\n    )\n    X_up, T_up, dXdT_up = up_trace.X, up_trace.T, up_trace.dXdT\n    nX_up, nT_up = up_trace.overX, up_trace.overT\n\n    t2 = nT_up + tjump_abs\n    dt2 = 0.1 * tjump_abs\n    x2 = fmin(nX_up, t2)\n    next_points.append([t2, dt2, x2, phase_key])\n\n    if np.linalg.norm(X_up[-1] - x2) &gt; deltaX_target:\n        for point in findApproxLocalMin(...):\n            next_points.append([t2, dt2, fmin(point, t2), phase_key])\n</code></pre>"},{"location":"modules/transitionFinder/transitionFinder/#46-building-a-phase-from-downup-pieces","title":"4.6. Building a <code>Phase</code> from down/up pieces","text":"<p>After tracing down and up:</p> <pre><code>if X_down is None:      # only traced upwards\n    X, T, dXdT = X_up, T_up, dXdT_up\nelif X_up is None:      # only traced downwards\n    X, T, dXdT = X_down, T_down, dXdT_down\nelse:\n    # join, avoiding duplicating the pivot\n    X = np.append(X_down, X_up[1:], axis=0)\n    T = np.append(T_down, T_up[1:], axis=0)\n    dXdT = np.append(dXdT_down, dXdT_up[1:], axis=0)\n</code></pre> <p>Then it applies the <code>forbidCrit</code> filter to the endpoints; if the phase is allowed and contains more than one point:</p> <pre><code>new_phase = Phase(phase_key, X, T, dXdT)\nif linked_from is not None:\n    new_phase.addLinkFrom(phases[linked_from])\nphases[phase_key] = new_phase\n</code></pre> <p>If the phase is forbidden, it and its descendants are treated as dead ends.</p> <p>At the end of the <code>while</code> loop, <code>phases</code> is a dictionary <code>{key \u2192 Phase}</code> covering all relevant phases in <code>[tLow, tHigh]</code>, with continuous (second-order) connections encoded through <code>addLinkFrom</code>.</p> <p>Physically: you get a tree/graph of phases. From a modest set of seeds, the algorithm explores the potential, discovering all phases connected through minima as temperature changes, and mapping how they appear and disappear.</p>"},{"location":"modules/transitionFinder/transitionFinder/#5-findapproxlocalmin-hunting-for-intermediate-phases-along-a-line","title":"5. <code>findApproxLocalMin</code>: hunting for intermediate phases along a line","text":"<pre><code>def findApproxLocalMin(\n    f,\n    x1,\n    x2,\n    args=(),\n    n=100,\n    edge=0.05,\n) -&gt; np.ndarray:\n</code></pre>"},{"location":"modules/transitionFinder/transitionFinder/#physical-idea","title":"Physical idea","text":"<p>When a phase ends at <code>(overX, overT)</code> and you step slightly in T and minimize again, you may land in a new minimum far away in field space. Between those two points <code>x1</code> and <code>x2</code> there may exist a third minimum that you would miss by simply re-minimizing.</p> <p><code>findApproxLocalMin</code> is a cheap detector of \u201cpossible hidden phases\u201d along the straight segment from <code>x1</code> to <code>x2</code>.</p>"},{"location":"modules/transitionFinder/transitionFinder/#algorithm","title":"Algorithm","text":"<ol> <li> <p>Ensure <code>x1</code> and <code>x2</code> have the same shape and reinterpret them as 1D vectors: <code>x1_vec</code>, <code>x2_vec</code>.</p> </li> <li> <p>Build a grid in a parameter \\(t \\in [\\text{edge}, 1 - \\text{edge}]\\):</p> </li> </ol> <pre><code>t_grid = np.linspace(edge, 1.0 - edge, n).reshape(n, 1)\nx_grid = x1_vec + t_grid * (x2_vec - x1_vec)  # (n, ndim)\n</code></pre> <p>The <code>edge</code> parameter trims the endpoints:</p> <ul> <li><code>edge=0</code> includes the endpoints,</li> <li> <p><code>edge=0.05</code> ignores the first and last 5% of the line, so you do not simply re-detect the original minima.</p> </li> <li> <p>Evaluate <code>f</code> on the grid:</p> </li> <li> <p>Try vectorized evaluation: <code>y_raw = f(x_grid, *args)</code>.</p> </li> <li>If the shape does not match or the call fails, fall back to a scalar loop <code>_evaluate_scalar_grid</code> which calls <code>f</code> point by point.</li> <li> <p>In the end, <code>y</code> is a 1D array of length <code>n</code>.</p> </li> <li> <p>Look for discrete internal minima:</p> </li> </ul> <pre><code>is_min = (y[2:] &gt; y[1:-1]) &amp; (y[:-2] &gt; y[1:-1])\nminima = x_grid[1:-1][is_min]\n</code></pre> <p>This is the classic finite-difference criterion: a point is a minimum if it is lower than its immediate neighbors.</p> <ol> <li>Return an array with shape <code>(k, ndim)</code> containing the approximate positions of these minima. It may be empty.</li> </ol> <p>Refinement is done later by the internal <code>fmin</code> of <code>traceMultiMin</code>.</p>"},{"location":"modules/transitionFinder/transitionFinder/#6-_removeredundantphase-and-removeredundantphases-cleaning-the-phase-graph","title":"6. <code>_removeRedundantPhase</code> and <code>removeRedundantPhases</code>: cleaning the phase graph","text":"<p>Despite all heuristics, you may still discover the same physical phase more than once (e.g. from different seeds). <code>removeRedundantPhases</code> is a post-processing step that:</p> <ul> <li>scans pairs of phases,</li> <li>checks whether they represent the same minimum over their overlapping temperature range,</li> <li>if they do, merges or discards one,</li> <li>and updates second-order links (<code>low_trans</code> / <code>high_trans</code>) consistently.</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#61-removeredundantphases","title":"6.1. <code>removeRedundantPhases</code>","text":"<pre><code>def removeRedundantPhases(\n    f,\n    phases,\n    xeps=1e-5,\n    diftol=1e-2,\n) -&gt; None:\n</code></pre> <p><code>phases</code> is modified in place.</p>"},{"location":"modules/transitionFinder/transitionFinder/#611-local-minimization","title":"6.1.1. Local minimization","text":"<p>Again a local <code>fmin</code> is defined:</p> <pre><code>def fmin(x, t):\n    xmin = optimize.fmin(\n        f,\n        x,\n        args=(t,),\n        xtol=xeps,\n        ftol=np.inf,\n        disp=False,\n    )\n    return np.asarray(xmin, dtype=float)\n</code></pre> <p>The idea is to guarantee that when comparing two phases you compare true minima of (f), not just spline values.</p>"},{"location":"modules/transitionFinder/transitionFinder/#612-loop-until-no-redundancies-remain","title":"6.1.2. Loop until no redundancies remain","text":"<pre><code>has_redundant_phase = True\nwhile has_redundant_phase:\n    has_redundant_phase = False\n    keys = list(phases.keys())\n\n    for i in keys:\n        ...\n        for j in keys:\n            ...\n            phase1 = phases[i]\n            phase2 = phases[j]\n\n            tmax = min(phase1.T[-1], phase2.T[-1])\n            tmin = max(phase1.T[0], phase2.T[0])\n            if tmin &gt; tmax:\n                continue\n            ...\n</code></pre> <p>For each pair <code>phase1</code>, <code>phase2</code>:</p> <ul> <li> <p>Compute the overlap in temperature:</p> </li> <li> <p><code>tmin</code> = larger of the two Tmin\u2019s,</p> </li> <li> <p><code>tmax</code> = smaller of the two Tmax\u2019s.</p> </li> <li> <p>If there is no overlap (<code>tmin &gt; tmax</code>), skip.</p> </li> </ul> <p>Then:</p> <ul> <li> <p>Compare positions at <code>tmax</code> and <code>tmin</code>:</p> </li> <li> <p>if the boundary matches exactly a stored point, use that,</p> </li> <li>otherwise interpolate via <code>valAt</code> and refine with <code>fmin</code>.</li> </ul> <p>Define:</p> <pre><code>dif = np.linalg.norm(x1 - x2)\nsame_at_tmax = dif &lt; diftol\n...\nsame_at_tmin = dif &lt; diftol\n</code></pre> <p>If <code>same_at_tmin</code> and <code>same_at_tmax</code> are both true:</p> <ul> <li>the two phases are indistinguishable at both ends of their overlapping temperature interval.</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#613-merging-cases","title":"6.1.3. Merging cases","text":"<p>If they are redundant:</p> <ul> <li> <p>Set <code>has_redundant_phase = True</code> so that the outer loop restarts after modifying <code>phases</code>.</p> </li> <li> <p>Define</p> </li> </ul> <pre><code>p_low  = phase1 if phase1.T[0] &lt; phase2.T[0] else phase2\np_high = phase1 if phase1.T[-1] &gt; phase2.T[-1] else phase2\n</code></pre> <ul> <li>Two scenarios:</li> </ul> <p>(a) <code>p_low is p_high</code>: they cover essentially the same temperature range.</p> <ul> <li> <p>Keep one and discard the other:</p> <pre><code>p_reject = phase1 if p_low is phase2 else phase2\n_removeRedundantPhase(phases, p_reject, p_low)\n</code></pre> </li> </ul> <p>(b) <code>p_low</code> and <code>p_high</code> differ: one covers lower temperatures, the other higher temperatures.</p> <ul> <li> <p>Cut and stitch:</p> <pre><code>mask_low  = p_low.T  &lt;= tmax\nmask_high = p_high.T &gt;  tmax\n\nT = np.append(p_low.T[mask_low],  p_high.T[mask_high])\nX = np.append(p_low.X[mask_low],  p_high.X[mask_high], axis=0)\ndXdT = np.append(p_low.dXdT[mask_low], p_high.dXdT[mask_high], axis=0)\n\nnew_key = f\"{p_low.key}_{p_high.key}\"\nnew_phase = Phase(new_key, X, T, dXdT)\nphases[new_key] = new_phase\n\n_removeRedundantPhase(phases, p_low,  new_phase)\n_removeRedundantPhase(phases, p_high, new_phase)\n</code></pre> </li> </ul> <p>You create a \u201cstitched\u201d phase covering the whole temperature range and replace the two old phases.</p> <p>If two phases coincide at only one end of the overlap, you hit:</p> <pre><code>elif same_at_tmin or same_at_tmax:\n    raise NotImplementedError(...)\n</code></pre> <p>This makes it explicit that the ambiguous \u201ctouching at one end only\u201d case is not handled automatically (it would require more sophisticated logic to split and stitch correctly).</p>"},{"location":"modules/transitionFinder/transitionFinder/#62-_removeredundantphase-reconnecting-the-graph","title":"6.2. <code>_removeRedundantPhase</code>: reconnecting the graph","text":"<pre><code>def _removeRedundantPhase(phases, removed_phase, redundant_with_phase):\n    for key in removed_phase.low_trans:\n        if key != redundant_with_phase.key:\n            p = phases[key]\n            p.high_trans.discard(removed_phase.key)\n            redundant_with_phase.addLinkFrom(p)\n    for key in removed_phase.high_trans:\n        if key != redundant_with_phase.key:\n            p = phases[key]\n            p.low_trans.discard(removed_phase.key)\n            redundant_with_phase.addLinkFrom(p)\n    del phases[removed_phase.key]\n</code></pre> <ul> <li> <p>For each neighbor in <code>low_trans</code> and <code>high_trans</code>:</p> </li> <li> <p>remove links to the phase that is being deleted,</p> </li> <li> <p>create the corresponding link with the surviving phase <code>redundant_with_phase</code>.</p> </li> <li> <p>Finally, delete the redundant phase from the dictionary.</p> </li> </ul> <p>Physically: you keep the phase graph coherent \u2014 no dangling links pointing to a deleted phase, and second-order connections are preserved via the \u201cmerged\u201d phase.</p>"},{"location":"modules/transitionFinder/transitionFinder/#7-getstartphase-picking-the-high-temperature-phase","title":"7. <code>getStartPhase</code>: picking the high-temperature phase","text":"<pre><code>def getStartPhase(\n    phases: Mapping[Hashable, Phase],\n    V: Optional[Callable[[np.ndarray, float], float]] = None,\n) -&gt; Hashable:\n</code></pre> <p>A seemingly simple function, but conceptually important. It answers:</p> <p>\u201cIn which phase is the Universe at very high temperature?\u201d</p>"},{"location":"modules/transitionFinder/transitionFinder/#logic","title":"Logic","text":"<ol> <li> <p>If <code>phases</code> is empty \u2192 raise an error.</p> </li> <li> <p>Scan all phases to find those with the largest maximum temperature:</p> </li> </ol> <pre><code>start_candidates = []\nTmax = None\nfor key, phase in phases.items():\n    phase_Tmax = phase.T[-1]\n    if Tmax is None or phase_Tmax &gt; Tmax:\n        Tmax = phase_Tmax\n        start_candidates = [key]\n    elif phase_Tmax == Tmax:\n        start_candidates.append(key)\n</code></pre> <ol> <li> <p>If there is only one candidate, or if <code>V</code> is <code>None</code>:</p> </li> <li> <p>return that candidate.</p> </li> <li> <p>If there are several phases that survive up to the same <code>Tmax</code> and a potential <code>V</code> is provided:</p> </li> <li> <p>evaluate <code>V(phase.X[-1], phase.T[-1])</code> for each candidate,</p> </li> <li>pick the one with the lowest potential \u2014 thermodynamically preferred.</li> </ol>"},{"location":"modules/transitionFinder/transitionFinder/#physical-interpretation","title":"Physical interpretation","text":"<ul> <li>In many models, at high enough T, there is a single \u201csymmetric\u201d phase, e.g. \\(\\phi=0\\).</li> <li>Sometimes, due to approximate symmetries, several phases may survive to the same maximal scanned temperature; then it is important to check the value of (V) and select the true global minimum.</li> <li>This \u201cstart phase\u201d is the initial state for any routine that builds the sequence of transitions as the Universe cools down.</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#putting-it-all-together-integrated-picture","title":"Putting it all together: integrated picture","text":"<p>The conceptual pipeline for Block A is:</p> <ol> <li> <p>Input: a potential \\(V(\\phi,T)\\) and its derivatives, plus a handful of seed minima.</p> </li> <li> <p><code>traceMultiMin</code>:</p> </li> <li> <p>uses <code>traceMinimum</code> to follow each minimum in temperature,</p> </li> <li>when a phase ends, explores nearby points in (T) and field space (<code>findApproxLocalMin</code>) to find new phases,</li> <li> <p>builds a dictionary of <code>Phase</code> objects with second-order connections (<code>low_trans</code> / <code>high_trans</code>).</p> </li> <li> <p><code>removeRedundantPhases</code>:</p> </li> <li> <p>ensures each physical phase appears only once in the graph.</p> </li> <li> <p><code>getStartPhase</code>:</p> </li> <li> <p>selects the high-temperature phase from which cosmological evolution starts.</p> </li> </ol> <p>From here, the later blocks (e.g. <code>tunneling1D</code> and related routines) will:</p> <ul> <li>take pairs of phases (false/true vacuum),</li> <li>for a given (T), evaluate \\(\\phi_\\text{false}(T)\\), \\(\\phi_\\text{true}(T)\\),</li> <li>solve the bounce equation and obtain \\(S_3(T)/T\\) or \\(S_4(T)\\),</li> <li>build \\(S(T)/T\\) vs. (T), find \\(T_n\\), \\(T_c\\), etc.,</li> <li>and ultimately estimate parameters like \\(\\alpha\\), \\(\\beta/H\\) and the corresponding gravitational-wave spectrum.</li> </ul> <p>In the tests we will use a concrete example potential, for instance</p> \\[ V(\\phi, T) = \\lambda \\phi^4 - ET\\phi^3 + D(T^2 - T_0^2)\\phi^2 \\] <p>and show explicitly how the functions in Block A reconstruct the phase structure and prepare the ground for tunneling and gravitational-wave calculations.</p>"},{"location":"modules/transitionFinder/transitionFinder/#block-b-tunneling-core-instantons-and-nucleation-temperature","title":"Block B \u2013 Tunneling core: instantons and nucleation temperature","text":"<p>In this block the focus changes: in Block A we only built the phase diagram as a function of \\(T\\) \u2013 which phases exist, where they start/end, and how the minima move in field space.</p> <p>Block B answers the really crucial physics question:</p> <p>Given a metastable phase (false vacuum) and other, more stable phases, when does the Universe actually make the transition via tunneling? And which bounce (instanton) dominates this nucleation?</p> <p>The pipeline is:</p> <ol> <li>Read the phase diagram (<code>Phase</code> object + <code>phases</code> dictionary from Block A).</li> <li>At each temperature \\(T\\), look at which phases are energetically accessible with \\(V_\\text{low}(T) &lt; V_\\text{high}(T)\\).</li> <li>For each candidate, try to solve the bounce (via <code>pathDeformation.fullTunneling</code> or <code>tunneling1D</code>).</li> <li>Choose the bounce with the smallest action \\(S(T)\\).</li> <li>Search for the \\(T\\) at which the nucleation condition is satisfied (by default \\(S(T)/T \\simeq 140\\)).</li> </ol> <p>From the numerical point of view, Block B provides:</p> <ul> <li>a clean backend for the bounce <code>_solve_bounce</code>,</li> <li>a \u201cscanner in \\(T\\)\u201d <code>_tunnelFromPhaseAtT</code>,</li> <li>helper functions to find the maximum \\(T_\\text{crit}\\) where the phase still makes sense,</li> <li>and the high-level function <code>tunnelFromPhase</code>, which directly returns the instanton and \\(T_\\text{nuc}\\).</li> </ul> <p>What follows is a function-by-function description.</p>"},{"location":"modules/transitionFinder/transitionFinder/#1-_solve_bounce-unified-backend-for-the-instanton","title":"1. <code>_solve_bounce</code>: unified backend for the instanton","text":"<pre><code>def _solve_bounce(\n    x_high: np.ndarray,\n    x_low: np.ndarray,\n    V_fixed: Callable[[np.ndarray], float],\n    dV_fixed: Callable[[np.ndarray], np.ndarray],\n    T: float,\n    fullTunneling_params: Optional[Mapping[str, Any]] = None,\n) -&gt; Tuple[Optional[Any], float, int]:\n    ...\n</code></pre> <p>Numerical goal</p> <p>Given:</p> <ul> <li>a metastable minimum (\u201cfalse vacuum\u201d) at <code>x_high</code>,</li> <li>a stable minimum at <code>x_low</code>,</li> <li>a fixed-temperature potential \\(V_\\text{fixed}(x) = V(x, T)\\),</li> <li>and its gradient \\(dV_\\text{fixed}(x) = \\nabla_x V(x, T)\\),</li> </ul> <p>this function calls <code>pathDeformation.fullTunneling</code> to:</p> <ul> <li>find the bounce \\(\\phi_b(r)\\) that connects \\(x_\\text{high} \\to x_\\text{low}\\),</li> <li>extract the Euclidean action \\(S\\),</li> <li>classify the type of transition.</li> </ul> <p>All of this is encapsulated in a single place, with standardized error handling.</p> <p>Treatment of edge cases</p> <p><code>pathDeformation.fullTunneling</code> can raise <code>tunneling1D.PotentialError</code> with standard messages:</p> <ul> <li> <p><code>\"no barrier\"</code>   \u2192 there is no barrier between the minima   \u2192 not a first-order transition (or second-order limit)   \u2192 <code>trantype = 0</code>, <code>action = 0.0</code>.</p> </li> <li> <p><code>\"stable, not metastable\"</code>   \u2192 the \u201cfalse vacuum\u201d is actually stable (no metastable well)   \u2192 there is no relevant bounce   \u2192 <code>trantype = 0</code>, <code>action = +\u221e</code>.</p> </li> </ul> <p>Any other message is propagated as an unexpected error (this is important: we do not hide genuine numerical problems).</p> <p>Output</p> <ul> <li> <p><code>instanton</code>:</p> </li> <li> <p>the object returned by <code>fullTunneling</code> if a bounce is found;</p> </li> <li> <p><code>None</code> in the <code>\"no barrier\"</code> or <code>\"stable, not metastable\"</code> cases.</p> </li> <li> <p><code>action</code>:</p> </li> <li> <p>\\(S\\) if <code>trantype = 1</code>,</p> </li> <li> <p><code>0.0</code> or <code>np.inf</code> in special cases.</p> </li> <li> <p><code>trantype</code>:</p> </li> <li> <p><code>1</code> \u2192 first-order transition with bounce,</p> </li> <li><code>0</code> \u2192 no bounce (second order, stable, etc.).</li> </ul> <p>Physical interpretation</p> <p><code>_solve_bounce</code> is the \u201cengine\u201d that turns a snapshot of the potential at a given temperature \\(T\\) into a physical object:</p> <ul> <li>radial profile \\(\\phi_b(r)\\),</li> <li>action \\(S_3(T)\\) (or \\(S_4\\), depending on the backend implementation),</li> <li>type of transition (first order or not).</li> </ul> <p>Everything else in Block B is essentially organization around repeated calls to <code>_solve_bounce</code> for different temperatures and phase pairs.</p>"},{"location":"modules/transitionFinder/transitionFinder/#2-_tunnelfromphaseatt-scan-all-possible-transitions-at-a-given-t","title":"2. <code>_tunnelFromPhaseAtT</code>: scan all possible transitions at a given \\(T\\)","text":"<pre><code>def _tunnelFromPhaseAtT(\n    T,\n    phases,\n    start_phase,\n    V,\n    dV,\n    phitol,\n    overlapAngle,\n    nuclCriterion,\n    fullTunneling_params,\n    verbose,\n    outdict,\n) -&gt; float:\n    ...\n</code></pre> <p>This function is the \u201c\\(S(T)\\) wrapper\u201d: it receives a temperature \\(T\\) and returns</p> \\[ nuclCriterion\\bigl( S_\\text{min}(T), T \\bigr), \\] <p>where \\(S_\\text{min}(T)\\) is the smallest action among all possible transitions from <code>start_phase</code> to any other phase with \\(V_\\text{low}(T) &lt; V_\\text{high}(T)\\).</p> <p>It also fills the cache <code>outdict[T]</code> with the best transition found.</p>"},{"location":"modules/transitionFinder/transitionFinder/#21-input-and-cache","title":"2.1. Input and cache","text":"<ul> <li> <p><code>T</code> may come as a scalar or array (because of <code>optimize.fmin</code>):</p> </li> <li> <p>the function always converts it to a scalar <code>T_val</code>.</p> </li> <li> <p>If <code>T_val</code> is already in <code>outdict</code>, it means we have already computed the best transition at that \\(T\\):</p> </li> <li> <p>it is enough to return <code>nuclCriterion(outdict[T_val][\"action\"], T_val)</code>.</p> </li> </ul> <p>This is important for efficiency: <code>brentq</code> and <code>fmin</code> will call <code>_tunnelFromPhaseAtT</code> many times with the same \\(T\\), and solving the bounce is expensive.</p>"},{"location":"modules/transitionFinder/transitionFinder/#22-finding-minima-at-fixed-t","title":"2.2. Finding minima at fixed \\(T\\)","text":"<p>It defines a precise 1D minimizer:</p> <pre><code>def fmin_min(x0):\n    xmin = optimize.fmin(V, x0, args=(T_val,), xtol=phitol, ftol=np.inf, disp=False)\n    return np.asarray(xmin, dtype=float)\n</code></pre> <ul> <li>First, it refines the minimum of the initial phase:</li> </ul> <pre><code>x0_guess = start_phase.valAt(T_val)\nx0 = fmin_min(x0_guess)\nV0 = V(x0, T_val)\n</code></pre> <ul> <li>Then it scans all other phases and looks for candidates:</li> </ul> <pre><code>for key, phase in phases.items():\n    if key == start_phase.key:\n        continue\n    # phase must exist at T\n    if phase.T[0] &gt; T_val or phase.T[-1] &lt; T_val:\n        continue\n\n    x1_guess = phase.valAt(T_val)\n    x1 = fmin_min(x1_guess)\n    V1 = V(x1, T_val)\n    if V1 &gt;= V0:\n        continue  # only care if V_low &lt; V_high\n    tunnel_list.append({ ... })\n</code></pre> <p>Physics: this step builds the list of possible transitions</p> \\[ \\text{high phase} \\to \\text{low phase} \\] <p>in which the \u201clow\u201d phase has smaller free energy at temperature \\(T\\).</p>"},{"location":"modules/transitionFinder/transitionFinder/#23-overlapangle-pruning-strongly-aligned-targets","title":"2.3. <code>overlapAngle</code>: pruning strongly aligned targets","text":"<p>If <code>overlapAngle &gt; 0</code>, we introduce a geometric criterion:</p> <ul> <li> <p>For each pair of candidates \\((i, j)\\):</p> </li> <li> <p>define the vectors</p> </li> </ul> \\[\\Delta x_i = x_i - x_0,\\quad \\Delta x_j = x_j - x_0\\] <ul> <li>compute the angle between them:</li> </ul> \\[\\cos\\theta_{ij}= \\frac{ \\Delta x_i \\cdot \\Delta x_j }{ \\lvert\\Delta x_i\\rvert \\lvert\\Delta x_j\\rvert }\\] <ul> <li>If \\(\\theta_{ij}\\) is smaller than <code>overlapAngle</code> (in degrees), that is,</li> </ul> <pre><code>dotij &gt;= sqrt(xi2 * xj2) * cos_overlap\n</code></pre> <p>then the two transitions are essentially \u201cin the same direction\u201d in field space.</p> <ul> <li>We keep only the one closer (in norm) to the false vacuum and discard the other.</li> </ul> <p>Physics: this avoids spending time solving very similar bounces that, in practice, have almost identical actions, keeping only the shortest direction in field space (the most promising for having smaller action).</p> <p>If you want to study all directions, just use <code>overlapAngle=0.0</code> in the high-level call.</p>"},{"location":"modules/transitionFinder/transitionFinder/#24-solving-bounces-and-choosing-the-smallest-s","title":"2.4. Solving bounces and choosing the smallest \\(S\\)","text":"<p>It defines \\(T\\)-fixed wrappers:</p> <pre><code>def V_fixed(x): return V(x, T_val)\ndef dV_fixed(x): return dV(x, T_val)\n</code></pre> <p>Then, for each candidate in <code>tunnel_list</code>:</p> <ul> <li> <p>prints information if <code>verbose=True</code>,</p> </li> <li> <p>calls <code>_solve_bounce(...)</code>,</p> </li> <li> <p>fills:</p> </li> <li> <p><code>tdict[\"instanton\"]</code>,</p> </li> <li><code>tdict[\"action\"]</code>,</li> <li> <p><code>tdict[\"trantype\"]</code>,</p> </li> <li> <p>updates <code>lowest_action</code> and <code>lowest_tdict</code> if the action is smaller.</p> </li> </ul> <p>In the end:</p> <ul> <li>it stores <code>lowest_tdict</code> in <code>outdict[T_val]</code>,</li> <li>it returns <code>nuclCriterion(lowest_action, T_val)</code>.</li> </ul> <p>Physics: for each \\(T\\), you construct the envelope</p> \\[ S_\\text{min}(T) = \\min_{\\text{target phases}} S_{\\text{bounce}, \\text{high phase} \\to \\text{low phase}}(T), \\] <p>which is what enters the nucleation condition.</p>"},{"location":"modules/transitionFinder/transitionFinder/#3-_potentialdiffforphase-who-is-energetically-preferred","title":"3. <code>_potentialDiffForPhase</code>: who is energetically preferred?","text":"<pre><code>def _potentialDiffForPhase(\n    T: float,\n    start_phase: Phase,\n    other_phases: Sequence[Phase],\n    V: Callable[[np.ndarray, float], float],\n) -&gt; float:\n    ...\n</code></pre> <p>This function is simple but conceptually important. It answers:</p> <p>At a given temperature \\(T\\), what is the smallest free-energy difference between any other phase and <code>start_phase</code>?</p> <p>More precisely:</p> <ul> <li> <p>it computes \\(V_0 = V(x_\\text{start}(T), T)\\),</p> </li> <li> <p>for each other phase \\(i\\):</p> </li> <li> <p>computes \\(V_i = V(x_i(T), T)\\),</p> </li> <li> <p>evaluates \\(V_i - V_0\\),</p> </li> <li> <p>and returns the minimum over all phases:</p> </li> </ul> \\[ \\Delta V_\\text{min}(T) = \\min_i \\bigl[ V_i(T) - V_0(T) \\bigr]. \\] <p>Interpretation</p> <ul> <li> <p>If \\(\\Delta V_\\text{min}(T) &gt; 0\\):   the potential of <code>start_phase</code> is lower than that of any other phase \u2192 it is energetically preferred (stable) at that \\(T\\).</p> </li> <li> <p>If \\(\\Delta V_\\text{min}(T) &lt; 0\\):   there exists some other phase with \\(V &lt; V_0\\) \u2192 <code>start_phase</code> is energetically disfavored (unstable) at that \\(T\\).</p> </li> </ul> <p>This sign is what <code>_maxTCritForPhase</code> uses to locate critical temperatures where <code>start_phase</code> ceases to be preferred.</p>"},{"location":"modules/transitionFinder/transitionFinder/#4-_maxtcritforphase-maximum-critical-t-for-the-initial-phase","title":"4. <code>_maxTCritForPhase</code>: maximum critical \\(T\\) for the initial phase","text":"<pre><code>def _maxTCritForPhase(\n    phases: Mapping[Hashable, Phase],\n    start_phase: Phase,\n    V: Callable[[np.ndarray, float], float],\n    Ttol: float,\n) -&gt; float:\n    ...\n</code></pre> <p>Physical question</p> <p>For the phase <code>start_phase</code>, what is the largest temperature \\(T_\\text{crit}\\) such that there exists another phase degenerate in free energy?</p> \\[ V_\\text{start}(T_\\text{crit}) \\approx V_\\text{other}(T_\\text{crit}). \\] <p>This temperature is relevant to delimit the range in which the false vacuum still makes sense as a metastable minimum.</p> <p>Numerical steps</p> <ol> <li> <p>It builds the list <code>other_phases</code> with all phases different from <code>start_phase</code>.</p> </li> <li> <p>It defines the relevant \\(T\\) bounds:</p> </li> <li> <p><code>Tmin</code> = largest initial \\(T\\) among the other phases;</p> </li> <li><code>Tmax</code> = smallest final \\(T\\) among the other phases;</li> <li> <p>then it intersects with \\([T_\\text{start,min}, T_\\text{start,max}]\\).</p> </li> <li> <p>It evaluates:</p> </li> </ol> <pre><code>DV_Tmin = _potentialDiffForPhase(Tmin, start_phase, other_phases, V)\nDV_Tmax = _potentialDiffForPhase(Tmax, start_phase, other_phases, V)\n</code></pre> <ul> <li>If <code>DV_Tmin &gt;= 0</code>: at <code>Tmin</code> the <code>start_phase</code> is already stable (lower than the others) \u2192 it returns <code>Tmin</code>.</li> <li> <p>If <code>DV_Tmax &lt;= 0</code>: at <code>Tmax</code> it is already unstable (some other phase has smaller \\(V\\)) \u2192 it returns <code>Tmax</code>.</p> </li> <li> <p>Otherwise, the signs of \\(\\Delta V\\) at <code>Tmin</code> and <code>Tmax</code> are opposite:</p> </li> <li> <p>it uses <code>optimize.brentq</code> on <code>_potentialDiffForPhase</code> to find the zero:</p> <p>$$  \\Delta V_\\text{min}(T_\\text{crit}) = 0.  $$</p> </li> <li> <p>it returns this <code>Tcrit</code> with tolerance <code>Ttol</code>.</p> </li> </ul> <p>Use inside Block B</p> <p><code>tunnelFromPhase</code> uses <code>_maxTCritForPhase</code> when the initial search in \\(T\\) does not directly find a nucleation solution:</p> <ul> <li>it restricts <code>Tmax</code> to this <code>Tmax_crit</code> to avoid searching for nucleation in a region where the minimum has already ceased to be physically meaningful (the phase has stopped being a local minimum).</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#5-tunnelfromphase-high-level-interface-for-t_n-and-the-instanton","title":"5. <code>tunnelFromPhase</code>: high-level interface for \\(T_n\\) and the instanton","text":"<pre><code>def tunnelFromPhase(\n    phases,\n    start_phase,\n    V,\n    dV,\n    Tmax,\n    Ttol=1e-3,\n    maxiter=100,\n    phitol=1e-8,\n    overlapAngle=45.0,\n    nuclCriterion=lambda S, T: S/(T + 1e-100) - 140.0,\n    verbose=True,\n    fullTunneling_params=None,\n) -&gt; Optional[Dict[str, Any]]:\n    ...\n</code></pre> <p>This is the function you will call \u201cin practice\u201d when you want to:</p> <ul> <li>find \\(T_n\\) (the nucleation temperature) for the transition starting from <code>start_phase</code>,</li> <li>obtain the dominant bounce in the form of the <code>instanton</code> object.</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#51-main-inputs","title":"5.1. Main inputs","text":"<ul> <li> <p><code>phases</code>: <code>{key \u2192 Phase}</code> dictionary from Block A.</p> </li> <li> <p><code>start_phase</code>: <code>Phase</code> object representing the initial metastable phase.</p> </li> <li> <p><code>V</code>, <code>dV</code>: potential and gradient, \\(V(x, T)\\) and \\(dV(x, T)\\).</p> </li> <li> <p><code>Tmax</code>: maximum \\(T\\) allowed for nucleation (you choose the range of interest).</p> </li> <li> <p><code>Ttol</code>: tolerance in \\(T\\) for locating the zero of <code>nuclCriterion</code>.</p> </li> <li> <p><code>phitol</code>: tolerance used in 1D minimizations in field space (to find minima).</p> </li> <li> <p><code>overlapAngle</code>: parameter used to prune nearly redundant directions in field space (passed to <code>_tunnelFromPhaseAtT</code>).</p> </li> <li> <p><code>nuclCriterion(S, T)</code>:</p> </li> <li> <p>default: \\(S/T - 140\\) (a standard choice in cosmological FOPTs),</p> </li> <li> <p>the routine seeks a \\(T\\) such that <code>nuclCriterion(...) = 0</code>.</p> </li> <li> <p><code>fullTunneling_params</code>: extra kwargs for <code>pathDeformation.fullTunneling</code>.</p> </li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#52-range-in-t","title":"5.2. Range in \\(T\\)","text":"<p>First, it defines the effective interval:</p> <ul> <li><code>Tmin = start_phase.T[0]</code>,</li> <li><code>T_highest_other</code> = largest final \\(T\\) among all phases,</li> <li><code>Tmax_eff = min(Tmax, T_highest_other)</code>.</li> </ul> <p>It checks whether <code>Tmax_eff &gt;= Tmin</code>; otherwise, the search does not make numerical sense.</p>"},{"location":"modules/transitionFinder/transitionFinder/#53-two-step-strategy","title":"5.3. Two-step strategy","text":"<p>The function tries, in order:</p> <ol> <li> <p>Direct root-finding with <code>brentq</code>:</p> </li> <li> <p>it defines \\(f(T) = _tunnelFromPhaseAtT(T, ...)\\),</p> </li> <li> <p>it tries to find a zero of \\(f\\) between <code>Tmin</code> and <code>Tmax_eff</code>:</p> <pre><code>Tnuc = brentq(f, Tmin, Tmax_eff, ...)\n</code></pre> </li> <li> <p>if this works, we are done: <code>Tnuc</code> is found directly.</p> </li> <li> <p>If <code>brentq</code> fails with the typical error    <code>\"f(a) and f(b) must have different signs\"</code>:</p> </li> <li> <p>it means that \\(nuclCriterion(S(T), T)\\) has the same sign over the whole interval:</p> <ul> <li>either it never crosses zero,</li> <li>or it does cross, but the endpoints do not show that clearly.</li> </ul> </li> </ol> <p>Then the function switches to a more careful mode:</p> <ul> <li> <p>it ensures that the endpoints <code>Tmin</code> and <code>Tmax_eff</code> have been computed (via <code>_tunnelFromPhaseAtT</code>) and cached in <code>outdict</code>;</p> </li> <li> <p>it checks:</p> <ul> <li>whether \\(nuclCriterion(S(T_\\text{max,eff}), T_\\text{max,eff}) &gt; 0\\) (tunneling too suppressed at high \\(T\\));</li> <li>and whether \\(nuclCriterion(S(T_\\text{min}), T_\\text{min}) &lt; 0\\) (strong tunneling at low \\(T\\)).</li> </ul> </li> <li> <p>if such a sign change exists, it restricts the maximum temperature to a <code>Tmax_crit</code> obtained from <code>_maxTCritForPhase</code> (the region where the phase is still physically meaningful).</p> </li> <li> <p>it then performs a minimization in \\(T\\) using <code>optimize.fmin</code> on <code>_tunnelFromPhaseAtT</code>, with a <code>callback</code>:</p> <ul> <li>as soon as the function enters a region with \\(nuclCriterion \\le 0\\), the callback raises a <code>StopIteration(T)</code>, containing an estimate of the \\(T\\) where this happens.</li> </ul> </li> <li> <p>once this <code>Tmin_opt</code> is obtained, it checks whether at that point \\(nuclCriterion\\) is indeed \\(\\le 0\\); if it is still \\(&gt; 0\\), the function concludes that there is no efficient nucleation \u2192 it returns <code>None</code>.</p> </li> <li> <p>if there is a genuine crossing, it performs a second <code>brentq</code> in a narrower interval \\((T_\\text{min,opt}, T_\\text{max,crit})\\) to better locate the zero.</p> </li> <li> <p>otherwise (for example, if \\(nuclCriterion\\) never becomes \\(&lt; 0\\) even at <code>Tmin</code>), it concludes that the transition does not nucleate in the given interval \u2192 it returns <code>None</code>.</p> </li> </ul> <p>If, on the other hand, the nucleation condition is already satisfied at <code>Tmax_eff</code> (i.e. \\(nuclCriterion \\le 0\\) there), the function simply defines:</p> <ul> <li><code>Tnuc = Tmax_eff</code>: nucleation \u201chappens immediately\u201d at the upper bound of the range.</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#54-output","title":"5.4. Output","text":"<p>After determining <code>Tnuc</code>:</p> <ul> <li>it ensures that <code>outdict[Tnuc]</code> has been filled by <code>_tunnelFromPhaseAtT</code>,</li> <li>it takes <code>rdict = outdict[Tnuc]</code>.</li> </ul> <p>If <code>rdict[\"trantype\"] &gt; 0</code> (first-order transition with bounce), it returns the dictionary:</p> <ul> <li><code>Tnuc</code> : nucleation temperature;</li> <li><code>low_vev</code>, <code>high_vev</code> : low- and high- T minima;</li> <li><code>low_phase</code>, <code>high_phase</code> : keys of the phases involved;</li> <li><code>action</code> : instanton action;</li> <li><code>instanton</code> : object returned by <code>fullTunneling</code>;</li> <li><code>trantype</code> : <code>1</code> for first-order transition.</li> </ul> <p>If <code>trantype</code> is <code>0</code> (no bounce \u2013 second-order case or stable), it returns <code>None</code>.</p> <p>Physical interpretation</p> <p>\\(T_n\\) is the temperature at which, according to the chosen criterion (typically \\(S(T)/T \\simeq 140\\)), the nucleation probability per Hubble volume becomes relevant.</p> <p>In terms of cosmological history:</p> <ul> <li>above \\(T_n\\), the Universe remains trapped in the metastable phase (unless there is a second-order transition);</li> <li>close to \\(T_n\\), bubbles of the true phase appear efficiently;</li> <li>the returned instanton is the solution that dominates this nucleation.</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#6-closing-block-b-integrated-view","title":"6. Closing Block B: integrated view","text":"<p>With Blocks A and B together, the full conceptual flow for a first-order phase transition is:</p> <ol> <li> <p>Build the phase diagram in \\(T\\):</p> </li> <li> <p>use <code>traceMultiMin</code> and <code>Phase</code> to find all phases;</p> </li> <li>clean redundancies with <code>removeRedundantPhases</code>;</li> <li> <p>choose the high-\\(T\\) phase with <code>getStartPhase</code>.</p> </li> <li> <p>Choose a metastable phase of interest (<code>start_phase</code>).</p> </li> <li> <p>Run the tunneling core:</p> </li> <li> <p>for each \\(T\\), <code>_tunnelFromPhaseAtT</code> builds all possible bounces starting from <code>start_phase</code> \u2192 \\(S_\\text{min}(T)\\);</p> </li> <li><code>_maxTCritForPhase</code> helps determine up to which temperature it makes sense to demand metastability;</li> <li> <p><code>tunnelFromPhase</code> combines everything, applies the nucleation criterion, and returns \\(T_n\\) and the dominant instanton.</p> </li> <li> <p>From \\(T_n\\) and the instanton, other blocks (or user scripts) can:</p> </li> <li> <p>reconstruct \\(S(T)/T\\) as a function of \\(T\\);</p> </li> <li>determine \\(T_c\\) (the critical temperature where the phases become degenerate);</li> <li>extract cosmological parameters such as \\(\\alpha\\) and \\(\\beta/H\\);</li> <li>compute gravitational-wave spectra.</li> </ol> <p>In the next test files, we will implement concrete examples using the same one-component Landau\u2013Ginzburg potential, to visualize:</p> <ul> <li>how <code>tunnelFromPhase</code> selects the correct target phase,</li> <li>how \\(S(T)/T\\) crosses \\(140\\),</li> <li>and how this connects to the phase diagram built in Block A.</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#block-c-transition-history-secondordertrans-findalltransitions-findcriticaltemperatures-addcrittempsforfulltransitions","title":"Block C \u2013 Transition history (<code>secondOrderTrans</code>, <code>findAllTransitions</code>, <code>findCriticalTemperatures</code>, <code>addCritTempsForFullTransitions</code>)","text":"<p>Block C takes everything built in Blocks A and B</p> <ul> <li>phases traced in temperature (<code>Phase</code>, <code>traceMultiMin</code>, <code>getStartPhase</code>);</li> <li>bounce solutions and nucleation temperatures (<code>tunnelFromPhase</code>);</li> </ul> <p>and turns it into something you actually want as a cosmologist:</p> <p>A coherent thermal history of the Universe: which phase is realized at which temperature, when first-order vs second-order transitions happen, and how far the system supercools before tunneling.</p> <p>Conceptually:</p> <ul> <li>Block A: \u201cWhat are the minima as a function of T?\u201d</li> <li>Block B: \u201cGiven two minima, when and how do we tunnel between them?\u201d</li> <li>Block C: \u201cChaining everything together, what is the full sequence of transitions as the Universe cools?\u201d</li> </ul> <p>Below we describe each Block C function (how it works, what it returns, and what it means physically) in the same style as the previous blocks. </p>"},{"location":"modules/transitionFinder/transitionFinder/#1-secondordertrans-encoding-second-order-transitions","title":"1. <code>secondOrderTrans</code> \u2013 encoding second-order transitions","text":"<p>Role: <code>secondOrderTrans(high_phase, low_phase, Tstr=\"Tnuc\")</code> is a small helper that builds a transition dictionary for cases where the transition is second order (no barrier, no bounce).</p> <p>In the language of Block A:</p> <ul> <li>Both <code>high_phase</code> and <code>low_phase</code> are <code>Phase</code> objects.</li> <li>The graph structure (via <code>low_trans</code>) tells us that, as T goes down, the system can slide continuously from <code>high_phase</code> into <code>low_phase</code>.</li> </ul> <p>Code behavior</p> <ul> <li> <p>It constructs a dictionary with keys:</p> </li> <li> <p><code>Tstr</code> (usually <code>\"Tnuc\"</code> or <code>\"Tcrit\"</code>),</p> </li> <li><code>high_phase</code>, <code>low_phase</code>,</li> <li><code>high_vev</code>, <code>low_vev</code>,</li> <li><code>action</code>, <code>instanton</code>, <code>trantype</code>.</li> <li> <p>For a second-order transition we use:</p> </li> <li> <p><code>action = 0.0</code>,</p> </li> <li><code>instanton = None</code>,</li> <li><code>trantype = 2</code>,</li> <li><code>high_vev</code> and <code>low_vev</code> set to the same field value (the first point of <code>high_phase.X</code>), reflecting that the VEV is continuous across the transition.</li> </ul> <p>Physically, this is a continuous symmetry restoration/breaking:</p> <ul> <li>No barrier \u2192 no instanton,</li> <li>Correlation length diverges at the critical point,</li> <li>Thermal fluctuations, not quantum tunneling, control the dynamics.</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#2-findalltransitions-building-a-full-thermal-history","title":"2. <code>findAllTransitions</code> \u2013 building a full thermal history","text":"<p>Role: <code>findAllTransitions(phases, V, dV, tunnelFromPhase_args=...)</code> takes the phase structure (Block A) and the tunneling machinery (Block B), and constructs a single cooling path:</p> \\[ \\text{Phase}_\\text{high} ;\\rightarrow; \\text{Phase}_1 ;\\rightarrow; \\text{Phase}_2 ;\\rightarrow; \\dots \\] <p>ordered from high temperature to low temperature.</p> <p>High-level algorithm</p> <ol> <li> <p>Start at high T</p> </li> <li> <p>Use <code>getStartPhase(phases, V)</code> to identify the dominant high-T phase (usually symmetric, \u03c6 \u2248 0).</p> </li> <li> <p>Set <code>Tmax</code> to the highest T where this phase is defined.</p> </li> <li> <p>Iterative step from a given <code>start_phase</code></p> </li> <li> <p>Remove <code>start_phase</code> from the working map (we won\u2019t tunnel into it again).</p> </li> <li> <p>Call <code>tunnelFromPhase(phases_work, start_phase, V, dV, Tmax, **tunnelFromPhase_args)</code>:</p> <ul> <li> <p>If a first-order transition is found, <code>tunnelFromPhase</code> returns a dict with:</p> <ul> <li><code>Tnuc</code>, <code>low_phase</code>, <code>high_phase</code>, <code>low_vev</code>, <code>high_vev</code>,</li> <li><code>instanton</code>, <code>action</code>, <code>trantype = 1</code>.<ul> <li>If no first-order solution exists, it returns <code>None</code>.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>If first-order succeeded:</p> <ul> <li>Append the returned dict to the <code>transitions</code> list.</li> <li>Set <code>start_phase = phases_work[low_phase]</code>.</li> <li>Update <code>Tmax = Tnuc</code> (we only look for later transitions).</li> </ul> </li> <li> <p>If first-order failed:</p> <ul> <li>Look at <code>start_phase.low_trans</code> (if present) \u2013 these are \u201cdownstream\u201d phases that can be reached continuously (second order).</li> <li>If at least one of them is still in <code>phases_work</code>, pick the first and build a second-order transition via <code>secondOrderTrans(start_phase, low_phase)</code>.</li> <li>Append that dict to <code>transitions</code>, update <code>start_phase = low_phase</code>, and set <code>Tmax</code> to the top of the new phase\u2019s T-range.</li> <li>If there are no valid <code>low_trans</code> targets, the history stops.</li> </ul> </li> </ol> <p>Outputs</p> <p>The function returns a list of transition dictionaries, each of which looks like:</p> <ul> <li> <p>First-order:</p> </li> <li> <p><code>{\"Tnuc\", \"low_vev\", \"high_vev\", \"low_phase\", \"high_phase\", \"action\", \"instanton\", \"trantype=1\"}</code></p> </li> <li> <p>Second-order:</p> </li> <li> <p>Same keys but with <code>action=0.0</code>, <code>instanton=None</code>, <code>trantype=2</code>.</p> </li> </ul> <p>They are automatically ordered from hottest to coldest along a single, consistent path in phase space.</p> <p>Physical interpretation on the toy model</p> <p>In the Landau\u2013Ginzburg model used in Blocks A and B:</p> <ul> <li>At high T: we start in the symmetric phase (\u03c6 \u2248 0).</li> <li> <p>As T drops:</p> </li> <li> <p><code>findAllTransitions</code> should find a first-order transition from the symmetric to the broken phase, with:</p> <ul> <li>A <code>Tnuc</code> slightly below the critical temperature (supercooling),</li> <li>Non-zero <code>action</code> and a <code>trantype=1</code>.</li> <li>If additional broken phases existed (multi-step symmetry breaking), they would appear as further entries, either first-order or second-order, depending on the barrier structure.</li> </ul> </li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#3-findcriticaltemperatures-scanning-for-degeneracies-tcrit","title":"3. <code>findCriticalTemperatures</code> \u2013 scanning for degeneracies <code>Tcrit</code>","text":"<p>Role: <code>findCriticalTemperatures(phases, V, start_high=False)</code> decouples the geometric information about phase degeneracies from the dynamical tunneling story.</p> <p>For every ordered pair of phases <code>(phase1 \u2192 phase2)</code> with overlapping temperature ranges, it asks:</p> <p>\u201cIs there a temperature <code>Tcrit</code> where <code>V(\u03c6\u2081(Tcrit), Tcrit) = V(\u03c6\u2082(Tcrit), Tcrit)</code>?\u201d</p> <p>If yes, <code>Tcrit</code> is a critical temperature where the two branches are degenerate in free energy.</p> <p>Code behavior</p> <ol> <li> <p>For each pair <code>(i, j)</code>:</p> </li> <li> <p>Identify the overlap interval in T:</p> <p>$$  [t_{\\min}, t_{\\max}] =  [\\max(T_i^{\\min}, T_j^{\\min}), \\min(T_i^{\\max}, T_j^{\\max})].  $$</p> </li> <li> <p>If there is no overlap (<code>tmin &gt;= tmax</code>):</p> </li> <li> <p>Check for a second-order link via <code>phase2.key in phase1.low_trans</code>.</p> </li> <li> <p>If such a link exists, construct a second-order transition using      <code>secondOrderTrans(phase1, phase2, \"Tcrit\")</code>.</p> </li> <li> <p>If there is overlap:</p> </li> <li> <p>Define:</p> <p>$$  \\Delta V(T) = V(\\phi_1(T), T) - V(\\phi_2(T), T),  $$</p> <p>with <code>\u03c61 = phase1.valAt(T)</code> and <code>\u03c62 = phase2.valAt(T)</code>.</p> </li> <li> <p>Evaluate <code>DV(tmin)</code> and <code>DV(tmax)</code>.</p> </li> <li> <p>Require:</p> <ul> <li><code>DV(tmin) &gt;= 0</code> and <code>DV(tmax) &lt;= 0</code>, so that <code>phase1</code> is higher    at one end and lower at the other \u2192 sign change.</li> </ul> </li> <li> <p>If the sign change exists, use <code>optimize.brentq</code> to find <code>Tcrit</code> in <code>[tmin, tmax]</code>.</p> </li> <li> <p>Build a transition dict:</p> <pre><code>{\n  \"Tcrit\": Tcrit,\n  \"high_vev\": phase1.valAt(Tcrit),\n  \"high_phase\": phase1.key,\n  \"low_vev\": phase2.valAt(Tcrit),\n  \"low_phase\": phase2.key,\n  \"trantype\": 1,\n}\n</code></pre> </li> <li> <p>After looping over all pairs, sort the list in decreasing <code>Tcrit</code>.</p> </li> </ol> <p>Physics: <code>Tcrit</code> vs <code>Tnuc</code></p> <ul> <li> <p>For a first-order transition, <code>Tcrit</code> is the temperature where two minima become degenerate.</p> </li> <li> <p>But nucleation actually happens at a lower <code>Tnuc</code> where:</p> </li> </ul> <p>$$   \\frac{S_3(T)}{T} \\approx 140   $$</p> <p>(or whatever criterion you use in <code>tunnelFromPhase</code>).</p> <ul> <li>The difference <code>Tcrit \u2212 Tnuc</code> is a direct measure of supercooling.</li> </ul> <p>For a purely second-order transition:</p> <ul> <li>The minima coalesce at <code>Tcrit</code>, there is no barrier, and we typically have <code>Tnuc \u2248 Tcrit</code> and <code>trantype=2</code>.</li> </ul>"},{"location":"modules/transitionFinder/transitionFinder/#4-addcrittempsforfulltransitions-matching-tnuc-with-tcrit","title":"4. <code>addCritTempsForFullTransitions</code> \u2013 matching <code>Tnuc</code> with <code>Tcrit</code>","text":"<p>Role: <code>addCritTempsForFullTransitions(phases, crit_trans, full_trans)</code> glues together:</p> <ul> <li>the dynamical information from supercooled transitions (<code>full_trans</code>, typically output from <code>findAllTransitions</code>), and</li> <li>the static degeneracy information from <code>findCriticalTemperatures</code> (<code>crit_trans</code>).</li> </ul> <p>For each nucleation transition with a given <code>Tnuc</code>, it tries to find the \u201ccorresponding\u201d <code>Tcrit</code> along the graph of phases, and attaches that dictionary under the key <code>\"crit_trans\"</code>.</p> <p>Why this is useful</p> <p>In any realistic model you often want to quote both:</p> <ul> <li>the critical temperature (thermodynamic degeneracy),</li> <li>the nucleation temperature (kinetic onset of the transition),</li> </ul> <p>for each step in the cosmological history. Knowing both is essential for:</p> <ul> <li>estimating latent heat and strength of the transition,</li> <li>computing gravitational-wave spectra (supercooling directly affects the signal),</li> <li>comparing with analytic expectations.</li> </ul> <p>How the matching works (logic overview)</p> <ol> <li> <p>Build \u201cparent\u201d chains in the critical graph</p> </li> <li> <p>For each phase <code>i</code> in <code>phases</code>, we construct a list <code>parents_dict[i]</code>:</p> <pre><code>parents = [i, ...]\n</code></pre> <p>by scanning <code>crit_trans</code> from low T to high T and, whenever we see a critical transition <code>high \u2192 low</code> with <code>low</code> already in <code>parents</code>, we append <code>high</code>.</p> </li> <li> <p>Intuitively: these chains encode ancestry along critical transitions when moving from low T \u2192 high T.</p> </li> <li> <p>For each nucleation transition <code>tdict</code> in <code>full_trans</code>:</p> </li> <li> <p>Extract <code>low_phase</code> and <code>high_phase</code>.</p> </li> <li> <p>Get ancestry lists:</p> <ul> <li><code>low_parents = parents_dict[low_phase]</code>,</li> <li><code>high_parents = parents_dict[high_phase]</code>.</li> <li> <p>Find the set of common parents between these chains and carefully prune them:</p> </li> <li> <p>Remove common ancestors from the tail of <code>low_parents</code>,</p> </li> <li>Trim the tail of <code>high_parents</code> so that they share only the relevant high-T part.</li> <li>This focuses our search on the segment of the phase graph that actually distinguishes the two phases associated with this nucleation event.</li> </ul> </li> <li> <p>Scan <code>crit_trans</code> (from low T to high T):</p> </li> <li> <p>For each candidate <code>tcdict</code> in <code>crit_trans</code>:</p> <ul> <li> <p>Skip if <code>Tcrit &lt; Tnuc</code> (we only accept degeneracies above or at the nucleation temperature).</p> </li> <li> <p>Check whether:</p> </li> </ul> <pre><code>tcdict[\"low_phase\"]  in low_parents\ntcdict[\"high_phase\"] in high_parents\n</code></pre> <ul> <li>The first such match is taken to be the critical counterpart of the nucleation transition.</li> </ul> </li> <li> <p>Attach this dict as:</p> <pre><code>tdict[\"crit_trans\"] = tcdict\n</code></pre> </li> <li> <p>If no match is found, set:</p> <pre><code>tdict[\"crit_trans\"] = None\n</code></pre> </li> </ol> <p>If you want to see the full Block C implementation, look at the <code>transitionFinder</code> module in the same file where Blocks A and B live. Block C is the \u201cglue layer\u201d that:</p> <ul> <li>takes the phase structure from Block A,</li> <li>the bounce physics from Block B,</li> <li> <p>and turns them into a human-readable thermal history with:</p> </li> <li> <p>which phases appear,</p> </li> <li>at which temperatures they become degenerate,</li> <li>at which temperatures they actually nucleate,</li> <li>and whether each step is first- or second-order.</li> </ul>"},{"location":"modules/tunneling1D/single_field/","title":"Single Field Instanton","text":"<p>This document describes the single-field instanton solver and the public API that underpins it. The implementation follows  the overshoot/undershoot shooting method and supports both thin-wall and thick-wall regimes with robust numerical defaults. see the example page of this class if you want to understand more of each function!.</p>"},{"location":"modules/tunneling1D/single_field/#module-overview","title":"Module overview","text":"<p><code>tunneling1D</code> provides tools to compute O(\u03b1+1)\u2013symmetric bounce (instanton) solutions in one field dimension. In the absence of gravity, the equation of motion for a radial profile <code>phi(r)</code> reads</p> \\[\\frac{d^2\\phi}{dr^2} + \\frac{\\alpha}{r}\\frac{d\\phi}{dr} = \\frac{dV}{d\\phi}\\] <p>with boundary conditions</p> \\[\\phi '(0)=0 \\qquad \\phi(\\infty)=\\phi_{\\rm metaMin}\\] <p>The primary entry point is the class <code>SingleFieldInstanton</code>, which:</p> <ul> <li>validates the potential and basic inputs,</li> <li>supplies numerically stable derivative approximations when the user does not provide them,</li> <li>detects a characteristic scale and the barrier location,</li> <li>and exposes high-level routines to find the profile and the action.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#behavioral-guarantees-compatibility","title":"Behavioral guarantees &amp; compatibility","text":"<ul> <li>Scalar/array semantics. All derivative helpers accept scalars or NumPy arrays and preserve shapes.</li> <li>Backward compatibility. Names and signatures are preserved. If you supply custom <code>dV</code>/<code>d2V</code>, the class uses them everywhere.</li> <li>Numerical robustness. Defaults favor stability in thin-wall and stiff potentials; the step size never collapses to zero even if the two minima coincide numerically.</li> <li>Clear errors. Missing metastability or barriers raise <code>PotentialError</code> with informative messages.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#quick-usage-example","title":"Quick usage example","text":"<pre><code>import numpy as np\nfrom CosmoTransitions.tunneling1D import SingleFieldInstanton\n\n# Quartic potential with two minima\ndef V(phi):  return 0.25*phi**4 - 0.49*phi**3 + 0.235*phi**2\n\n# Instantiate the solver (use builtin derivatives)\ninst = SingleFieldInstanton(\n    phi_absMin=1.0,\n    phi_metaMin=0.0,\n    V=V,\n    alpha=2,          # O(3) symmetry\n    phi_eps=1e-3,     # relative FD step (safe floor applied automatically)\n    fd_order=4,       # 4th-order differences\n    validate=True,\n)\n\n# prof = inst.findProfile()\n# S    = inst.findAction(prof)\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#reproducibility-notes","title":"Reproducibility notes","text":"<ul> <li>The FD step is <code>h = max(phi_eps * |\u0394phi|, fd_eps_min, auto_floor)</code>, where <code>auto_floor \u2248 sqrt(machine_eps) \u00d7 scale</code>.</li> <li>Built-in derivative formulas are central differences and do not cache potential evaluations across calls; users may optimize their <code>V</code> if desired.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#class-singlefieldinstanton","title":"Class: <code>SingleFieldInstanton</code>","text":"<p>Compute properties of a single-field instanton via the overshoot/undershoot method. Most users will only call <code>findProfile</code> and <code>findAction</code>,  but the constructor and derivative helpers are documented here because they define the potential interface and core validations.</p>"},{"location":"modules/tunneling1D/single_field/#signature","title":"Signature","text":"<pre><code>class SingleFieldInstanton:\n    def __init__(\n        self,\n        phi_absMin: float,\n        phi_metaMin: float,\n        V: Callable[[float | np.ndarray], float | np.ndarray],\n        dV: Callable | None = None,\n        d2V: Callable | None = None,\n        phi_eps: float = 1e-3,\n        alpha: int | float = 2,\n        phi_bar: float | None = None,\n        rscale: float | None = None,\n        *,\n        fd_order: int = 4,\n        fd_eps_min: float | None = None,\n        validate: bool = True,\n    )\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose","title":"Purpose","text":"<p>Create a solver instance for a single scalar field in a given potential <code>V(phi)</code>, with optional user-supplied derivatives.  The instance owns all numerical settings (finite-difference step/accuracy, friction <code>\u03b1</code>, barrier point, characteristic radius scale) required by later calls.</p>"},{"location":"modules/tunneling1D/single_field/#parameters","title":"Parameters","text":"<ul> <li> <p><code>phi_absMin</code> (float)   Field value of the stable (true) vacuum.</p> </li> <li> <p><code>phi_metaMin</code> (float)   Field value of the metastable (false) vacuum.</p> </li> <li> <p><code>V</code> (callable)   Potential <code>V(phi)</code>. It may accept scalars or NumPy arrays (vectorized); scalar support is sufficient.</p> </li> <li> <p><code>dV</code>, <code>d2V</code> (callable | None)   Optional first and second derivatives. If provided, they override the built-in finite-difference routines. Either or both may be supplied.</p> </li> <li> <p><code>phi_eps</code> (float, default <code>1e-3</code>) Relative finite-difference step used by the built-in <code>dV</code>/<code>d2V</code>. The absolute step is</p> </li> </ul> \\[h = \\texttt{phi_eps}\\times |\\phi_{metaMin}-\\phi_{absMin}| \\] <p>A safe lower floor is applied automatically (see Notes).</p> <ul> <li> <p><code>alpha</code> (int | float, default <code>2</code>)   Friction coefficient in the ODE. For O(\u03b1+1) symmetry, <code>alpha</code> equals the spatial dimension.</p> </li> <li> <p><code>phi_bar</code> (float | None)   Field value at the edge of the barrier, defined by <code>V(phi_bar) = V(phi_metaMin)</code>. If <code>None</code>, it is found by <code>findBarrierLocation()</code>.</p> </li> <li> <p><code>rscale</code> (float | None)   Characteristic radial scale. If <code>None</code>, it is found by <code>findRScale()</code>.</p> </li> <li> <p><code>fd_order</code> {2, 4}, keyword-only, default <code>4</code>   Order of the built-in central finite differences (ignored if the user passes <code>dV</code>/<code>d2V</code>).</p> </li> <li> <p><code>fd_eps_min</code> (float | None), keyword-only   Absolute lower bound on the FD step <code>h</code>. If <code>None</code>, a safe value of order <code>sqrt(machine_eps) \u00d7 scale</code> is used.</p> </li> <li> <p><code>validate</code> (bool, default <code>True</code>), keyword-only   Perform basic sanity checks and emit helpful errors/warnings.</p> </li> </ul>"},{"location":"modules/tunneling1D/single_field/#raises","title":"Raises","text":"<ul> <li> <p><code>PotentialError(\"V(phi_metaMin) &lt;= V(phi_absMin); tunneling cannot occur.\", \"stable, not metastable\")</code>   If the potential is not metastable.</p> </li> <li> <p><code>PotentialError(...)</code>   If barrier finding or scale detection fails (e.g., no barrier, negative curvature fit).</p> </li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes","title":"Notes","text":"<ul> <li> <p>Thin-wall acceleration. When minima are nearly degenerate, the solver starts integration near the wall using a local quadratic solution, making the search efficient even for extremely thin walls.</p> </li> <li> <p>FD step safety. The absolute step <code>h</code> is computed from the minima separation; if the separation is tiny (or zero due to user inputs), a machine-precision-aware floor is applied to prevent catastrophic cancellation.</p> </li> <li> <p>Overrides. If you pass custom <code>dV</code>/<code>d2V</code>, the solver will use those everywhere (including the high-accuracy helper <code>dV_from_absMin</code>).</p> </li> <li> <p>Caching. The constructor caches <code>V(phi_absMin)</code>, <code>V(phi_metaMin)</code> and basic deltas; downstream methods reuse them.</p> </li> </ul>"},{"location":"modules/tunneling1D/single_field/#lot-sf-1-potential-interface-validations","title":"Lot SF-1 \u2014 Potential interface &amp; validations","text":"<p>This lot modernizes the potential interface and core validations, and provides the built-in derivatives.  The public names are unchanged for backward compatibility.</p>"},{"location":"modules/tunneling1D/single_field/#__init__","title":"<code>__init__</code>","text":"<p>See the class section above for the full signature and behavior. Implementation highlights:</p> <ul> <li>Metastability check: require <code>V(phi_metaMin) &gt; V(phi_absMin)</code>.</li> <li>Robust FD step: <code>h = max(phi_eps * |\u0394phi|, fd_eps_min or auto_floor)</code>, where <code>\u0394phi = phi_metaMin - phi_absMin</code> and <code>auto_floor ~ sqrt(machine_eps) \u00d7 scale</code>.</li> <li>User overrides respected: any provided <code>dV</code>/<code>d2V</code> replace the built-ins transparently.</li> <li>Barrier/scale: compute <code>phi_bar</code> and <code>rscale</code> if not supplied; accept user input but warn if <code>V(phi_bar) \u2249 V(phi_metaMin)</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#dvphi","title":"<code>dV(phi)</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_1","title":"Signature","text":"<pre><code>dV(phi: float | np.ndarray) -&gt; float | np.ndarray\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_1","title":"Purpose","text":"<p>Built-in finite-difference approximation to ( V'(\\phi) ). Works with scalars or arrays (broadcasted).  If the user supplied a custom <code>dV</code> at construction, that override is used instead.</p>"},{"location":"modules/tunneling1D/single_field/#scheme","title":"Scheme","text":"<ul> <li> <p>Order 4 (default) \\(\\(V'(\\phi)\\approx\\frac{V(\\phi-2h)-8V(\\phi-h)+8V(\\phi+h)-V(\\phi+2h)}{12h}\\)\\)</p> </li> <li> <p>Order 2 (fallback) \\(\\(V'(\\phi)\\approx\\frac{V(\\phi+h)-V(\\phi-h)}{2h}\\)\\)</p> </li> </ul> <p>with h =  absolute FD step defined in <code>__init__</code>.</p>"},{"location":"modules/tunneling1D/single_field/#parameters-returns-and-raises","title":"Parameters, Returns and Raises","text":"<ul> <li>Parameters: <code>phi</code> (float | array-like) points where to evaluate.</li> <li>Returns: same shape as <code>phi</code>.</li> <li>Raises: only propagates exceptions from user <code>V</code> (non-finite, etc.).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes_1","title":"Notes","text":"<ul> <li>The routine is side-effect free and vectorization-friendly.</li> <li>The step <code>h</code> is absolute; see <code>__init__</code> for how it is chosen safely.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#dv_from_absmindelta_phi","title":"<code>dV_from_absMin(delta_phi)</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_2","title":"Signature","text":"<pre><code>dV_from_absMin(delta_phi: float) -&gt; float\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_2","title":"Purpose","text":"<p>High-accuracy derivative at \\((\\phi=\\phi_{\\rm absMin}+\\delta\\phi)\\). Near the minimum, direct finite differences can lose precision; we therefore blend a Taylor estimate using (V'') with the FD estimate. This happens because near the true minimum \\(V'(\\phi)\\) it's expected to be exactly zero, therefore it's relevant to evaluate with an alternative Method, i.e., <code>V'(\\phi) \\approx V''(\\phi_{\\rm absMin}) (\\phi-\\phi_{\\rm absMin})</code></p>"},{"location":"modules/tunneling1D/single_field/#method","title":"Method","text":"<ul> <li>Let \\((\\phi=\\phi_{\\rm absMin}+\\delta\\phi)\\)</li> <li>Compute <code>dV_fd = dV(phi)</code> (built-in or user override).</li> <li>Compute <code>dV_lin = d2V(phi) * delta_phi</code>.</li> <li>Blend with a smooth weight</li> </ul> <p>\\(\\(w = \\exp\\Big[-\\big(\\delta\\phi/h\\big)^2\\Big],\\qquad h=\\text{FD step}\\)\\)   Return \\((w\\cdot dV_{\\rm lin} + (1-w)dV_{\\rm fd})\\).</p>"},{"location":"modules/tunneling1D/single_field/#parameters-returns-and-raises_1","title":"Parameters, Returns and Raises","text":"<ul> <li>Parameters: <code>delta_phi</code> (float) offset from the absolute minimum.</li> <li>Returns: (float) blended derivative at <code>phi_absMin + delta_phi</code>.</li> <li>Raises: Propagates only if user-supplied <code>dV</code>/<code>d2V</code> fail.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes_2","title":"Notes","text":"<ul> <li>Guarantees <code>dV_from_absMin(0.0) = 0.0</code> to within round-off (through the blend).</li> <li>Uses the same <code>h</code> configured in <code>__init__</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#d2vphi","title":"<code>d2V(phi)</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_3","title":"Signature","text":"<pre><code>d2V(phi: float | np.ndarray) -&gt; float | np.ndarray\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_3","title":"Purpose","text":"<p>Built-in finite-difference approximation to \\((V''(\\phi))\\). Works with scalars or arrays (broadcasted).  If the user supplied a custom <code>d2V</code>, that takes precedence.</p>"},{"location":"modules/tunneling1D/single_field/#scheme_1","title":"Scheme","text":"<ul> <li> <p>Order 4 (default) \\(\\(V''(\\phi)\\approx\\frac{-V(\\phi-2h)+16V(\\phi-h)-30V(\\phi)+16V(\\phi+h)-V(\\phi+2h)}{12h^2}\\)\\)</p> </li> <li> <p>Order 2 (fallback) \\(\\(V''(\\phi)\\approx\\frac{V(\\phi+h)-2V(\\phi)+V(\\phi-h)}{h^2}\\)\\)</p> </li> </ul>"},{"location":"modules/tunneling1D/single_field/#parameters-returns-and-raises_2","title":"Parameters, Returns and Raises","text":"<ul> <li>Parameters: <code>phi</code> (float | array-like).</li> <li>Returns: same shape as <code>phi</code>.</li> <li>Raises: only propagates exceptions from <code>V</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes_3","title":"Notes","text":"<ul> <li>Uses the same safe absolute step <code>h</code> as <code>dV</code>.</li> <li>Vectorized; preserves input shape (scalar-in \u2192 scalar-out).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#lot-sf-2-barrier-scales","title":"Lot SF-2 \u2014 Barrier &amp; scales","text":"<p>This lot modernizes how we locate the barrier that separates the metastable (false) vacuum from the absolute (true) vacuum and  how we estimate a characteristic radial scale for the instanton solution.  Both functions keep their legacy names and public behavior, but the numerics and diagnostics are stronger and more transparent.</p>"},{"location":"modules/tunneling1D/single_field/#findbarrierlocation","title":"<code>findBarrierLocation</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_4","title":"Signature","text":"<pre><code>findBarrierLocation(self) -&gt; float\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_4","title":"Purpose","text":"<p>Return the edge of the barrier (<code>phi_bar</code>) defined implicitly by</p> \\[V(\\phi_{\\mathrm{bar}}) = V(\\phi_{\\mathrm{metaMin}})\\] <p>on the downhill side of the barrier when moving from the metastable minimum toward the absolute minimum. This is the crossing point at which the field \u201cleaves\u201d the false-vacuum plateau as it rolls toward the true vacuum.</p>"},{"location":"modules/tunneling1D/single_field/#behavior-algorithm-whats-new","title":"Behavior &amp; algorithm (what\u2019s new)","text":"<ul> <li>We first locate the barrier top (<code>phi_top</code>) \u2014 the maximizer of (V) \u2014 in the open interval between the two minima via a bounded 1D search (robust even if the potential has gentle wiggles).</li> <li>We then solve for the downhill crossing of \\((G(\\phi)=V(\\phi)-V(\\phi_{\\rm metaMin}))\\) between <code>phi_top</code> and the absolute minimum using a bracketed Brent root.</li> <li> <p>On success, we return <code>phi_bar</code>. We also cache diagnostics in <code>self._barrier_info</code>:</p> </li> <li> <p><code>phi_bar</code>, <code>phi_top</code>,</p> </li> <li><code>V_top_minus_Vmeta = V(phi_top) - V(phi_metaMin)</code>,</li> <li><code>V_meta</code>, <code>V_abs</code>,</li> <li><code>interval = (min(phi_metaMin, phi_absMin), max(...))</code>.</li> </ul> <p>This approach eliminates fragile reliance on strict monotonicity and makes error messages precise.</p>"},{"location":"modules/tunneling1D/single_field/#parameters-returns-and-raises_3","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <p>None (uses the instance state).</p> <p>Returns</p> <ul> <li><code>float</code>: <code>phi_bar</code> such that \\((V(\\phi_{\\rm bar})=V(\\phi_{\\rm metaMin}))\\).</li> </ul> <p>Raises</p> <ul> <li><code>PotentialError(\"\u2026\", \"no barrier\")</code>: if the barrier top cannot be located inside the interval, or the barrier height is non-positive (no barrier).</li> <li><code>PotentialError(\"\u2026\", \"stable, not metastable\")</code>: defensively raised if \\((V(\\phi_{\\rm metaMin}) \\le V(\\phi_{\\rm absMin}))\\).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes_4","title":"Notes","text":"<ul> <li>The method is purely 1D and makes no smoothness assumptions beyond what the line search and root solver require (continuous (V)).</li> <li>The cached <code>self._barrier_info</code> lets you reuse <code>phi_top</code> and heights in later analysis/plots without recomputation.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#findrscale","title":"<code>findRScale</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_5","title":"Signature","text":"<pre><code>findRScale(self) -&gt; float\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_5","title":"Purpose","text":"<p>Estimate a characteristic radial scale \\((r_{\\rm scale})\\) for the instanton solution.  This sets physical step sizes for ODE integration and helps select plotting ranges.</p>"},{"location":"modules/tunneling1D/single_field/#physical-meaning-of-the-scale","title":"Physical meaning of the scale","text":"<p>Near the barrier top the Euclidean EoM linearizes to</p> \\[\\phi'' + \\frac{\\alpha}{r}\\phi' \\simeq V''(\\phi_{\\rm top}) \\bigl(\\phi - \\phi_{\\rm top}\\bigr)\\] <p>If the top were strictly quadratic with curvature \\((V''(\\phi_{\\rm top})&lt;0)\\), a naive local scale is \\((r_{\\rm curv}\\sim 1/\\sqrt{\\lvert V''(\\phi_{\\rm top})\\rvert})\\). However, many relevant potentials in cosmology/phase transitions have flat-topped barriers \\(((V''(\\phi_{\\rm top})\\approx 0))\\), making \\((r_{\\rm curv})\\) blow up  even when tunneling is well-defined.</p> <p>To remain stable and legacy-compatible, we adopt a cubic surrogate for the barrier shape that matches:</p> <ul> <li>a maximum at the top \\(((\\phi_{\\rm top}))\\),</li> <li>a minimum at the metastable vacuum \\(((\\phi_{\\rm metaMin}))\\),</li> </ul> <p>which yields the robust scale</p> \\[\\boxed{ r_{\\rm scale} = r_{\\rm cubic} = \\frac{\\bigl|\\phi_{\\rm top}-\\phi_{\\rm metaMin}\\bigr|} {\\sqrt{6[V(\\phi_{\\rm top})-V(\\phi_{\\rm metaMin})]}} }\\] <p>This remains finite on flat tops and empirically tracks the small-oscillation period scale up to an \\((\\mathcal{O}(1))\\) factor \u2014 ideal for setting numerics.</p>"},{"location":"modules/tunneling1D/single_field/#behavior-algorithm-whats-new_1","title":"Behavior &amp; algorithm (what\u2019s new)","text":"<ul> <li>Reuses <code>findBarrierLocation</code> to validate the barrier and obtain <code>phi_top</code> and its height above the false vacuum.</li> <li>Computes and returns the legacy cubic scale \\((r_{\\rm cubic})\\) (unchanged public behavior).</li> <li>Also computes an optional curvature diagnostic \\((r_{\\rm curv} = 1/\\sqrt{-V''(\\phi_{\\rm top})})\\) when  \\((V''(\\phi_{\\rm top})&lt;0)\\) (otherwise (+\\infty)).</li> <li> <p>Caches diagnostics in <code>self._scale_info</code>:</p> </li> <li> <p><code>phi_top</code>, <code>V_top_minus_Vmeta</code>, <code>xtop = phi_top - phi_metaMin</code>,</p> </li> <li><code>rscale_cubic</code>, <code>rscale_curv</code>, <code>d2V_top</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#parameters-returns-and-raises_4","title":"Parameters, returns and Raises","text":"<p>Parameters</p> <p>None (uses the instance state).</p> <p>Returns</p> <ul> <li><code>float</code>: \\((r_{\\rm scale} = r_{\\rm cubic})\\), used elsewhere for step sizes and domain lengths.</li> </ul> <p>Raises</p> <ul> <li><code>PotentialError(\"\u2026\", \"no barrier\")</code>: if the barrier fails validation (no interior top or non-positive height).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes_5","title":"Notes","text":"<ul> <li>Returning the cubic scale preserves the legacy interface and numerical behavior.</li> <li>The diagnostics are helpful for thin-wall detection, performance tuning, and sanity plots.</li> </ul> <p>Here\u2019s the continuation of <code>single_field.md</code> for the next block.</p>"},{"location":"modules/tunneling1D/single_field/#lot-sf-3-quadratic-local-solution-initial-conditions","title":"Lot SF-3 \u2014 Quadratic local solution &amp; initial conditions","text":"<p>This block implements the local (near-center) analytic control we use to (i) evaluate the field in a small neighborhood of the bubble center and (ii) generate safe initial conditions away from the (r=0) singular point of the radial equation. The two public members covered here are:</p> <ul> <li><code>exactSolution(r, phi0, dV, d2V)</code></li> <li><code>initialConditions(delta_phi0, rmin, delta_phi_cutoff)</code></li> </ul> <p>Both are methods of <code>SingleFieldInstanton</code>.</p>"},{"location":"modules/tunneling1D/single_field/#physical-background-why-bessel-functions-appear","title":"Physical background (why Bessel functions appear)","text":"<p>The Euclidean bounce equation for a spherically symmetric profile in \\(((\\alpha+1))\\) spatial dimensions is</p> \\[\\phi''(r) + \\frac{\\alpha}{r}\\phi'(r) = V'(\\phi)\\qquad r\\ge 0\\] <p>Near a chosen point \\((\\phi_0)\\) (typically very close to the true minimum \\((\\phi_{\\rm absMin})\\) when constructing thin-wall bounces),  Taylor-expand the potential to quadratic order:</p> \\[V'(\\phi) \\approx dV + d2V(\\phi-\\phi_0); \\quad dV = V'(\\phi_0);\\quad d2V = V''(\\phi_0)\\] <p>Let \\((\\delta\\phi(r)=\\phi(r)-\\phi_0)\\). Then</p> \\[\\delta\\phi'' + \\frac{\\alpha}{r}\\delta\\phi' - d2V\\delta\\phi = dV\\] <p>Shift out the constant drive with \\((\\delta\\phi=\\psi + dV/d2V)\\) (when \\((d2V\\neq 0)\\)), to obtain the homogeneous equation</p> \\[\\psi'' + \\frac{\\alpha}{r}\\psi' - d2V\\psi = 0\\] <p>whose regular solution at the origin is expressed in terms of Bessel functions. Defining</p> \\[\\nu \\equiv \\frac{\\alpha-1}{2}\\qquad ,\\beta \\equiv \\sqrt{|d2V|},\\qquad t \\equiv \\beta r\\] <p>the regular solution is</p> <ul> <li>Stable curvature ((d2V&gt;0), harmonic well):</li> </ul> \\[\\phi(r)-\\phi_0 = \\frac{dV}{d2V}\\Bigg[\\Gamma(\\nu+1)\\Big(\\tfrac{t}{2}\\Big)^{-\\nu} I_\\nu(t)-1\\Bigg]\\] <ul> <li>Unstable curvature ((d2V&lt;0), inverted well, e.g. near the barrier top): replace \\((I_\\nu \\to J_\\nu)\\).</li> </ul> <p>Regularity at the origin enforces \\((\\phi'(0)=0)\\) for any \\((\\alpha\\ge 0)\\).</p> <p>If (d2V=0) (flat curvature), the ODE reduces to a constant drive and the exact regular solution is the polynomial</p> \\[\\phi(r)=\\phi_0 + \\frac{dV}{2(\\alpha+1)}r^2\\qquad \\phi'(r)=\\frac{dV}{\\alpha+1}r\\] <p>These closed forms are what the code evaluates, with numerically stable branches for small/large arguments.</p>"},{"location":"modules/tunneling1D/single_field/#exactsolution","title":"<code>exactSolution</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_6","title":"Signature","text":"<pre><code>exactSolution(r: float, phi0: float, dV: float, d2V: float) -&gt; exactSolution_rval\n# exactSolution_rval = namedtuple(\"exactSolution_rval\", \"phi dphi\")\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_6","title":"Purpose","text":"<p>Compute the regular local solution \\(((\\phi(r),\\phi'(r)))\\) at radius (r) assuming a quadratic expansion of the potential around \\((\\phi_0)\\). This is used to:</p> <ul> <li>accurately probe the profile near the origin,</li> <li>build safe, physically consistent initial conditions for the global ODE solver.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#key-definitions-appearing-in-formulas-and-code","title":"Key definitions (appearing in formulas and code)","text":"<ul> <li>\\((\\alpha)\\): friction power in the radial term, i.e. spacetime dimension minus 1.</li> <li>\\((\\nu=(\\alpha-1)/2)\\): effective Bessel index fixed by the radial Laplacian.</li> <li>\\((\\beta=\\sqrt{|d2V|})\\) and \\((t=\\beta r)\\): scale &amp; argument controlling oscillatory/exponential behavior.</li> <li>Regularity: \\((\\phi'(0)=0)\\) (enforced exactly by the implementation).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#parameters_1","title":"Parameters","text":"<ul> <li><code>r</code> (<code>float</code>): radius (\u2265 0). At <code>r==0</code> the method returns <code>(phi0, 0.0)</code> exactly.</li> <li><code>phi0</code> (<code>float</code>): expansion point for the quadratic model.</li> <li><code>dV</code> (<code>float</code>): \\((V'(\\phi_0))\\).</li> <li><code>d2V</code> (<code>float</code>): \\((V''(\\phi_0))\\).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#returns","title":"Returns","text":"<ul> <li><code>exactSolution_rval(phi, dphi)</code>: field and radial derivative at radius <code>r</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#implementation-notes","title":"Implementation notes","text":"<ul> <li>Flat curvature (<code>d2V==0</code>): uses the exact polynomial solution above (no Bessel calls).</li> <li>Small argument (<code>t = beta*r \u2264 1e-5</code>): uses a short even-power series up to (t^6), which is well-conditioned and avoids any division by <code>r</code>.</li> <li>General case: uses the Bessel/modified-Bessel forms, with overflow/underflow warnings suppressed locally; the combined expressions are finite.</li> <li>Input validation ensures all inputs are finite and <code>r\u22650</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#physical-interpretation","title":"Physical interpretation","text":"<ul> <li>(d2V&gt;0): local restoring force; near a true minimum the solution is \u201cmassive\u201d and grows as \\((I_\\nu(t))\\) but regularized to match \\((\\phi'(0)=0)\\).</li> <li>(d2V&lt;0): local tachyonic/inverted curvature, relevant near the barrier top; the solution is oscillatory via \\((J_\\nu)\\).</li> <li>(d2V=0): locally flat\u2014driven purely by the constant slope (dV); the profile starts quadratically from the center.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#initialconditions","title":"<code>initialConditions</code>","text":""},{"location":"modules/tunneling1D/single_field/#signature_7","title":"Signature","text":"<pre><code>initialConditions(delta_phi0: float, rmin: float, delta_phi_cutoff: float) -&gt; initialConditions_rval\n# initialConditions_rval = namedtuple(\"initialConditions_rval\", \"r0 phi dphi\")\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#purpose_7","title":"Purpose","text":"<p>Choose where to start integrating the full ODE (away from the (r=0) singularity) and with which values \\(((\\phi,\\phi'))\\), using the local quadratic solution as a high-accuracy guide.  The goal is to start just outside the bubble center yet already sufficiently displaced from the true minimum to keep the  overshoot/undershoot search efficient and stable.</p>"},{"location":"modules/tunneling1D/single_field/#inputs-meaning","title":"Inputs &amp; meaning","text":"<ul> <li><code>delta_phi0</code>: desired central offset \\(( \\phi(0)-\\phi_{\\rm absMin} )\\). In thin-wall cases this can be very small.</li> <li><code>rmin</code>: the smallest radius allowed for starting the global integration (relative to <code>rscale</code> in higher-level code).</li> <li><code>delta_phi_cutoff</code>: the target magnitude of the field offset at the starting radius \\((r_0)\\):   \\((|\\phi(r_0)-\\phi_{\\rm absMin}| &gt; |\\delta\\phi_{\\rm cutoff}|)\\).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#strategy-what-the-code-does","title":"Strategy (what the code does)","text":"<ol> <li>Construct \\((\\phi_0 = \\phi_{\\rm absMin} + \\delta\\phi_0)\\) and compute \\((dV=V'(\\phi_0))\\), \\((d2V=V''(\\phi_0))\\).</li> <li> <p>Use <code>exactSolution</code> at <code>rmin</code>.</p> </li> <li> <p>If \\((|\\phi(r_{\\min})-\\phi_{\\rm absMin}| &gt; |\\delta\\phi_{\\rm cutoff}|)\\), start there.</p> </li> <li>If the field is moving the wrong way (sign of \\((\\phi'(r_{\\min}))\\) opposite to \\((\\delta\\phi_0))\\), start there as well; increasing (r) won\u2019t fix the direction.</li> <li>Otherwise, geometrically increase (r) (\u00d710 each step) and re-evaluate with <code>exactSolution</code> until the cutoff is exceeded (this brackets the crossing).</li> <li>Solve for the exact \\((r_0)\\) by a 1D root find on    \\((f(r)=|\\phi(r)-\\phi_{\\rm absMin}|-|\\delta\\phi_{\\rm cutoff}|)\\).</li> <li>Return \\(((r_0,\\phi(r_0),\\phi'(r_0)))\\) as a named tuple.</li> </ol> <p>If the geometric search fails to bracket the crossing (pathological potential/settings), a clear <code>IntegrationError</code> is raised.</p>"},{"location":"modules/tunneling1D/single_field/#returns_1","title":"Returns","text":"<ul> <li><code>initialConditions_rval(r0, phi, dphi)</code>: starting radius and values to feed the global integrator.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#notes-guidance","title":"Notes &amp; guidance","text":"<ul> <li>This method is agnostic to the global wall shape; it only relies on the local quadratic model, which is accurate near the true minimum where \\((r_0)\\) lives in thin-wall cases.</li> <li>Choosing a too large <code>delta_phi_cutoff</code> may degrade accuracy (starting too far from the regime where the quadratic model is excellent). Too small can slow down the shoot or underflow numerics. The default policy used upstream balances these effects.</li> <li>The named-tuple interface is intentional\u2014downstream code can unpack by name or position.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#common-assumptions-for-both-functions","title":"Common assumptions (for both functions)","text":"<ul> <li>Spherical symmetry and regularity at the origin \\(((\\phi'(0)=0))\\).</li> <li>The principal branches for \\((\\sqrt{\\cdot})\\) and Bessel functions are used.</li> <li>\\((\\alpha\\ge 0)\\) (physical cases); nonetheless, the formulas are coded generically.</li> <li>All inputs are finite; non-finite inputs raise a value error upfront.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#numerical-stability-accuracy","title":"Numerical stability &amp; accuracy","text":"<ul> <li>Small-argument regime: the (t)-series keeps terms through \\((t^6)\\), which is more than enough for \\((t\\lesssim 10^{-2})\\) in double precision.</li> <li>Flat curvature: handled by an exact polynomial; no Bessel calls or divisions-by-(r).</li> <li>Overflow/underflow: benign warnings inside SciPy\u2019s Bessel routines are silenced locally, and the combinations used are finite by construction.</li> <li>Deterministic regularity: at <code>r==0</code>, <code>exactSolution</code> returns <code>(phi0, 0.0)</code> exactly.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#quick-reference-symbols","title":"Quick reference (symbols)","text":"<ul> <li>\\((\\alpha)\\): friction power in the radial Laplacian; equals spacetime dimension minus 1.</li> <li>\\((\\nu=(\\alpha-1)/2)\\): Bessel index.</li> <li>\\((dV=V'(\\phi_0))\\), \\((d2V=V''(\\phi_0))\\): local slope &amp; curvature of the potential.</li> <li>\\((\\beta=\\sqrt{|d2V|})\\), \\((t=\\beta r)\\): scale and argument for Bessel functions.</li> <li>\\((\\phi_{\\rm absMin})\\), \\((\\phi_{\\rm metaMin})\\): true and false vacuum field values (set in the class constructor).</li> <li><code>delta_phi0</code>, <code>delta_phi_cutoff</code>: user-level displacements used to place the start of the integration.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#lot-sf-4-ode-core-equation-adaptive-driver-sampler","title":"Lot SF-4 \u2014 ODE core (equation, adaptive driver, sampler)","text":"<p>This lot contains the numerical engine that integrates the bounce equation once the potential interface and scales are known. It provides:</p> <ul> <li>the equation of motion in first-order form;</li> <li>an adaptive step driver that marches the solution and classifies the outcome as overshoot, undershoot, or converged;</li> <li>a sampler that fills a user-chosen radial grid with a smooth profile using cubic Hermite interpolation between accepted RK steps;</li> <li>a small tolerance normalizer to make error controls explicit and robust.</li> </ul> <p>Throughout, we solve the radial Euclidean EOM for a single field,</p> \\[\\frac{d^2\\phi}{dr^2}+\\frac{\\alpha}{r}\\frac{d\\phi}{dr}= \\frac{dV}{d\\phi}(\\phi)\\] <p>where \\((\\alpha)\\) is the \u201cfriction\u201d coefficient (commonly \\((\\alpha=2)\\) for (O(3)) finite-temperature bounces and \\((\\alpha=3)\\) for \\((O(4))\\) zero-temperature bounces).  The \\((\\alpha/r)\\) term comes from the radial Laplacian in \\(((\\alpha+1))\\) dimensions.</p>"},{"location":"modules/tunneling1D/single_field/#_normalize_tolerances-internal-helper","title":"<code>_normalize_tolerances</code> (internal helper)","text":"<p>Signature</p> <pre><code>@staticmethod\n_normalize_tolerances(epsfrac, epsabs) -&gt; tuple[float, float, float, float]\n</code></pre> <p>Purpose</p> <p>Accepts either scalars or 2-component arrays for the relative/absolute tolerances and returns:</p> <ol> <li><code>ef_scalar</code> \u2013 a single relative tolerance passed to the RK stepper (strictest across components);</li> <li><code>ea_scalar</code> \u2013 a single absolute tolerance for the RK stepper (strictest across components);</li> <li><code>eps_phi</code>   \u2013 absolute threshold (3\u00d7 <code>epsabs</code> for \\((\\phi)\\)) used by our event/convergence tests;</li> <li><code>eps_dphi</code>  \u2013 absolute threshold (3\u00d7 <code>epsabs</code> for \\((d\\phi)\\)) used likewise.</li> </ol> <p>This keeps the step controller simple (scalar tolerances) while still giving per-component, physically meaningful stopping criteria.</p> <p>Notes</p> <ul> <li>If <code>epsabs</code> is scalar, both \\((\\phi)\\) and \\((d\\phi)\\) use the same \\((3\\times)\\) threshold; with a 2-vector, they may differ.</li> <li>The factor 3 in <code>eps_phi</code>, <code>eps_dphi</code> mirrors the legacy \u201cwithin ~3\u00d7 absolute tol \u21d2 good enough\u201d convention used elsewhere in this module.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#equationofmotion","title":"<code>equationOfMotion</code>","text":"<p>Signature</p> <pre><code>equationOfMotion(y: np.ndarray, r: float) -&gt; np.ndarray\n</code></pre> <p>Purpose</p> <p>Right-hand side of the first-order system for \\((y=[\\phi, \\dot\\phi])\\) \\((dot \u2261 (d/dr))\\):</p> \\[\\dot{\\phi} = y_1\\qquad \\dot{y}_1 = \\frac{dV}{d\\phi}(\\phi) - \\frac{\\alpha}{r} y_1\\] <p>Implementation details</p> <ul> <li>To guard against accidental calls at (r=0) (which should not happen in production\u2014integrations always start at (r&gt;0)), we replace (r) by a tiny positive <code>r_eff</code> if needed so the friction term stays finite.</li> <li>Uses the user-provided/derived <code>self.dV(phi)</code>.</li> </ul> <p>Physics notes</p> <p>The \\(( \\alpha/r )\\) \u201cfriction\u201d originates from the radial Laplacian in \\(((\\alpha+1))\\) Euclidean dimensions. Regular bounce solutions satisfy \\(( d\\phi/dr = \\mathcal{O}(r) )\\) as \\(( r\\to 0 )\\), so the product \\(( (\\alpha/r)d\\phi )\\) remains finite.</p>"},{"location":"modules/tunneling1D/single_field/#integrateprofile","title":"<code>integrateProfile</code>","text":"<p>Signature</p> <pre><code>integrateProfile(\n    r0: float,\n    y0: array_like,      # [phi(r0), dphi(r0)]\n    dr0: float,\n    epsfrac, epsabs,     # scalar or 2-vector tolerances\n    drmin: float,\n    rmax: float,\n    *eqn_args\n) -&gt; namedtuple(\"integrateProfile_rval\", \"r y convergence_type\")\n</code></pre> <p>What it does</p> <p>Advances the ODE solution from \\(((r_0,y_0))\\) using an adaptive Cash\u2013Karp RK5(4) stepper (<code>rkqs</code>) until one of three conditions is met:</p> <ol> <li>converged \u2013 both \\((|\\phi-\\phi_{\\rm metaMin}|&lt;\\epsilon_{\\phi})\\) and \\((|d\\phi|&lt;\\epsilon_{d\\phi})\\);</li> <li>overshoot \u2013 within a step the field crosses \\((\\phi_{\\rm metaMin})\\);</li> <li>undershoot \u2013 within a step the field \u201cturns back\u201d (sign of \\((d\\phi)\\) indicates motion away from the target).</li> </ol> <p>In (2) and (3), we locate the event inside the last accepted step by cubic Hermite interpolation (our <code>cubicInterpFunction</code>), and refine with a bracketing root find (<code>scipy.optimize.brentq</code>). If bracketing fails (rare, degenerate slope), we fall back to the point minimizing the relevant magnitude (either \\((|\\phi-\\phi_{\\rm metaMin}|)\\) or \\((|d\\phi|))\\) on a small uniform subgrid of the step.</p> <p>Inputs &amp; error control</p> <ul> <li> <p><code>epsfrac</code>, <code>epsabs</code> can be scalars or 2-vectors. They are normalized via <code>_normalize_tolerances</code>:</p> </li> <li> <p><code>ef_scalar</code>, <code>ea_scalar</code> go to <code>rkqs</code>;</p> </li> <li><code>eps_phi</code>, <code>eps_dphi</code> define the event/convergence thresholds.</li> <li><code>drmin</code> prevents step underflow; if an accepted step requests <code>dr&lt;drmin</code>, we abort with a clear <code>IntegrationError</code>.</li> <li><code>rmax</code> limits the total travelled distance; we abort if \\((r &gt; r_0 + r_{\\max})\\).</li> </ul> <p>Direction logic (overshoot vs. undershoot)</p> <p>We define a sign <code>ysign</code> that encodes \u201cwhere the target is\u201d relative to the current motion:</p> <ul> <li>If we start noticeably away from the target, <code>ysign = sign(phi - phi_metaMin)</code>.</li> <li>If we start essentially on target, we use <code>ysign = -sign(dphi)</code> so that moving away is treated as an undershoot and a crossing back is an overshoot.</li> </ul> <p>Given <code>ysign</code>, we classify a step by looking at:</p> <ul> <li>undershoot if <code>dphi * ysign &gt; +eps_dphi</code> (slope keeps pushing further from target);</li> <li>overshoot if <code>(phi - phi_metaMin) * ysign &lt; -eps_phi</code> (crossing the target).</li> </ul> <p>Return value</p> <p>A named tuple with:</p> <ul> <li><code>r</code> \u2013 the final radius (event location or the last time where convergence was satisfied),</li> <li><code>y</code> \u2013 the final state \\(([\\phi, d\\phi])\\) at that radius,</li> <li><code>convergence_type</code> \u2013 one of <code>\"converged\"</code>, <code>\"overshoot\"</code>, <code>\"undershoot\"</code>.</li> </ul> <p>Why cubic Hermite interpolation?</p> <p>We know \\((y_0, dy/dr\\cdot {r_0})\\) and \\((y_1, dy/dr\\cdot {r_1})\\) for both ends of a step.  The cubic Hermite (a.k.a. piecewise cubic with end slopes) reconstructs a smooth in-step curve that respects both values and slopes,  giving accurate, monotone-friendly event localization without taking extra ODE mini-steps.</p> <p>Typical usage</p> <p><code>findProfile</code> uses this method in a bisection-like loop over the shooting parameter, reading only the outcome (\u201cover/under/converged\u201d) and the precise event radius.  After the best initial condition is found, it calls <code>integrateAndSaveProfile</code> to produce a full, nicely sampled wall profile.</p>"},{"location":"modules/tunneling1D/single_field/#integrateandsaveprofile","title":"<code>integrateAndSaveProfile</code>","text":"<p>Signature</p> <pre><code>integrateAndSaveProfile(\n    R: array_like,       # monotonically increasing radii\n    y0: array_like,      # [phi(R[0]), dphi(R[0])]\n    dr: float,\n    epsfrac, epsabs,     # scalar or 2-vector tolerances\n    drmin: float,\n    *eqn_args\n) -&gt; namedtuple(\"Profile1D\", \"R Phi dPhi Rerr\")\n</code></pre> <p>Purpose</p> <p>Integrate the ODE once more and fill a user-specified radial grid (R) with \\((\\phi(R_i))\\) and \\((d\\phi/dR(R_i))\\).  This is the second (\u201csampling\u201d) pass typically used after the shooting has determined the correct initial condition and outer radius.</p> <p>How it works</p> <ul> <li>Uses the same adaptive RK driver as <code>integrateProfile</code>.</li> <li>Between accepted RK step endpoints \\(((r_0,y_0))\\) and \\(((r_1,y_1))\\), it evaluates the same cubic Hermite interpolant and writes samples for all <code>R[i] \u2208 (r0, r1]</code>.</li> <li>If a proposed accepted step would have <code>dr &lt; drmin</code>, it clamps to <code>drmin</code>, records <code>Rerr</code> on first occurrence (the radius where step clamping first became necessary), and continues so the output arrays are always fully populated.</li> </ul> <p>Outputs</p> <ul> <li><code>R</code> \u2013 the input grid, echoed back;</li> <li><code>Phi</code> \u2013 values \\((\\phi(R_i))\\);</li> <li><code>dPhi</code> \u2013 values \\((d\\phi/dR(R_i))\\);</li> <li><code>Rerr</code> \u2013 <code>None</code> if every accepted step satisfied <code>dr \u2265 drmin</code>; otherwise the first radius where clamping was applied.</li> </ul> <p>Notes</p> <ul> <li>This routine does not attempt to classify events (over/under/converged). That logic belongs in <code>integrateProfile</code>. Here the goal is to sample a known good solution.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#practical-guidance","title":"Practical guidance","text":"<ul> <li> <p>Tolerances. A good starting point mirrors the legacy defaults used in the higher-level driver:</p> </li> <li> <p><code>epsfrac = [phitol, phitol]</code>,</p> </li> <li><code>epsabs = [|\u0394\u03c6|\u00b7phitol, |\u0394\u03c6|/rscale \u00b7 phitol]</code>,     with <code>phitol ~ 1e-4</code> and <code>\u0394\u03c6 = \u03c6_metaMin \u2212 \u03c6_absMin</code>. You can also pass scalars.</li> <li>Initial step. Set <code>dr0 ~ rmin</code> (the same \u201csmall\u201d radius where we start, coming from Lot SF-2\u2019s <code>rscale</code>).</li> <li>Limits. Choose <code>rmax</code> comfortably above the expected wall thickness (often <code>~O(10)\u00b7rscale)</code>); choose <code>drmin</code> at least a few orders of magnitude below the smallest features you want to resolve.</li> <li>Performance. The cubic Hermite interpolation avoids tiny corrective micro-steps for event localization, which keeps the driver fast while maintaining smooth, physically sensible crossings.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#failure-modes-and-messages","title":"Failure modes and messages","text":"<ul> <li><code>IntegrationError(\"... exceeded rmax ...\")</code> \u2013 the profile did not settle/cross within the allowed domain; revisit <code>rmax</code> or the shooting parameter.</li> <li><code>IntegrationError(\"... step underflow ...\")</code> \u2013 the stepper kept asking for <code>dr &lt; drmin</code> to meet tolerances; loosen tolerances or increase <code>drmin</code> cautiously.</li> <li>Value errors guard obvious API misuse (non-finite <code>y0</code>, wrong shapes, non-monotonic <code>R</code>, etc.).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#summary","title":"Summary","text":"<p>Lot SF-4 equips the <code>SingleFieldInstanton</code> class with a clean, robust integrator:</p> <ul> <li>a physically faithful ODE (with friction and a safe \\((r\\to 0)\\) guard),</li> <li>an adaptive, tolerance-driven stepper with explicit convergence semantics (over/under/converged),</li> <li>and a high-quality sampler that turns accepted steps into smooth profiles on any grid.</li> </ul> <p>These pieces are deliberately modular: subclasses (e.g., constant friction walls) reuse the same machinery by passing extra arguments to <code>equationOfMotion</code> via <code>*eqn_args</code>, while keeping the numerics identical.</p>"},{"location":"modules/tunneling1D/single_field/#lot-sf-5-profile-search-overshootundershoot","title":"Lot SF-5 \u2014 Profile search (overshoot/undershoot)","text":"<p>Goal. Find the full bounce profile \\(( \\phi(r) )\\) by shooting on the unknown center value \\(( \\phi(0) )\\).  We adjust a scalar parameter (x) so that the outward integration converges onto the false (metastable) vacuum as \\(( r\\to\\infty )\\).  The search uses classic overshoot/undershoot bracketing and a final dense sampling pass.</p>"},{"location":"modules/tunneling1D/single_field/#singlefieldinstantonfindprofile","title":"<code>SingleFieldInstanton.findProfile(...)</code>","text":"<p>Signature (unchanged).</p> <pre><code>findProfile(\n    xguess=None, xtol=1e-4, phitol=1e-4,\n    thinCutoff=0.01, npoints=500, rmin=1e-4, rmax=1e4,\n    max_interior_pts=None\n) -&gt; Profile1D  # (R, Phi, dPhi, Rerr)\n</code></pre>"},{"location":"modules/tunneling1D/single_field/#what-problem-this-solves","title":"What problem this solves","text":"<p>We need the solution of</p> \\[\\phi''(r) + \\frac{\\alpha}{r}\\phi'(r) = V'(\\phi)\\] <p>that starts at the true minimum \\(((\\phi\\approx\\phi_{\\rm absMin}))\\) near (r=0) and asymptotes to the false minimum \\(((\\phi\\to\\phi_{\\rm metaMin}))\\) for large (r).  The correct central value \\((\\phi(0))\\) is not known a priori; we determine it by shoot-and-correct.</p>"},{"location":"modules/tunneling1D/single_field/#the-shooting-parameter-x","title":"The shooting parameter (x)","text":"<p>Instead of varying \\((\\phi(0))\\) directly, we vary</p> <p>\\(\\(\\boxed{\\phi(0) \\equiv \\phi_{\\rm absMin}+ e^{-x}\\big(\\phi_{\\rm metaMin}-\\phi_{\\rm absMin}\\big)}\\)\\)   so that:</p> <ul> <li>Small (x) \u2192 \\((\\phi(0))\\) close to the false minimum (high potential energy) \u2192 dynamics tend to overshoot across \\((\\phi_{\\rm metaMin})\\).</li> <li>Large (x) \u2192 \\((\\phi(0))\\) close to the true minimum (low energy) \u2192 dynamics turn around before reaching \\((\\phi_{\\rm metaMin})\\) (undershoot).</li> </ul> <p>If <code>xguess</code> is not provided, we choose a sensible default by placing \\((\\phi(0))\\) near the barrier \u201cedge\u201d \\((\\phi_{\\rm bar})\\), i.e.</p> \\[x_{\\rm init} \\approx -\\ln\\left( \\frac{\\phi_{\\rm bar}-\\phi_{\\rm absMin}}{\\phi_{\\rm metaMin}-\\phi_{\\rm absMin}} \\right).\\]"},{"location":"modules/tunneling1D/single_field/#radii-and-tolerances-numerics","title":"Radii and tolerances (numerics)","text":"<ul> <li> <p>We scale all radii with the characteristic <code>rscale</code> (Lot SF-2).</p> </li> <li> <p><code>rmin * rscale</code>: the starting radius guess and initial stepsize.</p> </li> <li><code>drmin = 0.01 * rmin * rscale</code>: minimum allowed stepsize for the RK driver.</li> <li><code>rmax * rscale</code>: maximum travel distance from the start.</li> <li> <p>Error controls for the adaptive RK driver (Lot SF-4):</p> </li> <li> <p><code>phitol</code> sets both relative (<code>epsfrac=[phitol, phitol]</code>) and absolute tolerances</p> </li> </ul> <p>\\(\\(epsabs = \\big[\\texttt{phitol}\\cdot |\\Delta\\phi|, \\texttt{phitol}\\cdot |\\Delta\\phi|/\\texttt{rscale}\\big]\\)\\)     for \\(([\\phi,\\phi'])\\).   * The driver uses a strict scalar for per-step control and per-component thresholds for event detection and convergence.</p>"},{"location":"modules/tunneling1D/single_field/#step-by-step-algorithm","title":"Step-by-step algorithm","text":"<ol> <li> <p>Map \\((x\\to\\Delta\\phi_0)\\). \\((\\Delta\\phi_0 = e^{-x}(\\phi_{\\rm metaMin}-\\phi_{\\rm absMin}))\\).</p> </li> <li> <p>Practical initial surface at \\((r_0&gt;0)\\).    Call <code>initialConditions(\u0394\u03c60, rmin*rscale, thinCutoff*|\u0394\u03c6|)</code>.    This uses the local quadratic solution (Lot SF-3) to pick \\((r_0)\\) such that    \\((|\\phi(r_0)-\\phi_{\\rm absMin}| \\approx \\texttt{thinCutoff}\\cdot|\\Delta\\phi|)\\)    and returns$ ((r_0,\\phi(r_0),\\phi'(r_0)))$.    Intuition: for thin walls, start integration near the wall (not at the exact center), which stabilizes shooting.</p> </li> <li> <p>Trial integration and event classification.    Run <code>integrateProfile(r0, y0, ...)</code> (Lot SF-4). Three outcomes:</p> </li> <li> <p><code>\"converged\"</code>: \\(( |\\phi-\\phi_{\\rm metaMin}| )\\) and \\(( |\\phi'| )\\) are within tolerance.</p> </li> <li><code>\"overshoot\"</code>: within the last step, \\((\\phi)\\) crossed \\((\\phi_{\\rm metaMin})\\);      we locate the crossing by cubic Hermite interpolation (with consistent slopes).</li> <li> <p><code>\"undershoot\"</code>: the field turns around before reaching \\((\\phi_{\\rm metaMin})\\)      (detected via \\((\\phi'=0 )\\)), again located by cubic interpolation.</p> </li> <li> <p>Bracket in (x) and bisect.    Maintain \\(([x_{\\min}, x_{\\max}])\\) such that:</p> </li> <li> <p>undershoot \u21d2 \\((x_{\\min} \\leftarrow x)\\) (we were too close to the true minimum);</p> </li> <li> <p>overshoot \u21d2 (\\(x_{\\max} \\leftarrow x)\\) (we were too close to the false minimum).      If no upper bound yet, expand geometrically (<code>xincrease \u2248 5</code>).      Once bracketing exists, bisect until \\((x_{\\max}-x_{\\min}&lt;\\texttt{xtol})\\) or we get <code>\"converged\"</code>.</p> </li> <li> <p>Final dense pass (returned profile).    With the last valid \\(((r_0,y_0))\\) and end radius \\((r_f)\\), build a uniform array    <code>R = linspace(r0, rf, npoints)</code> and call    <code>integrateAndSaveProfile(R, y0, ...)</code>.    This integrates adaptively and fills every <code>R[i]</code> by cubic Hermite interpolation between accepted RK steps. The return object is:</p> </li> <li> <p><code>R</code>: radii,</p> </li> <li><code>Phi</code>: (\\phi(R)),</li> <li><code>dPhi</code>: (\\phi'(R)),</li> <li> <p><code>Rerr</code>: first radius where the step would have fallen below <code>drmin</code> (if it happened), else <code>None</code>.</p> </li> <li> <p>(Optional) Interior points \\((0 \\le r &lt; r_0)\\).    If <code>max_interior_pts</code> is not zero, we synthesize points in the bubble interior using the analytic local solution (<code>exactSolution</code>) derived in Lot SF-3. We place up to <code>max_interior_pts</code> points on a non-uniform grid that lands exactly on (r=0) and \\((r=r_0)\\), then concatenate interior and integrated segments.</p> </li> <li> <p>If <code>max_interior_pts=None</code>, we default to <code>npoints//2</code>.</p> </li> <li>Set it to <code>0</code> to skip interior fill.</li> </ol>"},{"location":"modules/tunneling1D/single_field/#convergence-failure-modes-and-what-to-tweak","title":"Convergence / failure modes (and what to tweak)","text":"<ul> <li>Iteration cap reached while bracketing in (x): increase <code>rmax</code>, relax <code>phitol</code>, or widen <code>thinCutoff</code> so the initial surface is farther from the center (easier shooting).</li> <li>Step underflow (<code>dr &lt; drmin</code>) in the driver: increase <code>rmin</code> (hence <code>drmin</code>) or relax <code>phitol</code>.</li> <li>Both trials on the same side (can't bracket): try a smaller/larger <code>xguess</code>, or increase <code>xincrease</code> (implicitly done inside); extreme thin-wall cases often benefit from a larger <code>thinCutoff</code> (e.g. <code>0.05\u20130.2</code>).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#physical-interpretation_1","title":"Physical interpretation","text":"<ul> <li>In the thin-wall limit (almost degenerate minima), the correct (x) is large: \\((\\phi(0))\\) sits very close to the true vacuum and the wall is narrow. Small changes in (x) produce large changes in outcome\u2014hence the careful bracketing.</li> <li>In the thick-wall regime, the search is gentler: the field starts farther from the true minimum, and both overshoot/undershoot are easier to bracket.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#output-guarantees","title":"Output guarantees","text":"<ul> <li>The returned profile always corresponds to the last successful integration over \\(([r_0,r_f])\\), sampled at <code>npoints</code>. If an interior segment is synthesized, the profile begins at (r=0); otherwise it begins at \\((r=r_0&gt;0)\\) (typical for thin walls).</li> <li><code>Rerr</code> is purely diagnostic: if not <code>None</code>, it marks the first place where the integrator had to clamp a too-small step to <code>drmin</code>; the profile remains valid.</li> </ul> <p>In short: <code>findProfile</code> wraps three building blocks developed in the previous lots\u2014(i) a stable local start (<code>initialConditions</code>),  (ii) an event-aware, tolerance-controlled driver (<code>integrateProfile</code>), and (iii) a dense sampler (<code>integrateAndSaveProfile</code>)\u2014into a robust overshoot/undershoot search in the single scalar parameter (x).</p>"},{"location":"modules/tunneling1D/single_field/#lot-sf-6-action-post-processing","title":"Lot SF-6 \u2014 Action &amp; post-processing","text":"<p>Goal.  Given a converged bounce profile \\(((R,\\Phi(R),\\Phi'(R)))\\), compute the Euclidean action and provide diagnostics  and geometric scales that are useful for interpretation and downstream phenomenology. This lot modernizes the legacy <code>findAction</code> and adds practical post-processing helpers.</p> <p>Context &amp; notation</p> <ul> <li>We work in \\((d=\\alpha+1)\\) radial dimensions (i.e., \\((\\alpha=d-1)\\) in the ODE).</li> <li>The unit \\((\\alpha)\\)-sphere area is</li> </ul> \\[\\Omega_\\alpha \\equiv \\frac{2\\pi^{(\\alpha+1)/2}}{\\Gamma!\\big((\\alpha+1)/2\\big)}\\] <ul> <li>A profile is the named tuple returned by <code>findProfile</code>: <code>profile.R</code>, <code>profile.Phi</code>, <code>profile.dPhi</code> (and <code>profile.Rerr</code>).</li> <li>We subtract the false-vacuum energy \\((V(\\phi_{\\rm meta}))\\) so the action density is anchored at the metastable vacuum.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#whats-new-vs-the-legacy","title":"What\u2019s new vs. the legacy","text":"<ul> <li>New: <code>actionBreakdown(profile)</code> \u2014 splits (S) into kinetic/potential/\u201cinterior bulk\u201d pieces and returns per-radius densities for plotting and checks.</li> <li>New: <code>wallDiagnostics(profile, frac=(0.1,0.9))</code> \u2014 estimates wall position and thickness directly from the profile (levels in \\((\\phi)\\) and peak \\((|\\Phi'|)\\)).</li> <li>New: <code>betaEff(profile, method=...)</code> \u2014 proxies for an inverse length/time scale \\((\\beta_{\\rm eff})\\) (<code>\"rscale\"</code>, <code>\"curvature\"</code>, <code>\"wall\"</code>).</li> <li>Improved: <code>evenlySpacedPhi(...)</code> \u2014 robust \\((\\phi)\\)-space resampling with monotonicity enforcement and endpoint padding (zero slopes at vacua).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#physics-background-why-these-formulas","title":"Physics background (why these formulas)","text":"<p>The action (with the false-vacuum constant removed) is</p> \\[S = \\int_{r_0}^{\\infty}\\Big[\\tfrac12(\\partial_r\\phi)^2+\\big(V(\\phi)-V(\\phi_{\\rm meta})\\big)\\Big]  r^\\alpha dr\\Omega_\\alpha +\\] \\[+\\underbrace{ \\int_{0}^{r_0} \\big(V(\\phi(r_0)) - V(\\phi_{\\rm meta})\\big),d^dr }_{\\text{\u201cinterior bulk\u201d}}\\] <p>because thin-wall integrations start at \\((r=r_0&gt;0)\\). Regularity implies$ (\\phi'(r)\\sim\\mathcal{O}(r))$, so the gradient contribution from \\(([0,r_0])\\) is negligible, but the potential offset must be accounted for via the (d)-ball volume:</p> \\[{\\rm Vol}_d(r_0)=\\frac{\\pi^{d/2}}{\\Gamma(d/2+1)}r_0^d\\] <p>This matches the original legacy semantics while making the computation explicit and numerically stable.</p>"},{"location":"modules/tunneling1D/single_field/#findactionprofile","title":"<code>findAction(profile)</code>","text":"<p>What it computes. The scalar Euclidean action (S) using</p> \\[S_{\\rm line}=\\int_{r_0}^{\\infty}\\left[\\tfrac12\\Phi'(r)^2 + V(\\Phi(r))-V(\\phi_{\\rm meta})\\right] r^\\alpha dr\\Omega_\\alpha\\] \\[\\Delta S_{\\rm interior}={\\rm Vol}*d(r_0)\\big[V(\\Phi(r_0))-V(\\phi*{\\rm meta})\\big]\\] <p>and returns \\((S=S_{\\rm line}+\\Delta S_{\\rm interior})\\).</p> <p>Inputs. <code>profile</code> (from <code>findProfile</code>): arrays <code>R</code>, <code>Phi</code>, <code>dPhi</code> must be 1D, same length \\((\\ge 2)\\).</p> <p>Output. A single <code>float</code> \u2014 the Euclidean action.</p> <p>Why it matters. (S) controls the (zero-temperature) tunneling rate prefactor \\(( \\Gamma \\propto e^{-S} )\\) (up to determinants). In thermal problems \\((S_3/T)\\) plays the analogous role;  our formulation and helpers are designed to interface cleanly with those workflows later.</p> <p>Numerical notes.</p> <ul> <li>Uses Simpson integration on the line contribution with the correct geometric weight \\((r^\\alpha\\Omega_\\alpha)\\).</li> <li>Adds the interior potential-only bulk term if \\((r_0&gt;0)\\).</li> </ul>"},{"location":"modules/tunneling1D/single_field/#evenlyspacedphiphi-dphi-npoints100-k1-fixabstrue","title":"<code>evenlySpacedPhi(phi, dphi, npoints=100, k=1, fixAbs=True)</code>","text":"<p>What it does. Resamples \\(((\\phi(r), \\phi'(r)))\\) onto a uniform grid in \\((\\phi)\\), returning arrays \\(((\\phi_i, \\phi'_i))\\) with \\((\\phi_i)\\) equally spaced.</p> <p>Why it\u2019s useful.</p> <ul> <li>Many diagnostics/plots are more readable vs field value than vs radius (e.g., comparing kinetic vs potential terms along the wall).</li> <li>Makes it easy to overlay different profiles in the same \\((\\phi)\\)-space.</li> </ul> <p>Key options.</p> <ul> <li><code>fixAbs=True</code> pads endpoints to exactly \\(((\\phi_{\\rm abs},\\phi_{\\rm meta}))\\) with zero slopes \u2014 physically correct for regular instantons.</li> <li>Enforces monotonic \\((\\phi)\\) (drops tiny backtracks before spline fitting) to avoid oscillatory spline artifacts.</li> <li><code>k=1</code> (linear) is very robust; <code>k=3</code> gives smooth derivatives when the data are clean.</li> </ul> <p>Output. <code>phi2</code>, <code>dphi2</code> (both 1D arrays with length <code>npoints</code>).</p>"},{"location":"modules/tunneling1D/single_field/#actionbreakdownprofile-new","title":"<code>actionBreakdown(profile)</code>  \u2014 New","text":"<p>What it returns. A named tuple with:</p> <ul> <li><code>S_total</code>: same value as <code>findAction(profile)</code>.</li> <li><code>S_kin</code>, <code>S_pot</code>: line integrals of the kinetic and potential pieces separately.</li> <li><code>S_interior</code>: the interior bulk correction.</li> <li>Copies of <code>r</code>, <code>phi</code>, <code>dphi</code>.</li> <li> <p><code>density</code>: a dict with arrays</p> </li> <li> <p><code>density[\"kin\"]</code> = \\(tfrac12\\Phi'^2 r^\\alpha \\Omega_\\alpha\\),</p> </li> <li><code>density[\"pot\"]</code> = \\((V(\\Phi)-V_{\\rm meta}) r^\\alpha \\Omega_\\alpha\\)</li> <li><code>density[\"tot\"] = density[\"kin\"] + density[\"pot\"]</code>.</li> </ul> <p>Why it\u2019s helpful.</p> <ul> <li>Lets you plot where the action is accumulated (e.g., most weight sits in the wall).</li> <li>Makes sanity checks straightforward (e.g., verify positivity of densities, small contribution far from the wall, etc.).</li> </ul> <p>Caveat. <code>density[\"tot\"]</code> covers only the line part; the interior bulk is a single additive scalar, not a distributed density.</p>"},{"location":"modules/tunneling1D/single_field/#walldiagnosticsprofile-frac01-09-new","title":"<code>wallDiagnostics(profile, frac=(0.1, 0.9))</code>  \u2014 New","text":"<p>Idea. Characterize the wall geometry directly from the profile.</p> <p>Definitions.</p> <ul> <li>Let \\((\\Delta\\phi \\equiv \\phi_{\\rm meta}-\\phi_{\\rm abs})\\).</li> <li>Define field levels</li> </ul> \\[\\phi_{\\rm lo}=\\phi_{\\rm abs}+f_{\\rm lo}\\Delta\\phi\\] \\[\\phi_{\\rm hi}= \\phi_{\\rm abs}+f_{\\rm hi}\\Delta\\phi  \\] \\[(\\phi_{\\rm mid}=\\tfrac12(\\phi_{\\rm abs}+\\phi_{\\rm meta})) \\] <ul> <li>Invert the (monotonic) profile to get radii \\((r(\\phi))\\);</li> </ul> <p>What it returns.</p> <ul> <li><code>r_peak</code>: radius where \\((|\\Phi'|)\\) is maximal (often used as \u201cwall center\u201d).</li> <li><code>r_mid</code>: radius where \\((\\phi=\\phi_{\\rm mid})\\).</li> <li><code>r_lo</code>, <code>r_hi</code>: radii at the chosen fractional field levels.</li> <li><code>thickness</code> = \\(|r_{\\rm hi} - r_{\\rm lo}|\\).</li> <li>The field levels <code>phi_lo</code>, <code>phi_hi</code>.</li> </ul> <p>Why it\u2019s useful.</p> <ul> <li>Provides a coordinate-free estimate of wall thickness and location.</li> <li>Enables simple comparisons between thin- and thick-wall regimes.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#betaeffprofile-methodrscale-new","title":"<code>betaEff(profile, method=\"rscale\")</code>  \u2014 New","text":"<p>Purpose. Return a proxy for the inverse timescale/length \\((\\beta_{\\rm eff})\\) often used for order-of-magnitude reasoning.  This is not the cosmological \\((\\beta \\equiv -d(S_3/T)/dt)\\); computing that requires a (T)-dependent potential and \\((S_3(T)/T)\\).</p> <p>Methods.</p> <ul> <li><code>\"rscale\"</code>: \\((\\beta_{\\rm eff} = 1/\\texttt{rscale})\\).   Always defined; <code>rscale</code> was obtained in Lot SF-2 from barrier geometry.</li> <li><code>\"curvature\"</code>: \\((\\beta_{\\rm eff} = \\sqrt{|V''(\\phi_{\\rm top})|})\\).   Uses the second derivative at the barrier top; agrees with \\((1/\\texttt{rscale})\\) up to \\((\\mathcal{O}(1))\\) in many models.</li> <li><code>\"wall\"</code>: \\((\\beta_{\\rm eff}=1/\\texttt{thickness})\\).   Thickness from <code>wallDiagnostics</code>; simple geometric proxy tied to the wall width.</li> </ul> <p>When to use which.</p> <ul> <li>If you just need one number: <code>\"rscale\"</code>.</li> <li>If the barrier curvature is physically meaningful in your model: <code>\"curvature\"</code>.</li> <li>If your analysis hinges on wall width (e.g., friction effects): <code>\"wall\"</code>.</li> </ul>"},{"location":"modules/tunneling1D/single_field/#practical-guidance-pitfalls","title":"Practical guidance &amp; pitfalls","text":"<ul> <li>Profiles starting at \\((r_0&gt;0)\\) (thin walls):   Expect a nonzero interior bulk potential term. The kinetic part from \\(([0,r_0])\\) is suppressed by regularity.</li> <li>Units &amp; scaling:   (S) is dimensionless if (r) and (V) are in consistent units (as in the usual bounce conventions). All geometric addends preserve dimensional consistency.</li> <li>Monotonicity in (\\phi):   Small numerical back-and-forth in (\\phi(r)) can spoil interpolation in (\\phi)-space. The resampler removes those via a monotonic-indices filter before spline fitting.</li> <li>Interpreting densities:   Most of the action density typically localizes in the wall; plotting <code>density[\"kin\"]</code> and <code>density[\"pot\"]</code> helps verify this and diagnose integration issues.</li> </ul>"},{"location":"modules/tunneling1D/tests_single_field/","title":"Tests \u2014 Single Field Instanton","text":"<p>This page collects hands-on examples for the Single Field Instanton module, organized by lot.  Each example states the physical meaning, the expected outcome, a slot for the console output/code and (when applicable) an image slot.</p> <p>These examples correspond to the class SingleFieldInstaton only.</p>"},{"location":"modules/tunneling1D/tests_single_field/#lot-sf-1-potential-interface-validations","title":"Lot SF-1 \u2014 Potential Interface &amp; Validations","text":"<p>See the full, executable script for this lot here: <code>tests/single_field/Lot_SF_1.py</code>. for all example the potential chosen was:</p> \\[\\text{THIN}: \\frac{1}{4}\\phi ^4 - 0.49\\phi ^3 + 0.235 \\phi ^2 \\] \\[\\text{THICK}:  \\frac{1}{4}\\phi ^4 - \\frac{2}{5}\\phi^3 + \\frac{1}{10}\\phi^2 \\] <p>How to run just this case</p> <pre><code>python -m tests.tunneling1D.single_field.Lot_SF1 \n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#example-1-metastability-validation-exception-path","title":"Example 1 \u2014 Metastability validation (exception path)","text":"<p>What it shows (physics): A tunneling solution exists only if the false (metastable) vacuum is higher in energy than the true (absolute) vacuum: \\((V(\\phi_{\\text{meta}}) &gt; V(\\phi_{\\text{abs}}))\\).  Swapping them violates metastability and must raise a clear error.</p> <p>Expected result: Constructing <code>SingleFieldInstanton</code> with <code>V(phi_metaMin) \u2264 V(phi_absMin)</code> raises a <code>PotentialError</code> explaining that the configuration is \u201cstable, not metastable.\u201d</p> <p>Console output:</p> <pre><code>=== Test 1: Metastability validation ===\nOK: PotentialError raised as expected -&gt; ('V(phi_metaMin) &lt;= V(phi_absMin); tunneling cannot occur.', 'stable, not metastable')\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#example-2-accuracy-of-derivative-helpers-o4-vs-o2-near-minimum-blend-tests-3-4","title":"Example 2 \u2014 Accuracy of derivative helpers (o4 vs o2) &amp; near-minimum blend (Tests 3 + 4)","text":"<p>What it shows (physics):</p> <ul> <li>For smooth potentials, 4th-order FD (our default) is more accurate than 2nd-order for both (V') and (V'').</li> <li>Very close to the absolute minimum, the helper <code>dV_from_absMin</code> smoothly blends to the local linear behavior \\((V'(\\phi)\\approx V''(\\phi),\\Delta\\phi)\\) , improving numerical stability where finite differences can be noisy.</li> </ul> <p>Expected result:</p> <ul> <li>Reported max errors for o(4) are lower than for o(2) when compared to analytic (V') and (V'') (both thin and thick quartic examples).</li> <li>The lines <code>delta=... -&gt; dV_from_absMin=..., ref\u2248d2V*delta=..., rel.err=...</code> show tiny relative errors (\u226a 1% for the tiny offsets used).</li> </ul> <p>Console output:</p> <pre><code>=== Test 3: Built-in FD vs analytic derivatives ===\n[THIN] max|dV_fd4 - dV_true|  = 1.253e-13\n[THIN] max|d2V_fd4 - d2V_true|= 3.888e-10\n[THIN] max|dV_fd2 - dV_true|  = 7.100e-07\n[THIN] max|d2V_fd2 - d2V_true|= 5.002e-07\n[THIN] barrier check: V(phi_bar) - V(phi_metaMin) = +2.602e-12\n\n[THICK] max|dV_fd4 - dV_true|  = 1.127e-13\n[THICK] max|d2V_fd4 - d2V_true|= 3.779e-10\n[THICK] max|dV_fd2 - dV_true|  = 8.000e-07\n[THICK] max|d2V_fd2 - d2V_true|= 5.002e-07\n[THICK] barrier check: V(phi_bar) - V(phi_metaMin) = +3.056e-11\n\n=== Test 4: dV_from_absMin near \u03c6_absMin ===\ndelta=1.0e-06 -&gt; dV_from_absMin=5.300e-07, ref\u2248d2V*delta=5.300e-07, rel.err=4.538e-10\ndelta=5.0e-06 -&gt; dV_from_absMin=2.650e-06, ref\u2248d2V*delta=2.650e-06, rel.err=5.739e-11\ndelta=1.0e-05 -&gt; dV_from_absMin=5.300e-06, ref\u2248d2V*delta=5.300e-06, rel.err=3.055e-09\ndelta=5.0e-05 -&gt; dV_from_absMin=2.651e-05, ref\u2248d2V*delta=2.651e-05, rel.err=3.604e-07\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#example-3-visual-check-vphi-vphi-vphi-test-5","title":"Example 3 \u2014 Visual check: \\((V(\\phi)), (V'(\\phi)), (V''(\\phi))\\) (Test 5)","text":"<p>What it shows (physics):</p> <ul> <li>Potential shapes for thin vs thick cases.</li> <li>Agreement between analytic and built-in derivative operators for (V') and (V'').</li> <li>This is a pre-instanton sanity check that the potential interface + derivative helpers behave as expected.</li> </ul> <p>Expected result:</p> <ul> <li>Curves for analytic vs built-in (V') and (V'') visually overlap.</li> <li>Residuals printed by the script are small (implementation- and BLAS-dependent, typically in the (10^{-8})\u2013(10^{-6}) range on these quartics).</li> </ul> <p>Image slots:</p> <p>Thin-wall \u2014 Potential </p> <p>Thin-wall \u2014 First derivative </p> <p>Thin-wall \u2014 Second derivative </p> <p>Thick-wall \u2014 Potential </p> <p>Thick-wall \u2014 First derivative </p> <p>Thick-wall \u2014 Second derivative </p> <p>Console output:</p> <pre><code>=== Test 5: Plots (potential and derivatives) ===\n[THIN] residuals: max|V'_fd - V'_ref|=1.253e-13, max|V''_fd - V''_ref|=3.888e-10\n[THICK] residuals: max|V'_fd - V'_ref|=1.127e-13, max|V''_fd - V''_ref|=3.779e-10\n\n---------- END OF TESTS: Lot SF-1 ----------\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#lot-sf-2-barrier-scales","title":"Lot SF-2 \u2014 Barrier &amp; scales","text":"<p>Goal. Visualize the potential barrier geometry and report the characteristic length scale(s) used by the solver:</p> <ul> <li> <p>Vertical markers for:</p> </li> <li> <p>\\(( \\phi_{\\rm top} )\\): location of the barrier maximum between \\(( \\phi_{\\rm meta} )\\) and \\(( \\phi_{\\rm bar} )\\);</p> </li> <li>\\(( \\phi_{\\rm bar} )\\): \u201cedge\u201d on the downhill side where \\(( V(\\phi_{\\rm bar}) = V(\\phi_{\\rm meta}) )\\).</li> <li>Horizontal line at \\(( V(\\phi_{\\rm meta}) )\\).</li> <li> <p>Printed diagnostics:</p> </li> <li> <p><code>phi_top</code>, <code>phi_bar</code>, \\(( \\Delta V_{\\rm top} \\equiv V(\\phi_{\\rm top}) - V(\\phi_{\\rm meta}) )\\);</p> </li> <li><code>rscale_cubic</code> (robust/legacy) and, when defined, <code>rscale_curv</code> from \\((V''(\\phi_{\\rm top}))\\).</li> </ul> <p>Physics intuition:</p> <ul> <li>Thin wall (nearly degenerate minima) \u2192 sharper barrier (more negative (V'') at the top) \u2192 smaller length scale (wall is thinner).</li> <li>Thick wall (more separated minima) \u2192 broader barrier \u2192 larger length scale.</li> </ul> <p>See the full, executable script for this lot here: <code>tests/single_field/Lot_SF2.py</code>. for all example the potential chosen was:</p> \\[\\text{THIN}: \\frac{1}{4}\\phi ^4 - 0.49\\phi ^3 + 0.235 \\phi ^2 \\] \\[\\text{THICK}:  \\frac{1}{4}\\phi ^4 - \\frac{2}{5}\\phi^3 + \\frac{1}{10}\\phi^2 \\] <p>Script: <code>tests/tunneling1D/single_field/Lot_SF2.py</code></p> <p>How to run just this case (Run both examples at once)</p> <pre><code>python -m tests.tunneling1D.single_field.Lot_SF2  # it includes thin- and thick-wall cases\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#test-a-thin-wall-barrier-markers-scales","title":"Test A \u2014 Thin-wall: barrier markers &amp; scales","text":"<p>What this shows</p> <ul> <li>\\((V(\\phi))\\) with the barrier top and edge identified.</li> <li>Console readout with the barrier height and the two characteristic scales.</li> </ul> <p>Expected outcome (physics)</p> <ul> <li>\\((\\phi_{\\rm top})\\) sits between \\((\\phi_{\\rm meta}=0)\\) and \\((\\phi_{\\rm abs}=1)\\).</li> <li>\\((V(\\phi_{\\rm top}) &gt; V(\\phi_{\\rm meta}))\\) so \\(( \\Delta V_{\\rm top} &gt; 0 )\\).</li> <li><code>rscale_cubic</code> is finite and typically smaller than in the thick-wall case (thinner wall).</li> <li><code>rscale_curv</code> is reported finite if \\((V''(\\phi_{\\rm top})&lt;0)\\); otherwise shown as \u221e (flat top).</li> </ul> <p>Example console output</p> <pre><code>========================================================================\nCASE: Thin-wall demo\n========================================================================\nBarrier diagnostics:\n  phi_metaMin = 0,  V(phi_metaMin) = 0\n  phi_top     = 0.46999999834,  \u0394V_top \u2261 V(top)-V(meta) = 0.0132374325\n  phi_bar     = 0.837171431377  (V equals V(phi_metaMin) on downhill side)\nScale diagnostics:\n  rscale_cubic (legacy/robust) = 1.66770930502\n  rscale_curv  (from V'' at top)= 2.00360975005  with  V''(top) = -0.249099999801\n</code></pre> <p>Figure \u201cThin-wall demo: Potential with barrier markers.\u201d </p>"},{"location":"modules/tunneling1D/tests_single_field/#test-b-thick-wall-barrier-markers-scales","title":"Test B \u2014 Thick-wall: barrier markers &amp; scales","text":"<p>What this shows</p> <ul> <li>Same plot/diagnostics as Test A, now for a broader barrier.</li> </ul> <p>Expected outcome (physics)</p> <ul> <li>\\((\\phi_{\\rm top})\\) again lies between \\((\\phi_{\\rm meta})\\) and \\((\\phi_{\\rm abs})\\).</li> <li>Barrier height and curvature differ from the thin-wall case; you should observe a larger <code>rscale_cubic</code> (thicker wall).</li> <li><code>rscale_curv</code> is finite if the barrier top is genuinely curved; otherwise \u221e for a flat-ish top.</li> </ul> <p>Example console output (you will paste your run here)</p> <pre><code>========================================================================\nCASE: Thick-wall demo\n========================================================================\nBarrier diagnostics:\n  phi_metaMin = 0,  V(phi_metaMin) = 0\n  phi_top     = 0.200000001967,  \u0394V_top \u2261 V(top)-V(meta) = 0.0012\n  phi_bar     = 0.310102050146  (V equals V(phi_metaMin) on downhill side)\nScale diagnostics:\n  rscale_cubic (legacy/robust) = 2.35702262713\n  rscale_curv  (from V'' at top)= 2.49999998156  with  V''(top) = -0.16000000236\n</code></pre> <p>Figure \u201cThick-wall demo: Potential with barrier markers.\u201d </p>"},{"location":"modules/tunneling1D/tests_single_field/#lot-3-quadratic-local-solution-initial-conditions","title":"Lot 3 \u2014 Quadratic local solution &amp; initial conditions","text":"<p>See the full, executable script for this lot here: <code>tests/single_field/Lot_SF3.py</code>. for all example the potential chosen was:</p> \\[\\text{THIN}: \\frac{1}{4}\\phi ^4 - 0.49\\phi ^3 + 0.235 \\phi ^2 \\] \\[\\text{THICK}:  \\frac{1}{4}\\phi ^4 - \\frac{2}{5}\\phi^3 + \\frac{1}{10}\\phi^2 \\] <p>This lot illustrates the local (small-radius) analytic solution used by <code>SingleFieldInstanton.exactSolution</code> and how we choose practical starting points via <code>SingleFieldInstanton.initialConditions</code>. We work with the same thin- and thick-wall toy potentials from previous lots.</p> <p>How to run just this case (Run both examples at once)</p> <pre><code>python -m tests.tunneling1D.single_field.Lot_SF3  # it includes all tests (more than the ones here)\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#test-1-local-quadratic-solution-near-the-true-minimum-stable-curvature","title":"Test 1 \u2014 Local quadratic solution near the true minimum (stable curvature)","text":"<p>What it shows</p> <ul> <li>Around the stable minimum, \\((V''(\\phi_0)&gt;0)\\), the non-singular solution behaves smoothly with \\((\\phi'(0)=0)\\) and a quadratic rise at small (r).</li> <li>The plot overlays \\((\\phi(r)-\\phi_0)\\) and \\((\\phi'(r))\\) computed by <code>exactSolution</code>.</li> </ul> <p>Expected result</p> <ul> <li>\\((\\phi'(0)=0)\\) numerically.</li> <li>\\((\\phi(r)-\\phi_0)\\) grows \\((\\propto r^2)\\) for very small (r); \\((\\phi'(r)\\propto r)\\).</li> </ul> <p>Console excerpts (typical)</p> <pre><code>=== Test 1: Local quadratic solution near abs minimum (d2V &gt; 0) ===\n Thin: dV(phi0)=5.315e-04, d2V(phi0)=5.331e-01, rscale\u22481.668e+00\n  Expectation: phi'(0)=0, smooth quadratic rise; numerical curve should be regular.\n\n Thick: dV(phi0)=8.018e-04, d2V(phi0)=8.036e-01, rscale\u22482.357e+00\n  Expectation: phi'(0)=0, smooth quadratic rise; numerical curve should be regular.\n</code></pre> <p>Figure</p> <p></p> <p></p>"},{"location":"modules/tunneling1D/tests_single_field/#test-2-local-solution-near-the-barrier-top-unstable-curvature","title":"Test 2 \u2014 Local solution near the barrier top (unstable curvature)","text":"<p>What it shows</p> <ul> <li>At the barrier top \\((\\phi_{\\text{top}})\\), \\((V'(\\phi_{\\text{top}})\\approx 0)\\) and \\((V''(\\phi_{\\text{top}})&lt;0)\\).</li> <li><code>exactSolution</code> switches to the \\((J_\\nu)\\) branch; the solution remains regular at (r=0) with \\((\\phi'(0)=0)\\), </li> <li>but the local shape reflects the inverted curvature.</li> </ul> <p>Expected result</p> <ul> <li>Printed curvature satisfies \\((d^2V(\\phi_{\\text{top}})&lt;0)\\) (up to near-flat numerical cases).</li> <li>Plots show a small-(r) \u201cinverted\u201d profile relative to \\((\\phi_{\\text{top}})\\), still smooth at the origin.</li> </ul> <p>Console excerpts (typical)</p> <pre><code>=== Test 2: Local solution near barrier top (d2V &lt; 0) ===\n Thin: phi_top=0.470000, dV(phi_top)=-1.268e-10, d2V(phi_top)=-2.491e-01\n  Expectation: d2V &lt; 0 \u2192 oscillatory (J_\u03bd) behavior; still regular at r=0 with phi'(0)=0.\n\n Thick: phi_top=0.200000, dV(phi_top)=-2.250e-11, d2V(phi_top)=-1.600e-01\n  Expectation: d2V &lt; 0 \u2192 oscillatory (J_\u03bd) behavior; still regular at r=0 with phi'(0)=0.\n</code></pre> <p>Figure</p> <p></p> <p></p>"},{"location":"modules/tunneling1D/tests_single_field/#test-4-initialconditions-pick-r_0phir_0phir_0-and-visualize-the-short-path","title":"Test 4 \u2014 <code>initialConditions</code>: pick \\(((r_0,\\phi(r_0),\\phi'(r_0)))\\) and visualize the short path","text":"<p>What it shows</p> <ul> <li>Given an interior offset \\((\\Delta\\phi_0)\\) and a target cutoff \\((|\\Delta\\phi(r_0)|)\\), we solve for a practical \\((r_0)\\).</li> <li>The short trajectory from (r=0) to \\((r=r_0)\\) is plotted using the same local quadratic solution; the chosen starting point is marked.</li> </ul> <p>Expected result</p> <ul> <li>$|\\phi(r_0)-\\phi_{\\text{abs}}|\\gtrsim $ cutoff.</li> <li>\\(sign(\\phi'(r_0))=\\operatorname{sign}(\\Delta\\phi_0)\\).</li> </ul> <p>Console excerpts (typical)</p> <pre><code>=== Test 4: initialConditions (r0, phi(r0), phi'(r0)) ===\n Thin: r0=1.667709e-03, phi(r0)=1.018316e+00, phi'(r0)=5.685050e-06\n  Expectation: |phi(r0)-phi_absMin| \u2273 cutoff, and phi'(r0) has the same sign as delta_phi0.\n\n Thick: r0=2.357023e-03, phi(r0)=1.018316e+00, phi'(r0)=1.199135e-05\n  Expectation: |phi(r0)-phi_absMin| \u2273 cutoff, and phi'(r0) has the same sign as delta_phi0.\n</code></pre> <p>Figure</p> <p></p> <p></p>"},{"location":"modules/tunneling1D/tests_single_field/#test-5-initialconditions-error-path-unreachable-cutoff","title":"Test 5 \u2014 <code>initialConditions</code> error path (unreachable cutoff)","text":"<p>What it shows</p> <ul> <li>If \\((\\Delta\\phi_0=0)\\) exactly (starting right at the true minimum) and the cutoff is strictly positive, </li> <li>the local model never reaches the cutoff; the function raises a clear <code>IntegrationError</code>.</li> </ul> <p>Expected result</p> <ul> <li>A caught <code>IntegrationError</code> with an informative message.</li> </ul> <p>Console excerpts (typical)</p> <pre><code>=== Test 5: initialConditions error (unreachable cutoff) ===\n Thin: Caught expected IntegrationError:\n   initialConditions: failed to bracket r0 (no crossing found).\n\n Thick: Caught expected IntegrationError:\n   initialConditions: failed to bracket r0 (no crossing found).\n\n---------- END OF TESTS: Lot SF-3 ----------\n</code></pre> <ul> <li>For more context (potential, barrier, and scaling) see Lots SF1 and SF2 above.</li> </ul>"},{"location":"modules/tunneling1D/tests_single_field/#lot-sf-4-ode-core-eom-event-detection-sampler","title":"Lot SF-4 \u2014 ODE core (EOM, event detection, sampler)","text":"<p>Goal. Exercise the heart of the solver:</p> <ul> <li>The equation of motion (EOM) used everywhere:</li> </ul> \\[\\frac{d^2\\phi}{dr^2} + \\frac{\\alpha}{r}\\frac{d\\phi}{dr} = b\\frac{dV}{d\\phi}(\\phi)\\] <p>written as a first-order system in \\((y=(\\phi,\\phi'))\\). * The adaptive RKQS driver that advances the solution and classifies steps as   undershoot (turning point before reaching the false vacuum) or overshoot   (crosses \\((\\phi_{\\rm meta})\\) within the step). * The sampler that records \\(((\\phi,\\phi'))\\) on a user grid (R) using cubic   Hermite interpolation between accepted RK steps.</p> <p>Physics intuition.</p> <ul> <li>For the bounce, the field starts near the true minimum \\((\\phi_{\\rm abs})\\) and tries to \u201cclimb\u201d toward the false minimum \\((\\phi_{\\rm meta})\\).</li> <li>If it turns around \\(((\\phi'\\to 0))\\) before it ever reaches \\((\\phi_{\\rm meta})\\), we say undershoot.</li> <li>If it crosses \\((\\phi_{\\rm meta})\\) at finite radius, that\u2019s an overshoot.</li> <li>The friction term \\((\\alpha,\\phi'/r)\\) is large at small (r), so the outcome depends delicately on the starting offset and slope.</li> </ul> <p>Script: <code>tests/tunneling1D/single_field/Lot_SF4.py</code> Run all examples in this lot:</p> <pre><code>python -m tests.tunneling1D.single_field.Lot_SF4\n</code></pre> <p>We keep the same toy potentials as before:</p> \\[\\textbf{THIN}: \\quad \\tfrac14\\phi^4 - 0.49\\phi^3 + 0.235\\phi^2\\] \\[\\textbf{THICK}: \\quad \\tfrac14\\phi^4 - \\tfrac{2}{5}\\phi^3 + \\tfrac{1}{10}\\phi^2\\] <p>Notes on tolerances. In the examples we build \\((\\texttt{epsfrac}=[\\texttt{phitol},\\texttt{phitol}])\\) and \\((\\texttt{epsabs}=[\\texttt{phitol}\\cdot|\\Delta\\phi|,\\texttt{phitol}\\cdot|\\Delta\\phi|/r_{\\rm scale}])\\). If you see a \u201cstep size underflow\u201d in thin-wall cases, relaxing to <code>phitol=1e-4</code> is often enough.</p>"},{"location":"modules/tunneling1D/tests_single_field/#test-b-thin-wall-event-detection-two-undershoots","title":"Test B \u2014 Thin-wall: event detection (two undershoots)","text":"<p>What this shows</p> <ul> <li>How <code>integrateProfile</code> detects turning points on a thin-wall potential.</li> <li>Two runs with different \u201cshooting\u201d parameters (x) (mapped internally to the initial offset \\((\\Delta\\phi_0 = e^{-x}(\\phi_{\\rm meta}-\\phi_{\\rm abs})))\\).</li> <li>For this potential and the chosen cutoff, both choices typically undershoot (large friction and small initial energy).</li> </ul> <p>Expected outcome</p> <ul> <li>Printed classification: <code>undershoot</code> in both panels, with an event radius \\((r_{\\rm evt})\\) where \\((\\phi'(r_{\\rm evt})\\approx 0)\\).</li> <li>Plots show \\((\\phi(r))\\) decreasing from near (\\phi_{\\rm abs}), then flattening at the turning point before reaching \\((\\phi_{\\rm meta})\\) (dashed line).</li> </ul> <p>How the figure is built</p> <ul> <li>We integrate until the event is detected, then call <code>integrateAndSaveProfile</code> to sample \\((\\phi(r))\\) densely up to \\((r_{\\rm evt})\\).</li> <li>The event is marked with a vertical dotted line and a dot at \\(((r_{\\rm evt},\\phi(r_{\\rm evt})))\\).</li> </ul> <p>Console excerpt</p> <pre><code>=== Test B: Event detection on thin-wall potential ===\n[thin-wall :: x=6.00] event = undershoot at r=1.566617e+01 (phi=2.441311e-01, dphi=6.852158e-17)\n[thin-wall :: x=0.20] event = undershoot at r=1.046569e-02 (phi=1.812700e-01, dphi=1.498745e-04)\n</code></pre> <p>Figure Thin-wall: two trajectories that undershoot (turning point before the false vacuum).</p> <p></p>"},{"location":"modules/tunneling1D/tests_single_field/#test-c-thick-wall-one-undershoot-one-overshoot","title":"Test C \u2014 Thick-wall: one undershoot, one overshoot","text":"<p>What this shows</p> <ul> <li> <p>On the thick-wall potential, different (x) give opposite outcomes:</p> </li> <li> <p>A smaller initial offset (low energy) \u2192 undershoot;</p> </li> <li>A larger offset (high energy) \u2192 overshoot (crossing of \\(\\phi_{meta}\\) ).</li> </ul> <p>Expected outcome</p> <ul> <li>Left panel: <code>undershoot</code> with \\((\\phi'(r_{\\rm evt})\\approx 0)\\) at finite (r), and \\((\\phi(r))\\) still above \\((\\phi_{\\rm meta})\\).</li> <li>Right panel: <code>overshoot</code> with a detected root of \\((\\phi(r)-\\phi_{\\rm meta}=0)\\); the crossing point is annotated.</li> </ul> <p>Console excerpt</p> <pre><code>=== Test C: Event detection on thick-wall potential ===\n[thick-wall :: x=0.20] event = undershoot at r=4.714045e-03 (phi=1.812693e-01, dphi=4.642159e-06)\n[thick-wall :: x=6.00] event =  overshoot at r=1.218941e+01 (phi=-4.989932e-15, dphi=-1.713411e-01)\n</code></pre> <p>Figure Thick-wall: undershoot (left) and overshoot (right); both events detected and marked. </p>"},{"location":"modules/tunneling1D/tests_single_field/#test-d-sampling-with-integrateandsaveprofile-on-a-user-grid","title":"Test D \u2014 Sampling with <code>integrateAndSaveProfile</code> on a user grid","text":"<p>What this shows</p> <ul> <li>You provide a monotone grid \\((R={r_i})\\) and a starting state \\(((r_0,\\phi(r_0),\\phi'(r_0)))\\).</li> <li>The solver advances with adaptive RK and fills every requested point using cubic Hermite interpolation (the same shape preserved internally for events).</li> </ul> <p>Expected outcome</p> <ul> <li>A smooth curve \\((\\phi(r))\\) across the whole user grid.</li> <li><code>Rerr</code> is <code>None</code> in typical runs; if the step would fall below <code>drmin</code>, the step is clamped and <code>Rerr</code> reports the first radius where this happened.</li> </ul> <p>Console excerpt (paste your run)</p> <pre><code>=== Test D: integrateAndSaveProfile on a user R-grid ===\nProfile sampled at 300 points.\nRerr (first clamped step radius) = None\n</code></pre> <p>Figure \u201cSampling \\(\\phi(r)\\) on a fixed grid provided by the user. </p>"},{"location":"modules/tunneling1D/tests_single_field/#test-f-explicit-initial-conditions-thin-wall","title":"Test F \u2014 Explicit initial conditions (thin-wall)","text":"<p>What this shows</p> <ul> <li>Instead of deriving \\(((r_0,\\phi(r_0),\\phi'(r_0)))\\) from a shooting parameter (x), we set them explicitly to demonstrate that the event classification logic does not depend on how the initial state was chosen.</li> <li> <p>Two examples:</p> </li> <li> <p>A gentle start near the true minimum with a small negative slope \u2192 often undershoot.</p> </li> <li>A more aggressive start with sizable downhill slope \u2192 tends to overshoot (depending on details of the potential and tolerances).</li> </ul> <p>Expected outcome</p> <ul> <li>Clear printed event classification with the detected \\((r_{\\rm evt})\\).</li> <li>Plots up to the event look consistent with the classification (turning point vs. crossing).</li> </ul> <p>Console excerpt (paste your run)</p> <pre><code>=== Test F: Explict Initial Conditions on thin-wall potential ===\n[thin-wall :: x=[0.001, [0.9, -0.1]]] event = undershoot at r=1.045860e+01 (phi=3.544355e-01, dphi=0.000000e+00)\n[thin-wall :: x=[1, [0.3, -2]]] event =  overshoot at r=1.176781e+00 (phi=-1.040834e-17, dphi=-1.439106e+00)\n---------- END: Lot SF-4 examples ----------\n</code></pre> <p>Figure Thin-wall with explicit initial states: undershoot (left) and overshoot (right). </p> <p>See more: full executable script at <code>tests/single_field/Lot_SF4.py</code>.</p>"},{"location":"modules/tunneling1D/tests_single_field/#lot-sf-5-profile-search-findprofile","title":"Lot SF-5 \u2014 Profile search (<code>findProfile</code>)","text":"<p>Goal. Demonstrate the full overshoot/undershoot shooting procedure that determines the instanton profile \\(( \\phi(r) )\\), and show how two knobs\u2014<code>thinCutoff</code> and the optional \u201cinterior fill\u201d\u2014affect only the very small-( r ) part of the curve in thin-wall situations.</p> <p>Solver recap (physics): We want the regular (non-singular) solution that starts near the true minimum \\(( \\phi_{\\rm abs} )\\) at ( r=0 ) and asymptotes to the false minimum \\(( \\phi_{\\rm meta} )\\) as \\(( r\\to\\infty )\\).  <code>findProfile</code> varies the \u201cshooting\u201d parameter ( x ) (equivalently \\(( \\Delta\\phi_0 \\propto e^{-x} )\\) )  and repeatedly integrates the ODE.</p> <ul> <li>If the trajectory crosses \\(( \\phi_{\\rm meta} )\\) within a step \u21d2 overshoot (initial kick too large).</li> <li>If it turns around (hits \\(( \\phi'(r)=0 )\\) ) before reaching \\(( \\phi_{\\rm meta} )\\) \u21d2 undershoot (kick too small).   Bisection on ( x ) lands on the unique critical trajectory; then the profile is sampled densely.</li> </ul> <p>See the full, executable script here: <code>tests/tunneling1D/single_field/Lot_SF5.py</code>.</p> <p>For all examples we reuse the same toy potentials:</p> \\[\\textbf{THIN:}\\quad \\tfrac{1}{4}\\phi^4 - 0.49,\\phi^3 + 0.235,\\phi^2\\] \\[\\textbf{THICK:}\\quad \\tfrac{1}{4}\\phi^4 - \\tfrac{2}{5}\\phi^3 + \\tfrac{1}{10}\\phi^2\\] <p>with \\(( \\phi_{\\rm abs}=1 )\\) and \\(( \\phi_{\\rm meta}=0 )\\), and \\(( \\alpha=2 )\\) (O(3) bounce).</p> <p>Script: <code>tests/tunneling1D/single_field/Lot_SF5.py</code> How to run just this lot</p> <pre><code>python -m tests.tunneling1D.single_field.Lot_SF5\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#test-1-legacy-demo-thin-thick-walls-default-settings","title":"Test 1 \u2014 Legacy demo: thin &amp; thick walls (default settings)","text":"<p>What this shows</p> <ul> <li>A faithful reproduction of the legacy quick-start: one call per potential,</li> </ul> <pre><code>  profile = SingleFieldInstanton(1.0, 0.0, V, dV).findProfile()\n</code></pre> <p>and a plot of \\(( \\phi(r) )\\). * Horizontal guides at \\(( \\phi_{\\rm abs} )\\) and \\(( \\phi_{\\rm meta} )\\) for context. * Console diagnostics: start/end radii, terminal residual \\(( |\\phi(r_f)-\\phi_{\\rm meta}| )\\).</p> <p>Physical expectations</p> <ul> <li>Thin-wall: The field sits near \\(( \\phi_{\\rm abs} )\\) until a relatively sharp transition (\u201cthin\u201d wall) then approaches \\(( \\phi_{\\rm meta} )\\).</li> <li>Thick-wall: Transition is more gradual; the wall is \u201cthicker.\u201d</li> <li>Both runs should converge without manual tuning (defaults are chosen to be robust).</li> </ul> <p>Paste your console excerpt here</p> <pre><code>=== Test 1: Legacy demo \u2014 thin &amp; thick walls ===\n=== Test 1: Legacy demo \u2014 thin &amp; thick walls ===\n[thin-wall] profile: R[0]=0.000000e+00, R[-1]=6.193054e+01\n         \u03c6(r0)=1.000000e+00, \u03c6(rf)=-1.857581e-04, |\u03c6(rf)-\u03c6_meta|=1.858e-04, \u03c6'(rf)=-1.679e-04\n         Rerr=None\n\n[thick-wall] profile: R[0]=0.000000e+00, R[-1]=2.089406e+01\n         \u03c6(r0)=7.420233e-01, \u03c6(rf)=9.449128e-06, |\u03c6(rf)-\u03c6_meta|=9.449e-06, \u03c6'(rf)=-1.251e-04\n         Rerr=None\n</code></pre> <p>Figure \u201cfindProfile \u2014 legacy thin/thick demos; horizontal guides at \\(\\phi_{abs}\\) and \\(\\phi_{meta}\\).\u201d </p>"},{"location":"modules/tunneling1D/tests_single_field/#test-2-sensitivity-to-thincutoff-and-interior-fill-thin-wall","title":"Test 2 \u2014 Sensitivity to <code>thinCutoff</code> and interior fill (thin wall)","text":"<p>What this shows</p> <ul> <li> <p>Two thin-wall profiles with identical physics but different handling of the tiny-radius region:</p> </li> <li> <p>Case A: <code>thinCutoff=0.01</code>, <code>max_interior_pts=None</code> (default). The solver places synthetic points inside the bubble using the local quadratic solution to illustrate the smooth \\(( r\\to0 )\\) behavior.</p> </li> <li>Case B: <code>thinCutoff=0.15</code>, <code>max_interior_pts=0</code>. We start farther from the origin (bigger cutoff) and disable interior fill, so the curve begins at \\(( r=r_0&gt;0 )\\).</li> </ul> <p>Physical expectations</p> <ul> <li>The two curves should match once ( r ) is beyond the artificially chosen \\(( r_0 )\\). Only the very small-( r ) portion differs\u2014this is numerical bookkeeping, not different physics.</li> <li>The terminal residual and action should be essentially unchanged; only \\(( r_0 )\\) and the early segment of \\(( \\phi(r) )\\) shift.</li> </ul> <p>Paste your console excerpt here</p> <pre><code>=== Test 2: Sensitivity to thinCutoff and interior fill (thin wall) ===\n[thin (A: thinCutoff=0.01, interior ON)] profile: R[0]=0.000000e+00, R[-1]=6.323233e+01\n         \u03c6(r0)=1.000000e+00, \u03c6(rf)=-2.498747e-20, |\u03c6(rf)-\u03c6_meta|=2.499e-20, \u03c6'(rf)=-1.572e-05\n         Rerr=None\n\n[thin (B: thinCutoff=0.15, interior OFF)] profile: R[0]=3.469565e+01, R[-1]=5.052437e+01\n         \u03c6(r0)=8.500000e-01, \u03c6(rf)=1.395670e-04, |\u03c6(rf)-\u03c6_meta|=1.396e-04, \u03c6'(rf)=4.599e-18\n         Rerr=None\n</code></pre> <p>Figure Effect of <code>thinCutoff</code> &amp; interior fill in a thin-wall case \u2014 curves overlay for \\(r \\gtrsim r_0\\). </p>"},{"location":"modules/tunneling1D/tests_single_field/#lot-sf-6-action-post-processing","title":"Lot SF-6 \u2014 Action &amp; post-processing","text":"<p>Goal. Take a computed bounce profile and extract physically meaningful, easy-to-compare summaries:</p> <ul> <li>Total Euclidean action via <code>findAction</code>.</li> <li>A full action breakdown (kinetic, potential, interior bulk) and per-r densities via <code>actionBreakdown</code>.</li> <li>A uniform \u03c6-grid view of the wall via <code>evenlySpacedPhi</code>.</li> <li>Wall geometry (location and thickness) via <code>wallDiagnostics</code>.</li> <li>Order-of-magnitude \u03b2-proxies via <code>betaEff</code> (<code>rscale</code>, <code>curvature</code>, <code>wall</code>).</li> </ul> <p>We continue to use the same benchmark potentials as in earlier lots:</p> \\[\\textbf{THIN:}\\quad V(\\phi)=\\tfrac14\\phi^4 - 0.49\\phi^3 + 0.235\\phi^2 \\] \\[ \\textbf{THICK:}\\quad V(\\phi)=\\tfrac14\\phi^4 - 0.40\\phi^3 + 0.10\\phi^2 \\] <p>with \\((\\phi_{\\rm abs}=1)\\) (true vacuum) and \\((\\phi_{\\rm meta}=0)\\) (false vacuum).</p> <p>Script: <code>tests/tunneling1D/single_field/Lot_SF6.py</code> Run all examples:</p> <pre><code>python -m tests.tunneling1D.single_field.Lot_SF6\n</code></pre>"},{"location":"modules/tunneling1D/tests_single_field/#test-a-action-density-breakdown","title":"Test A \u2014 Action &amp; density breakdown","text":"<p>What this shows</p> <ul> <li> <p>For each potential, we compute the profile, then:</p> </li> <li> <p><code>findAction(profile)</code> \u2192 total Euclidean action (S).</p> </li> <li><code>actionBreakdown(profile)</code> \u2192 numerical values of (S_{\\rm kin}), (S_{\\rm pot}), interior bulk, and arrays of per-r densities:</li> </ul> \\[\\text{kin density}=\\tfrac12(\\phi')^2r^{\\alpha}\\Omega_\\alpha \\] \\[\\text{pot density}=\\big[V(\\phi)-V(\\phi_{\\rm meta})\\big]r^{\\alpha}\\Omega_\\alpha\\] <ul> <li>Plots of the densities vs (r) highlight where the action accumulates (typically in the wall).</li> </ul> <p>Expected outcome (physics)</p> <ul> <li>The thin-wall case shows a narrow, high density peak (sharper wall).</li> <li>The thick-wall case shows a broader distribution (wall spread out).</li> <li>Console check: \\((S_{\\rm total}\\approx S_{\\rm kin}+S_{\\rm pot}+S_{\\rm interior})\\) (within numerical accuracy).</li> </ul> <p>Example console excerpt</p> <pre><code>=== Test A: Actions and density breakdown ===\n[thin-wall]\n  S_total    = 1.093093e+03\n   S_kin     = 1.639021e+03\n   S_pot     = -5.459281e+02\n   S_interior= 0.000000e+00\n  (check) S_kin + S_pot + S_interior = 1.093093e+03\n[thick-wall]\n  S_total    = 6.630329e+00\n   S_kin     = 9.946114e+00\n   S_pot     = -3.315785e+00\n   S_interior= 0.000000e+00\n  (check) S_kin + S_pot + S_interior = 6.630329e+00\n</code></pre> <p>Figure \u201cAction densities vs (r): thin (left) and thick (right). The peak localizes around the wall.\u201d </p>"},{"location":"modules/tunneling1D/tests_single_field/#test-b-uniform-grid-resampling-evenlyspacedphi","title":"Test B \u2014 Uniform \u03c6-grid resampling (<code>evenlySpacedPhi</code>)","text":"<p>What this shows</p> <ul> <li> <p>We resample \\(((\\phi,\\phi'))\\) on an evenly spaced grid in \\((\\phi)\\) rather than (r):</p> </li> <li> <p>This gives a clean, potential-centric view of the wall: \\((d\\phi/dr)\\) vs \\((\\phi)\\).</p> </li> <li>Helpful to compare how quickly the field sweeps through field space.</li> </ul> <p>Expected outcome (physics)</p> <ul> <li>Thin-wall: a sharper feature in \\((d\\phi/dr)\\) near mid-\\((\\phi)\\) (rapid transition).</li> <li>Thick-wall: a smoother, broader shape in \\((d\\phi/dr)\\) across \\((\\phi)\\).</li> </ul> <p>Figure \u201cResampled \\((d\\phi/dr)\\) vs \\((\\phi)\\): thin and thick. Both curves start/end with zero slope at the vacua.\u201d </p> <p></p>"},{"location":"modules/tunneling1D/tests_single_field/#test-c-wall-diagnostics-location-thickness","title":"Test C \u2014 Wall diagnostics (location &amp; thickness)","text":"<p>What this shows</p> <ul> <li> <p><code>wallDiagnostics(profile, frac=(0.1,0.9))</code> reports:</p> </li> <li> <p><code>r_peak</code>: where \\((|\\phi'|)\\) is maximal (wall center),</p> </li> <li><code>r_lo</code>/<code>r_hi</code>: radii where \\((\\phi)\\) reaches 10% and 90% of the total excursion,</li> <li><code>thickness</code> = \\((|r_{\\rm hi}-r_{\\rm lo}|)\\)</li> <li><code>r_mid</code>: where \\((\\phi)\\) is halfway between the vacua.</li> </ul> <p>Expected outcome (physics)</p> <ul> <li>Thin-wall \u2192 smaller thickness; <code>r_peak</code> between <code>r_lo</code> and <code>r_hi</code>.</li> <li>Thick-wall \u2192 larger thickness; markers spaced farther apart.</li> </ul> <p>Example console excerpt</p> <pre><code>=== Test C: Wall diagnostics (location &amp; thickness) ===\n[thin-wall] r_peak=4.706284e+01, r_mid=4.707676e+01, r_lo=4.396172e+01, r_hi=5.019140e+01, thickness=6.229675e+00 (phi_lo=0.900, phi_hi=0.100)\n[thick-wall] r_peak=4.399554e+00, r_mid=3.787229e+00, r_lo=0.000000e+00, r_hi=7.990970e+00, thickness=7.990970e+00 (phi_lo=0.900, phi_hi=0.100)\n</code></pre> <p>Figure \u201c(\\phi(r)) with vertical markers at <code>r_lo</code>, <code>r_mid</code>, <code>r_hi</code>, and <code>r_peak</code>.\u201d </p> <p></p>"},{"location":"modules/tunneling1D/tests_single_field/#test-d-beta_rm-eff-proxies-rscale-vs-curvature-vs-wall","title":"Test D \u2014 \\((\\beta_{\\rm eff})\\) proxies: <code>rscale</code> vs <code>curvature</code> vs <code>wall</code>","text":"<p>What this shows</p> <p>We compare three quick inverse-length scales (proxies for a nucleation timescale):</p> <ol> <li><code>rscale</code>: \\((\\beta_{\\rm eff}=1/r_{\\rm scale})\\) (always defined, robust).</li> <li><code>curvature</code>: \\((\\beta_{\\rm eff}=\\sqrt{|V''(\\phi_{\\rm top})|})\\) (requires a well-defined barrier top).</li> <li><code>wall</code>: \\((\\beta_{\\rm eff}=1/\\text{thickness})\\) (from <code>wallDiagnostics</code>).</li> </ol> <p>Expected outcome (physics)</p> <ul> <li>Thin-wall: larger \\((\\beta_{\\rm eff}(\\text{wall}))\\) (thinner wall \u2192 shorter scale).</li> <li><code>rscale</code> and <code>curvature</code> are often comparable within \\((\\mathcal{O}(1))\\) factors.</li> <li>Thick-wall: all three proxies tend to be smaller.</li> </ul> <p>Example console excerpt</p> <pre><code>=== Test D: \u03b2_eff proxies (rscale, curvature, wall) ===\n[thin-wall] \u03b2_rscale=5.996249e-01, \u03b2_curv=4.990992e-01, \u03b2_wall=1.605220e-01\n[thick-wall] \u03b2_rscale=4.242641e-01, \u03b2_curv=4.000000e-01, \u03b2_wall=1.251412e-01\n---------- END: Lot SF-6 examples ----------\n</code></pre> <p>Figure \u201cGrouped bars of \\((\\beta_{\\rm eff})\\) for thin vs thick, comparing the three proxies.\u201d </p> <p>See the full, executable script for this lot here: <code>tests/single_field/Lot_SF6.py</code></p> <p>Tip: When comparing different models or temperatures, keep the same plotting and diagnostics so differences in actions, wall thickness, and \\((\\beta_{\\rm eff})\\) are immediately visible and quantitatively comparable.</p>"}]}